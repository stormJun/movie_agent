# === OpenAI 相关 ===
# 模型类型选择：openai 或 gemini（默认 openai）
MODEL_TYPE=openai
# OpenAI API 密钥
OPENAI_API_KEY = 'sk-xxx'
# OpenAI 兼容服务地址（可指向代理或本地兼容服务）
OPENAI_BASE_URL = 'http://localhost:13000/v1'

# 向量模型名称（用于嵌入检索）
OPENAI_EMBEDDINGS_MODEL = 'text-embedding-3-large'
# 生成模型名称（用于回答生成）
OPENAI_LLM_MODEL = 'gpt-4o'

# 采样温度：越高越随机，建议 0~1
TEMPERATURE = 0
# 生成回答的最大 Token 限制
MAX_TOKENS = 2000
# RAG 生成超时（秒）
RAG_ANSWER_TIMEOUT_S = 180
# synthesize 兜底配置
RAG_SYNTHESIZE_MAX_CHARS = 1500
RAG_SYNTHESIZE_MAX_EVIDENCE = 3
RAG_SYNTHESIZE_EVIDENCE_STRATEGY = 'score'

# === 服务并发 ===
# FastAPI 进程数（影响 API 并发能力）
FASTAPI_WORKERS = 2

# === 文本切分与基础 RAG ===
# 文本分块大小（字符数）
CHUNK_SIZE = 500
# 分块重叠长度（字符数），用于保持上下文连续性
CHUNK_OVERLAP = 100
# 文本分块器：simple（纯 Python，稳定）/ hanlp（更好，但依赖较重）
TEXT_CHUNKER_PROVIDER = 'simple'
# 单篇文档允许的最大字符数
MAX_TEXT_LENGTH = 500000
# 相似度阈值（0~1），用于过滤向量检索结果
SIMILARITY_THRESHOLD = 0.9

# === RAG 语义（领域/知识库配置；语义默认值统一在 backend/config/rag_semantics.py 定义）===
# 知识库名称（用于部分提示词语义）
KB_NAME = '华东理工大学'
# 默认回答格式（中文提示，示例：多个段落、表格等）
# - 读取入口：backend/config/rag_semantics.py
# - 注入方式：infrastructure.config.graphrag_settings 将语义覆盖注入到 graphrag_agent.config.settings
RESPONSE_TYPE = '多个段落'
# 知识图谱主题（领域描述）
GRAPH_THEME = '华东理工大学学生管理'
# 领域实体类型（逗号分隔）
GRAPH_ENTITY_TYPES = '学生类型,奖学金类型,处分类型,部门,学生职责,管理规定'
# 领域关系类型（逗号分隔）
GRAPH_RELATIONSHIP_TYPES = '申请,评选,违纪,资助,申诉,管理,权利义务,互斥'
# Agent 工具说明（可选）
LC_DESCRIPTION =
GL_DESCRIPTION =
NAIVE_DESCRIPTION =
# 前端示例问题（逗号分隔，可选）
FRONTEND_EXAMPLES =

# 是否输出更详细的调试日志
VERBOSE = True

# === 统一构建框架（文档模式 / 结构化模式）===
# document: 现有“文档 → chunk → LLM抽取 → __Entity__”流程
# structured: 结构化数据（电影）导入 + Canonical 层生成
GRAPH_BUILD_MODE = 'document'

# document 模式写入前缀（用于同库隔离；例如 edu；留空则不做前缀化写入）
DOCUMENT_KB_PREFIX = ''
# document 模式的数据目录（默认项目根目录 files/；同库共存建议指向“学生管理文档目录”）
# 例如：FILES_DIR = 'files/txt文件'
FILES_DIR =
# document 模式默认只处理文档类扩展名（避免把结构化 JSON/缓存当作知识库文档导入）
DOCUMENT_FILE_EXTENSIONS = '.txt,.pdf,.md,.doc,.docx'
# 是否递归扫描 FILES_DIR 子目录
DOCUMENT_RECURSIVE = True

# 结构化数据目录（电影预处理产物所在目录，支持 files/ 或 files/movie_data/）
STRUCTURED_DATA_DIR = 'files/movie_data'
# Canonical 实体 id 前缀（用于同库隔离；默认 movie）
STRUCTURED_KB_PREFIX = 'movie'

# 构建流程开关（用于降级/分段执行）
# 是否在构建前清理全部索引：
# - document 模式默认 True（避免索引冲突）
# - structured 模式默认 False（避免影响共库的其他知识库）
# 建议：留空以使用“按模式默认值”
BUILD_DROP_ALL_INDEXES =
BUILD_RUN_GRAPH = True
BUILD_RUN_INDEX_AND_COMMUNITY = True
BUILD_RUN_CHUNK_INDEX = True

# Phase 3 细分开关（用于“只补跑社区摘要”等场景）
# - BUILD_RUN_ENTITY_INDEX=false：不重算实体 embedding / 不动实体向量索引
# - BUILD_RUN_COMMUNITY_DETECTION=false：不重跑社区检测（要求库里已有 __Community__/IN_COMMUNITY）
BUILD_RUN_ENTITY_INDEX = True
BUILD_RUN_COMMUNITY_DETECTION = True
STRUCTURED_RESET_DOMAIN = False
STRUCTURED_RESET_CANONICAL = False
STRUCTURED_BATCH_SIZE = 500

# 向量索引名称（实体/Chunk 分开，避免 Neo4j index name 冲突）
# 说明：LocalSearch/HybridTool 默认使用 LOCAL_SEARCH_INDEX_NAME（建议电影用 movie_vector）
LOCAL_SEARCH_INDEX_NAME = 'movie_vector'
ENTITY_VECTOR_INDEX_NAME = 'movie_vector'
CHUNK_VECTOR_INDEX_NAME = 'movie_chunk_vector'

# === Phase 3（索引与社区）共库隔离 / 降级开关 ===
# 仅处理特定知识库前缀（用于共库隔离，比如 "movie:"）
GRAPH_ENTITY_ID_PREFIX_FILTER = 'movie:'
GRAPH_CHUNK_ID_PREFIX_FILTER = 'movie:'

# 社区节点命名空间前缀（避免 __Community__.id 冲突；默认可与实体前缀一致）
GRAPH_COMMUNITY_ID_PREFIX = 'movie:'

# 结构化模式（电影）默认建议跳过以下步骤（避免“跨知识库合并/污染”与额外成本）
GRAPH_SKIP_SIMILAR_ENTITY = True
GRAPH_SKIP_ENTITY_MERGE = True
GRAPH_SKIP_ENTITY_QUALITY = True
GRAPH_SKIP_COMMUNITY = False
GRAPH_SKIP_COMMUNITY_SUMMARY = True

# === 可选：KB label（用于同库多 KB 的实体/Chunk 向量索引隔离）===
# 通常无需手工设置：默认会由 GRAPH_*_PREFIX_FILTER 自动推导为：
# - GRAPH_ENTITY_KB_LABEL = KB_<kb>_entity
# - GRAPH_CHUNK_KB_LABEL = KB_<kb>_chunk
# GRAPH_ENTITY_KB_LABEL =
# GRAPH_CHUNK_KB_LABEL =

# === 社区摘要（Global Search 依赖）===
# 默认只为 Top 200（按 community_rank）生成摘要；设置为 0 表示全量（level=0）
COMMUNITY_SUMMARY_LIMIT = 200
# 默认只补齐缺失的社区摘要（断点续跑友好）
COMMUNITY_SUMMARY_ONLY_MISSING = True
# 摘要生成并发（按 LLM 端点限流调整）
COMMUNITY_SUMMARY_MAX_WORKERS = 4
# 分批收集社区信息的最大批次数；0 表示不限制
COMMUNITY_SUMMARY_MAX_BATCHES = 20
# 控制每个社区摘要输入规模（避免 prompt 过大）；0 表示不限制（不建议）
COMMUNITY_SUMMARY_MAX_NODES = 50
COMMUNITY_SUMMARY_MAX_RELS = 100

# === 批处理与线程池 ===
# 全局最大线程数
MAX_WORKERS = 4
# 多智能体执行模式：sequential（串行）或 parallel（并行）
MA_WORKER_EXECUTION_MODE = 'sequential'
# 并行模式下的最大并发任务数
MA_WORKER_MAX_CONCURRENCY = 4
# 通用批处理大小
BATCH_SIZE = 100
# 实体批量操作大小
ENTITY_BATCH_SIZE = 50
# 文本块批量操作大小
CHUNK_BATCH_SIZE = 100
# 向量嵌入批处理大小
EMBEDDING_BATCH_SIZE = 64
# LLM 批量请求大小
LLM_BATCH_SIZE = 5
# 社区（图算法）批量处理大小
COMMUNITY_BATCH_SIZE = 50

# === Neo4j Graph Data Science (GDS) 参数 ===
# GDS 使用的内存上限（GB）
GDS_MEMORY_LIMIT = 6
# GDS 并发度
GDS_CONCURRENCY = 4
# GDS 数据规模限制（节点数）
GDS_NODE_COUNT_LIMIT = 50000
# GDS 算法超时时间（秒）
GDS_TIMEOUT_SECONDS = 300

# === 实体消歧/对齐 ===
# 文本编辑距离阈值（0~1，越小越严格）
DISAMBIG_STRING_THRESHOLD = 0.7
# 向量相似度阈值
DISAMBIG_VECTOR_THRESHOLD = 0.85
# 判定为未知（NIL）的阈值
DISAMBIG_NIL_THRESHOLD = 0.6
# 候选实体数量
DISAMBIG_TOP_K = 5
# 对齐冲突阈值
ALIGNMENT_CONFLICT_THRESHOLD = 0.5
# 对齐最小分组大小
ALIGNMENT_MIN_GROUP_SIZE = 2

# === Neo4j 连接信息 ===
# Neo4j 地址
NEO4J_URI='neo4j://localhost:7687'
# Neo4j 用户名
NEO4J_USERNAME='neo4j'
# Neo4j 密码
NEO4J_PASSWORD='12345678'
# 最大连接池大小
NEO4J_MAX_POOL_SIZE = 10
# 是否在启动时刷新 Schema
NEO4J_REFRESH_SCHEMA = false

# === PostgreSQL（Chat 会话记录持久化）===
# 说明：
# - 若未配置 Postgres，服务会回退到 InMemoryConversationStore（仅用于本地/测试，重启即丢）。
# - 推荐生产环境使用 Postgres 作为聊天记录的 system-of-record。
#
# 1) 优先使用 DSN（最简单）
# POSTGRES_DSN='postgresql://postgres:postgres@localhost:5432/graphrag_chat'
#
# 2) 或使用分段配置（当 POSTGRES_HOST 非空时启用）
POSTGRES_HOST=''
POSTGRES_PORT=5432
POSTGRES_USER='postgres'
POSTGRES_PASSWORD='postgres'
POSTGRES_DB='graphrag_chat'

# === 运行时目录（生成产物 / 第三方依赖缓存） ===
# 说明：
# - 本仓库不再提供“Agent 内部检索缓存/结果缓存”机制；检索默认实时执行。
# - 运行过程中产生的构建产物、索引等建议统一落在 `files/`（避免污染源码目录）。
RUNTIME_ROOT = './files'
# tiktoken 等第三方依赖的缓存目录（可选；默认会使用 RUNTIME_ROOT/tiktoken）
# TIKTOKEN_CACHE_DIR = './files/tiktoken'

# === 相似实体检测 ===
# 允许的最大编辑距离
SIMILAR_ENTITY_WORD_EDIT_DISTANCE = 3
# 检测批处理大小
SIMILAR_ENTITY_BATCH_SIZE = 500
# 运行所需的内存上限（GB）
SIMILAR_ENTITY_MEMORY_LIMIT = 6
# 返回的候选实体数量
SIMILAR_ENTITY_TOP_K = 10

# === 检索工具参数 ===
# 向量检索返回数量
SEARCH_VECTOR_LIMIT = 5
# 文本检索返回数量
SEARCH_TEXT_LIMIT = 5
# 语义检索 Top K
SEARCH_SEMANTIC_TOP_K = 5
# 关键词检索 Top K
SEARCH_RELEVANCE_TOP_K = 5
# 朴素检索返回条数
NAIVE_SEARCH_TOP_K = 3
# 本地检索返回的文本块数量
LOCAL_SEARCH_TOP_CHUNKS = 3
# 本地检索返回的社区数量
LOCAL_SEARCH_TOP_COMMUNITIES = 3
# 图外关系检索数量
LOCAL_SEARCH_TOP_OUTSIDE_RELS = 10
# 图内关系检索数量
LOCAL_SEARCH_TOP_INSIDE_RELS = 10
# 返回的相关实体数量
LOCAL_SEARCH_TOP_ENTITIES = 10
# Neo4j 向量索引名称
LOCAL_SEARCH_INDEX_NAME = 'movie_vector'
# 全局搜索默认层级
GLOBAL_SEARCH_LEVEL = 0
# 全局搜索批大小
GLOBAL_SEARCH_BATCH_SIZE = 5
# 混合检索实体数量上限
HYBRID_SEARCH_ENTITY_LIMIT = 15
# 混合检索图探索最大跳数
HYBRID_SEARCH_MAX_HOP = 2
# 混合检索社区数量
HYBRID_SEARCH_TOP_COMMUNITIES = 3
# 混合检索批大小
HYBRID_SEARCH_BATCH_SIZE = 10
# 混合检索的社区层级
HYBRID_SEARCH_COMMUNITY_LEVEL = 0

# === 服务端运行 ===
# 监听地址
SERVER_HOST = '0.0.0.0'
# 监听端口
SERVER_PORT = 8000
# 是否热重载
SERVER_RELOAD = false
# 日志级别
SERVER_LOG_LEVEL = 'info'
# 工作进程数（优先于 FASTAPI_WORKERS）
SERVER_WORKERS = 2
# SSE keepalive 心跳间隔（秒）；长检索阶段避免代理/网关断连
SSE_HEARTBEAT_S = 15

# === KB 自动路由（movie/edu）===
# 是否启用意图识别路由（启发式优先，LLM 兜底）
KB_AUTO_ROUTE = true
# 当请求显式携带 kb_prefix 但意图识别认为是另一知识库时，是否允许覆盖
KB_AUTO_ROUTE_OVERRIDE = true
# 覆盖 kb_prefix 需要达到的最低置信度
KB_AUTO_ROUTE_MIN_CONFIDENCE = 0.75

# === Phase 2（handlers + infrastructure/rag）===
# 是否启用知识库编排层（backend/application/handlers）+ 通用执行层（backend/infrastructure/rag）
PHASE2_ENABLE_KB_HANDLERS = true
# 旧开关保留兼容，未设置 PHASE2_ENABLE_KB_HANDLERS 时会回落到此值
PHASE2_ENABLE_BUSINESS_AGENTS = true

# === 前端默认配置 ===
# API 网关地址
FRONTEND_API_URL = 'http://localhost:8000'
# 默认使用的 Agent 名称
FRONTEND_DEFAULT_AGENT = 'naive_rag_agent'
# 是否默认开启调试面板
FRONTEND_DEFAULT_DEBUG = false
# 是否展示思维链
FRONTEND_SHOW_THINKING = true
# 是否允许深度研究工具
FRONTEND_USE_DEEPER_TOOL = true
# 是否启用流式输出
FRONTEND_USE_STREAM = true
# 是否允许链式探索工具
FRONTEND_USE_CHAIN_EXPLORATION = true

# === 图谱可视化（前端）===
# 是否启用物理模拟
KG_PHYSICS_ENABLED = true
# 节点默认大小
KG_NODE_SIZE = 25
# 边线宽
KG_EDGE_WIDTH = 2
# 弹簧长度（节点间距）
KG_SPRING_LENGTH = 150
# 引力系数（负数表示斥力）
KG_GRAVITY = -5000

# === Agent 调度相关 ===
# 最大递归深度（LangGraph）
AGENT_RECURSION_LIMIT = 5
# 单批次传入 LangGraph 的消息碎片数
AGENT_CHUNK_SIZE = 4
# 普通 Agent 的流式 flush 阈值（字符数）
AGENT_STREAM_FLUSH_THRESHOLD = 40
# DeepResearch Agent 的流式 flush 阈值
DEEP_AGENT_STREAM_FLUSH_THRESHOLD = 80
# Fusion Agent 的流式 flush 阈值
FUSION_AGENT_STREAM_FLUSH_THRESHOLD = 60

# === 多智能体编排 ===
# 单次 Planner 允许生成的最大任务数
MA_PLANNER_MAX_TASKS = 6
# 是否允许在澄清未完成时继续执行
MA_ALLOW_UNCLARIFIED_PLAN = true
# 默认任务领域标签
MA_DEFAULT_DOMAIN = '通用'
# 执行结束后是否自动生成报告
MA_AUTO_GENERATE_REPORT = true
# 如果需要用户澄清是否立即停止执行
MA_STOP_ON_CLARIFICATION = true
# Planner 未返回执行信号时是否视为失败
MA_STRICT_PLAN_SIGNAL = true
# 默认报告类型（short_answer / long_document）
MA_DEFAULT_REPORT_TYPE = 'long_document'
# 是否启用一致性检查
MA_ENABLE_CONSISTENCY_CHECK = true
# 是否开启 Map-Reduce 写作模式
MA_ENABLE_MAPREDUCE = true
# 触发 Map-Reduce 的证据条数阈值
MA_MAPREDUCE_THRESHOLD = 20
# Reduce 阶段每次允许的最大 Token 预算
MA_MAX_TOKENS_PER_REDUCE = 4000
# Map 阶段是否并行调用
MA_ENABLE_PARALLEL_MAP = true
# 单个章节写作允许的证据数量
MA_SECTION_MAX_EVIDENCE = 8
# 多批写作时保留的前文上下文长度
MA_SECTION_MAX_CONTEXT_CHARS = 800
# 反思阶段是否允许自动重试
MA_REFLECTION_ALLOW_RETRY = false
# 单个目标任务允许的反思重试次数
MA_REFLECTION_MAX_RETRIES = 1

# === Langsmith 监控（可选）===
# 是否启用 Langsmith Tracing
LANGSMITH_TRACING=true
# Langsmith 服务地址
LANGSMITH_ENDPOINT="https://api.smith.langchain.com"
# Langsmith API Key
LANGSMITH_API_KEY="xxx"
# Langsmith 项目名称
LANGSMITH_PROJECT="xxx"

# === Langfuse 可观测性（可选）===
# 是否启用 Langfuse 追踪
LANGFUSE_ENABLED=false
# Langfuse Public Key（在 Langfuse Web UI 的 Settings > API Keys 中获取）
LANGFUSE_PUBLIC_KEY="pk-xxx"
# Langfuse Secret Key
LANGFUSE_SECRET_KEY="sk-xxx"
# Langfuse 服务地址（本地部署使用 http://localhost:3000）
LANGFUSE_HOST="http://localhost:3000"

# === Chat history persistence (PostgreSQL) ===
# Note: docker-compose in this repo binds Postgres to host port 5433 to avoid
# conflicts with other local stacks (e.g. dify). Adjust if needed.
POSTGRES_HOST=127.0.0.1
POSTGRES_PORT=5433
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=graphrag_chat

# === Gemini 配置（可选，支持 API Key 和 OAuth 两种认证方式）===
# 认证类型：api_key 或 oauth
GEMINI_AUTH_TYPE=api_key
# API Key 模式
GEMINI_API_KEY=your_gemini_api_key_here
# OAuth 模式（Google 账号认证，需要配置 Application Default Credentials）
GEMINI_PROJECT_ID=your_project_id
GEMINI_LOCATION=us-central1
# 模型名称
GEMINI_LLM_MODEL=gemini-2.0-flash-exp
GEMINI_EMBEDDINGS_MODEL=text-embedding-004
# 生成参数
GEMINI_TEMPERATURE=0
GEMINI_MAX_TOKENS=2000

# === 长期记忆（mem0，可选）===
# 是否启用长期记忆召回（recall）
MEMORY_ENABLE=false
# 是否允许写入长期记忆（默认关闭，避免污染）
MEMORY_WRITE_ENABLE=false
# 召回条数
MEMORY_TOP_K=5
# 召回最小相关性分数（provider 可能不返回 score，则会当作 0）
MEMORY_MIN_SCORE=0.6
# 注入 prompt 的最大字符数
MEMORY_MAX_CHARS=1200
# 写入策略（当前仅支持 rules：只写入"我喜欢/我不喜欢/我叫/请不要…"等稳定信息）
MEMORY_WRITE_MODE=rules

# === 对话历史摘要（Phase 1，可选）===
# 启用后：会在对话较长时，把“较早历史”压缩成摘要注入 prompt，同时保留最近窗口的原始消息。
# 注意：摘要生成会调用一次 LLM（异步 best-effort），可能增加少量成本。
CHAT_SUMMARY_ENABLE=true
# 只有 completed 消息达到该数量才会尝试生成/更新摘要
CHAT_SUMMARY_MIN_MESSAGES=10
# 已存在摘要时，只有“新增可摘要消息”达到该数量才会更新（避免频繁摘要）
CHAT_SUMMARY_UPDATE_DELTA=5
# 保留最近 N 条原始消息（其余进入摘要层）
CHAT_SUMMARY_WINDOW_SIZE=6
# 摘要最大字符数（超出截断）
CHAT_SUMMARY_MAX_CHARS=1200

# === 主动式情节记忆（Phase 2，可选）===
# 在“当前会话内”做语义相关的历史召回（补齐 Phase 1 仅按时间窗口的盲区）。
# 启用后会带来额外 embeddings 成本（召回/索引都需要）。
EPISODIC_MEMORY_ENABLE=true
# 每次召回返回的片段数量
EPISODIC_MEMORY_TOP_K=3
# 每次召回最多扫描最近多少条 episodes（越大越慢）
EPISODIC_MEMORY_SCAN_LIMIT=200
# 相似度阈值（0~1），低于该阈值的候选会被丢弃
EPISODIC_MEMORY_MIN_SCORE=0.25
# auto/always/never：always 每轮都召回（更激进，成本更高）
EPISODIC_MEMORY_RECALL_MODE=always
# 注入 prompt 的最大字符数
EPISODIC_MEMORY_MAX_CONTEXT_CHARS=1200

# Phase 2: Milvus 向量库（推荐）
EPISODIC_VECTOR_BACKEND=milvus
# 复用你已经在 Docker 里跑着的 milvus-standalone（通常暴露 19530 到宿主机）：
# - backend 在宿主机运行：localhost
# - backend 在 Docker 容器内运行：host.docker.internal（macOS/Windows）
EPISODIC_MILVUS_HOST="localhost"
EPISODIC_MILVUS_PORT=19530
EPISODIC_MILVUS_COLLECTION="conversation_episodes"
# 可选：提前固定向量维度（0 表示首次 embed 后自动探测）
EPISODIC_MILVUS_EMBEDDING_DIM=0

# Memory provider 选择（mem0, postgres, null）
MEMORY_PROVIDER=mem0

# mem0 服务端（自托管/本地）
MEM0_BASE_URL=""
MEM0_API_KEY=""
MEM0_TIMEOUT_S=10
# 如你的 mem0 部署路径不同，可覆盖 API path
MEM0_SEARCH_PATH="/v1/memories/search"
MEM0_ADD_PATH="/v1/memories"

# mem0 自托管服务端（本仓库提供 mem0-compatible service，可选）
# 启动：docker compose -f docker-compose.yaml -f docker-compose.mem0.yaml up -d --build
# MEM0_BASE_URL="http://localhost:8830"
# mem0 service 连接 PostgreSQL + Milvus（服务端侧）
# 注意：若 mem0 service 运行在 Docker 容器内，推荐让 compose 使用默认值（连接 postgres:5432）。
# 仅在你需要自定义连接时才显式设置这些变量。
# mem0 service 认证与 user_id 解析（服务端侧；默认 internal/trusted 模式即可）
# MEM0_AUTH_MODE="api_key"  # api_key / jwt
# MEM0_JWT_SECRET=""        # 仅在 MEM0_AUTH_MODE=jwt 时需要（或复用 MEM0_API_KEY）
# MEM0_JWT_ALGORITHMS="HS256"
# MEM0_TRUST_REQUEST_USER_ID=true   # trusted internal caller: accept user_id in request body
# MEM0_USER_ID_HEADER="x-user-id"   # production: accept upstream injected user_id header
# MEM0_ENABLE_TTL=false
# MEM0_DEFAULT_TTL_DAYS=90
# MEM0_EMBEDDING_DIM=""  # 固定维度（可选；空值表示动态检测）
# Embeddings（mem0 service 侧；推荐用 MEM0_OPENAI_* 避免与本机其他服务的 OPENAI_* 冲突）
# MEM0_OPENAI_API_KEY=""
# MEM0_OPENAI_BASE_URL=""
# MEM0_OPENAI_EMBEDDINGS_MODEL=""
# MEM0_PG_DSN="postgresql://postgres:postgres@postgres:5432/graphrag_chat"   # 容器内访问
# MEM0_PG_DSN="postgresql://postgres:postgres@localhost:5433/graphrag_chat" # 本机进程访问（复用 compose 暴露端口）
# MEM0_VECTOR_BACKEND="milvus"  # milvus / none
# MEM0_MILVUS_HOST="host.docker.internal"  # 容器内访问本机 Milvus
# MEM0_MILVUS_PORT=19530
# MEM0_MILVUS_COLLECTION="mem0_memories"
# MEM0_STRICT_EMBEDDINGS=false

# === Query-Time Enrichment（TMDB 实时知识增强）===
# 功能总开关（默认开启）
ENRICHMENT_ENABLE=true
# TMDB API 配置（从 https://www.themoviedb.org/settings/api 获取）
TMDB_BASE_URL=https://api.themoviedb.org/3
# TMDB API Token (Bearer Token，推荐使用)
TMDB_API_TOKEN=your_tmdb_api_token_here
# TMDB API Key (备用)
TMDB_API_KEY=your_tmdb_api_key_here
# API 超时时间（秒）
TMDB_TIMEOUT_S=5.0
# 缓存 TTL（秒），Phase 2 实现
ENRICHMENT_CACHE_TTL_S=3600
# 重试次数
ENRICHMENT_MAX_RETRIES=2
# 异步持久化开关，Phase 3 实现
ENRICHMENT_ASYNC_WRITE_ENABLE=true
ENRICHMENT_WRITE_QUEUE_SIZE=100
