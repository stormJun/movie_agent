#!/usr/bin/env python3
"""
ç”µå½±æ•°æ®é¢„å¤„ç†è„šæœ¬ï¼ˆæ¨¡å—åŒ–ç‰ˆæœ¬ï¼‰

å…¥å£æ–‡ä»¶ä»…è´Ÿè´£ CLI ä¸æµç¨‹ç¼–æ’ï¼›æ ¸å¿ƒé€»è¾‘æ‹†åˆ†åˆ°åŒç›®å½•çš„æ¨¡å—ä¸­ï¼š
- movielens_parser.py
- tmdb_client.py
- tmdb_cache.py
- enricher.py
- io_utils.py
"""

import argparse
import os
from collections import defaultdict
from pathlib import Path

import pandas as pd
from dotenv import load_dotenv
from tqdm import tqdm

from enricher import MovieDataEnricher
from io_utils import save_json
from movielens_parser import MovieLensParser
from tmdb_client import TMDBClient


def main():
    parser = argparse.ArgumentParser(
        description="ç”µå½±æ•°æ®é¢„å¤„ç†ï¼ˆMovieLens + TMDBï¼Œå¯ç¦»çº¿é™çº§ï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # å®Œæ•´è¿è¡Œï¼ˆæ¨èï¼‰
  python %(prog)s --source-dir SparrowRecSys-master/target/classes/webroot/sampledata

  # è‡ªå®šä¹‰è¾“å‡ºç›®å½•
  python %(prog)s --source-dir /path/to/data --output-dir files/movie_data

  # è°ƒæ•´é€Ÿç‡é™åˆ¶ï¼ˆé¿å… TMDB é™æµï¼‰
  python %(prog)s --source-dir /path/to/data --rate-limit 3.5
        """
    )

    parser.add_argument('--source-dir', type=str, required=True,
                       help='MovieLens æ•°æ®ç›®å½•ï¼ˆåŒ…å« movies.csv, links.csv, ratings.csvï¼‰')
    parser.add_argument('--output-dir', type=str, default='files/movie_data',
                       help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: files/movie_dataï¼‰')
    parser.add_argument('--cache-dir', type=str, default='files/tmdb_cache',
                       help='TMDB ç¼“å­˜ç›®å½•ï¼ˆé»˜è®¤: files/tmdb_cacheï¼‰')
    parser.add_argument('--rate-limit', type=float, default=4.0,
                       help='TMDB API é€Ÿç‡é™åˆ¶ï¼Œå•ä½: è¯·æ±‚/ç§’ï¼ˆé»˜è®¤: 4.0ï¼‰')
    parser.add_argument('--skip-optional', action='store_true',
                       help='è·³è¿‡å¯é€‰ API è°ƒç”¨ï¼ˆrecommendations, similarï¼‰ä»¥èŠ‚çœæ—¶é—´')
    parser.add_argument('--limit', type=int, default=0,
                       help='ä»…å¤„ç†å‰ N éƒ¨ç”µå½±ï¼ˆ0 è¡¨ç¤ºå…¨éƒ¨ï¼›ç”¨äºå¿«é€ŸçƒŸå›±æµ‹è¯•ï¼‰')

    args = parser.parse_args()

    load_dotenv()

    source_dir = Path(args.source_dir)
    output_dir = Path(args.output_dir)
    cache_dir = Path(args.cache_dir)

    # éªŒè¯æºç›®å½•
    if not source_dir.exists():
        print(f"âŒ é”™è¯¯: æºæ•°æ®ç›®å½•ä¸å­˜åœ¨: {source_dir}")
        return 1

    required_files = ['movies.csv', 'links.csv', 'ratings.csv']
    for file in required_files:
        if not (source_dir / file).exists():
            print(f"âŒ é”™è¯¯: ç¼ºå°‘å¿…éœ€æ–‡ä»¶: {source_dir / file}")
            return 1

    output_dir.mkdir(parents=True, exist_ok=True)
    cache_dir.mkdir(parents=True, exist_ok=True)

    print("=" * 80)
    print("ğŸ¬ ç”µå½±æ•°æ®é¢„å¤„ç†æµç¨‹ï¼ˆå®Œæ•´ä¿®å¤ç‰ˆ v2.0ï¼‰")
    print("=" * 80)
    print(f"æºç›®å½•: {source_dir}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ç¼“å­˜ç›®å½•: {cache_dir}")
    print(f"é€Ÿç‡é™åˆ¶: {args.rate_limit} è¯·æ±‚/ç§’")

    # Step 1: è§£æ MovieLens æ•°æ®
    print("\n" + "=" * 80)
    print("[1/4] è§£æ MovieLens æ•°æ®")
    print("=" * 80)

    parser_ml = MovieLensParser(source_dir)

    movies_df = parser_ml.parse_movies()
    links_df = parser_ml.parse_links()
    ratings_stats = parser_ml.parse_ratings()

    print(f"\nâœ… ç”µå½±æ•°é‡: {len(movies_df)}")
    print(f"   - æœ‰ TMDB ID: {links_df['tmdbId'].notna().sum()}")
    print(f"   - æ—  TMDB ID: {links_df['tmdbId'].isna().sum()}")
    print(f"âœ… è¯„åˆ†ç»Ÿè®¡: {len(ratings_stats)} éƒ¨ç”µå½±")

    # åˆå¹¶ movies å’Œ links
    merged_df = movies_df.merge(links_df, on='movieId', how='left')
    if args.limit and args.limit > 0:
        merged_df = merged_df.head(args.limit).reset_index(drop=True)
        print(f"\nâš ï¸  limit ç”Ÿæ•ˆï¼šä»…å¤„ç†å‰ {len(merged_df)} éƒ¨ç”µå½±ï¼ˆç”¨äºå¿«é€ŸéªŒè¯æµç¨‹ï¼‰")

    # Step 2: åˆå§‹åŒ– TMDB å®¢æˆ·ç«¯
    print("\n" + "=" * 80)
    print("[2/4] åˆå§‹åŒ– TMDB API å®¢æˆ·ç«¯")
    print("=" * 80)

    tmdb_api_token = os.getenv("TMDB_API_TOKEN", "")
    tmdb_api_key = os.getenv("TMDB_API_KEY", "")

    if not tmdb_api_token and not tmdb_api_key:
        print("\nâš ï¸  è­¦å‘Š: æœªè®¾ç½® TMDB_API_TOKEN æˆ– TMDB_API_KEY")
        print("   å°†ä»…ä½¿ç”¨ MovieLens æ•°æ®ï¼Œè·³è¿‡ TMDB æ•°æ®è·å–")
        print("   è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® TMDB_API_TOKEN ä»¥è·å–å®Œæ•´æ•°æ®\n")
        tmdb_client = None
    else:
        # è¯»å–ä»£ç†é…ç½®
        proxies = {}
        http_proxy = os.getenv("HTTP_PROXY")
        https_proxy = os.getenv("HTTPS_PROXY")

        if http_proxy:
            proxies['http'] = http_proxy
        if https_proxy:
            proxies['https'] = https_proxy

        if proxies:
            print(f"\nâœ… ä½¿ç”¨ä»£ç†: {proxies.get('https', proxies.get('http'))}")

        tmdb_client = TMDBClient(
            api_token=tmdb_api_token,
            api_key=tmdb_api_key,
            rate_limit=args.rate_limit,
            proxies=proxies if proxies else None
        )

        print(f"âœ… TMDB å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        print(f"   - é€Ÿç‡é™åˆ¶: {args.rate_limit} è¯·æ±‚/ç§’")
        print(f"   - ç¼“å­˜ç›®å½•: {cache_dir}\n")

    # Step 3: å¢å¼ºç”µå½±æ•°æ®
    print("=" * 80)
    print("[3/4] å¢å¼ºç”µå½±æ•°æ®ï¼ˆè°ƒç”¨ TMDB APIï¼‰")
    print("=" * 80)

    enricher = MovieDataEnricher(tmdb_client, cache_dir, skip_optional=args.skip_optional)
    enriched_movies = []

    for idx, row in tqdm(merged_df.iterrows(), total=len(merged_df), desc="å¤„ç†ç”µå½±"):
        movie_id = int(row['movieId'])
        rating_stat = ratings_stats.get(movie_id)
        enriched = enricher.enrich_movie(row, row, rating_stat)

        enriched_movies.append(enriched)

    print(f"\nâœ… å¤„ç†å®Œæˆ: {len(enriched_movies)} éƒ¨ç”µå½±")

    # Step 4: ä¿å­˜ç»“æœ
    print("\n" + "=" * 80)
    print("[4/4] ä¿å­˜ç»“æœ")
    print("=" * 80)

    # 4.1 ä¿å­˜ç”µå½±æ•°æ®
    movies_output = output_dir / "movies_enriched.json"
    save_json(enriched_movies, movies_output)
    print(f"\nâœ… ç”µå½±æ•°æ®: {movies_output}")
    print(f"   - æ–‡ä»¶å¤§å°: {movies_output.stat().st_size / 1024 / 1024:.2f} MB")

    if tmdb_client:
        # 4.2 ä¿å­˜äººç‰©æ•°æ®
        persons_output = output_dir / "persons.json"
        save_json(list(enricher.all_persons.values()), persons_output)
        print(f"\nâœ… äººç‰©æ•°æ®: {persons_output}")
        print(f"   - äººæ•°: {len(enricher.all_persons)}")

        # ç»Ÿè®¡äººå‘˜ç±»å‹
        person_types = defaultdict(int, enricher.summarize_person_types())
        print(f"   - æ¼”å‘˜: {person_types.get('actor', 0)}")
        print(f"   - å¯¼æ¼”: {person_types.get('director', 0)}")
        print(f"   - æ—¢æ˜¯æ¼”å‘˜åˆæ˜¯å¯¼æ¼”: {person_types.get('both', 0)}")

        # 4.3 ä¿å­˜å…³é”®è¯
        keywords_output = output_dir / "keywords.json"
        save_json(list(enricher.all_keywords.values()), keywords_output)
        print(f"\nâœ… å…³é”®è¯æ•°æ®: {keywords_output}")
        print(f"   - å…³é”®è¯æ•°: {len(enricher.all_keywords)}")

        # 4.4 ä¿å­˜åˆ¶ä½œå…¬å¸
        companies_output = output_dir / "companies.json"
        save_json(list(enricher.all_companies.values()), companies_output)
        print(f"\nâœ… åˆ¶ä½œå…¬å¸: {companies_output}")
        print(f"   - å…¬å¸æ•°: {len(enricher.all_companies)}")

        # 4.5 ä¿å­˜å›½å®¶
        countries_output = output_dir / "countries.json"
        save_json(list(enricher.all_countries.values()), countries_output)
        print(f"\nâœ… å›½å®¶æ•°æ®: {countries_output}")
        print(f"   - å›½å®¶æ•°: {len(enricher.all_countries)}")

        # 4.6 ä¿å­˜è¯­è¨€
        languages_output = output_dir / "languages.json"
        save_json(list(enricher.all_languages.values()), languages_output)
        print(f"\nâœ… è¯­è¨€æ•°æ®: {languages_output}")
        print(f"   - è¯­è¨€æ•°: {len(enricher.all_languages)}")

    # æœ€ç»ˆç»Ÿè®¡
    print("\n" + "=" * 80)
    print("âœ… é¢„å¤„ç†å®Œæˆ!")
    print("=" * 80)

    # âœ… ä¿®å¤ç»Ÿè®¡é€»è¾‘
    tmdb_count = sum(1 for m in enriched_movies if m.get('data_source') == 'movielens+tmdb')
    movielens_only_count = len(enriched_movies) - tmdb_count

    print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
    print(f"   - æ€»ç”µå½±æ•°: {len(enriched_movies)}")
    print(f"   - åŒ…å« TMDB æ•°æ®: {tmdb_count} ({tmdb_count/len(enriched_movies)*100:.1f}%)")
    print(f"   - ä»… MovieLens æ•°æ®: {movielens_only_count} ({movielens_only_count/len(enriched_movies)*100:.1f}%)")

    if tmdb_client:
        print(f"\nğŸ“Š å®ä½“ç»Ÿè®¡:")
        print(f"   - äººç‰©: {len(enricher.all_persons)}")
        print(f"   - å…³é”®è¯: {len(enricher.all_keywords)}")
        print(f"   - åˆ¶ä½œå…¬å¸: {len(enricher.all_companies)}")
        print(f"   - å›½å®¶: {len(enricher.all_countries)}")
        print(f"   - è¯­è¨€: {len(enricher.all_languages)}")

    print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶ä½ç½®: {output_dir}/")
    print(f"ğŸ“ TMDB ç¼“å­˜ä½ç½®: {cache_dir}/")

    return 0


if __name__ == "__main__":
    exit(main())
