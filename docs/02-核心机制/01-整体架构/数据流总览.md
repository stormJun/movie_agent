# 数据流总览

---

## 📋 元信息

- **目标读者**：所有读者（开发者、架构师、产品经理）
- **阅读时间**：15分钟
- **难度**：⭐⭐
- **前置知识**：基础数据处理概念
- **最后更新**：2026-01-04

---

## 📖 本文大纲

- [完整数据流程图](#完整数据流程图)
- [阶段一：文档摄取](#阶段一文档摄取)
- [阶段二：知识图谱构建](#阶段二知识图谱构建)
- [阶段三：索引构建](#阶段三索引构建)
- [阶段四：用户问答](#阶段四用户问答)
- [数据存储详解](#数据存储详解)
- [性能优化要点](#性能优化要点)
- [相关文档](#相关文档)

---

## 完整数据流程图

本系统的数据流分为两大主线：**构建时数据流**（离线）和**查询时数据流**（在线）。

### 总览流程

```mermaid
graph TB
    subgraph 构建时[构建时数据流 - 离线处理]
        direction TB

        A[📁 原始文档<br/>files/] --> B[📄 文档摄取<br/>DocumentProcessor]
        B --> C[✂️ 文本分块<br/>TextChunker]
        C --> D[🧠 实体关系提取<br/>LLM驱动]

        D --> E[🔍 实体消歧<br/>Disambiguation]
        E --> F[🔗 实体对齐<br/>Alignment]
        F --> G[(Neo4j图数据库<br/>实体+关系)]

        G --> H[🏘️ 社区检测<br/>Leiden/SLLPA]
        H --> I[📊 社区摘要<br/>LLM生成]

        G --> J[🔢 实体向量索引<br/>Entity Index]
        C --> K[🔢 文本块向量索引<br/>Chunk Index]

        I --> G
    end

    subgraph 查询时[查询时数据流 - 在线查询]
        direction TB

        U[👤 用户问题] --> V[🤖 Agent选择<br/>NaiveRag/Graph/Hybrid...]

        V --> W{检索策略}

        W -->|向量检索| X1[Chunk Index查询]
        W -->|图谱检索| X2[Neo4j Cypher查询]
        W -->|社区检索| X3[社区摘要检索]

        X1 --> Y[知识融合]
        X2 --> Y
        X3 --> Y

        Y --> Z[🧠 LLM生成答案]
        Z --> AA[💬 返回用户<br/>+推理轨迹]
    end

    构建时 -.-> 查询时

    style A fill:#f9f,stroke:#333
    style G fill:#9f9,stroke:#333
    style J fill:#ff9,stroke:#333
    style K fill:#ff9,stroke:#333
    style Y fill:#9ff,stroke:#333
```

---

## 阶段一：文档摄取

### 流程详解

```mermaid
graph TB
    A[files/目录] --> B{FileReader<br/>扫描文件}

    B --> C1[.txt文件]
    B --> C2[.pdf文件]
    B --> C3[.docx文件]
    B --> C4[.md文件]
    B --> C5[.csv/.json/.yml]

    C1 --> D[文本提取]
    C2 --> E[PyPDF2解析]
    C3 --> F[python-docx解析]
    C4 --> D
    C5 --> G[结构化解析]

    D --> H[DocumentProcessor<br/>文档处理器]
    E --> H
    F --> H
    G --> H

    H --> I[元数据提取<br/>文件名/路径/大小]

    I --> J{TextChunker<br/>分块策略}

    J -->|HanLP| K1[语义分块<br/>中文优化]
    J -->|Simple| K2[固定窗口<br/>CHUNK_SIZE=500]

    K1 --> L[Chunks列表<br/>每个Chunk包含:]
    K2 --> L

    L --> M[chunk_id<br/>chunk_text<br/>source_file<br/>chunk_index]

    M --> N[(暂存到内存<br/>待后续处理)]

    style H fill:#9f9,stroke:#333
    style J fill:#ff9,stroke:#333
```

### 关键参数

| 参数 | 默认值 | 说明 | 配置位置 |
|------|--------|------|---------|
| `CHUNK_SIZE` | 500 | 分块大小（字符数） | `.env` |
| `OVERLAP` | 100 | 分块重叠长度 | `.env` |
| `MAX_TEXT_LENGTH` | 500000 | 单文件最大长度 | `.env` |
| `TEXT_CHUNKER_PROVIDER` | hanlp | 分块策略（hanlp/simple） | `.env` |

### 支持的文件格式

```mermaid
mindmap
  root((文件格式))
    文本类
      TXT 纯文本
      MD Markdown
    文档类
      PDF Adobe PDF
      DOCX Word 2007+
      DOC Word 97-2003
    数据类
      CSV 逗号分隔
      JSON 结构化数据
      YAML/YML 配置文件
```

### 数据输出示例

```python
# DocumentProcessor输出格式
[
    {
        "filepath": "files/学生手册.pdf",
        "filename": "学生手册.pdf",
        "extension": ".pdf",
        "content": "完整文本内容...",
        "content_length": 45230,
        "chunks": [
            ["第一章 学生管理总则", "第一条..."],
            ["第二条...", "第三条..."],
            ...
        ],
        "chunk_count": 89,
        "average_chunk_length": 508
    },
    ...
]
```

---

## 阶段二：知识图谱构建

### 完整流程

```mermaid
graph TB
    A[Chunks列表] --> B[实体关系提取<br/>LLM批量调用]

    B --> C{提取结果}
    C --> D1[实体列表<br/>name/type/description]
    C --> D2[关系列表<br/>source/target/type]

    D1 --> E[实体消歧<br/>Entity Disambiguation]

    E --> E1[String Recall<br/>字符串召回]
    E1 --> E2[候选实体池<br/>top_k=5]
    E2 --> E3[Vector Rerank<br/>向量重排序]
    E3 --> E4{相似度判断}

    E4 -->|高于阈值| F1[映射到Canonical<br/>规范实体]
    E4 -->|低于阈值| F2[NIL检测<br/>创建新实体]

    F1 --> G[实体对齐<br/>Entity Alignment]
    F2 --> G

    G --> G1[检测同名冲突<br/>描述矛盾?]
    G1 --> G2{冲突严重度}

    G2 -->|高| H1[拆分实体]
    G2 -->|中| H2[合并保留关系]
    G2 -->|低| H3[保持不变]

    H1 --> I[(Neo4j存储<br/>CREATE节点)]
    H2 --> I
    H3 --> I

    D2 --> J[关系验证<br/>实体存在性检查]
    J --> K[(Neo4j存储<br/>CREATE关系)]

    I --> L[图一致性验证]
    K --> L

    style E fill:#ff9,stroke:#333
    style G fill:#f9f,stroke:#333
    style I fill:#9f9,stroke:#333
```

### 实体关系提取详解

#### LLM提示词结构

```python
# 实体提取提示词
ENTITY_EXTRACTION_PROMPT = f"""
从以下文本中提取实体，要求：
1. 实体类型必须为：{entity_types}
2. 提取实体名称、类型、简短描述
3. 返回JSON格式

文本：{{text}}

输出示例：
{{
  "entities": [
    {{"name": "优秀学生", "type": "学生类型", "description": "德智体美全面发展的学生"}},
    ...
  ]
}}
"""

# 关系提取提示词
RELATIONSHIP_EXTRACTION_PROMPT = f"""
从以下文本中提取实体间的关系，要求：
1. 关系类型必须为：{relationship_types}
2. 明确source和target实体
3. 返回JSON格式

文本：{{text}}
已识别实体：{{entities}}

输出示例：
{{
  "relationships": [
    {{"source": "优秀学生", "target": "国家奖学金", "type": "申请"}},
    ...
  ]
}}
"""
```

### 实体消歧算法

```mermaid
graph LR
    A[Mention: '优秀生'] --> B[String Recall<br/>编辑距离/模糊匹配]

    B --> C[候选池]
    C --> C1[优秀学生<br/>score=0.9]
    C --> C2[优秀生源<br/>score=0.7]
    C --> C3[优秀员工<br/>score=0.5]

    C --> D[Vector Rerank<br/>Embedding相似度]

    D --> E{最高分>阈值?}
    E -->|是 0.92>0.85| F[映射到'优秀学生']
    E -->|否| G[创建新实体'优秀生']

    style D fill:#ff9,stroke:#333
```

**关键参数**：

| 参数 | 默认值 | 说明 |
|------|--------|------|
| `DISAMBIG_STRING_THRESHOLD` | 0.7 | 字符串召回阈值 |
| `DISAMBIG_VECTOR_THRESHOLD` | 0.85 | 向量重排阈值 |
| `DISAMBIG_NIL_THRESHOLD` | 0.6 | NIL检测阈值 |
| `DISAMBIG_TOP_K` | 5 | 候选实体数量 |

### 实体对齐机制

```mermaid
graph TB
    A[规范实体: '国家奖学金'] --> B[收集所有mentions<br/>和它们的描述]

    B --> C{描述一致性检查}

    C --> D1[描述A: 8000元/年<br/>学习成绩优异]
    C --> D2[描述B: 本科生最高奖学金<br/>德智体美全面发展]
    C --> D3[描述C: 评选名额有限<br/>需要公示]

    D1 --> E[冲突检测]
    D2 --> E
    D3 --> E

    E --> F{冲突类型}

    F -->|属性互补| G[合并描述<br/>保留所有信息]
    F -->|属性矛盾| H[人工标注<br/>或拆分实体]

    G --> I[更新Neo4j<br/>SET description]

    style E fill:#ff9,stroke:#333
    style G fill:#9f9,stroke:#333
```

### Neo4j存储模式

```cypher
// 实体节点示例
CREATE (e:学生类型 {
  id: "entity_001",
  name: "优秀学生",
  description: "在德智体美全面发展方面表现突出的学生",
  mentions: ["优秀学生", "优秀生", "优秀在校生"],
  source_chunks: ["chunk_001", "chunk_045"]
})

// 关系示例
CREATE (e1)-[:申请 {
  confidence: 0.95,
  source_chunk: "chunk_001"
}]->(e2)
```

---

## 阶段三：索引构建

### 双索引策略

```mermaid
graph TB
    subgraph 实体索引构建[实体向量索引构建]
        A1[Neo4j实体节点] --> B1[提取实体信息<br/>name+type+description]
        B1 --> C1[Embedding API<br/>OpenAI/本地模型]
        C1 --> D1[向量化<br/>维度1536/768]
        D1 --> E1[存储到Neo4j<br/>向量索引'vector']
    end

    subgraph 文本索引构建[文本块向量索引构建]
        A2[Chunk节点] --> B2[提取文本内容<br/>chunk_text]
        B2 --> C2[Embedding API<br/>批量调用]
        C2 --> D2[向量化<br/>维度1536/768]
        D2 --> E2[存储到Neo4j<br/>向量索引'chunk_vector']
    end

    E1 --> F{索引类型}
    E2 --> F

    F --> G1[vector<br/>实体语义检索]
    F --> G2[chunk_vector<br/>文本语义检索]

    style E1 fill:#9f9,stroke:#333
    style E2 fill:#ff9,stroke:#333
```

### 社区检测与摘要

```mermaid
graph TB
    A[(Neo4j图谱)] --> B[GDS图投影<br/>将图加载到内存]

    B --> C{社区检测算法}

    C -->|优先| D[Leiden算法<br/>模块度优化]
    C -->|备选| E[SLLPA算法<br/>标签传播]

    D --> F{检测到社区?}
    E --> F

    F -->|是| G[社区分层<br/>Level 0,1,2...]
    F -->|否| H[Fallback<br/>使用Leiden重试]

    G --> I[每个社区<br/>提取节点+关系]

    I --> J[LLM批量摘要<br/>BATCH_SIZE=5]

    J --> K[生成社区摘要<br/>300-500字]

    K --> L[(存储Community节点<br/>CREATE到Neo4j)]

    L --> M[创建层级关系<br/>PART_OF链接]

    style D fill:#9f9,stroke:#333
    style J fill:#ff9,stroke:#333
```

**社区检测参数**：

| 参数 | 默认值 | 说明 |
|------|--------|------|
| `GRAPH_COMMUNITY_ALGORITHM` | leiden | 算法选择（leiden/sllpa） |
| `GDS_MEMORY_LIMIT` | 6GB | GDS内存限制 |
| `GDS_CONCURRENCY` | 4 | 并发度 |
| `COMMUNITY_BATCH_SIZE` | 50 | 摘要生成批次 |

### 索引构建顺序（重要）

```mermaid
graph LR
    A[步骤1<br/>构建基础图谱] --> B[步骤2<br/>实体索引+社区检测]
    B --> C[步骤3<br/>文本块索引]

    A -.->|依赖| D[实体+关系存在]
    B -.->|依赖| E[实体向量索引存在]
    C -.->|依赖| F[实体索引完成]

    style B fill:#ff9,stroke:#333
    style C fill:#f99,stroke:#333
```

**⚠️ 关键约束**：
- **Chunk索引必须在Entity索引之后**
- 原因：Chunk索引构建时需要查询Entity索引来关联实体
- 违反顺序会导致索引不完整

---

## 阶段四：用户问答

### 完整查询流程

```mermaid
	sequenceDiagram
	    participant U as 用户
	    participant F as Frontend
	    participant S as Server/API
	    participant A as Agent
	    participant SE as Search
	    participant N as Neo4j
	    participant L as LLM

    U->>F: 输入问题
    F->>S: POST /api/v1/chat

    S->>A: ask(query, agent_type)

	    A->>A: 选择检索工具

            alt NaiveRag
                A->>SE: naive_search(query)
                SE->>N: 向量检索Chunk
                N-->>SE: Top-K Chunks
            else GraphAgent
                A->>SE: local_search(query)
                SE->>N: 识别实体
                N-->>SE: 实体列表
                SE->>N: 扩展邻域(1-2跳)
                N-->>SE: 邻域子图
            else HybridAgent
                A->>SE: hybrid_search(query)
                par 并行检索
                    SE->>N: 向量检索
                    SE->>N: 图谱检索
                    SE->>N: 社区检索
                end
                N-->>SE: 融合结果
            end

            SE-->>A: 检索上下文

            A->>L: 生成答案(context)
            L-->>A: 答案+推理

	            A-->>S: 流式返回

    S-->>F: SSE流
    F-->>U: 实时显示答案
```

### 检索策略对比

```mermaid
graph TB
    A[用户查询] --> B{问题分类}

    B -->|简单事实| C1[NaiveRag<br/>向量检索]
    B -->|关系推理| C2[GraphAgent<br/>图谱检索]
    B -->|综合问题| C3[HybridAgent<br/>混合检索]
    B -->|复杂研究| C4[DeepResearch<br/>多步推理]

    C1 --> D1[Chunk Vector Index]
    D1 --> E1[Top-3文本块]

    C2 --> D2[实体识别+图遍历]
    D2 --> E2[实体+关系+社区]

    C3 --> D3[三路并行]
    D3 --> E3[向量+图谱+社区]

    C4 --> D4[Chain of Exploration]
    D4 --> E4[5步推理链]

    E1 --> F[LLM生成]
    E2 --> F
    E3 --> F
    E4 --> F

    F --> G[最终答案]

    style C3 fill:#9f9,stroke:#333
    style C4 fill:#ff9,stroke:#333
```

### Local Search详细流程

```mermaid
graph TB
    A[用户问题:<br/>'优秀学生的申请条件'] --> B[实体识别<br/>向量相似度匹配]

    B --> C[种子实体:<br/>'优秀学生']

    C --> D[邻域扩展<br/>1-2跳关系]

    D --> E[相关实体]
    E --> E1[国家奖学金<br/>-申请-]
    E --> E2[德育考核<br/>-评选-]
    E --> E3[先进个人<br/>-权利义务-]

    D --> F[相关社区]
    F --> F1[社区0:<br/>学生奖励体系]

    D --> G[相关文本块]
    G --> G1[Chunk_045:<br/>申请条件详细说明]

    E --> H[上下文融合]
    F --> H
    G --> H

    H --> I[LLM生成答案<br/>基于完整上下文]

    style D fill:#ff9,stroke:#333
    style H fill:#9f9,stroke:#333
```

**Local Search参数**：

| 参数 | 默认值 | 说明 |
|------|--------|------|
| `top_entities` | 10 | 最多扩展实体数 |
| `top_chunks` | 3 | 相关文本块数 |
| `top_communities` | 3 | 相关社区数 |
| `top_inside_relationships` | 10 | 内部关系数 |
| `top_outside_relationships` | 10 | 外部关系数 |

### Global Search详细流程

```mermaid
graph TB
    A[用户问题:<br/>'学校学生管理总体思路'] --> B[社区摘要检索<br/>语义相似度]

    B --> C[相关社区列表]

    C --> C1[社区0<br/>学生奖励体系<br/>score=0.92]
    C --> C2[社区1<br/>违纪处理流程<br/>score=0.88]
    C --> C3[社区3<br/>学籍管理规定<br/>score=0.85]

    C1 --> D[Map阶段<br/>LLM并行处理]
    C2 --> D
    C3 --> D

    D --> E1[子答案1:<br/>奖励激励机制...]
    D --> E2[子答案2:<br/>纪律约束体系...]
    D --> E3[子答案3:<br/>学籍权益保障...]

    E1 --> F[Reduce阶段<br/>LLM聚合]
    E2 --> F
    E3 --> F

    F --> G[全局视角答案<br/>三大支柱总结]

    style D fill:#ff9,stroke:#333
    style F fill:#9f9,stroke:#333
```

---

## 数据存储详解

### Neo4j图数据库

**存储内容**：

```mermaid
graph LR
    subgraph Neo4j图数据库
        A[实体节点<br/>6种类型]
        B[关系边<br/>8种类型]
        C[社区节点<br/>Community]
        D[文本块节点<br/>Chunk]

        A -->|关系| B
        A -->|PART_OF| C
        D -->|CONTAINS| A
    end

    style A fill:#9f9,stroke:#333
```

**节点类型**：

| 节点类型 | Label | 属性 | 数量估算 |
|----------|-------|------|---------|
| 实体节点 | 学生类型/奖学金类型/... | id, name, description, mentions | ~1200 |
| 社区节点 | Community | id, level, summary, size | ~15 |
| 文本块节点 | Chunk | id, text, source_file, index | ~5000 |

**关系类型**：
- 申请、评选、违纪、资助、申诉、管理、权利义务、互斥（共8种）
- PART_OF（实体→社区）
- CONTAINS（Chunk→实体）

### 向量索引

**两类索引**：

```mermaid
graph LR
    subgraph 向量索引
        A[vector<br/>实体索引]
        B[chunk_vector<br/>文本块索引]
    end

    A --> C[用途:<br/>实体语义检索]
    B --> D[用途:<br/>文本语义检索]

    C --> E[支持Local/Hybrid Search]
    D --> F[支持Naive/Hybrid Search]

    style A fill:#9f9,stroke:#333
    style B fill:#ff9,stroke:#333
```

**索引参数**：

| 索引名 | 向量维度 | 相似度算法 | 数据量 |
|--------|---------|----------|--------|
| vector | 1536 (OpenAI) | Cosine | ~1200 |
| chunk_vector | 1536 (OpenAI) | Cosine | ~5000 |

### 检索结果不缓存（v3 strict）

v3 strict 默认不做检索结果缓存：每次请求都执行实时检索与生成。可感知性与稳定性主要通过 SSE `progress` 事件、超时与降级策略来保证。

### 文件注册表

**file_registry.json结构**：

```json
{
  "files/学生手册.pdf": {
    "filepath": "files/学生手册.pdf",
    "file_hash": "a3d5f2e1...",
    "last_modified": "2026-01-01T10:00:00",
    "status": "processed",
    "chunks_count": 89,
    "entities_count": 45,
    "relationships_count": 120,
    "processed_at": "2026-01-01T10:05:30"
  },
  ...
}
```

**用途**：
- 增量更新：跟踪文件变化
- 去重：避免重复处理
- 回滚：删除文件时清理相关数据

---

## 性能优化要点

### 批处理优化

```mermaid
graph LR
    A[大量数据] --> B{批处理}

    B --> C1[实体批次<br/>BATCH_SIZE=50]
    B --> C2[文本块批次<br/>BATCH_SIZE=100]
    B --> C3[Embedding批次<br/>BATCH_SIZE=64]
    B --> C4[LLM批次<br/>BATCH_SIZE=5]

    C1 --> D[并行处理<br/>ThreadPool]
    C2 --> D
    C3 --> D
    C4 --> D

    D --> E[性能提升<br/>3-5倍]

    style B fill:#ff9,stroke:#333
    style E fill:#9f9,stroke:#333
```

**关键参数**：

| 参数 | 默认值 | 说明 | 影响 |
|------|--------|------|------|
| `MAX_WORKERS` | 4 | 线程池大小 | 并行度 |
| `ENTITY_BATCH_SIZE` | 50 | 实体批次 | 消歧效率 |
| `EMBEDDING_BATCH_SIZE` | 64 | 向量批次 | API效率 |
| `LLM_BATCH_SIZE` | 5 | LLM批次 | 生成效率 |

### 可感知性优化（SSE progress + keepalive）

长检索阶段通过周期性 `progress`/心跳事件避免链路空转导致的代理断连；前端可用进度条/状态提示提升体验。

### Neo4j查询优化

**索引优化**：
```cypher
// 为常用查询字段创建索引
CREATE INDEX entity_name_idx FOR (e:学生类型) ON (e.name);
CREATE INDEX chunk_id_idx FOR (c:Chunk) ON (c.id);
```

**查询优化**：
```cypher
// 避免全图扫描，使用LIMIT
MATCH (e:学生类型)-[r]-(related)
WHERE e.name = '优秀学生'
RETURN e, r, related
LIMIT 100

// 使用向量索引加速
CALL db.index.vector.queryNodes(
  'vector',
  5,
  [0.1, 0.2, ...]  // 查询向量
) YIELD node, score
```

---

## 相关文档

### 内部文档
- [系统架构总览](./系统架构总览.md) - 整体架构设计
- [本项目的创新点](../../01-理论基础/本项目的创新点.md) - 技术创新说明
- [知识图谱构建](../02-核心子系统/知识图谱构建.md) - 构建详细步骤
- [实体消歧和对齐](../03-关键特性/实体消歧和对齐.md) - 消歧算法详解
- [搜索引擎](../02-核心子系统/搜索引擎.md) - 多级检索实现

### 外部参考
- [Neo4j数据导入最佳实践](https://neo4j.com/docs/operations-manual/current/tools/neo4j-admin-import/)
- [OpenAI Embeddings API](https://platform.openai.com/docs/guides/embeddings)
- [LangChain Document Loaders](https://python.langchain.com/docs/modules/data_connection/document_loaders/)

---

## 更新日志

| 日期 | 版本 | 更新内容 |
|------|------|----------|
| 2026-01-04 | v1.0 | 初始版本，完整数据流说明 |

---

**贡献者**：项目团队
**维护者**：架构委员会
**反馈渠道**：GitHub Issues
