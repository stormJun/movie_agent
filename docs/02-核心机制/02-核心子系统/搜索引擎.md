# æœç´¢å¼•æ“

---

## ğŸ“‹ å…ƒä¿¡æ¯

- **ç›®æ ‡è¯»è€…**ï¼šå¼€å‘è€…ã€æ¶æ„å¸ˆ
- **é˜…è¯»æ—¶é—´**ï¼š50åˆ†é’Ÿ
- **éš¾åº¦**ï¼šâ­â­â­
- **å‰ç½®çŸ¥è¯†**ï¼šNeo4j Cypherã€å‘é‡æ£€ç´¢ã€å›¾ç®—æ³•
- **æœ€åæ›´æ–°**ï¼š2026-01-04

---

## ğŸ“– æœ¬æ–‡å¤§çº²

- [ç³»ç»Ÿæ¦‚è§ˆ](#ç³»ç»Ÿæ¦‚è§ˆ)
- [Local Searchï¼ˆæœ¬åœ°æœç´¢ï¼‰](#local-searchæœ¬åœ°æœç´¢)
- [Global Searchï¼ˆå…¨å±€æœç´¢ï¼‰](#global-searchå…¨å±€æœç´¢)
- [Hybrid Searchï¼ˆæ··åˆæœç´¢ï¼‰](#hybrid-searchæ··åˆæœç´¢)
- [Deep Researchï¼ˆæ·±åº¦ç ”ç©¶ï¼‰](#deep-researchæ·±åº¦ç ”ç©¶)
- [æœç´¢ç­–ç•¥å¯¹æ¯”](#æœç´¢ç­–ç•¥å¯¹æ¯”)
- [å‘é‡æ£€ç´¢å®ç°](#å‘é‡æ£€ç´¢å®ç°)
- [å›¾è°±æ£€ç´¢å®ç°](#å›¾è°±æ£€ç´¢å®ç°)
- [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
- [é…ç½®å‚æ•°](#é…ç½®å‚æ•°)
- [ç›¸å…³æ–‡æ¡£](#ç›¸å…³æ–‡æ¡£)

---

## ç³»ç»Ÿæ¦‚è§ˆ

### æ ¸å¿ƒç†å¿µ

æœç´¢å¼•æ“æ˜¯è¿æ¥ç”¨æˆ·æŸ¥è¯¢å’ŒçŸ¥è¯†å›¾è°±çš„å…³é”®æ¡¥æ¢ï¼Œè´Ÿè´£ä»æµ·é‡å›¾è°±æ•°æ®ä¸­é«˜æ•ˆã€å‡†ç¡®åœ°æ£€ç´¢ç›¸å…³ä¿¡æ¯ã€‚

**æ ¸å¿ƒç›®æ ‡**ï¼š
1. **é«˜å¬å›ç‡**ï¼šæ‰¾åˆ°æ‰€æœ‰ç›¸å…³ä¿¡æ¯
2. **é«˜å‡†ç¡®ç‡**ï¼šè¿‡æ»¤æ— å…³ä¿¡æ¯
3. **ä½å»¶è¿Ÿ**ï¼šå¿«é€Ÿè¿”å›ç»“æœ
4. **å¯è§£é‡Šæ€§**ï¼šæä¾›æ£€ç´¢è·¯å¾„å’Œè¯æ®

### å››ç§æœç´¢ç­–ç•¥

```mermaid
graph TB
    Query[ç”¨æˆ·æŸ¥è¯¢] --> Decision{æŸ¥è¯¢ç±»å‹åˆ†æ}

    Decision -->|å…·ä½“å®ä½“æŸ¥è¯¢| Local[Local Search<br/>æœ¬åœ°æœç´¢]
    Decision -->|å…¨å±€æ€§é—®é¢˜| Global[Global Search<br/>å…¨å±€æœç´¢]
    Decision -->|é€šç”¨æŸ¥è¯¢| Hybrid[Hybrid Search<br/>æ··åˆæœç´¢]
    Decision -->|å¤æ‚æ¨ç†| Deep[Deep Research<br/>æ·±åº¦ç ”ç©¶]

    Local --> R1[å®ä½“é‚»å±…æ‰©å±•<br/>1-2è·³èŒƒå›´]
    Global --> R2[ç¤¾åŒºæ‘˜è¦èšåˆ<br/>Map-Reduce]
    Hybrid --> R3[å‘é‡+å›¾è°±èåˆ<br/>åŒçº§æ£€ç´¢]
    Deep --> R4[å¤šæ­¥è¿­ä»£æœç´¢<br/>Think-Search-Reason]

    R1 --> Answer[ç”Ÿæˆç­”æ¡ˆ]
    R2 --> Answer
    R3 --> Answer
    R4 --> Answer

    style Local fill:#e3f2fd
    style Global fill:#fff3e0
    style Hybrid fill:#e8f5e9
    style Deep fill:#fce4ec
```

### æ¶æ„å±‚çº§

```mermaid
graph TB
    subgraph å·¥å…·å±‚[å·¥å…·å±‚ Tool Layer]
        LST[LocalSearchTool]
        GST[GlobalSearchTool]
        HST[HybridSearchTool]
        DRT[DeepResearchTool]
    end

    subgraph æ ¸å¿ƒå±‚[æ ¸å¿ƒå±‚ Core Search]
        LS[LocalSearch]
        GS[GlobalSearch]
        HS[HybridSearch]
        DR[DeepResearch]
    end

    subgraph æ•°æ®å±‚[æ•°æ®å±‚ Data Access]
        VR[VectorRetrieval<br/>å‘é‡æ£€ç´¢]
        GR[GraphRetrieval<br/>å›¾è°±æ£€ç´¢]
        CR[CommunityRetrieval<br/>ç¤¾åŒºæ£€ç´¢]
    end

    subgraph å­˜å‚¨å±‚[å­˜å‚¨å±‚ Storage]
        Neo[(Neo4j)]
        VI[Vector Index]
    end

    LST --> LS
    GST --> GS
    HST --> HS
    DRT --> DR

    LS --> VR
    LS --> GR
    GS --> CR
    HS --> VR
    HS --> GR
    DR --> VR
    DR --> GR

    VR --> Neo
    VR --> VI
    GR --> Neo
    CR --> Neo

    style å·¥å…·å±‚ fill:#e3f2fd
    style æ ¸å¿ƒå±‚ fill:#fff3e0
    style æ•°æ®å±‚ fill:#e8f5e9
    style å­˜å‚¨å±‚ fill:#fce4ec
```

---

## Local Searchï¼ˆæœ¬åœ°æœç´¢ï¼‰

### æ ¸å¿ƒæ€æƒ³

**å®ä½“ä¸ºä¸­å¿ƒ**ï¼šä»æŸ¥è¯¢ä¸­è¯†åˆ«æ ¸å¿ƒå®ä½“ï¼Œæ¢ç´¢å…¶é‚»å±…èŠ‚ç‚¹å’Œå…³ç³»ã€‚

**é€‚ç”¨åœºæ™¯**ï¼š
- "å¥–å­¦é‡‘çš„ç”³è¯·æ¡ä»¶æ˜¯ä»€ä¹ˆï¼Ÿ"
- "å­¦ç”Ÿè¿çºªä¼šå—åˆ°ä»€ä¹ˆå¤„åˆ†ï¼Ÿ"
- "è¯„å®¡å§”å‘˜ä¼šçš„èŒè´£æœ‰å“ªäº›ï¼Ÿ"

### å·¥ä½œæµç¨‹

```mermaid
sequenceDiagram
    participant U as ç”¨æˆ·
    participant LS as LocalSearch
    participant VI as VectorIndex
    participant Neo as Neo4j
    participant LLM as LLM

    U->>LS: æŸ¥è¯¢: "å¥–å­¦é‡‘ç”³è¯·æ¡ä»¶"
    LS->>VI: å‘é‡ç›¸ä¼¼åº¦æœç´¢
    Note over VI: æŸ¥æ‰¾ç›¸ä¼¼å®ä½“

    VI-->>LS: Top-K å®ä½“<br/>[å›½å®¶å¥–å­¦é‡‘, å­¦ç”Ÿ, ç”³è¯·æ¡ä»¶]

    LS->>Neo: æ‰©å±•é‚»å±…èŠ‚ç‚¹
    Note over Neo: 1-2è·³å›¾è°±æ‰©å±•<br/>åŒ…å«å…³ç³»å’Œç¤¾åŒº

    Neo-->>LS: è¿”å›ç»“æ„åŒ–æ•°æ®<br/>- Chunks<br/>- ç¤¾åŒºæ‘˜è¦<br/>- å†…éƒ¨å…³ç³»<br/>- å¤–éƒ¨å…³ç³»<br/>- å®ä½“æè¿°

    LS->>LLM: ç”Ÿæˆç­”æ¡ˆ
    Note over LLM: Context + Question

    LLM-->>LS: ç”Ÿæˆçš„ç­”æ¡ˆ
    LS-->>U: è¿”å›ç­”æ¡ˆ
```

### æ£€ç´¢æŸ¥è¯¢

**æ ¸å¿ƒ Cypher æŸ¥è¯¢**ï¼š

```cypher
WITH collect(node) as nodes
WITH
collect {
    UNWIND nodes as n
    MATCH (n)<-[:MENTIONS]-(c:__Chunk__)
    WITH distinct c, count(distinct n) as freq
    RETURN {id:c.id, text: c.text} AS chunkText
    ORDER BY freq DESC
    LIMIT $topChunks
} AS text_mapping,
collect {
    UNWIND nodes as n
    MATCH (n)-[:IN_COMMUNITY]->(c:__Community__)
    WITH distinct c, c.community_rank as rank, c.weight AS weight
    RETURN c.summary
    ORDER BY rank, weight DESC
    LIMIT $topCommunities
} AS report_mapping,
collect {
    UNWIND nodes as n
    MATCH (n)-[r]-(m:__Entity__)
    WHERE NOT m IN nodes
    RETURN r.description AS descriptionText
    ORDER BY r.weight DESC
    LIMIT $topOutsideRels
} as outsideRels,
collect {
    UNWIND nodes as n
    MATCH (n)-[r]-(m:__Entity__)
    WHERE m IN nodes
    RETURN r.description AS descriptionText
    ORDER BY r.weight DESC
    LIMIT $topInsideRels
} as insideRels,
collect {
    UNWIND nodes as n
    RETURN n.description AS descriptionText
} as entities
RETURN {
    Chunks: text_mapping,
    Reports: report_mapping,
    Relationships: outsideRels + insideRels,
    Entities: entities
} AS text, 1.0 AS score, {} AS metadata
```

**æŸ¥è¯¢è§£æ**ï¼š

1. **Chunks**ï¼šæå–æåˆ°æ ¸å¿ƒå®ä½“çš„æ–‡æœ¬å—ï¼ŒæŒ‰é¢‘ç‡æ’åº
2. **Reports**ï¼šè·å–å®ä½“æ‰€å±ç¤¾åŒºçš„æ‘˜è¦
3. **OutsideRels**ï¼šå®ä½“ä¸å¤–éƒ¨å®ä½“çš„å…³ç³»
4. **InsideRels**ï¼šæ ¸å¿ƒå®ä½“ä¹‹é—´çš„å…³ç³»
5. **Entities**ï¼šå®ä½“æœ¬èº«çš„æè¿°

### é‚»å±…æ‰©å±•ç­–ç•¥

```mermaid
graph TB
    E[æ ¸å¿ƒå®ä½“<br/>å›½å®¶å¥–å­¦é‡‘]

    E --> E1[1è·³é‚»å±…]
    E --> E2[1è·³é‚»å±…]
    E --> E3[1è·³é‚»å±…]

    E1 --> E11[2è·³é‚»å±…]
    E1 --> E12[2è·³é‚»å±…]

    E2 --> E21[2è·³é‚»å±…]

    E -.->|MENTIONS| C1[Chunk 1]
    E -.->|MENTIONS| C2[Chunk 2]

    E -->|IN_COMMUNITY| CO[Community ç¤¾åŒºæ‘˜è¦]

    style E fill:#e8f5e9
    style E1 fill:#e3f2fd
    style E2 fill:#e3f2fd
    style E3 fill:#e3f2fd
    style E11 fill:#fff3e0
    style E12 fill:#fff3e0
    style E21 fill:#fff3e0
```

### æ ¸å¿ƒä»£ç 

```python
class LocalSearch:
    def __init__(self, llm, embeddings, response_type: str = "å¤šä¸ªæ®µè½"):
        self.llm = llm
        self.embeddings = embeddings
        self.response_type = response_type

        # æ£€ç´¢å‚æ•°
        self.top_chunks = LOCAL_SEARCH_SETTINGS["top_chunks"]             # 5
        self.top_communities = LOCAL_SEARCH_SETTINGS["top_communities"]   # 3
        self.top_outside_rels = LOCAL_SEARCH_SETTINGS["top_outside_relationships"]  # 10
        self.top_inside_rels = LOCAL_SEARCH_SETTINGS["top_inside_relationships"]    # 10
        self.top_entities = LOCAL_SEARCH_SETTINGS["top_entities"]         # 5

    def search(self, query: str) -> str:
        """æ‰§è¡Œæœ¬åœ°æœç´¢"""
        # 1. åˆå§‹åŒ–å‘é‡å­˜å‚¨
        vector_store = from_existing_index(
            self.embeddings,
            index_name=self.index_name,
            retrieval_query=self.retrieval_query  # ä¸Šé¢çš„ Cypher æŸ¥è¯¢
        )

        # 2. æ‰§è¡Œç›¸ä¼¼åº¦æœç´¢
        docs = vector_store.similarity_search(
            query,
            k=self.top_entities,
            params={
                "topChunks": self.top_chunks,
                "topCommunities": self.top_communities,
                "topOutsideRels": self.top_outside_rels,
                "topInsideRels": self.top_inside_rels,
            }
        )

        # 3. ä½¿ç”¨ LLM ç”Ÿæˆå“åº”
        prompt = ChatPromptTemplate.from_messages([
            ("system", LC_SYSTEM_PROMPT),
            ("human", LOCAL_SEARCH_CONTEXT_PROMPT),
        ])

        chain = prompt | self.llm | StrOutputParser()

        response = chain.invoke({
            "context": docs[0].page_content if docs else "",
            "input": query,
            "response_type": self.response_type
        })

        return response
```

### ç¤¾åŒºæƒé‡åˆå§‹åŒ–

```python
def _init_community_weights(self):
    """åˆå§‹åŒ–ç¤¾åŒºèŠ‚ç‚¹çš„æƒé‡ï¼ˆåŸºäºæåˆ°è¯¥ç¤¾åŒºçš„ chunk æ•°ï¼‰"""
    self.db_query("""
    MATCH (n:`__Community__`)<-[:IN_COMMUNITY]-()<-[:MENTIONS]-(c)
    WITH n, count(distinct c) AS chunkCount
    SET n.weight = chunkCount
    """)
```

---

## Global Searchï¼ˆå…¨å±€æœç´¢ï¼‰

### æ ¸å¿ƒæ€æƒ³

**ç¤¾åŒºä¸ºä¸­å¿ƒ**ï¼šé‡‡ç”¨ Map-Reduce æ¨¡å¼ï¼Œå…ˆå¯¹æ¯ä¸ªç¤¾åŒºç”Ÿæˆä¸­é—´æŠ¥å‘Šï¼Œå†æ•´åˆä¸ºå…¨å±€ç­”æ¡ˆã€‚

**é€‚ç”¨åœºæ™¯**ï¼š
- "æ€»ç»“æ‰€æœ‰å¥–å­¦é‡‘ç±»å‹"
- "å­¦ç”Ÿå¯ä»¥è·å¾—å“ªäº›èµ„åŠ©ï¼Ÿ"
- "å­¦æ ¡æœ‰å“ªäº›ç®¡ç†è§„å®šï¼Ÿ"

### å·¥ä½œæµç¨‹

```mermaid
graph TB
    Query[ç”¨æˆ·æŸ¥è¯¢:<br/>"æ€»ç»“æ‰€æœ‰å¥–å­¦é‡‘ç±»å‹"]

    Query --> GetComm[è·å–ç¤¾åŒºæ•°æ®]

    GetComm --> C1[ç¤¾åŒº1:<br/>å›½å®¶å¥–å­¦é‡‘]
    GetComm --> C2[ç¤¾åŒº2:<br/>å­¦æ ¡å¥–å­¦é‡‘]
    GetComm --> C3[ç¤¾åŒº3:<br/>ç¤¾ä¼šå¥–å­¦é‡‘]

    subgraph Mapé˜¶æ®µ[Map é˜¶æ®µ - å¹¶è¡Œå¤„ç†]
        C1 --> M1[LLMç”Ÿæˆ:<br/>ä¸­é—´æŠ¥å‘Š1]
        C2 --> M2[LLMç”Ÿæˆ:<br/>ä¸­é—´æŠ¥å‘Š2]
        C3 --> M3[LLMç”Ÿæˆ:<br/>ä¸­é—´æŠ¥å‘Š3]
    end

    M1 --> Reduce[Reduceé˜¶æ®µ]
    M2 --> Reduce
    M3 --> Reduce

    Reduce --> LLM[LLMæ•´åˆ]
    LLM --> Answer[æœ€ç»ˆç­”æ¡ˆ]

    style Mapé˜¶æ®µ fill:#e3f2fd
    style Reduce fill:#fff3e0
    style Answer fill:#e8f5e9
```

### Map é˜¶æ®µ

**ç›®æ ‡**ï¼šä¸ºæ¯ä¸ªç¤¾åŒºç”Ÿæˆä¸­é—´æŠ¥å‘Šã€‚

```python
def _process_communities(self, query: str, communities: List[dict]) -> List[str]:
    """Map é˜¶æ®µï¼šå¤„ç†ç¤¾åŒºæ•°æ®ç”Ÿæˆä¸­é—´ç»“æœ"""
    # è®¾ç½® Map æç¤ºæ¨¡æ¿
    map_prompt = ChatPromptTemplate.from_messages([
        ("system", MAP_SYSTEM_PROMPT),
        ("human", GLOBAL_SEARCH_MAP_PROMPT),
    ])

    map_chain = map_prompt | self.llm | StrOutputParser()

    results = []
    for community in tqdm(communities, desc="æ­£åœ¨å¤„ç†ç¤¾åŒºæ•°æ®"):
        response = map_chain.invoke({
            "question": query,
            "context_data": community["output"]
        })
        results.append(response)

    return results
```

**Map æç¤ºè¯**ï¼š

```python
MAP_SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†æ•´ç†ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä»ç»™å®šçš„ç¤¾åŒºæ•°æ®ä¸­æå–ä¸é—®é¢˜ç›¸å…³çš„ä¿¡æ¯ã€‚

**è¦æ±‚**ï¼š
1. ä»…æå–ä¸é—®é¢˜ç›´æ¥ç›¸å…³çš„ä¿¡æ¯
2. ä¿æŒä¿¡æ¯çš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§
3. å¦‚æœç¤¾åŒºæ•°æ®ä¸åŒ…å«ç›¸å…³ä¿¡æ¯ï¼Œè¿”å›"æ— ç›¸å…³ä¿¡æ¯"
"""

GLOBAL_SEARCH_MAP_PROMPT = """
é—®é¢˜: {question}

ç¤¾åŒºæ•°æ®:
{context_data}

è¯·æå–ä¸é—®é¢˜ç›¸å…³çš„å…³é”®ä¿¡æ¯ã€‚
"""
```

### Reduce é˜¶æ®µ

**ç›®æ ‡**ï¼šæ•´åˆæ‰€æœ‰ä¸­é—´æŠ¥å‘Šï¼Œç”Ÿæˆå…¨å±€ç­”æ¡ˆã€‚

```python
def _reduce_results(self, query: str, intermediate_results: List[str]) -> str:
    """Reduce é˜¶æ®µï¼šæ•´åˆä¸­é—´ç»“æœç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ"""
    reduce_prompt = ChatPromptTemplate.from_messages([
        ("system", REDUCE_SYSTEM_PROMPT),
        ("human", GLOBAL_SEARCH_REDUCE_PROMPT),
    ])

    reduce_chain = reduce_prompt | self.llm | StrOutputParser()

    return reduce_chain.invoke({
        "report_data": intermediate_results,
        "question": query,
        "response_type": self.response_type,
    })
```

**Reduce æç¤ºè¯**ï¼š

```python
REDUCE_SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†æ•´åˆä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†å¤šä¸ªä¸­é—´æŠ¥å‘Šæ•´åˆä¸ºä¸€ä¸ªå®Œæ•´ã€è¿è´¯çš„ç­”æ¡ˆã€‚

**è¦æ±‚**ï¼š
1. æ•´åˆæ‰€æœ‰æœ‰ä»·å€¼çš„ä¿¡æ¯
2. å»é™¤é‡å¤å†…å®¹
3. ä¿æŒé€»è¾‘æ¸…æ™°
4. è¾“å‡ºæ ¼å¼ä¸º {response_type}
"""

GLOBAL_SEARCH_REDUCE_PROMPT = """
é—®é¢˜: {question}

ä¸­é—´æŠ¥å‘Š:
{report_data}

è¯·æ•´åˆä»¥ä¸ŠæŠ¥å‘Šï¼Œç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„ç­”æ¡ˆã€‚
"""
```

### ç¤¾åŒºæ•°æ®è·å–

```python
def _get_community_data(self, level: int) -> List[dict]:
    """è·å–æŒ‡å®šå±‚çº§çš„ç¤¾åŒºæ•°æ®"""
    return self.graph.query(
        """
        MATCH (c:__Community__)
        WHERE c.level = $level
        RETURN {communityId:c.id, full_content:c.full_content} AS output
        """,
        params={"level": level},
    )
```

### å®Œæ•´æœç´¢æµç¨‹

```python
class GlobalSearch:
    def search(self, query: str, level: int) -> str:
        """æ‰§è¡Œå…¨å±€æœç´¢"""
        # 1. è·å–ç¤¾åŒºæ•°æ®
        communities = self._get_community_data(level)

        # 2. Map é˜¶æ®µï¼šå¤„ç†ç¤¾åŒºæ•°æ®
        intermediate_results = self._process_communities(query, communities)

        # 3. Reduce é˜¶æ®µï¼šç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
        return self._reduce_results(query, intermediate_results)
```

---

## Hybrid Searchï¼ˆæ··åˆæœç´¢ï¼‰

### æ ¸å¿ƒæ€æƒ³

**åŒçº§æ£€ç´¢**ï¼šç»“åˆå‘é‡æ£€ç´¢ï¼ˆè¯­ä¹‰åŒ¹é…ï¼‰å’Œå›¾è°±æ£€ç´¢ï¼ˆç»“æ„æ¨ç†ï¼‰ï¼Œå¹³è¡¡å‡†ç¡®ç‡å’Œå¬å›ç‡ã€‚

**é€‚ç”¨åœºæ™¯**ï¼š
- å¤§éƒ¨åˆ†é€šç”¨æŸ¥è¯¢
- æ—¢éœ€è¦è¯­ä¹‰ç†è§£åˆéœ€è¦ç»“æ„æ¨ç†çš„æŸ¥è¯¢

### åŒçº§å…³é”®è¯æå–

```mermaid
graph TB
    Query[æŸ¥è¯¢: å¥–å­¦é‡‘ç”³è¯·æ¡ä»¶å’Œæµç¨‹]

    Query --> KE[å…³é”®è¯æå–<br/>LLM]

    KE --> LL[ä½çº§å…³é”®è¯<br/>Low-Level]
    KE --> HL[é«˜çº§å…³é”®è¯<br/>High-Level]

    LL --> L1[å¥–å­¦é‡‘]
    LL --> L2[ç”³è¯·]
    LL --> L3[æ¡ä»¶]
    LL --> L4[æµç¨‹]

    HL --> H1[ç”³è¯·æµç¨‹]
    HL --> H2[èµ„æ ¼è¦æ±‚]

    L1 --> VR[å‘é‡æ£€ç´¢<br/>ç²¾ç¡®åŒ¹é…]
    L2 --> VR
    L3 --> VR
    L4 --> VR

    H1 --> GR[å›¾è°±æ£€ç´¢<br/>ç»“æ„æ¨ç†]
    H2 --> GR

    VR --> Merge[ç»“æœèåˆ]
    GR --> Merge

    style LL fill:#e3f2fd
    style HL fill:#fff3e0
    style Merge fill:#e8f5e9
```

### å…³é”®è¯æå–å®ç°

```python
def extract_keywords(self, query: str) -> Dict[str, List[str]]:
    """æå–åŒçº§å…³é”®è¯"""
    # è°ƒç”¨ LLM æå–å…³é”®è¯
    prompt = """
    è¯·ä»ä»¥ä¸‹æŸ¥è¯¢ä¸­æå–å…³é”®è¯ï¼Œåˆ†ä¸ºä¸¤ç±»ï¼š

    1. ä½çº§å…³é”®è¯ï¼ˆlow_levelï¼‰ï¼šå…·ä½“çš„å®ä½“åç§°ã€æ“ä½œåŠ¨è¯
    2. é«˜çº§å…³é”®è¯ï¼ˆhigh_levelï¼‰ï¼šæŠ½è±¡æ¦‚å¿µã€ä¸»é¢˜

    æŸ¥è¯¢: {query}

    è¯·ä»¥ JSON æ ¼å¼è¾“å‡ºï¼š
    {{
        "low_level": ["å…³é”®è¯1", "å…³é”®è¯2", ...],
        "high_level": ["å…³é”®è¯1", "å…³é”®è¯2", ...]
    }}
    """

    result = self.keyword_chain.invoke({"query": query})

    # è§£æ JSON
    keywords = json.loads(result)

    return keywords
```

### å‘é‡æ£€ç´¢

```python
def _vector_search(self, query: str, keywords: Dict, top_k: int = 5) -> List[Dict]:
    """å‘é‡æ£€ç´¢ï¼ˆä½¿ç”¨ä½çº§å…³é”®è¯ï¼‰"""
    # 1. ç”ŸæˆæŸ¥è¯¢å‘é‡
    query_vec = self.embeddings.embed_query(query)

    # 2. å‘é‡ç›¸ä¼¼åº¦æœç´¢
    cypher = """
    CALL db.index.vector.queryNodes(
        'entity_index',
        $top_k,
        $query_vec
    )
    YIELD node, score
    RETURN node.id AS entity_id,
           node.description AS description,
           score
    ORDER BY score DESC
    """

    results = self.graph.query(cypher, params={
        'top_k': top_k,
        'query_vec': query_vec
    })

    return results
```

### å›¾è°±æ£€ç´¢

```python
def _graph_search(self, keywords: Dict, max_hops: int = 2) -> List[Dict]:
    """å›¾è°±æ£€ç´¢ï¼ˆä½¿ç”¨é«˜çº§å…³é”®è¯ï¼‰"""
    high_level_keywords = keywords.get("high_level", [])

    if not high_level_keywords:
        return []

    # åŸºäºå…³é”®è¯çš„å›¾è°±æ‰©å±•
    cypher = """
    MATCH (e:`__Entity__`)
    WHERE any(kw IN $keywords WHERE toLower(e.id) CONTAINS toLower(kw))

    // æ‰©å±•é‚»å±…ï¼ˆæœ€å¤š max_hops è·³ï¼‰
    CALL apoc.path.subgraphNodes(e, {
        maxLevel: $max_hops,
        relationshipFilter: "RELATES_TO"
    })
    YIELD node

    // æ”¶é›†å®ä½“å’Œå…³ç³»
    WITH collect(distinct node) AS nodes
    UNWIND nodes AS n
    MATCH (n)-[r]-(m)
    WHERE m IN nodes

    RETURN n.id AS entity_id,
           n.description AS description,
           type(r) AS relationship,
           r.description AS rel_description,
           m.id AS related_entity
    """

    results = self.graph.query(cypher, params={
        'keywords': high_level_keywords,
        'max_hops': max_hops
    })

    return results
```

### ç»“æœèåˆ

```python
def _merge_results(self, vector_results: List[Dict],
                  graph_results: List[Dict],
                  alpha: float = 0.6, beta: float = 0.4) -> List[Dict]:
    """åŠ æƒèåˆå‘é‡å’Œå›¾è°±æ£€ç´¢ç»“æœ"""
    # 1. å½’ä¸€åŒ–å‘é‡ç»“æœçš„åˆ†æ•°
    if vector_results:
        max_vec_score = max(r['score'] for r in vector_results)
        for r in vector_results:
            r['normalized_score'] = r['score'] / max_vec_score

    # 2. å½’ä¸€åŒ–å›¾è°±ç»“æœçš„åˆ†æ•°ï¼ˆåŸºäºè·¯å¾„é•¿åº¦ï¼‰
    if graph_results:
        for r in graph_results:
            # è·¯å¾„è¶ŠçŸ­ï¼Œåˆ†æ•°è¶Šé«˜
            r['normalized_score'] = 1.0 / (r.get('path_length', 1) + 1)

    # 3. åˆå¹¶å¹¶å»é‡
    entity_scores = {}

    for r in vector_results:
        entity_id = r['entity_id']
        entity_scores[entity_id] = {
            'entity_id': entity_id,
            'description': r['description'],
            'score': alpha * r['normalized_score'],
            'source': 'vector'
        }

    for r in graph_results:
        entity_id = r['entity_id']
        if entity_id in entity_scores:
            # å®ä½“å·²å­˜åœ¨ï¼Œåˆå¹¶åˆ†æ•°
            entity_scores[entity_id]['score'] += beta * r['normalized_score']
            entity_scores[entity_id]['source'] = 'hybrid'
        else:
            entity_scores[entity_id] = {
                'entity_id': entity_id,
                'description': r['description'],
                'score': beta * r['normalized_score'],
                'source': 'graph'
            }

    # 4. æ’åºå¹¶è¿”å›
    merged = sorted(
        entity_scores.values(),
        key=lambda x: x['score'],
        reverse=True
    )

    return merged
```

### å®Œæ•´æœç´¢æµç¨‹

```python
class HybridSearchTool:
    def search(self, query: str) -> str:
        """æ‰§è¡Œæ··åˆæœç´¢"""
        # 1. æå–å…³é”®è¯
        keywords = self.extract_keywords(query)

        # 2. å‘é‡æ£€ç´¢
        vector_results = self._vector_search(query, keywords, top_k=5)

        # 3. å›¾è°±æ£€ç´¢
        graph_results = self._graph_search(keywords, max_hops=2)

        # 4. èåˆç»“æœ
        merged_results = self._merge_results(
            vector_results,
            graph_results,
            alpha=0.6,  # å‘é‡æƒé‡
            beta=0.4    # å›¾è°±æƒé‡
        )

        # 5. ç”Ÿæˆç­”æ¡ˆ
        context = self._format_results(merged_results)

        prompt = ChatPromptTemplate.from_messages([
            ("system", LC_SYSTEM_PROMPT),
            ("human", HYBRID_TOOL_QUERY_PROMPT),
        ])

        chain = prompt | self.llm | StrOutputParser()

        response = chain.invoke({
            "context": context,
            "question": query,
            "response_type": self.response_type
        })

        return response
```

### å›é€€ç­–ç•¥

å½“å›¾è°±ä¸­æ²¡æœ‰åŒ¹é…å®ä½“æ—¶ï¼Œä½¿ç”¨ Chunk å…³é”®è¯æœç´¢ä½œä¸ºå›é€€ï¼š

```python
def _fallback_chunk_keyword_search(self, query: str, keywords: List[str],
                                   limit: int = 5) -> List[Dict]:
    """åŸºäºå…³é”®è¯çš„ Chunk æ–‡æœ¬åŒ¹é…æ£€ç´¢ï¼ˆå›é€€ç­–ç•¥ï¼‰"""
    # ä½¿ç”¨ jieba åˆ†è¯ä½œä¸ºä¿åº•
    if not keywords:
        import jieba
        keywords = jieba.lcut(query)

    # Chunk æ–‡æœ¬åŒ¹é…æŸ¥è¯¢
    chunk_query = """
    MATCH (c:__Chunk__)
    WITH c, size([w IN $keywords WHERE c.text CONTAINS w]) AS hits
    WHERE hits > 0
    RETURN c.id AS id,
           c.text AS text,
           c.fileName AS fileName,
           hits AS hits
    ORDER BY hits DESC
    LIMIT $limit
    """

    results = self.graph.query(chunk_query, params={
        'keywords': keywords[:8],  # é™åˆ¶å…³é”®è¯æ•°é‡
        'limit': limit
    })

    return results
```

---

## Deep Researchï¼ˆæ·±åº¦ç ”ç©¶ï¼‰

### æ ¸å¿ƒæ€æƒ³

**å¤šæ­¥è¿­ä»£**ï¼šThink-Search-Reason å¾ªç¯ï¼Œé€æ­¥æ·±å…¥æ¢ç´¢çŸ¥è¯†å›¾è°±ã€‚

**é€‚ç”¨åœºæ™¯**ï¼š
- å¤æ‚å¤šè·³æ¨ç†
- éœ€è¦å±•ç¤ºæ¨ç†è¿‡ç¨‹
- ç ”ç©¶æ€§æŸ¥è¯¢

### å·¥ä½œæµç¨‹

```mermaid
sequenceDiagram
    participant U as ç”¨æˆ·
    participant DR as DeepResearch
    participant TM as ThinkingModule
    participant SM as SearchModule
    participant RM as ReasoningModule

    U->>DR: å¤æ‚æŸ¥è¯¢

    loop è¿­ä»£æ¢ç´¢ï¼ˆæœ€å¤š3è½®ï¼‰
        DR->>TM: å½“å‰çŠ¶æ€
        TM-->>DR: ç”Ÿæˆå­é—®é¢˜

        DR->>SM: æ‰§è¡Œå­é—®é¢˜æœç´¢
        Note over SM: è°ƒç”¨ LocalSearch<br/>æˆ– HybridSearch

        SM-->>DR: è¿”å›è¯æ®

        DR->>RM: è¯æ® + å­é—®é¢˜
        RM-->>DR: æ¨ç†ç»“è®º

        Note over DR: åˆ¤æ–­æ˜¯å¦éœ€è¦ç»§ç»­æ¢ç´¢
    end

    DR->>DR: æœ€ç»ˆæ•´åˆ
    DR-->>U: å®Œæ•´ç­”æ¡ˆ + æ¨ç†é“¾
```

### Thinking æ¨¡å—

```python
class ThinkingModule:
    def analyze(self, query: str, context: Dict) -> Dict:
        """åˆ†æå½“å‰çŠ¶æ€ï¼Œç”Ÿæˆå­é—®é¢˜"""
        prompt = """
        å½“å‰æŸ¥è¯¢: {query}

        å·²çŸ¥ä¿¡æ¯:
        {context}

        è¯·åˆ†æä»¥ä¸‹å†…å®¹ï¼š
        1. å½“å‰ä¿¡æ¯æ˜¯å¦è¶³å¤Ÿå›ç­”é—®é¢˜ï¼Ÿ
        2. è¿˜éœ€è¦æ¢ç´¢å“ªäº›æ–¹å‘ï¼Ÿ
        3. ä¸‹ä¸€æ­¥åº”è¯¥æœç´¢ä»€ä¹ˆï¼Ÿ

        è¯·ä»¥ JSON æ ¼å¼è¾“å‡ºï¼š
        {{
            "is_sufficient": true/false,
            "sub_questions": ["å­é—®é¢˜1", "å­é—®é¢˜2", ...],
            "reasoning": "æ¨ç†è¿‡ç¨‹"
        }}
        """

        result = self.llm.invoke(prompt.format(
            query=query,
            context=json.dumps(context, ensure_ascii=False)
        ))

        return json.loads(result.content)
```

### Search æ¨¡å—

```python
class SearchModule:
    def execute(self, sub_question: str) -> Dict:
        """æ‰§è¡Œå­é—®é¢˜æœç´¢"""
        # é€‰æ‹©æœç´¢ç­–ç•¥
        if self._is_local_query(sub_question):
            # ä½¿ç”¨æœ¬åœ°æœç´¢
            result = self.local_search.search(sub_question)
        else:
            # ä½¿ç”¨æ··åˆæœç´¢
            result = self.hybrid_search.search(sub_question)

        return {
            "question": sub_question,
            "evidence": result,
            "source": "local" if self._is_local_query(sub_question) else "hybrid"
        }
```

### Reasoning æ¨¡å—

```python
class ReasoningModule:
    def integrate(self, query: str, evidences: List[Dict]) -> Dict:
        """æ•´åˆè¯æ®ï¼Œç”Ÿæˆæ¨ç†ç»“è®º"""
        prompt = """
        åŸå§‹é—®é¢˜: {query}

        æ”¶é›†çš„è¯æ®:
        {evidences}

        è¯·åŸºäºä»¥ä¸Šè¯æ®ï¼Œè¿›è¡Œæ¨ç†å¹¶ç”Ÿæˆç»“è®ºã€‚

        è¾“å‡ºæ ¼å¼ï¼š
        {{
            "conclusion": "æ¨ç†ç»“è®º",
            "supporting_evidence": ["è¯æ®1", "è¯æ®2", ...],
            "reasoning_chain": ["æ¨ç†æ­¥éª¤1", "æ¨ç†æ­¥éª¤2", ...]
        }}
        """

        result = self.llm.invoke(prompt.format(
            query=query,
            evidences=json.dumps(evidences, ensure_ascii=False)
        ))

        return json.loads(result.content)
```

### è¿­ä»£æ§åˆ¶

```python
class DeepResearch:
    def research(self, query: str, max_iterations: int = 3) -> Dict:
        """æ‰§è¡Œæ·±åº¦ç ”ç©¶"""
        context = {"evidences": [], "reasoning_steps": []}

        for iteration in range(max_iterations):
            # 1. Thinkingï¼šåˆ†æå½“å‰çŠ¶æ€
            thinking_result = self.thinking.analyze(query, context)

            if thinking_result["is_sufficient"]:
                # ä¿¡æ¯è¶³å¤Ÿï¼Œåœæ­¢è¿­ä»£
                break

            # 2. Searchï¼šæ‰§è¡Œå­é—®é¢˜æœç´¢
            for sub_q in thinking_result["sub_questions"]:
                evidence = self.search.execute(sub_q)
                context["evidences"].append(evidence)

            # 3. Reasoningï¼šæ¨ç†æ•´åˆ
            reasoning_result = self.reasoning.integrate(query, context["evidences"])
            context["reasoning_steps"].append(reasoning_result)

        # 4. ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
        final_answer = self._generate_final_answer(query, context)

        return {
            "answer": final_answer,
            "thinking_steps": context["reasoning_steps"],
            "evidences": context["evidences"]
        }
```

### çŸ¥è¯†å›¾è°±æ¢ç´¢

```python
def explore_graph(self, entity: str, max_depth: int = 3) -> Dict:
    """æ¢ç´¢çŸ¥è¯†å›¾è°±ï¼ˆæ·±åº¦ä¼˜å…ˆï¼‰"""
    cypher = """
    MATCH path = (start:`__Entity__` {id: $entity})-[*1..$max_depth]-(end)
    RETURN path,
           length(path) AS depth,
           [n IN nodes(path) | n.id] AS entities,
           [r IN relationships(path) | type(r)] AS relations
    ORDER BY depth
    LIMIT 20
    """

    paths = self.graph.query(cypher, params={
        'entity': entity,
        'max_depth': max_depth
    })

    return {
        "entity": entity,
        "paths": paths,
        "exploration_depth": max_depth
    }
```

---

## æœç´¢ç­–ç•¥å¯¹æ¯”

### åŠŸèƒ½å¯¹æ¯”è¡¨

| ç‰¹æ€§ | Local Search | Global Search | Hybrid Search | Deep Research |
|------|--------------|---------------|---------------|---------------|
| **æ£€ç´¢èŒƒå›´** | å®ä½“é‚»å±…ï¼ˆ1-2è·³ï¼‰ | æ‰€æœ‰ç¤¾åŒº | å‘é‡+å›¾è°± | è¿­ä»£æ‰©å±• |
| **æ£€ç´¢ç²’åº¦** | ç»†ç²’åº¦ | ç²—ç²’åº¦ | ä¸­ç­‰ç²’åº¦ | è‡ªé€‚åº” |
| **å“åº”é€Ÿåº¦** | å¿«ï¼ˆ1-2sï¼‰ | æ…¢ï¼ˆ10-30sï¼‰ | ä¸­ï¼ˆ3-5sï¼‰ | æ…¢ï¼ˆ10-20sï¼‰ |
| **å‡†ç¡®ç‡** | é«˜ | ä¸­ | é«˜ | æé«˜ |
| **å¬å›ç‡** | ä¸­ | é«˜ | é«˜ | æé«˜ |
| **æ¨ç†èƒ½åŠ›** | ä½ | ä½ | ä¸­ | é«˜ |
| **å¯è§£é‡Šæ€§** | ä¸­ | ä½ | ä¸­ | æé«˜ |
| **é€‚ç”¨æŸ¥è¯¢** | å…·ä½“å®ä½“æŸ¥è¯¢ | å…¨å±€æ€§é—®é¢˜ | é€šç”¨æŸ¥è¯¢ | å¤æ‚æ¨ç† |
| **èµ„æºæ¶ˆè€—** | ä½ | é«˜ | ä¸­ | é«˜ |

### æ€§èƒ½å¯¹æ¯”

```mermaid
graph TB
    subgraph å“åº”é€Ÿåº¦[å“åº”é€Ÿåº¦ï¼ˆç§’ï¼‰]
        L1[Local: 1-2s]
        H1[Hybrid: 3-5s]
        D1[Deep: 10-20s]
        G1[Global: 10-30s]
    end

    subgraph å‡†ç¡®ç‡[å‡†ç¡®ç‡]
        L2[Local: 85%]
        H2[Hybrid: 88%]
        D2[Deep: 95%]
        G2[Global: 75%]
    end

    subgraph å¬å›ç‡[å¬å›ç‡]
        L3[Local: 70%]
        H3[Hybrid: 85%]
        D3[Deep: 90%]
        G3[Global: 95%]
    end

    style L1 fill:#e8f5e9
    style G1 fill:#ffebee
    style L2 fill:#fff3e0
    style D2 fill:#e8f5e9
    style L3 fill:#ffebee
    style G3 fill:#e8f5e9
```

### é€‰æ‹©å»ºè®®

```mermaid
graph TD
    Q{æŸ¥è¯¢åˆ†æ}

    Q -->|å®ä½“æ˜ç¡®| C1{éœ€è¦æ¨ç†?}
    Q -->|å®ä½“ä¸æ˜ç¡®| C2{èŒƒå›´å¤§?}

    C1 -->|å¦| Local[Local Search<br/>å¿«é€Ÿæ£€ç´¢]
    C1 -->|æ˜¯| Deep[Deep Research<br/>æ·±åº¦æ¨ç†]

    C2 -->|æ˜¯| Global[Global Search<br/>å…¨å±€èšåˆ]
    C2 -->|å¦| Hybrid[Hybrid Search<br/>æ··åˆæ£€ç´¢]

    style Local fill:#e8f5e9
    style Global fill:#fff3e0
    style Hybrid fill:#e3f2fd
    style Deep fill:#fce4ec
```

---

## å‘é‡æ£€ç´¢å®ç°

### å‘é‡ç´¢å¼•

```cypher
-- å®ä½“å‘é‡ç´¢å¼•
CREATE VECTOR INDEX entity_index IF NOT EXISTS
FOR (e:`__Entity__`)
ON e.embedding
OPTIONS {
    indexConfig: {
        `vector.dimensions`: 1536,
        `vector.similarity_function`: 'cosine'
    }
}

-- Chunk å‘é‡ç´¢å¼•
CREATE VECTOR INDEX chunk_index IF NOT EXISTS
FOR (c:`__Chunk__`)
ON c.embedding
OPTIONS {
    indexConfig: {
        `vector.dimensions`: 1536,
        `vector.similarity_function`: 'cosine'
    }
}
```

### å‘é‡æœç´¢

```python
def vector_search(query: str, index_name: str, top_k: int = 5) -> List[Dict]:
    """å‘é‡ç›¸ä¼¼åº¦æœç´¢"""
    # 1. å‘é‡åŒ–æŸ¥è¯¢
    query_vec = embeddings.embed_query(query)

    # 2. è°ƒç”¨å‘é‡ç´¢å¼•
    cypher = """
    CALL db.index.vector.queryNodes(
        $index_name,
        $top_k,
        $query_vec
    )
    YIELD node, score
    RETURN node, score
    ORDER BY score DESC
    """

    results = graph.query(cypher, params={
        'index_name': index_name,
        'top_k': top_k,
        'query_vec': query_vec
    })

    return results
```

### å‘é‡ç”Ÿæˆä¼˜åŒ–

```python
def batch_generate_embeddings(texts: List[str], batch_size: int = 64) -> List[List[float]]:
    """æ‰¹é‡ç”Ÿæˆå‘é‡ï¼ˆä¼˜åŒ–æ€§èƒ½ï¼‰"""
    embeddings = []

    for i in range(0, len(texts), batch_size):
        batch = texts[i:i + batch_size]
        batch_embeddings = embedding_model.embed_documents(batch)
        embeddings.extend(batch_embeddings)

    return embeddings
```

---

## å›¾è°±æ£€ç´¢å®ç°

### è·¯å¾„æŸ¥è¯¢

```cypher
-- æŸ¥æ‰¾ä¸¤ä¸ªå®ä½“ä¹‹é—´çš„è·¯å¾„
MATCH path = shortestPath(
    (e1:`__Entity__` {id: $entity1})-[*..5]-(e2:`__Entity__` {id: $entity2})
)
RETURN path
```

### é‚»å±…æ‰©å±•

```cypher
-- N è·³é‚»å±…æ‰©å±•
MATCH (e:`__Entity__` {id: $entity})
CALL apoc.path.subgraphNodes(e, {
    maxLevel: $max_hops,
    relationshipFilter: "RELATES_TO"
})
YIELD node
RETURN collect(distinct node) AS neighbors
```

### ç¤¾åŒºèšåˆ

```cypher
-- è·å–å®ä½“æ‰€å±ç¤¾åŒºçš„æ‰€æœ‰å®ä½“
MATCH (e:`__Entity__` {id: $entity})-[:IN_COMMUNITY]->(c:`__Community__`)
MATCH (c)<-[:IN_COMMUNITY]-(other:`__Entity__`)
RETURN collect(distinct other) AS community_members
```

---

## æ€§èƒ½ä¼˜åŒ–

### ç¼“å­˜ç­–ç•¥

```python
class SearchCache:
    def __init__(self):
        self.cache = {}

    def get(self, key: str) -> Optional[str]:
        """è·å–ç¼“å­˜"""
        return self.cache.get(key)

    def set(self, key: str, value: str):
        """è®¾ç½®ç¼“å­˜"""
        self.cache[key] = value

# ä½¿ç”¨ç¼“å­˜
cache = SearchCache()

def search_with_cache(query: str) -> str:
    # æ£€æŸ¥ç¼“å­˜
    cached_result = cache.get(query)
    if cached_result:
        return cached_result

    # æ‰§è¡Œæœç´¢
    result = search(query)

    # ç¼“å­˜ç»“æœ
    cache.set(query, result)

    return result
```

### æ‰¹é‡æŸ¥è¯¢

```python
def batch_search(queries: List[str]) -> List[str]:
    """æ‰¹é‡æœç´¢ï¼ˆå¹¶è¡Œï¼‰"""
    with ThreadPoolExecutor(max_workers=4) as executor:
        futures = [executor.submit(search, q) for q in queries]
        results = [f.result() for f in futures]

    return results
```

### æŸ¥è¯¢ä¼˜åŒ–

```cypher
-- ä½¿ç”¨ç´¢å¼•åŠ é€ŸæŸ¥è¯¢
CREATE INDEX entity_type_index IF NOT EXISTS
FOR (e:`__Entity__`) ON (e.type);

-- ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢
MATCH (e:`__Entity__`)
WHERE e.type = $entity_type
RETURN e
```

---

## é…ç½®å‚æ•°

### Local Search é…ç½®

```python
LOCAL_SEARCH_SETTINGS = {
    "top_chunks": 5,                 # æ£€ç´¢çš„ Chunk æ•°é‡
    "top_communities": 3,            # æ£€ç´¢çš„ç¤¾åŒºæ•°é‡
    "top_outside_relationships": 10, # å¤–éƒ¨å…³ç³»æ•°é‡
    "top_inside_relationships": 10,  # å†…éƒ¨å…³ç³»æ•°é‡
    "top_entities": 5,               # æ£€ç´¢çš„å®ä½“æ•°é‡
    "index_name": "entity_index"     # å‘é‡ç´¢å¼•åç§°
}
```

### Hybrid Search é…ç½®

```python
HYBRID_SEARCH_SETTINGS = {
    "entity_limit": 10,         # å®ä½“æ£€ç´¢æ•°é‡
    "max_hop_distance": 2,      # æœ€å¤§è·³æ•°
    "top_communities": 5,       # ç¤¾åŒºæ•°é‡
    "batch_size": 100,          # æ‰¹å¤„ç†å¤§å°
    "community_level": 0,       # ç¤¾åŒºå±‚çº§
    "vector_weight": 0.6,       # å‘é‡æƒé‡
    "graph_weight": 0.4         # å›¾è°±æƒé‡
}
```

### Deep Research é…ç½®

```python
DEEP_RESEARCH_SETTINGS = {
    "max_iterations": 3,        # æœ€å¤§è¿­ä»£æ¬¡æ•°
    "max_exploration_depth": 3, # å›¾è°±æ¢ç´¢æ·±åº¦
    "evidence_threshold": 5     # è¯æ®æ•°é‡é˜ˆå€¼
}
```

---

## ç›¸å…³æ–‡æ¡£

- [Agentç³»ç»Ÿ](./Agentç³»ç»Ÿ.md) - äº†è§£å¦‚ä½•å°†æœç´¢å¼•æ“é›†æˆåˆ° Agent
- [çŸ¥è¯†å›¾è°±æ„å»º](./çŸ¥è¯†å›¾è°±æ„å»º.md) - äº†è§£æœç´¢çš„æ•°æ®æ¥æº
- [ç³»ç»Ÿæ¶æ„æ€»è§ˆ](../01-æ•´ä½“æ¶æ„/ç³»ç»Ÿæ¶æ„æ€»è§ˆ.md) - äº†è§£æ•´ä½“æ¶æ„
- [Neo4j Cypher æ–‡æ¡£](https://neo4j.com/docs/cypher-manual/) - Cypher æŸ¥è¯¢è¯­è¨€
- [LangChain Retrieval æ–‡æ¡£](https://python.langchain.com/docs/modules/data_connection/) - æ£€ç´¢æ¨¡å—

---

## æ›´æ–°æ—¥å¿—

| ç‰ˆæœ¬ | æ—¥æœŸ | æ›´æ–°å†…å®¹ | ä½œè€… |
|------|------|----------|------|
| 1.0 | 2026-01-04 | åˆå§‹ç‰ˆæœ¬ï¼Œå®Œæ•´è¦†ç›–4ç§æœç´¢ç­–ç•¥ | Claude |
| - | - | - | - |
