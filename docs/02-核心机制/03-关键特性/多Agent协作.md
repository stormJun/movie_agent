# å¤š Agent åä½œ

> **ç›®æ ‡è¯»è€…**ï¼šæ¶æ„å¸ˆã€å¼€å‘è€…
> **é˜…è¯»æ—¶é—´**ï¼š45 åˆ†é’Ÿ
> **å‰ç½®çŸ¥è¯†**ï¼šäº†è§£ Agent ç³»ç»Ÿã€LangGraph åŸºç¡€
> **éš¾åº¦ç­‰çº§**ï¼šâ­â­â­â­

## ğŸ“‹ æœ¬æ–‡å¤§çº²

- [1. ä¸ºä»€ä¹ˆéœ€è¦å¤š Agent åä½œ](#1-ä¸ºä»€ä¹ˆéœ€è¦å¤š-agent-åä½œ)
- [2. Plan-Execute-Report æ¶æ„](#2-plan-execute-report-æ¶æ„)
- [3. Plan é˜¶æ®µï¼šä»»åŠ¡è§„åˆ’](#3-plan-é˜¶æ®µä»»åŠ¡è§„åˆ’)
  - [3.1 Clarifierï¼šæ„å›¾æ¾„æ¸…](#31-clarifieræ„å›¾æ¾„æ¸…)
  - [3.2 TaskDecomposerï¼šä»»åŠ¡åˆ†è§£](#32-taskdecomposerä»»åŠ¡åˆ†è§£)
  - [3.3 PlanReviewerï¼šè®¡åˆ’å®¡æŸ¥](#33-planreviewerè®¡åˆ’å®¡æŸ¥)
- [4. Execute é˜¶æ®µï¼šä»»åŠ¡æ‰§è¡Œ](#4-execute-é˜¶æ®µä»»åŠ¡æ‰§è¡Œ)
  - [4.1 WorkerCoordinatorï¼šå·¥ä½œåè°ƒ](#41-workercoordinatorå·¥ä½œåè°ƒ)
  - [4.2 ä¿¡å·ç³»ç»Ÿ](#42-ä¿¡å·ç³»ç»Ÿ)
  - [4.3 å¹¶è¡Œæ‰§è¡Œ](#43-å¹¶è¡Œæ‰§è¡Œ)
- [5. Report é˜¶æ®µï¼šæŠ¥å‘Šç”Ÿæˆ](#5-report-é˜¶æ®µæŠ¥å‘Šç”Ÿæˆ)
  - [5.1 OutlineBuilderï¼šå¤§çº²æ„å»º](#51-outlinebuilderå¤§çº²æ„å»º)
  - [5.2 SectionWriterï¼šç« èŠ‚å†™ä½œ](#52-sectionwriterç« èŠ‚å†™ä½œ)
  - [5.3 ConsistencyCheckerï¼šä¸€è‡´æ€§æ£€æŸ¥](#53-consistencycheckerä¸€è‡´æ€§æ£€æŸ¥)
- [6. FusionGraphRAGAgent å®ç°](#6-fusiongraphragagent-å®ç°)
- [7. ä¸å• Agent çš„å¯¹æ¯”](#7-ä¸å•-agent-çš„å¯¹æ¯”)
- [8. é€‚ç”¨åœºæ™¯](#8-é€‚ç”¨åœºæ™¯)
- [9. é…ç½®ä¸ä½¿ç”¨](#9-é…ç½®ä¸ä½¿ç”¨)

---

## 1. ä¸ºä»€ä¹ˆéœ€è¦å¤š Agent åä½œ

### 1.1 å• Agent çš„å±€é™

ä¼ ç»Ÿçš„å• Agent æ¶æ„ï¼ˆå¦‚ NaiveRagAgentã€GraphAgentã€HybridAgentï¼‰åœ¨å¤„ç†ç®€å•åˆ°ä¸­ç­‰å¤æ‚åº¦çš„é—®é¢˜æ—¶è¡¨ç°è‰¯å¥½ï¼Œä½†é¢å¯¹çœŸæ­£å¤æ‚çš„ä»»åŠ¡æ—¶ä¼šé‡åˆ°ä»¥ä¸‹ç“¶é¢ˆï¼š

#### 1.1.1 å¤æ‚ä»»åŠ¡éš¾ä»¥å¤„ç†

**é—®é¢˜ç¤ºä¾‹**ï¼š
```
ç”¨æˆ·é—®é¢˜ï¼š"è¯·æ’°å†™ä¸€ç¯‡å…³äºåä¸œç†å·¥å¤§å­¦å­¦ç”Ÿå¥–å­¦é‡‘ä½“ç³»çš„å®Œæ•´åˆ†ææŠ¥å‘Šï¼Œ
åŒ…æ‹¬å„ç±»å¥–å­¦é‡‘çš„è®¾ç«‹ç›®çš„ã€ç”³è¯·æ¡ä»¶ã€è¯„å®¡æµç¨‹ã€äº’æ–¥å…³ç³»ã€èµ„é‡‘æ¥æºã€
è¦†ç›–èŒƒå›´ï¼Œå¹¶æå‡ºæ”¹è¿›å»ºè®®ã€‚"
```

**å• Agent çš„å›°å¢ƒ**ï¼š
- æ— æ³•å°†ä»»åŠ¡åˆ†è§£ä¸ºç»“æ„åŒ–çš„å­ä»»åŠ¡
- æ‰€æœ‰å·¥ä½œåœ¨ä¸€ä¸ªæ¨ç†é“¾ä¸­å®Œæˆï¼Œå®¹æ˜“é—æ¼å…³é”®ç»´åº¦
- LLM ä¸Šä¸‹æ–‡çª—å£æœ‰é™ï¼Œéš¾ä»¥åŒæ—¶å¤„ç†å¤šä¸ªç»´åº¦çš„ä¿¡æ¯

#### 1.1.2 æ¨ç†é“¾è¿‡é•¿å®¹æ˜“å‡ºé”™

**Chain of Thought çš„å±€é™**ï¼š

```mermaid
graph LR
    Q[å¤æ‚é—®é¢˜] --> T1[æ€è€ƒ1] --> T2[æ€è€ƒ2] --> T3[æ€è€ƒ3] --> T4[æ€è€ƒ4] --> T5[æ€è€ƒ5]
    T5 --> T6[æ€è€ƒ6] --> T7[æ€è€ƒ7] --> E[å‡ºé”™/åç¦»ä¸»é¢˜]

    style E fill:#ffebee
```

å• Agent çš„æ¨ç†é“¾è¶…è¿‡ 5-7 æ­¥åï¼Œå®¹æ˜“å‡ºç°ï¼š
- é—å¿˜æœ€åˆçš„é—®é¢˜ç›®æ ‡
- æ¨ç†åç¦»ä¸»é¢˜
- ä¿¡æ¯å†—ä½™æˆ–é—æ¼

#### 1.1.3 æ— æ³•ç”Ÿæˆé•¿æ–‡æ¡£

**é•¿æ–‡æ¡£ç”Ÿæˆçš„æŒ‘æˆ˜**ï¼š

| æ–‡æ¡£é•¿åº¦ | å• Agent è¡¨ç° | ä¸»è¦é—®é¢˜ |
|---------|-------------|---------|
| < 500 å­— | ä¼˜ç§€ | æ— æ˜æ˜¾é—®é¢˜ |
| 500-1500 å­— | è‰¯å¥½ | ç»“æ„æ¾æ•£ï¼Œç¼ºä¹å±‚æ¬¡ |
| 1500-3000 å­— | ä¸€èˆ¬ | é‡å¤å†…å®¹å¤šï¼Œé€»è¾‘è·³è·ƒ |
| > 3000 å­— | å·® | æ— æ³•å®Œæˆæˆ–è´¨é‡æä½ |

**æ ¹æœ¬åŸå› **ï¼š
- LLM è¾“å‡ºé•¿åº¦é™åˆ¶ï¼ˆé€šå¸¸ 2000-4000 tokensï¼‰
- æ— ç« èŠ‚è§„åˆ’èƒ½åŠ›
- ç¼ºä¹ Map-Reduce å¼çš„å†…å®¹æ•´åˆæœºåˆ¶

#### 1.1.4 ç¼ºä¹ä¸“ä¸šåˆ†å·¥

å• Agent éœ€è¦åŒæ—¶æ‰¿æ‹…ï¼š
- é—®é¢˜ç†è§£
- æ£€ç´¢ç­–ç•¥é€‰æ‹©
- è¯æ®æ”¶é›†
- æ¨ç†æ•´åˆ
- ç­”æ¡ˆç”Ÿæˆ
- è´¨é‡æ£€æŸ¥

è¿™ç§"å…¨èƒ½å‹"è®¾è®¡å¯¼è‡´æ¯ä¸ªç¯èŠ‚éƒ½éš¾ä»¥åšåˆ°æè‡´ã€‚

### 1.2 å¤š Agent çš„ä¼˜åŠ¿

å¤š Agent åä½œç³»ç»Ÿé€šè¿‡ **åˆ†å·¥åä½œ** å’Œ **ä¸“ä¸šåŒ–** è§£å†³äº†ä¸Šè¿°é—®é¢˜ï¼š

#### 1.2.1 ä»»åŠ¡åˆ†è§£ä¸ä¸“ä¸šåŒ–

```mermaid
graph TB
    Complex[å¤æ‚ä»»åŠ¡] --> Plan[Planner<br/>ä¸“æ³¨äºä»»åŠ¡åˆ†è§£]
    Plan --> T1[å­ä»»åŠ¡1]
    Plan --> T2[å­ä»»åŠ¡2]
    Plan --> T3[å­ä»»åŠ¡3]

    T1 --> E1[Retrieval Executor<br/>ä¸“æ³¨äºæ£€ç´¢]
    T2 --> E2[Research Executor<br/>ä¸“æ³¨äºæ·±åº¦ç ”ç©¶]
    T3 --> E3[Reflection Executor<br/>ä¸“æ³¨äºè´¨é‡è¯„ä¼°]

    E1 --> Report[Reporter<br/>ä¸“æ³¨äºæŠ¥å‘Šç”Ÿæˆ]
    E2 --> Report
    E3 --> Report

    style Plan fill:#e3f2fd
    style E1 fill:#fff3e0
    style E2 fill:#fff3e0
    style E3 fill:#fff3e0
    style Report fill:#e8f5e9
```

**ä¸“ä¸šåŒ–çš„å¥½å¤„**ï¼š
- æ¯ä¸ª Agent ä¸“æ³¨äºæ“…é•¿çš„é¢†åŸŸï¼Œæå‡å•ç‚¹èƒ½åŠ›
- é€šè¿‡ç»„åˆå®ç°å¤æ‚èƒ½åŠ›ï¼Œè€Œéä¾èµ–å•ä¸€"å…¨èƒ½" Agent
- ä¾¿äºç‹¬ç«‹ä¼˜åŒ–å’Œå‡çº§

#### 1.2.2 å¹¶è¡Œæ‰§è¡Œæå‡æ•ˆç‡

**ä¸²è¡Œ vs å¹¶è¡Œ**ï¼š

```mermaid
gantt
    title å• Agent vs å¤š Agent æ‰§è¡Œæ—¶é—´å¯¹æ¯”
    dateFormat  ss
    axisFormat %Sç§’

    section å• Agent
    å­ä»»åŠ¡1 :a1, 00, 5s
    å­ä»»åŠ¡2 :a2, after a1, 5s
    å­ä»»åŠ¡3 :a3, after a2, 5s
    ç”Ÿæˆç­”æ¡ˆ :a4, after a3, 3s

    section å¤š Agent
    å­ä»»åŠ¡1 :b1, 00, 5s
    å­ä»»åŠ¡2 :b2, 00, 5s
    å­ä»»åŠ¡3 :b3, 00, 5s
    ç”Ÿæˆç­”æ¡ˆ :b4, after b1 b2 b3, 3s
```

**æ—¶é—´èŠ‚çœ**ï¼š
- å• Agentï¼š5 + 5 + 5 + 3 = 18 ç§’
- å¤š Agentï¼ˆå¹¶è¡Œï¼‰ï¼šmax(5, 5, 5) + 3 = 8 ç§’
- æå‡ï¼š55% çš„æ—¶é—´èŠ‚çœ

#### 1.2.3 è§’è‰²åˆ†å·¥æå‡è´¨é‡

**è´¨é‡ä¿éšœæœºåˆ¶**ï¼š

| è§’è‰² | èŒè´£ | è´¨é‡æå‡ç‚¹ |
|------|------|-----------|
| **Clarifier** | æ¾„æ¸…æ¨¡ç³Šé—®é¢˜ | é¿å…ç†è§£åå·® |
| **TaskDecomposer** | ç»“æ„åŒ–åˆ†è§£ | ç¡®ä¿é—®é¢˜è¦†ç›–å®Œæ•´ |
| **PlanReviewer** | è®¡åˆ’å®¡æŸ¥ | å‘ç°åˆ†è§£ä¸­çš„é—æ¼å’Œå†—ä½™ |
| **RetrievalExecutor** | ç²¾å‡†æ£€ç´¢ | ä¸“æ³¨äºå¬å›ç‡å’Œå‡†ç¡®ç‡ |
| **ResearchExecutor** | æ·±åº¦ç ”ç©¶ | ä¸“æ³¨äºæ¨ç†æ·±åº¦ |
| **ReflectionExecutor** | è´¨é‡åæ€ | å‘ç°ä½è´¨é‡ç»“æœå¹¶è§¦å‘é‡è¯• |
| **ConsistencyChecker** | ä¸€è‡´æ€§æ£€æŸ¥ | éªŒè¯å¼•ç”¨ã€é€»è¾‘ä¸€è‡´æ€§ |

è¿™ç§ **å¤šå±‚è´¨é‡æŠŠå…³** æœºåˆ¶æ˜¯å• Agent æ— æ³•å®ç°çš„ã€‚

#### 1.2.4 å¯æ‰©å±•æ€§å¼º

**æ¨¡å—åŒ–è®¾è®¡çš„ä¼˜åŠ¿**ï¼š

```python
# æ·»åŠ æ–°çš„ Executor éå¸¸ç®€å•
class CustomExecutor(BaseExecutor):
    def can_handle(self, task_type: str) -> bool:
        return task_type == "my_custom_task"

    def execute_task(self, task, state, signal):
        # è‡ªå®šä¹‰æ‰§è¡Œé€»è¾‘
        pass

# æ³¨å†Œåˆ° WorkerCoordinator
coordinator.register_executor(CustomExecutor())
```

æ— éœ€ä¿®æ”¹æ ¸å¿ƒæ¡†æ¶ï¼Œå³å¯æ‰©å±•æ–°èƒ½åŠ›

---

## 2. Plan-Execute-Report æ¶æ„

### 2.1 æ•´ä½“æµç¨‹

Plan-Execute-Reportï¼ˆPERï¼‰æ¶æ„æ˜¯æœ¬é¡¹ç›®å¤š Agent ç³»ç»Ÿçš„æ ¸å¿ƒè®¾è®¡æ¨¡å¼ï¼Œå°†å¤æ‚ä»»åŠ¡çš„å¤„ç†åˆ†ä¸ºä¸‰ä¸ªæ¸…æ™°çš„é˜¶æ®µï¼š

```mermaid
graph TD
    A[ç”¨æˆ·é—®é¢˜] --> B[Plan é˜¶æ®µ]

    subgraph Plan[Plan é˜¶æ®µ]
        C[Clarifier<br/>æ„å›¾æ¾„æ¸…]
        D[TaskDecomposer<br/>ä»»åŠ¡åˆ†è§£]
        E[PlanReviewer<br/>è®¡åˆ’å®¡æŸ¥]
        C --> D --> E
    end

    B --> Plan
    Plan --> F[PlanSpec<br/>æ‰§è¡Œè®¡åˆ’]

    F --> G[Execute é˜¶æ®µ]

    subgraph Execute[Execute é˜¶æ®µ]
        H[WorkerCoordinator<br/>ä»»åŠ¡è°ƒåº¦]
        I1[Retrieval Worker]
        I2[Research Worker]
        I3[Reflection Worker]
        H --> I1
        H --> I2
        H --> I3
    end

    G --> Execute
    Execute --> J[ExecutionRecords<br/>æ‰§è¡Œè®°å½•]

    J --> K[Report é˜¶æ®µ]

    subgraph Report[Report é˜¶æ®µ]
        L[OutlineBuilder<br/>å¤§çº²æ„å»º]
        M[SectionWriter<br/>ç« èŠ‚å†™ä½œ]
        N[ConsistencyChecker<br/>ä¸€è‡´æ€§æ£€æŸ¥]
        L --> M --> N
    end

    K --> Report
    Report --> O[æœ€ç»ˆæŠ¥å‘Š]

    style Plan fill:#e3f2fd,stroke:#0066cc
    style Execute fill:#fff3e0,stroke:#ff9800
    style Report fill:#e8f5e9,stroke:#4caf50
```

**å…³é”®ç‰¹ç‚¹**ï¼š
- **å•å‘æ•°æ®æµ**ï¼šPlan â†’ Execute â†’ Reportï¼ŒèŒè´£æ¸…æ™°ï¼Œæ— å¾ªç¯ä¾èµ–
- **é˜¶æ®µè§£è€¦**ï¼šæ¯ä¸ªé˜¶æ®µå¯ç‹¬ç«‹ä¼˜åŒ–å’Œæµ‹è¯•
- **æ ‡å‡†æ¥å£**ï¼šé˜¶æ®µé—´é€šè¿‡è§„èŒƒåŒ–çš„æ•°æ®ç»“æ„é€šä¿¡ï¼ˆPlanSpecã€ExecutionRecordsï¼‰

### 2.2 ä¸‰é˜¶æ®µèŒè´£

| é˜¶æ®µ | æ ¸å¿ƒèŒè´£ | è¾“å…¥ | è¾“å‡º | ä¸»è¦ç»„ä»¶ |
|------|---------|------|------|---------|
| **Plan** | å°†ç”¨æˆ·é—®é¢˜è½¬åŒ–ä¸ºç»“æ„åŒ–çš„æ‰§è¡Œè®¡åˆ’ | `PlanExecuteState`ï¼ˆåŒ…å«åŸå§‹æŸ¥è¯¢ï¼‰ | `PlanSpec`ï¼ˆä»»åŠ¡å›¾ + æ‰§è¡Œä¿¡å·ï¼‰ | Clarifier<br/>TaskDecomposer<br/>PlanReviewer |
| **Execute** | æŒ‰è®¡åˆ’å¹¶è¡Œ/ä¸²è¡Œæ‰§è¡Œä»»åŠ¡ï¼Œæ”¶é›†è¯æ® | `PlanExecutionSignal` | `List[ExecutionRecord]`ï¼ˆæ‰§è¡Œè®°å½• + è¯æ®ï¼‰ | WorkerCoordinator<br/>RetrievalExecutor<br/>ResearchExecutor<br/>ReflectionExecutor |
| **Report** | å°†æ‰§è¡Œç»“æœæ•´åˆä¸ºç»“æ„åŒ–æŠ¥å‘Š | `ExecutionRecords` + `PlanSpec` | `ReportResult`ï¼ˆæœ€ç»ˆæŠ¥å‘Šï¼‰ | OutlineBuilder<br/>SectionWriter<br/>ConsistencyChecker |

**è®¾è®¡åŸåˆ™**ï¼š
1. **Plan é˜¶æ®µæ³¨é‡"åˆ†è§£"**ï¼šå°†å¤æ‚é—®é¢˜æ‹†è§£ä¸ºå¯æ‰§è¡Œçš„åŸå­ä»»åŠ¡
2. **Execute é˜¶æ®µæ³¨é‡"å¹¶è¡Œ"**ï¼šå……åˆ†åˆ©ç”¨å¤šæ ¸èµ„æºï¼Œæå‡æ‰§è¡Œæ•ˆç‡
3. **Report é˜¶æ®µæ³¨é‡"æ•´åˆ"**ï¼šMap-Reduce å¼çš„å†…å®¹èšåˆï¼Œæ”¯æŒé•¿æ–‡æ¡£ç”Ÿæˆ

### 2.3 æ•°æ®æµ

#### 2.3.1 æ ¸å¿ƒæ•°æ®ç»“æ„

**PlanExecuteStateï¼ˆå…¨å±€çŠ¶æ€ï¼‰**ï¼š
```python
@dataclass
class PlanExecuteState:
    """è´¯ç©¿æ•´ä¸ªæµç¨‹çš„å…¨å±€çŠ¶æ€"""
    session_id: str                         # ä¼šè¯ID
    original_query: str                     # åŸå§‹æŸ¥è¯¢
    refined_query: Optional[str]            # æ¾„æ¸…åçš„æŸ¥è¯¢
    plan: Optional[PlanSpec]                # æ‰§è¡Œè®¡åˆ’
    execution_records: List[ExecutionRecord]  # æ‰§è¡Œè®°å½•
    evidence_map: Dict[str, RetrievalResult]  # è¯æ®ç´¢å¼•
    execution_context: Optional[ExecutionContext]  # æ‰§è¡Œä¸Šä¸‹æ–‡
    plan_context: PlanContext               # è§„åˆ’ä¸Šä¸‹æ–‡
```

**PlanSpecï¼ˆæ‰§è¡Œè®¡åˆ’ï¼‰**ï¼š
```python
@dataclass
class PlanSpec:
    """Plan é˜¶æ®µè¾“å‡ºçš„æ‰§è¡Œè®¡åˆ’"""
    plan_id: str                            # è®¡åˆ’ID
    problem_statement: ProblemStatement     # é—®é¢˜é™ˆè¿°
    task_graph: TaskGraph                   # ä»»åŠ¡ä¾èµ–å›¾
    acceptance_criteria: AcceptanceCriteria # éªŒæ”¶æ ‡å‡†
    status: str                             # è®¡åˆ’çŠ¶æ€

    def to_execution_signal(self) -> PlanExecutionSignal:
        """è½¬æ¢ä¸ºæ‰§è¡Œä¿¡å·"""
        pass
```

**ExecutionRecordï¼ˆæ‰§è¡Œè®°å½•ï¼‰**ï¼š
```python
@dataclass
class ExecutionRecord:
    """Execute é˜¶æ®µè¾“å‡ºçš„å•æ¬¡ä»»åŠ¡æ‰§è¡Œè®°å½•"""
    record_id: str                          # è®°å½•ID
    task_id: str                            # å…³è”ä»»åŠ¡ID
    worker_type: str                        # æ‰§è¡Œå™¨ç±»å‹
    tool_calls: List[ToolCall]              # å·¥å…·è°ƒç”¨åˆ—è¡¨
    evidence: List[RetrievalResult]         # æ£€ç´¢åˆ°çš„è¯æ®
    reflection: Optional[ReflectionResult]  # åæ€ç»“æœ
    metadata: ExecutionMetadata             # å…ƒæ•°æ®ï¼ˆå»¶è¿Ÿã€Tokenæ¶ˆè€—ç­‰ï¼‰
```

#### 2.3.2 æ•°æ®æµè½¬å›¾

```mermaid
sequenceDiagram
    participant U as ç”¨æˆ·
    participant O as Orchestrator
    participant P as Planner
    participant E as Executor
    participant R as Reporter

    U->>O: æäº¤é—®é¢˜

    Note over O,P: Plan é˜¶æ®µ
    O->>P: PlanExecuteState
    P->>P: Clarifier.analyze()
    P->>P: TaskDecomposer.decompose()
    P->>P: PlanReviewer.review()
    P-->>O: PlanSpec

    Note over O,E: Execute é˜¶æ®µ
    O->>E: PlanExecutionSignal

    par å¹¶è¡Œæ‰§è¡Œ
        E->>E: RetrievalExecutor
        E->>E: ResearchExecutor
        E->>E: ReflectionExecutor
    end

    E-->>O: List[ExecutionRecord]

    Note over O,R: Report é˜¶æ®µ
    O->>R: ExecutionRecords + PlanSpec
    R->>R: OutlineBuilder.build()
    R->>R: SectionWriter.write()
    R->>R: ConsistencyChecker.check()
    R-->>O: ReportResult

    O-->>U: æœ€ç»ˆæŠ¥å‘Š
```

**å…³é”®ç‚¹**ï¼š
- State åœ¨å„é˜¶æ®µé—´å…±äº«ï¼Œä½†æ¯é˜¶æ®µåªè¯»å†™è‡ªå·±èŒè´£èŒƒå›´å†…çš„å­—æ®µ
- é€šè¿‡ `PlanExecutionSignal` å’Œ `ExecutionRecords` è§£è€¦é˜¶æ®µé—´çš„ç›´æ¥ä¾èµ–
- æ”¯æŒä¸­é—´ç»“æœç¼“å­˜å’Œæ–­ç‚¹ç»­ä¼ 

---

## 3. Plan é˜¶æ®µï¼šä»»åŠ¡è§„åˆ’

Plan é˜¶æ®µæ˜¯å¤š Agent åä½œçš„èµ·ç‚¹ï¼Œè´Ÿè´£å°†ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€é—®é¢˜è½¬åŒ–ä¸ºç»“æ„åŒ–çš„æ‰§è¡Œè®¡åˆ’ã€‚

### 3.1 Clarifierï¼šæ„å›¾æ¾„æ¸…

#### 3.1.1 èŒè´£

Clarifier é€šè¿‡ LLM åˆ†æç”¨æˆ·æŸ¥è¯¢ï¼Œè¯†åˆ«æ½œåœ¨çš„æ¨¡ç³Šç‚¹å¹¶ç”Ÿæˆæ¾„æ¸…é—®é¢˜ï¼š

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
- æ£€æµ‹æŸ¥è¯¢ä¸­çš„æ­§ä¹‰ï¼ˆæ—¶é—´èŒƒå›´ã€å…·ä½“å¯¹è±¡ã€éœ€æ±‚æ·±åº¦ï¼‰
- ç”Ÿæˆé’ˆå¯¹æ€§çš„æ¾„æ¸…é—®é¢˜åˆ—è¡¨
- è¿”å›æ¨¡ç³Šç±»å‹æ ‡ç­¾ï¼ˆä¾¿äºåç»­å¤„ç†ï¼‰

#### 3.1.2 å·¥ä½œæµç¨‹

```mermaid
graph TD
    Q[ç”¨æˆ·æŸ¥è¯¢] --> C{Clarifieråˆ†æ}
    C -->|æ˜ç¡®| Clear[æ— éœ€æ¾„æ¸…<br/>ç»§ç»­ä»»åŠ¡åˆ†è§£]
    C -->|æ¨¡ç³Š| Ambiguous[ç”Ÿæˆæ¾„æ¸…é—®é¢˜]

    Ambiguous --> Check{ç”¨æˆ·æ˜¯å¦<br/>æä¾›å‡è®¾?}
    Check -->|æ˜¯| Use[ä½¿ç”¨å‡è®¾ç»§ç»­]
    Check -->|å¦| Ask[è¿”å›æ¾„æ¸…é—®é¢˜<br/>ç­‰å¾…ç”¨æˆ·å›ç­”]

    Use --> Clear
    Ask --> Answer[ç”¨æˆ·å›ç­”]
    Answer --> Clear

    style Ambiguous fill:#fff3e0
    style Ask fill:#ffebee
    style Clear fill:#e8f5e9
```

#### 3.1.3 å®ç°ä»£ç 

```python
# backend/graphrag_agent/agents/multi_agent/planner/clarifier.py

class Clarifier:
    """æŸ¥è¯¢æ¾„æ¸…èŠ‚ç‚¹"""

    def __init__(self, llm: Optional[BaseChatModel] = None):
        self._llm = llm or get_llm_model()

    def analyze(self, context: PlanContext) -> ClarificationResult:
        """
        åˆ†ææŸ¥è¯¢æ˜¯å¦éœ€è¦æ¾„æ¸…

        å‚æ•°:
            context: Planner å½“å‰ä¸Šä¸‹æ–‡

        è¿”å›:
            ClarificationResult
        """
        # æ„é€  Prompt
        prompt = CLARIFY_PROMPT.format(
            query=context.refined_query or context.original_query,
            domain=context.domain_context or "é€šç”¨",
        )

        # è°ƒç”¨ LLM
        response = self._invoke_llm(prompt)

        # è§£æ JSON è¾“å‡º
        parsed = parse_json_text(response)

        return ClarificationResult(
            needs_clarification=parsed.get("needs_clarification", False),
            questions=parsed.get("questions", []),
            ambiguity_types=parsed.get("ambiguity_types", []),
            raw_response=response
        )
```

**ClarificationResult æ•°æ®ç»“æ„**ï¼š
```python
class ClarificationResult(BaseModel):
    """æ¾„æ¸…ç»“æœ"""
    needs_clarification: bool           # æ˜¯å¦éœ€è¦æ¾„æ¸…
    questions: List[str]                # æ¾„æ¸…é—®é¢˜åˆ—è¡¨
    ambiguity_types: List[str]          # æ¨¡ç³Šç±»å‹ï¼ˆå¦‚"æ—¶é—´èŒƒå›´"ã€"å…·ä½“å¯¹è±¡"ï¼‰
    raw_response: Optional[str]         # LLM åŸå§‹è¾“å‡º
```

#### 3.1.4 Prompt ç¤ºä¾‹

```python
CLARIFY_PROMPT = """
åˆ†æä»¥ä¸‹æŸ¥è¯¢æ˜¯å¦å­˜åœ¨æ¨¡ç³Šä¸æ¸…ä¹‹å¤„ï¼š

ã€æŸ¥è¯¢ã€‘{query}
ã€é¢†åŸŸã€‘{domain}

è¯·åˆ¤æ–­ï¼š
1. æŸ¥è¯¢æ˜¯å¦è¶³å¤Ÿæ˜ç¡®ï¼Ÿ
2. å¦‚æœå­˜åœ¨æ¨¡ç³Šï¼Œå…·ä½“æ˜¯ä»€ä¹ˆç±»å‹çš„æ¨¡ç³Šï¼ˆæ—¶é—´èŒƒå›´ã€å…·ä½“å¯¹è±¡ã€éœ€æ±‚æ·±åº¦ç­‰ï¼‰ï¼Ÿ
3. éœ€è¦å‘ç”¨æˆ·æå‡ºå“ªäº›æ¾„æ¸…é—®é¢˜ï¼Ÿ

è¾“å‡º JSON æ ¼å¼ï¼š
{{
    "needs_clarification": true/false,
    "ambiguity_types": ["ç±»å‹1", "ç±»å‹2"],
    "questions": ["é—®é¢˜1", "é—®é¢˜2"]
}}
"""
```

#### 3.1.5 å®é™…æ¡ˆä¾‹

**æ¡ˆä¾‹1ï¼šæ—¶é—´èŒƒå›´æ¨¡ç³Š**
```json
{
    "åŸå§‹æŸ¥è¯¢": "å¥–å­¦é‡‘è¯„å®šæµç¨‹æ˜¯ä»€ä¹ˆï¼Ÿ",
    "æ¾„æ¸…ç»“æœ": {
        "needs_clarification": true,
        "ambiguity_types": ["æ—¶é—´èŒƒå›´"],
        "questions": [
            "æ‚¨æƒ³äº†è§£çš„æ˜¯å½“å‰å­¦å¹´çš„å¥–å­¦é‡‘è¯„å®šæµç¨‹ï¼Œè¿˜æ˜¯å†å¹´çš„å˜åŒ–æƒ…å†µï¼Ÿ"
        ]
    }
}
```

**æ¡ˆä¾‹2ï¼šå¯¹è±¡ä¸æ˜ç¡®**
```json
{
    "åŸå§‹æŸ¥è¯¢": "å¥–å­¦é‡‘ç”³è¯·æ¡ä»¶",
    "æ¾„æ¸…ç»“æœ": {
        "needs_clarification": true,
        "ambiguity_types": ["å…·ä½“å¯¹è±¡"],
        "questions": [
            "æ‚¨æƒ³äº†è§£å“ªä¸€ç±»å¥–å­¦é‡‘çš„ç”³è¯·æ¡ä»¶ï¼Ÿï¼ˆå›½å®¶å¥–å­¦é‡‘/å›½å®¶åŠ±å¿—å¥–å­¦é‡‘/æ ¡å†…å¥–å­¦é‡‘ï¼‰"
        ]
    }
}
```

**æ¡ˆä¾‹3ï¼šæ˜ç¡®æŸ¥è¯¢**
```json
{
    "åŸå§‹æŸ¥è¯¢": "æ—·è¯¾ç´¯è®¡è¾¾åˆ°50å­¦æ—¶ä¼šå—åˆ°ä»€ä¹ˆå¤„åˆ†ï¼Ÿ",
    "æ¾„æ¸…ç»“æœ": {
        "needs_clarification": false,
        "ambiguity_types": [],
        "questions": []
    }
}
```

### 3.2 TaskDecomposerï¼šä»»åŠ¡åˆ†è§£

#### 3.2.1 èŒè´£

TaskDecomposer å°†æ¾„æ¸…åçš„æŸ¥è¯¢æ‹†è§£ä¸ºç»“æ„åŒ–çš„ä»»åŠ¡å›¾ï¼ˆTaskGraphï¼‰ï¼Œæ¯ä¸ªä»»åŠ¡å¯¹åº”ä¸€ä¸ªå¯æ‰§è¡Œçš„åŸå­æ“ä½œã€‚

**åˆ†è§£ç­–ç•¥**ï¼š
- è¯†åˆ«é—®é¢˜ä¸­çš„å¤šä¸ªç»´åº¦ï¼ˆå¦‚"ç”³è¯·æ¡ä»¶"ã€"è¯„å®¡æµç¨‹"ã€"äº’æ–¥å…³ç³»"ï¼‰
- æ¯ä¸ªç»´åº¦å¯¹åº”ä¸€ä¸ªå­ä»»åŠ¡
- åˆ†æä»»åŠ¡é—´çš„ä¾èµ–å…³ç³»ï¼ˆå¦‚"å¿…é¡»å…ˆæ£€ç´¢è§„å®šï¼Œå†åˆ†æäº’æ–¥å…³ç³»"ï¼‰
- ä¸ºæ¯ä¸ªä»»åŠ¡é€‰æ‹©åˆé€‚çš„å·¥å…·ç±»å‹ï¼ˆlocal_searchã€global_searchã€deep_research ç­‰ï¼‰

#### 3.2.2 ä»»åŠ¡å›¾ç»“æ„

ä»»åŠ¡ä¾èµ–å›¾ï¼ˆTaskGraphï¼‰ä½¿ç”¨ **DAGï¼ˆæœ‰å‘æ— ç¯å›¾ï¼‰** è¡¨ç¤ºä»»åŠ¡ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼Œæ˜¯ Plan é˜¶æ®µçš„æ ¸å¿ƒè¾“å‡ºã€‚

**å¯è§†åŒ–ç¤ºä¾‹**ï¼š

```mermaid
graph TB
    subgraph TaskGraph[ä»»åŠ¡ä¾èµ–å›¾ TaskGraph]
        T1[Task 1<br/>æ£€ç´¢å¥–å­¦é‡‘ç±»å‹]
        T2[Task 2<br/>æ£€ç´¢ç”³è¯·æ¡ä»¶]
        T3[Task 3<br/>æ£€ç´¢è¯„å®¡æµç¨‹]
        T4[Task 4<br/>åˆ†æäº’æ–¥å…³ç³»]
        T5[Task 5<br/>ç»¼åˆæ•´ç†]

        T1 --> T2
        T1 --> T3
        T2 --> T4
        T3 --> T4
        T4 --> T5
    end

    style T1 fill:#e3f2fd
    style T2 fill:#fff3e0
    style T3 fill:#fff3e0
    style T4 fill:#fce4ec
    style T5 fill:#e8f5e9
```

**ä¾èµ–å…³ç³»è¯´æ˜**ï¼š

| ä»»åŠ¡ | ä¾èµ–ä»»åŠ¡ | è¯´æ˜ |
|------|---------|------|
| Task 1 | æ—  | å¯ç«‹å³æ‰§è¡Œï¼ˆæ ¹èŠ‚ç‚¹ï¼‰ |
| Task 2 | Task 1 | å¿…é¡»ç­‰å¾… Task 1 å®Œæˆ |
| Task 3 | Task 1 | å¿…é¡»ç­‰å¾… Task 1 å®Œæˆï¼Œä¸ Task 2 å¹¶è¡Œ |
| Task 4 | Task 2, Task 3 | å¿…é¡»ç­‰å¾… Task 2 å’Œ Task 3 éƒ½å®Œæˆ |
| Task 5 | Task 4 | æœ€åçš„ä»»åŠ¡ï¼ˆå¶å­èŠ‚ç‚¹ï¼‰ |

**æ‰§è¡Œé¡ºåº**ï¼š

```
Parallel æ¨¡å¼ï¼ˆmax_workers=2ï¼‰:

Round 1: [Task 1] â†’ å®Œæˆ
Round 2: [Task 2, Task 3] â†’ å¹¶è¡Œæ‰§è¡Œ
Round 3: [Task 4] â†’ ç­‰å¾… Task 2, 3 éƒ½å®Œæˆ
Round 4: [Task 5] â†’ å®Œæˆ

æ€»è€—æ—¶ â‰ˆ max(Task2, Task3) + Task4 + Task5
```

**ä»»åŠ¡å›¾çš„ä¸‰å¤§ç‰¹æ€§**ï¼š

##### 1ï¸âƒ£ ä¾èµ–å…³ç³»çš„è¡¨è¾¾

**ä¸ºä»€ä¹ˆéœ€è¦ä¾èµ–å…³ç³»ï¼Ÿ**

```
åœºæ™¯ï¼šåˆ†æå¥–å­¦é‡‘ä½“ç³»

âŒ æ— ä¾èµ–ï¼ˆå• Agentï¼‰ï¼š
ä¸€æ¬¡æ€§æŸ¥è¯¢æ‰€æœ‰ä¿¡æ¯
â†’ å®¹æ˜“é—æ¼ç»†èŠ‚
â†’ æ— æ³•åˆ†æ­¥éªŒè¯
â†’ ä¸Šä¸‹æ–‡çª—å£æº¢å‡º

âœ… æœ‰ä¾èµ–ï¼ˆå¤š Agentï¼‰ï¼š
Task 1: æŸ¥è¯¢å¥–å­¦é‡‘ç§ç±»
Task 2: åŸºäºç§ç±»æŸ¥è¯¢ç”³è¯·æ¡ä»¶ï¼ˆä¾èµ– Task 1ï¼‰
Task 3: åŸºäºç”³è¯·æ¡ä»¶åˆ†æè¯„å®¡æµç¨‹ï¼ˆä¾èµ– Task 2ï¼‰
â†’ æ¸è¿›å¼æ·±å…¥
â†’ æ¯æ­¥éƒ½æœ‰ä¸Šä¸‹æ–‡
â†’ æ˜“äºçº é”™å’Œå›æº¯
```

**ä¾èµ–å…³ç³»çš„å®šä¹‰**ï¼š

```python
# ç¤ºä¾‹ï¼šåˆ†æå›½å®¶å¥–å­¦é‡‘å’ŒåŠ±å¿—å¥–å­¦é‡‘çš„å…³ç³»

task_a = TaskNode(
    task_id="task_a",
    description="æŸ¥è¯¢å›½å®¶å¥–å­¦é‡‘ä¿¡æ¯",
    depends_on=[]  # æ— ä¾èµ–
)

task_b = TaskNode(
    task_id="task_b",
    description="æŸ¥è¯¢åŠ±å¿—å¥–å­¦é‡‘ä¿¡æ¯",
    depends_on=[]  # æ— ä¾èµ–ï¼Œå¯ä¸ task_a å¹¶è¡Œ
)

task_c = TaskNode(
    task_id="task_c",
    description="å¯¹æ¯”ä¸¤ç§å¥–å­¦é‡‘çš„å·®å¼‚",
    depends_on=["task_a", "task_b"]  # ä¾èµ– a å’Œ b
)

# ä»»åŠ¡å›¾ç»“æ„ï¼š
#     task_a â”€â”€â”
#              â”œâ”€â”€â†’ task_c
#     task_b â”€â”€â”˜
```

##### 2ï¸âƒ£ æ‰§è¡Œæ¨¡å¼çš„é€‰æ‹©

TaskGraph æ”¯æŒä¸‰ç§æ‰§è¡Œæ¨¡å¼ï¼š

| æ¨¡å¼ | è¯´æ˜ | é€‚ç”¨åœºæ™¯ | æ€§èƒ½ |
|------|------|---------|------|
| **sequential** | ä¸²è¡Œæ‰§è¡Œ | ä»»åŠ¡æœ‰å¼ºä¾èµ–å…³ç³»ã€éœ€è¦ä¸¥æ ¼é¡ºåº | æ…¢ä½†å¯é  |
| **parallel** | å¹¶è¡Œæ‰§è¡Œ | ä»»åŠ¡é—´ä¾èµ–è¾ƒå°‘ã€å¯å¹¶è¡ŒåŒ– | å¿«ä½†å¤æ‚ |
| **adaptive** | è‡ªé€‚åº”é€‰æ‹© | æ ¹æ®ä»»åŠ¡ç‰¹å¾è‡ªåŠ¨é€‰æ‹©ï¼ˆå½“å‰é™çº§ä¸º sequentialï¼‰ | æ™ºèƒ½ä½†å®éªŒæ€§ |

**é…ç½®æ–¹å¼**ï¼š

```python
# æ–¹å¼1ï¼šåœ¨ TaskGraph ä¸­æŒ‡å®š
task_graph = TaskGraph(
    nodes=[task1, task2, task3],
    execution_mode="parallel"  # æ˜¾å¼æŒ‡å®š
)

# æ–¹å¼2ï¼šé€šè¿‡ç¯å¢ƒå˜é‡é…ç½®
# .env
MULTI_AGENT_EXECUTION_MODE=parallel  # å…¨å±€é»˜è®¤æ¨¡å¼

# æ–¹å¼3ï¼šWorkerCoordinator è¦†ç›–
coordinator = WorkerCoordinator(
    execution_mode="sequential"  # è¦†ç›– Planner çš„é€‰æ‹©
)
```

**æ‰§è¡Œæ¨¡å¼å¯¹æ¯”**ï¼š

```
åœºæ™¯ï¼š4ä¸ªç‹¬ç«‹ä»»åŠ¡ï¼ˆæ— ä¾èµ–å…³ç³»ï¼‰
Task 1: 2ç§’
Task 2: 3ç§’
Task 3: 2ç§’
Task 4: 4ç§’

Sequential æ¨¡å¼ï¼š
0s â”€â”€â”€> Task1 â”€â”€> 2s
2s â”€â”€â”€> Task2 â”€â”€> 5s
5s â”€â”€â”€> Task3 â”€â”€> 7s
7s â”€â”€â”€> Task4 â”€â”€> 11s
æ€»è€—æ—¶ï¼š11ç§’

Parallel æ¨¡å¼ï¼ˆmax_workers=2ï¼‰ï¼š
0s â”€â”€â”€> Task1 â”
      â””â”€â”€> Task2 â”˜  # å¹¶è¡Œ
2s â”€â”€â”€> Task3 â”  # Task1å®Œæˆï¼Œæ›¿è¡¥Task3
      â””â”€â”€> Task4 â”˜  # Task2è¿˜åœ¨è¿è¡Œ
5s â”€â”€â”€> Task4å®Œæˆ
æ€»è€—æ—¶ï¼š7ç§’ï¼ˆèŠ‚çœ 36%ï¼‰

Parallel æ¨¡å¼ï¼ˆmax_workers=4ï¼‰ï¼š
0s â”€â”€â”€> Task1 â”
      â”œâ”€â”€> Task2 â”¤  # å…¨éƒ¨å¹¶è¡Œ
      â”œâ”€â”€> Task3 â”¤
      â””â”€â”€> Task4 â”˜
3s â”€â”€â”€> Task1, Task3å®Œæˆ
4s â”€â”€â”€> Task2å®Œæˆ
4s â”€â”€â”€> Task4å®Œæˆ
æ€»è€—æ—¶ï¼š4ç§’ï¼ˆèŠ‚çœ 64%ï¼‰
```

##### 3ï¸âƒ£ æ ¸å¿ƒç®—æ³•ï¼šæ‹“æ‰‘æ’åº

TaskGraph ä½¿ç”¨ **Kahn ç®—æ³•** è¿›è¡Œæ‹“æ‰‘æ’åºï¼š

```python
def topological_sort(self) -> List[TaskNode]:
    """
    è·å–ä»»åŠ¡çš„æ‹“æ‰‘æ’åº

    ç®—æ³•ï¼šKahn's Algorithm
    æ—¶é—´å¤æ‚åº¦ï¼šO(V + E)
    ç©ºé—´å¤æ‚åº¦ï¼šO(V)

    è¿”å›ï¼šæŒ‰ä¾èµ–é¡ºåºæ’åˆ—çš„ä»»åŠ¡åˆ—è¡¨
    """
    # 1. è®¡ç®—å…¥åº¦
    in_degree = {node.task_id: 0 for node in self.nodes}
    for node in self.nodes:
        for dep_id in node.depends_on:
            in_degree[node.task_id] += 1

    # 2. æ‰¾åˆ°æ‰€æœ‰å…¥åº¦ä¸º0çš„èŠ‚ç‚¹ï¼ˆæ— ä¾èµ–ï¼‰
    queue = deque([task_id for task_id, degree in in_degree.items() if degree == 0])

    # 3. æŒ‰ä¼˜å…ˆçº§æ’åº
    queue = deque(sorted(queue, key=lambda x: priority_map[x]))

    # 4. ä¾æ¬¡å¤„ç†
    ordered_nodes = []
    while queue:
        current = queue.popleft()
        ordered_nodes.append(current)

        # 5. å‡å°‘ä¾èµ–æ­¤èŠ‚ç‚¹çš„å…¶ä»–èŠ‚ç‚¹çš„å…¥åº¦
        for neighbor in get_dependents(current):
            in_degree[neighbor] -= 1
            if in_degree[neighbor] == 0:
                queue.append(neighbor)

    return ordered_nodes
```

**æ‹“æ‰‘æ’åºç¤ºä¾‹**ï¼š

```
è¾“å…¥ä»»åŠ¡å›¾ï¼š
Task 1: depends_on = []
Task 2: depends_on = ["task_1"]
Task 3: depends_on = ["task_1"]
Task 4: depends_on = ["task_2", "task_3"]
Task 5: depends_on = ["task_4"]

åˆå§‹å…¥åº¦ï¼š
task_1: 0
task_2: 1 (ä¾èµ– task_1)
task_3: 1 (ä¾èµ– task_1)
task_4: 2 (ä¾èµ– task_2, task_3)
task_5: 1 (ä¾èµ– task_4)

æ‹“æ‰‘æ’åºè¿‡ç¨‹ï¼š
Step 1: queue = [task_1]
        output = [task_1]
        æ›´æ–°å…¥åº¦ï¼štask_2: 0, task_3: 0, task_4: 1

Step 2: queue = [task_2, task_3]  # (æŒ‰ä¼˜å…ˆçº§æ’åº)
        output = [task_1, task_2, task_3]
        æ›´æ–°å…¥åº¦ï¼štask_4: 0

Step 3: queue = [task_4]
        output = [task_1, task_2, task_3, task_4]
        æ›´æ–°å…¥åº¦ï¼štask_5: 0

Step 4: queue = [task_5]
        output = [task_1, task_2, task_3, task_4, task_5]

æœ€ç»ˆé¡ºåºï¼š[task_1, task_2, task_3, task_4, task_5]
```

**å¾ªç¯ä¾èµ–æ£€æµ‹**ï¼š

```python
def validate_dependencies(self) -> bool:
    """
    éªŒè¯ä»»åŠ¡ä¾èµ–çš„åˆæ³•æ€§

    æ£€æŸ¥ï¼š
    1. ä¾èµ–çš„ä»»åŠ¡IDæ˜¯å¦å­˜åœ¨
    2. æ˜¯å¦å­˜åœ¨å¾ªç¯ä¾èµ–
    """
    # âŒ é”™è¯¯ç¤ºä¾‹ï¼šå¾ªç¯ä¾èµ–
    # task_1.depends_on = ["task_2"]
    # task_2.depends_on = ["task_1"]
    #
    # æ£€æµ‹ç»“æœï¼šValueError("ä»»åŠ¡å›¾ä¸­å­˜åœ¨å¾ªç¯ä¾èµ–")

    # âœ… æ­£ç¡®ç¤ºä¾‹ï¼šæ— å¾ªç¯ä¾èµ–
    # task_1.depends_on = []
    # task_2.depends_on = ["task_1"]
    # task_3.depends_on = ["task_2"]
    #
    # æ£€æµ‹ç»“æœï¼šTrue
```

##### 4ï¸âƒ£ åŠ¨æ€ä»»åŠ¡è°ƒåº¦

åœ¨ Execute é˜¶æ®µï¼ŒWorkerCoordinator ä¼šåŠ¨æ€è·å–å¯æ‰§è¡Œä»»åŠ¡ï¼š

```python
def get_ready_tasks(self, completed_task_ids: List[str]) -> List[TaskNode]:
    """
    è·å–å¯ä»¥æ‰§è¡Œçš„ä»»åŠ¡

    å‚æ•°ï¼š
        completed_task_ids: å·²å®Œæˆçš„ä»»åŠ¡IDåˆ—è¡¨

    è¿”å›ï¼š
        å¯ä»¥æ‰§è¡Œçš„ä»»åŠ¡èŠ‚ç‚¹åˆ—è¡¨ï¼ˆä¾èµ–å·²æ»¡è¶³ä¸”çŠ¶æ€ä¸ºpendingï¼‰

    ç¤ºä¾‹ï¼š
        åˆå§‹çŠ¶æ€ï¼š
        â†’ completed = []
        â†’ è¿”å› [task_1, task_2]ï¼ˆæ— ä¾èµ–çš„ä»»åŠ¡ï¼‰

        task_1 å®Œæˆåï¼š
        â†’ completed = ["task_1"]
        â†’ è¿”å› [task_2, task_3]ï¼ˆä¾èµ–åªåŒ…å« task_1 çš„ä»»åŠ¡ï¼‰

        task_2, task_3 å®Œæˆåï¼š
        â†’ completed = ["task_1", "task_2", "task_3"]
        â†’ è¿”å› [task_4]ï¼ˆæ‰€æœ‰ä¾èµ–éƒ½æ»¡è¶³çš„ä»»åŠ¡ï¼‰
    """
    completed_set = set(completed_task_ids)
    ready_tasks = []

    for node in self.nodes:
        if node.status != "pending":
            continue

        # æ£€æŸ¥ä¾èµ–æ˜¯å¦å…¨éƒ¨å®Œæˆ
        if all(dep_id in completed_set for dep_id in node.depends_on):
            ready_tasks.append(node)

    # æŒ‰ä¼˜å…ˆçº§æ’åº
    ready_tasks.sort(key=lambda x: x.priority)
    return ready_tasks
```

**è°ƒåº¦ç¤ºä¾‹ï¼ˆParallel æ¨¡å¼ï¼‰**ï¼š

```
ä»»åŠ¡å›¾ï¼š
task_1 (priority=1) â† æ— ä¾èµ–
task_2 (priority=2) â† ä¾èµ– task_1
task_3 (priority=1) â† æ— ä¾èµ–
task_4 (priority=3) â† ä¾èµ– task_2, task_3

æ‰§è¡Œè¿‡ç¨‹ï¼ˆmax_workers=2ï¼‰ï¼š

Round 1: è·å–å¯æ‰§è¡Œä»»åŠ¡
         â†’ get_ready_tasks([])
         â†’ è¿”å› [task_1, task_3]ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼š1, 3, 2ï¼‰
         â†’ æäº¤ task_1 å’Œ task_3 åˆ°çº¿ç¨‹æ± 

Round 2: task_1 å®Œæˆ
         â†’ get_ready_tasks(["task_1"])
         â†’ è¿”å› [task_2]ï¼ˆtask_4 è¿˜è¦ç­‰ task_3ï¼‰
         â†’ æäº¤ task_2 åˆ°çº¿ç¨‹æ± 

Round 3: task_3 å®Œæˆ
         â†’ get_ready_tasks(["task_1", "task_3"])
         â†’ è¿”å› []ï¼ˆtask_4 è¿˜è¦ç­‰ task_2ï¼‰

Round 4: task_2 å®Œæˆ
         â†’ get_ready_tasks(["task_1", "task_2", "task_3"])
         â†’ è¿”å› [task_4]ï¼ˆæ‰€æœ‰ä¾èµ–éƒ½æ»¡è¶³ï¼‰
         â†’ æäº¤ task_4 åˆ°çº¿ç¨‹æ± 

Round 5: task_4 å®Œæˆ
         â†’ æ‰€æœ‰ä»»åŠ¡å®Œæˆ
```

#### 3.2.3 TaskNode æ•°æ®ç»“æ„

```python
class TaskNode(BaseModel):
    """ä»»åŠ¡èŠ‚ç‚¹"""
    task_id: str                # å”¯ä¸€æ ‡è¯†ï¼ˆå¦‚ "task_a1b2c3d4"ï¼‰
    task_type: TaskTypeLiteral  # ä»»åŠ¡ç±»å‹ï¼ˆè§ä¸‹è¡¨ï¼‰
    description: str            # ä»»åŠ¡æè¿°
    priority: Literal[1, 2, 3]  # ä¼˜å…ˆçº§ï¼ˆ1=é«˜, 2=ä¸­, 3=ä½ï¼‰
    depends_on: List[str]       # ä¾èµ–çš„ä»»åŠ¡IDåˆ—è¡¨
    parameters: Dict[str, Any]  # æ‰§è¡Œå‚æ•°ï¼ˆå¦‚ {"query": "xxx"}ï¼‰
    entities: List[str]         # ç›¸å…³å®ä½“
    status: str                 # çŠ¶æ€ï¼ˆpending/running/completed/failedï¼‰
```

**æ”¯æŒçš„ä»»åŠ¡ç±»å‹**ï¼š

| task_type | è¯´æ˜ | å¯¹åº” Executor |
|-----------|------|--------------|
| `local_search` | æœ¬åœ°å›¾è°±æœç´¢ | RetrievalExecutor |
| `global_search` | å…¨å±€ç¤¾åŒºæœç´¢ | RetrievalExecutor |
| `hybrid_search` | æ··åˆæœç´¢ | RetrievalExecutor |
| `naive_search` | åŸºç¡€å‘é‡æ£€ç´¢ | RetrievalExecutor |
| `deep_research` | æ·±åº¦è¿­ä»£ç ”ç©¶ | ResearchExecutor |
| `deeper_research` | å¢å¼ºæ·±åº¦ç ”ç©¶ | ResearchExecutor |
| `chain_exploration` | é“¾å¼å›¾è°±æ¢ç´¢ | ResearchExecutor |
| `reflection` | è´¨é‡åæ€ | ReflectionExecutor |
| `custom` | è‡ªå®šä¹‰ä»»åŠ¡ | æ‰©å±•Executor |

#### 3.2.4 å®ç°ä»£ç 

```python
# backend/graphrag_agent/agents/multi_agent/planner/task_decomposer.py

class TaskDecomposer:
    """ä»»åŠ¡åˆ†è§£èŠ‚ç‚¹"""

    def __init__(self, llm: Optional[BaseChatModel] = None, max_tasks: int = 6):
        self._llm = llm or get_llm_model()
        self._max_tasks = max_tasks  # æœ€å¤šåˆ†è§£ä¸º 6 ä¸ªå­ä»»åŠ¡

    def decompose(self, query: str) -> TaskDecompositionResult:
        """
        æ ¹æ®æŸ¥è¯¢ç”Ÿæˆ TaskGraph

        å‚æ•°:
            query: å·²æ¾„æ¸…çš„ç›®æ ‡æŸ¥è¯¢

        è¿”å›:
            TaskDecompositionResultï¼ˆåŒ…å« TaskGraphï¼‰
        """
        # æ„é€  Prompt
        prompt = TASK_DECOMPOSE_PROMPT.format(
            query=query,
            max_tasks=self._max_tasks,
        )

        # è°ƒç”¨ LLM
        response = self._invoke_llm(prompt)

        # è§£æ JSON
        parsed = parse_json_text(response)

        # æ„å»º TaskGraphï¼ˆåŒ…å«æ•°æ®æ¸…æ´—ï¼‰
        task_graph = self._build_task_graph(parsed)

        return TaskDecompositionResult(
            task_graph=task_graph,
            raw_task_graph=parsed,
            raw_response=response,
        )

    def _build_task_graph(self, data: Dict[str, Any]) -> TaskGraph:
        """
        å°† LLM è¾“å‡ºçš„ JSON è½¬æ¢ä¸º TaskGraph æ¨¡å‹

        æ¸…æ´—ç­–ç•¥ï¼š
        1. è¡¥å……ç¼ºå¤±å­—æ®µï¼ˆstatusã€priority ç­‰ï¼‰
        2. è§„èŒƒåŒ–ä»»åŠ¡ç±»å‹ï¼ˆæ— æ³•è¯†åˆ«çš„æ˜ å°„åˆ° customï¼‰
        3. ç¡®ä¿ä¾èµ–å­—æ®µä¸ºåˆ—è¡¨
        """
        nodes_data = data.get("nodes", [])
        sanitized_nodes = []

        for raw in nodes_data:
            node_dict = dict(raw)

            # è§„èŒƒåŒ–ä»»åŠ¡ç±»å‹
            task_type = node_dict.get("task_type", "custom")
            if task_type not in TASK_TYPE_CHOICES:
                node_dict.setdefault("parameters", {})["original_task_type"] = task_type
                task_type = "custom"
            node_dict["task_type"] = task_type

            # è¡¥å……å¿…å¤‡å­—æ®µ
            node_dict.setdefault("priority", 2)
            node_dict.setdefault("estimated_tokens", 500)
            node_dict.setdefault("depends_on", [])
            node_dict.setdefault("entities", [])
            node_dict.setdefault("parameters", {})
            node_dict.setdefault("status", "pending")

            sanitized_nodes.append(TaskNode(**node_dict))

        task_graph = TaskGraph(
            nodes=sanitized_nodes,
            execution_mode=data.get("execution_mode", "sequential")
        )

        # éªŒè¯ä¾èµ–å…³ç³»ï¼ˆæ£€æµ‹å¾ªç¯ä¾èµ–ï¼‰
        task_graph.validate_dependencies()

        return task_graph
```

#### 3.2.5 ä¾èµ–å…³ç³»éªŒè¯

TaskGraph æ”¯æŒæ‹“æ‰‘æ’åºå’Œå¾ªç¯ä¾èµ–æ£€æµ‹ï¼š

```python
class TaskGraph(BaseModel):
    """ä»»åŠ¡ä¾èµ–å›¾"""
    nodes: List[TaskNode]
    execution_mode: Literal["sequential", "parallel", "adaptive"]

    def validate_dependencies(self) -> bool:
        """
        éªŒè¯ä¾èµ–åˆæ³•æ€§ï¼š
        1. ä¾èµ–çš„ä»»åŠ¡IDå¿…é¡»å­˜åœ¨
        2. ä¸èƒ½å­˜åœ¨å¾ªç¯ä¾èµ–
        """
        task_id_set = {node.task_id for node in self.nodes}

        # æ£€æŸ¥ä¾èµ–ä»»åŠ¡æ˜¯å¦å­˜åœ¨
        for node in self.nodes:
            for dep_id in node.depends_on:
                if dep_id not in task_id_set:
                    raise ValueError(f"ä»»åŠ¡ {node.task_id} ä¾èµ–çš„ä»»åŠ¡ {dep_id} ä¸å­˜åœ¨")

        # æ‹“æ‰‘æ’åºæ£€æµ‹å¾ªç¯ä¾èµ–
        visited = set()
        rec_stack = set()

        def has_cycle(task_id: str) -> bool:
            visited.add(task_id)
            rec_stack.add(task_id)

            current_node = next((n for n in self.nodes if n.task_id == task_id), None)
            if not current_node:
                return False

            for dep_id in current_node.depends_on:
                if dep_id not in visited:
                    if has_cycle(dep_id):
                        return True
                elif dep_id in rec_stack:
                    return True  # æ£€æµ‹åˆ°å¾ªç¯

            rec_stack.remove(task_id)
            return False

        for node in self.nodes:
            if node.task_id not in visited:
                if has_cycle(node.task_id):
                    raise ValueError("ä»»åŠ¡å›¾ä¸­å­˜åœ¨å¾ªç¯ä¾èµ–")

        return True

    def topological_sort(self) -> List[TaskNode]:
        """è¿”å›æ‹“æ‰‘æ’åºåçš„ä»»åŠ¡åˆ—è¡¨"""
        # ä½¿ç”¨ Kahn ç®—æ³•
        in_degree = {node.task_id: 0 for node in self.nodes}
        adjacency = defaultdict(list)

        for node in self.nodes:
            for dep_id in node.depends_on:
                adjacency[dep_id].append(node.task_id)
                in_degree[node.task_id] += 1

        queue = deque(sorted(
            (node for node in self.nodes if in_degree[node.task_id] == 0),
            key=lambda x: (x.priority, x.task_id)
        ))

        ordered_nodes = []
        while queue:
            current = queue.popleft()
            ordered_nodes.append(current)

            for neighbor_id in adjacency[current.task_id]:
                in_degree[neighbor_id] -= 1
                if in_degree[neighbor_id] == 0:
                    neighbor_node = next(n for n in self.nodes if n.task_id == neighbor_id)
                    queue.append(neighbor_node)

            queue = deque(sorted(queue, key=lambda x: (x.priority, x.task_id)))

        return ordered_nodes
```

### 3.3 PlanReviewerï¼šè®¡åˆ’å®¡æŸ¥

#### 3.3.1 èŒè´£

PlanReviewer å¯¹ TaskDecomposer ç”Ÿæˆçš„ä»»åŠ¡å›¾è¿›è¡Œå®¡æŸ¥å’Œä¼˜åŒ–ï¼š

**æ£€æŸ¥é¡¹**ï¼š
- **å®Œæ•´æ€§**ï¼šä»»åŠ¡æ˜¯å¦è¦†ç›–é—®é¢˜çš„æ‰€æœ‰ç»´åº¦
- **å¯è¡Œæ€§**ï¼šæ¯ä¸ªä»»åŠ¡æ˜¯å¦å¯æ‰§è¡Œï¼ˆå·¥å…·ç±»å‹åŒ¹é…ã€å‚æ•°å®Œæ•´ï¼‰
- **æ•ˆç‡**ï¼šæ˜¯å¦å­˜åœ¨å†—ä½™ä»»åŠ¡ã€èƒ½å¦åˆå¹¶

**ä¼˜åŒ–ç­–ç•¥**ï¼š
- åˆå¹¶ç›¸ä¼¼ä»»åŠ¡
- è°ƒæ•´ä¼˜å…ˆçº§
- è¡¥å……é—æ¼ä»»åŠ¡
- ä¼˜åŒ–ä¾èµ–å…³ç³»

#### 3.3.2 å®ç°ä»£ç 

```python
# backend/graphrag_agent/agents/multi_agent/planner/plan_reviewer.py

class PlanReviewer:
    """è®¡åˆ’å®¡æ ¡èŠ‚ç‚¹"""

    def review(
        self,
        *,
        original_query: str,
        refined_query: Optional[str],
        task_graph: TaskGraph,
        assumptions: list[str],
        background_info: Optional[str] = None,
        user_intent: Optional[str] = None,
    ) -> PlanReviewOutcome:
        """
        å®¡æŸ¥å¹¶ä¼˜åŒ–ä»»åŠ¡å›¾

        è¿”å›:
            PlanReviewOutcomeï¼ˆåŒ…å«æœ€ç»ˆ PlanSpecï¼‰
        """
        # å°† TaskGraph åºåˆ—åŒ–ä¸º JSON
        task_graph_json = json.dumps(task_graph.to_dict(), ensure_ascii=False, indent=2)

        # æ„é€  Prompt
        prompt = PLAN_REVIEW_PROMPT.format(
            query=original_query,
            refined_query=refined_query or original_query,
            task_graph=task_graph_json,
            assumptions=json.dumps(assumptions or [], ensure_ascii=False),
        )

        # è°ƒç”¨ LLM
        response = self._invoke_llm(prompt)
        parsed = parse_json_text(response)

        # è§£æ ProblemStatement
        problem_statement_data = parsed.get("problem_statement", {})
        problem_statement_data.setdefault("background_info", background_info)
        problem_statement_data.setdefault("user_intent", user_intent)

        # è§£æ AcceptanceCriteria
        acceptance_data = parsed.get("acceptance_criteria", {})

        # è§£æå®¡æŸ¥åçš„ TaskGraphï¼ˆä¼˜å…ˆä½¿ç”¨ LLM è¿”å›çš„ï¼Œå¦åˆ™ä½¿ç”¨åŸå§‹çš„ï¼‰
        reviewed_task_graph = self._resolve_task_graph(
            parsed.get("task_graph"),
            task_graph
        )

        # æ„å»º PlanSpec
        plan_spec = PlanSpec(
            problem_statement=ProblemStatement(**problem_statement_data),
            assumptions=assumptions,
            task_graph=reviewed_task_graph,
            acceptance_criteria=AcceptanceCriteria(**acceptance_data) if acceptance_data else AcceptanceCriteria(),
            status="draft",
        )

        # éªŒè¯è®¡åˆ’
        validation_data = parsed.get("validation_results", {})
        validation = PlanValidationResult(raw_response=response, **validation_data)

        try:
            plan_spec.validate()
        except ValueError as exc:
            validation.is_valid = False
            validation.issues.append(str(exc))

        return PlanReviewOutcome(
            plan_spec=plan_spec,
            validation=validation,
            reviewed_task_graph=reviewed_task_graph,
            extra_data={}
        )
```

#### 3.3.3 éªŒæ”¶æ ‡å‡†

```python
class AcceptanceCriteria(BaseModel):
    """éªŒæ”¶æ ‡å‡†"""
    completion_conditions: List[str]     # å®Œæˆæ¡ä»¶åˆ—è¡¨
    quality_requirements: List[str]      # è´¨é‡è¦æ±‚
    min_evidence_count: int = 1          # æœ€å°‘è¯æ®æ•°é‡
    min_confidence: float = 0.7          # æœ€ä½ç½®ä¿¡åº¦

# ç¤ºä¾‹ï¼š
{
    "completion_conditions": [
        "æ‰€æœ‰å­ä»»åŠ¡å¿…é¡»æˆåŠŸæ‰§è¡Œ",
        "è‡³å°‘æ£€ç´¢åˆ° 5 æ¡ç›¸å…³è¯æ®"
    ],
    "quality_requirements": [
        "ç­”æ¡ˆå¿…é¡»åŸºäºçŸ¥è¯†å›¾è°±ä¸­çš„çœŸå®æ•°æ®",
        "å¼•ç”¨å¿…é¡»æ ‡æ³¨æ¥æº"
    ],
    "min_evidence_count": 5,
    "min_confidence": 0.8
}
```

#### 3.3.4 è¾“å‡ºç¤ºä¾‹

**å®Œæ•´çš„ PlanSpec**ï¼š
```json
{
    "plan_id": "plan_123abc",
    "version": 1,
    "problem_statement": {
        "original_query": "å¥–å­¦é‡‘ä½“ç³»åˆ†æ",
        "refined_query": "æ’°å†™åä¸œç†å·¥å¤§å­¦å­¦ç”Ÿå¥–å­¦é‡‘ä½“ç³»çš„å®Œæ•´åˆ†ææŠ¥å‘Š",
        "background_info": "ç”¨æˆ·éœ€è¦äº†è§£å­¦æ ¡å¥–å­¦é‡‘è®¾ç½®çš„å…¨è²Œ",
        "user_intent": "æŠ¥å‘Šç”Ÿæˆ"
    },
    "assumptions": [
        "æŠ¥å‘Šéœ€è¦è¦†ç›–æ‰€æœ‰ç±»å‹çš„å¥–å­¦é‡‘",
        "éœ€è¦åŒ…å«æ”¹è¿›å»ºè®®"
    ],
    "task_graph": {
        "nodes": [
            {
                "task_id": "task_001",
                "task_type": "global_search",
                "description": "æ£€ç´¢æ‰€æœ‰å¥–å­¦é‡‘ç±»å‹åŠå…¶åˆ†ç±»",
                "priority": 1,
                "depends_on": [],
                "parameters": {"query": "å¥–å­¦é‡‘ç±»å‹"}
            },
            {
                "task_id": "task_002",
                "task_type": "local_search",
                "description": "æ£€ç´¢æ¯ç§å¥–å­¦é‡‘çš„ç”³è¯·æ¡ä»¶",
                "priority": 2,
                "depends_on": ["task_001"],
                "parameters": {"query": "å¥–å­¦é‡‘ ç”³è¯·æ¡ä»¶"}
            }
        ],
        "execution_mode": "parallel"
    },
    "acceptance_criteria": {
        "completion_conditions": ["æ‰€æœ‰ä»»åŠ¡å®Œæˆ", "è‡³å°‘10æ¡è¯æ®"],
        "quality_requirements": ["åŸºäºçœŸå®æ•°æ®", "é€»è¾‘æ¸…æ™°"],
        "min_evidence_count": 10,
        "min_confidence": 0.75
    },
    "status": "draft"
}
```

---

## 4. Execute é˜¶æ®µï¼šä»»åŠ¡æ‰§è¡Œ

Execute é˜¶æ®µè´Ÿè´£æŒ‰ç…§ Plan ç”Ÿæˆçš„ä»»åŠ¡å›¾å®é™…æ‰§è¡Œæ£€ç´¢ã€ç ”ç©¶å’Œåæ€ä»»åŠ¡ï¼Œå¹¶æ”¶é›†è¯æ®ã€‚

### 4.1 WorkerCoordinatorï¼šå·¥ä½œåè°ƒ

#### 4.1.1 èŒè´£

WorkerCoordinator æ˜¯ Execute é˜¶æ®µçš„æ ¸å¿ƒè°ƒåº¦å™¨ï¼Œè´Ÿè´£ï¼š

**æ ¸å¿ƒèŒè´£**ï¼š
- è§£æ `PlanExecutionSignal`ï¼Œæå–ä»»åŠ¡åˆ—è¡¨å’Œæ‰§è¡Œé¡ºåº
- æ ¹æ®ä»»åŠ¡ç±»å‹ï¼ˆtask_typeï¼‰é€‰æ‹©åˆé€‚çš„ Executor
- æ£€æŸ¥ä»»åŠ¡ä¾èµ–å…³ç³»ï¼Œç¡®ä¿ä¾èµ–ä»»åŠ¡å®Œæˆåå†æ‰§è¡Œ
- æ”¯æŒä¸²è¡Œï¼ˆsequentialï¼‰å’Œå¹¶è¡Œï¼ˆparallelï¼‰ä¸¤ç§æ‰§è¡Œæ¨¡å¼
- ç®¡ç†åæ€é‡è¯•ï¼ˆReflection Retryï¼‰æœºåˆ¶

#### 4.1.2 Executor é€‰æ‹©æœºåˆ¶

```mermaid
graph TD
    Task[TaskNode] --> Check{åˆ¤æ–­ task_type}

    Check -->|local_search<br/>global_search<br/>hybrid_search<br/>naive_search| Retrieval[RetrievalExecutor]
    Check -->|deep_research<br/>deeper_research| Research[ResearchExecutor]
    Check -->|reflection| Reflection[ReflectionExecutor]
    Check -->|custom| Custom[è‡ªå®šä¹‰Executor]

    Retrieval --> Result[ExecutionRecord]
    Research --> Result
    Reflection --> Result
    Custom --> Result

    style Retrieval fill:#fff3e0
    style Research fill:#e3f2fd
    style Reflection fill:#fce4ec
```

#### 4.1.3 æ ¸å¿ƒä»£ç å®ç°

```python
# backend/graphrag_agent/agents/multi_agent/executor/worker_coordinator.py

class WorkerCoordinator:
    """Worker åè°ƒå™¨"""

    def __init__(
        self,
        executors: Optional[List[BaseExecutor]] = None,
        *,
        execution_mode: Optional[str] = None,
        max_parallel_workers: Optional[int] = None,
    ):
        # é»˜è®¤æ³¨å†Œä¸‰ç§ Executor
        if executors is None:
            executors = [
                RetrievalExecutor(),  # æ£€ç´¢
                ResearchExecutor(),   # ç ”ç©¶
                ReflectionExecutor(), # åæ€
            ]
        self.executors = executors

        # æ‰§è¡Œæ¨¡å¼ï¼šsequentialï¼ˆä¸²è¡Œï¼‰æˆ– parallelï¼ˆå¹¶è¡Œï¼‰
        self.execution_mode = execution_mode or MULTI_AGENT_WORKER_EXECUTION_MODE

        # å¹¶è¡Œåº¦ï¼ˆæœ€å¤§å¹¶å‘ä»»åŠ¡æ•°ï¼‰
        self.max_parallel_workers = max_parallel_workers or MULTI_AGENT_WORKER_MAX_CONCURRENCY

    def execute_plan(
        self,
        state: PlanExecuteState,
        signal: PlanExecutionSignal,
    ) -> List[ExecutionRecord]:
        """æ ¹æ®è®¡åˆ’ä¿¡å·æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡"""
        # å‡†å¤‡ä»»åŠ¡æ˜ å°„è¡¨
        task_map = self._prepare_tasks(signal)

        # æ ‡è®°è®¡åˆ’çŠ¶æ€ä¸ºæ‰§è¡Œä¸­
        if state.plan is not None:
            state.plan.status = "executing"

        # é€‰æ‹©æ‰§è¡Œæ¨¡å¼
        effective_mode = self._resolve_execution_mode(signal.execution_mode)

        # æ‰§è¡Œä»»åŠ¡
        if effective_mode == "parallel":
            results = self._execute_parallel(state, signal, task_map)
        else:
            results = self._execute_sequential(state, signal, task_map)

        # æ›´æ–°è®¡åˆ’çŠ¶æ€
        if state.plan is not None:
            node_status = [node.status for node in state.plan.task_graph.nodes]
            if all(status == "completed" for status in node_status):
                state.plan.status = "completed"
            elif any(status == "failed" for status in node_status):
                state.plan.status = "failed"

        return results

    def _select_executor(self, task_type: str) -> Optional[BaseExecutor]:
        """æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹© Executor"""
        for executor in self.executors:
            if executor.can_handle(task_type):
                return executor
        return None
```

#### 4.1.4 ä¾èµ–å…³ç³»æ£€æŸ¥

WorkerCoordinator åœ¨æ‰§è¡Œä»»åŠ¡å‰ä¼šæ£€æŸ¥ä¾èµ–ï¼š

```python
def _check_dependencies(self, task: TaskNode, state: PlanExecuteState) -> tuple[bool, Optional[str], str]:
    """
    æ£€æŸ¥ä»»åŠ¡ä¾èµ–æ˜¯å¦æ»¡è¶³

    è¿”å›:
        (æ˜¯å¦å¯æ‰§è¡Œ, é”™è¯¯ä¿¡æ¯, å¤±è´¥åŸå› æ ‡ç­¾)
    """
    if not task.depends_on:
        return True, None, "none"

    # è·å–ä»»åŠ¡çŠ¶æ€æ˜ å°„
    plan = state.plan
    status_map = {}
    if plan is not None:
        status_map = {node.task_id: node.status for node in plan.task_graph.nodes}

    # è·å–å·²å®Œæˆä»»åŠ¡åˆ—è¡¨
    exec_context = state.execution_context
    completed_ids = set(exec_context.completed_task_ids if exec_context else [])

    failed_dependencies = []
    pending_dependencies = []
    missing_dependencies = []

    # æ£€æŸ¥æ¯ä¸ªä¾èµ–ä»»åŠ¡
    for dep_id in task.depends_on:
        status = status_map.get(dep_id)

        if status == "failed":
            failed_dependencies.append(dep_id)
        elif status == "completed" or dep_id in completed_ids:
            continue  # ä¾èµ–å·²æ»¡è¶³
        elif status is None:
            missing_dependencies.append(dep_id)
        else:
            pending_dependencies.append(dep_id)

    # åˆ¤æ–­ä¾èµ–çŠ¶æ€
    if failed_dependencies:
        return False, f"ä¾èµ–ä»»åŠ¡å¤±è´¥: {', '.join(failed_dependencies)}", "dependency_failed"

    if missing_dependencies:
        return False, f"ä¾èµ–ä»»åŠ¡ç¼ºå¤±: {', '.join(missing_dependencies)}", "dependency_missing"

    if pending_dependencies:
        return False, f"ä¾èµ–ä»»åŠ¡æœªå®Œæˆ: {', '.join(pending_dependencies)}", "dependency_unfinished"

    return True, None, "ready"
```

### 4.2 ä¿¡å·ç³»ç»Ÿ

Execute é˜¶æ®µçš„ä¸‰ç§ Executor é€šè¿‡ `task_type` å­—æ®µè¿›è¡Œä»»åŠ¡åˆ†å‘ï¼š

| ä¿¡å·ç±»å‹ | è§¦å‘æ¡ä»¶ | å¯¹åº” Executor | ä¸»è¦èŒè´£ | å…¸å‹ä»»åŠ¡ç±»å‹ |
|---------|---------|-------------|---------|-------------|
| **Retrieval** | `task_type` ä¸ºæ£€ç´¢ç±»å·¥å…· | `RetrievalExecutor` | è°ƒç”¨ç°æœ‰æœç´¢å·¥å…·ï¼ˆlocal/global/hybrid/naive searchï¼‰ï¼Œæ”¶é›†è¯æ® | `local_search`<br/>`global_search`<br/>`hybrid_search`<br/>`naive_search`<br/>`chain_exploration` |
| **Research** | `task_type` ä¸ºç ”ç©¶ç±»å·¥å…· | `ResearchExecutor` | æ‰§è¡Œæ·±åº¦ç ”ç©¶ï¼ˆDeepSearchï¼‰ï¼Œç”Ÿæˆæ¨ç†é“¾å’Œç»“æ„åŒ–ç­”æ¡ˆ | `deep_research`<br/>`deeper_research` |
| **Reflection** | `task_type` ä¸º `reflection` | `ReflectionExecutor` | å¯¹å…¶ä»–ä»»åŠ¡çš„è¾“å‡ºè¿›è¡Œè´¨é‡éªŒè¯ï¼Œè§¦å‘é‡è¯•æœºåˆ¶ | `reflection` |

#### 4.2.1 RetrievalExecutorï¼ˆæ£€ç´¢æ‰§è¡Œå™¨ï¼‰

**èŒè´£**ï¼šè°ƒç”¨æœç´¢å·¥å…·ï¼Œè¿”å›ç»“æ„åŒ–çš„æ£€ç´¢ç»“æœã€‚

```python
class RetrievalExecutor(BaseExecutor):
    """æ£€ç´¢ä»»åŠ¡æ‰§è¡Œå™¨"""

    worker_type: str = "retrieval_executor"

    def can_handle(self, task_type: str) -> bool:
        # æ£€æŸ¥æ˜¯å¦åœ¨å·¥å…·æ³¨å†Œè¡¨ä¸­
        return task_type in self._tool_registry or task_type in self._extra_factories

    def execute_task(self, task: TaskNode, state: PlanExecuteState, signal: PlanExecutionSignal) -> TaskExecutionResult:
        """æ‰§è¡Œæ£€ç´¢ä»»åŠ¡"""
        tool_name = task.task_type
        payload = self.build_default_inputs(task)  # æ„å»ºè¾“å…¥å‚æ•°

        # è·å–å·¥å…·å®ä¾‹ï¼ˆå¸¦ç¼“å­˜ï¼‰
        tool_instance = self._get_tool_instance(tool_name)

        # è°ƒç”¨å·¥å…·
        structured_output = self._invoke_tool(tool_instance, tool_name, payload)

        # æå–è¯æ®ï¼ˆRetrievalResult åˆ—è¡¨ï¼‰
        evidence = self._extract_evidence(state, structured_output)

        # åˆ›å»ºæ‰§è¡Œè®°å½•
        record = ExecutionRecord(
            task_id=task.task_id,
            session_id=state.session_id,
            worker_type=self.worker_type,
            tool_calls=[ToolCall(tool_name=tool_name, args=payload, result=structured_output)],
            evidence=evidence,
            metadata=ExecutionMetadata(...)
        )

        # æ›´æ–°çŠ¶æ€
        self._update_state(state, task, record, success, error_message)

        return TaskExecutionResult(record=record, success=success, error=error_message)
```

**å…³é”®ç‚¹**ï¼š
- `structured_output` åŒ…å« `{"answer": "...", "retrieval_results": [...]}`
- `retrieval_results` è¢«è½¬æ¢ä¸º `RetrievalResult` å¯¹è±¡ï¼Œå­˜å…¥ `evidence` å­—æ®µ
- ç»“æœå†™å…¥ `state.execution_context.retrieval_cache[task_id]`

#### 4.2.2 ResearchExecutorï¼ˆç ”ç©¶æ‰§è¡Œå™¨ï¼‰

**èŒè´£**ï¼šæ‰§è¡Œæ·±åº¦ç ”ç©¶ä»»åŠ¡ï¼ˆDeepSearchï¼‰ï¼Œç”Ÿæˆæ¨ç†é“¾ã€‚

```python
class ResearchExecutor(BaseExecutor):
    """æ·±åº¦ç ”ç©¶ä»»åŠ¡æ‰§è¡Œå™¨"""

    worker_type: str = "research_executor"
    SUPPORTED_TASKS = {"deep_research", "deeper_research"}

    def execute_task(self, task: TaskNode, state: PlanExecuteState, signal: PlanExecutionSignal) -> TaskExecutionResult:
        """æ‰§è¡Œç ”ç©¶ä»»åŠ¡"""
        tool_name = task.task_type
        payload = self.build_default_inputs(task)

        # è°ƒç”¨ DeepResearchTool
        tool = self._get_tool_instance(tool_name)
        result_payload = tool.search(payload)

        # æå–ç­”æ¡ˆå’Œå¼•ç”¨
        evidence, answer_text, references = self._wrap_research_output(
            state, task, tool_name, result_payload
        )

        # åˆ›å»ºæ‰§è¡Œè®°å½•
        record = ExecutionRecord(
            task_id=task.task_id,
            worker_type=self.worker_type,
            evidence=evidence,  # åŒ…å«æ¨ç†ç»“æœå’Œå¼•ç”¨è¯æ®
            metadata=ExecutionMetadata(environment={"references": references})
        )

        return TaskExecutionResult(record=record, success=success)
```

**å…³é”®ç‚¹**ï¼š
- `result_payload` é€šå¸¸åŒ…å« `{"answer": "...", "references": [...]}`
- ç­”æ¡ˆè¢«åŒ…è£…ä¸º `RetrievalResult`ï¼Œæ–¹ä¾¿ Reporter å¼•ç”¨
- å¼•ç”¨çš„è¯æ® ID è¢«è§£æå¹¶å…³è”åˆ°å·²æœ‰çš„ `RetrievalResult`

#### 4.2.3 ReflectionExecutorï¼ˆåæ€æ‰§è¡Œå™¨ï¼‰

**èŒè´£**ï¼šéªŒè¯å…¶ä»–ä»»åŠ¡çš„è¾“å‡ºè´¨é‡ï¼Œè§¦å‘é‡è¯•ã€‚

```python
class ReflectionExecutor(BaseExecutor):
    """åæ€ä»»åŠ¡æ‰§è¡Œå™¨"""

    worker_type: str = "reflection_executor"

    def execute_task(self, task: TaskNode, state: PlanExecuteState, signal: PlanExecutionSignal) -> TaskExecutionResult:
        """å¯¹æŒ‡å®šä»»åŠ¡ç»“æœè¿›è¡Œåæ€ä¸éªŒè¯"""
        payload = self.build_default_inputs(task)

        # è§£æè¦éªŒè¯çš„æŸ¥è¯¢å’Œç­”æ¡ˆ
        query, answer, target_task_id = self._resolve_query_answer(state, payload, current_task_id=task.task_id)

        # æ„å»ºå‚è€ƒå…³é”®è¯ï¼ˆä»å·²æ£€ç´¢çš„è¯æ®ä¸­æå–ï¼‰
        reference_keywords = self._build_reference_keywords(state, target_task_id, query)

        # è°ƒç”¨ AnswerValidationTool
        validation_payload = self._validation_tool.validate(
            query, answer, reference_keywords=reference_keywords
        )

        # åˆ¤æ–­æ˜¯å¦é€šè¿‡éªŒè¯
        validation_passed = validation_payload.get("validation", {}).get("passed", False)

        # ç”Ÿæˆæ”¹è¿›å»ºè®®
        suggestions = []
        if not validation_passed:
            suggestions = self._derive_keyword_suggestions(query, answer, reference_keywords)

        # åˆ›å»ºåæ€ç»“æœ
        reflection = ReflectionResult(
            success=validation_passed,
            confidence=0.85 if validation_passed else 0.4,
            suggestions=suggestions,
            needs_retry=not validation_passed,  # è§¦å‘é‡è¯•æ ‡å¿—
            reasoning="éªŒè¯é€šè¿‡" if validation_passed else "éªŒè¯æœªé€šè¿‡ï¼Œå»ºè®®é‡è¯•"
        )

        record = ExecutionRecord(
            task_id=task.task_id,
            worker_type=self.worker_type,
            reflection=reflection,
            metadata=ExecutionMetadata(environment={"target_task_id": target_task_id, "validation_passed": validation_passed})
        )

        return TaskExecutionResult(record=record, success=True)
```

**é‡è¯•æœºåˆ¶**ï¼š

å½“ `reflection.needs_retry = True` æ—¶ï¼ŒWorkerCoordinator ä¼šï¼š
1. æ£€æŸ¥é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤æœ€å¤š 3 æ¬¡ï¼‰
2. å°†ç›®æ ‡ä»»åŠ¡çŠ¶æ€é‡ç½®ä¸º `pending`
3. é‡æ–°æ‰§è¡Œç›®æ ‡ä»»åŠ¡
4. å†æ¬¡æ‰§è¡Œåæ€ä»»åŠ¡éªŒè¯
5. å¦‚æœä»æœªé€šè¿‡ï¼Œè®°å½•å¤±è´¥ä½†ç»§ç»­æ‰§è¡Œåç»­ä»»åŠ¡

### 4.3 å¹¶è¡Œæ‰§è¡Œ

#### 4.3.1 å¹¶è¡Œæ‰§è¡Œæœºåˆ¶

WorkerCoordinator æ”¯æŒä¸¤ç§æ‰§è¡Œæ¨¡å¼ï¼š

| æ¨¡å¼ | è¯´æ˜ | é€‚ç”¨åœºæ™¯ | é…ç½®æ–¹å¼ |
|------|------|---------|---------|
| **Sequential** | ä¸²è¡Œæ‰§è¡Œï¼ŒæŒ‰æ‹“æ‰‘æ’åºé€ä¸ªæ‰§è¡Œä»»åŠ¡ | ä»»åŠ¡é—´å¼ºä¾èµ–ã€èµ„æºå—é™ç¯å¢ƒ | `execution_mode: "sequential"` |
| **Parallel** | å¹¶è¡Œæ‰§è¡Œï¼Œä¾èµ–æ»¡è¶³çš„ä»»åŠ¡åŒæ—¶æ‰§è¡Œ | ä»»åŠ¡é—´å¼±ä¾èµ–ã€éœ€è¦æå‡é€Ÿåº¦ | `execution_mode: "parallel"` |

**å¹¶è¡Œæ‰§è¡Œæµç¨‹**ï¼š

```mermaid
sequenceDiagram
    participant WC as WorkerCoordinator
    participant Pool as ThreadPoolExecutor
    participant E1 as Executor 1
    participant E2 as Executor 2
    participant E3 as Executor 3

    WC->>WC: è·å–æ— ä¾èµ–ä»»åŠ¡åˆ—è¡¨
    WC->>Pool: åˆ›å»ºçº¿ç¨‹æ±  (max_workers=3)

    par å¹¶è¡Œæ‰§è¡Œæ— ä¾èµ–ä»»åŠ¡
        WC->>Pool: submit(task_1)
        Pool->>E1: execute_task(task_1)
        WC->>Pool: submit(task_2)
        Pool->>E2: execute_task(task_2)
        WC->>Pool: submit(task_3)
        Pool->>E3: execute_task(task_3)
    end

    E1-->>WC: ExecutionRecord_1
    E2-->>WC: ExecutionRecord_2
    E3-->>WC: ExecutionRecord_3

    WC->>WC: æ›´æ–°å®ŒæˆçŠ¶æ€
    WC->>WC: æ£€æŸ¥æ–°çš„å¯æ‰§è¡Œä»»åŠ¡

    WC->>Pool: submit(task_4)
    Pool->>E1: execute_task(task_4)
    E1-->>WC: ExecutionRecord_4

    WC-->>WC: æ‰€æœ‰ä»»åŠ¡å®Œæˆ
```

#### 4.3.2 ExecutionRecord æ•°æ®ç»“æ„

æ¯ä¸ªä»»åŠ¡æ‰§è¡Œå®Œæˆåä¼šç”Ÿæˆä¸€ä¸ª `ExecutionRecord`ï¼š

```python
@dataclass
class ExecutionRecord:
    """æ‰§è¡Œè®°å½•"""
    record_id: str                          # è®°å½•å”¯ä¸€ID
    task_id: str                            # å…³è”ä»»åŠ¡ID
    session_id: str                         # ä¼šè¯ID
    worker_type: str                        # æ‰§è¡Œå™¨ç±»å‹ï¼ˆretrieval_executor/research_executor/reflection_executorï¼‰
    inputs: Dict[str, Any]                  # è¾“å…¥å‚æ•°
    tool_calls: List[ToolCall]              # å·¥å…·è°ƒç”¨åˆ—è¡¨
    evidence: List[RetrievalResult]         # æ£€ç´¢åˆ°çš„è¯æ®
    reflection: Optional[ReflectionResult]  # åæ€ç»“æœï¼ˆä»… ReflectionExecutorï¼‰
    metadata: ExecutionMetadata             # å…ƒæ•°æ®

@dataclass
class ExecutionMetadata:
    """æ‰§è¡Œå…ƒæ•°æ®"""
    worker_type: str                        # Worker ç±»å‹
    latency_seconds: float                  # æ‰§è¡Œå»¶è¿Ÿï¼ˆç§’ï¼‰
    tool_calls_count: int                   # å·¥å…·è°ƒç”¨æ¬¡æ•°
    evidence_count: int                     # è¯æ®æ•°é‡
    environment: Dict[str, Any]             # ç¯å¢ƒä¿¡æ¯
```

**ç”¨é€”**ï¼š
- æä¾›å®Œæ•´çš„æ‰§è¡Œè¿½è¸ªå’Œè°ƒè¯•ä¿¡æ¯
- ä½œä¸º Report é˜¶æ®µçš„è¯æ®æ¥æº
- æ”¯æŒæ‰§è¡Œè®°å½•çš„æŒä¹…åŒ–å’Œå›æ”¾

---

## 5. Report é˜¶æ®µï¼šæŠ¥å‘Šç”Ÿæˆ

Report é˜¶æ®µè´Ÿè´£å°† Execute é˜¶æ®µæ”¶é›†çš„è¯æ®æ•´åˆä¸ºç»“æ„åŒ–çš„é•¿æ–‡æ¡£æŠ¥å‘Šã€‚

### 5.1 OutlineBuilderï¼šå¤§çº²æ„å»º

#### 5.1.1 èŒè´£

OutlineBuilder æ ¹æ®æ‰§è¡Œè¯æ®å’Œè®¡åˆ’ç›®æ ‡ç”Ÿæˆç»“æ„åŒ–çš„æŠ¥å‘Šå¤§çº²ã€‚

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
- åˆ†ææ‰€æœ‰æ‰§è¡Œè®°å½•ä¸­çš„è¯æ®
- æ ¹æ®é—®é¢˜ç»´åº¦ç”Ÿæˆç« èŠ‚ç»“æ„
- ä¸ºæ¯ä¸ªç« èŠ‚åˆ†é…ç›¸å…³è¯æ® ID
- é¢„ä¼°æ¯ä¸ªç« èŠ‚çš„å­—æ•°

#### 5.1.2 å¤§çº²ç”Ÿæˆç­–ç•¥

```mermaid
graph TD
    Evidence[ExecutionRecords] --> Analyze[åˆ†æè¯æ®è¦†ç›–èŒƒå›´]
    Plan[PlanSpec] --> Analyze

    Analyze --> Cluster[æŒ‰ä¸»é¢˜èšç±»è¯æ®]
    Cluster --> Sections[ç”Ÿæˆç« èŠ‚åˆ—è¡¨]

    Sections --> Assign[ä¸ºç« èŠ‚åˆ†é…è¯æ®ID]
    Assign --> Estimate[é¢„ä¼°å­—æ•°]

    Estimate --> Outline[ReportOutline]

    style Evidence fill:#fff3e0
    style Plan fill:#e3f2fd
    style Outline fill:#e8f5e9
```

#### 5.1.3 å®ç°ä»£ç 

```python
# backend/graphrag_agent/agents/multi_agent/reporter/outline_builder.py

class OutlineBuilder:
    """çº²è¦ç”Ÿæˆå™¨"""

    def __init__(self, llm: Optional[BaseChatModel] = None):
        self._llm = llm or get_llm_model()

    def build_outline(
        self,
        *,
        query: str,
        plan_summary: str,
        evidence_summary: str,
        evidence_count: int,
        report_type: str,
    ) -> ReportOutline:
        """
        ç”ŸæˆæŠ¥å‘Šçº²è¦

        å‚æ•°:
            query: åŸå§‹æŸ¥è¯¢
            plan_summary: è®¡åˆ’æ‘˜è¦
            evidence_summary: è¯æ®æ‘˜è¦
            evidence_count: è¯æ®æ€»æ•°
            report_type: æŠ¥å‘Šç±»å‹ï¼ˆshort_answer / long_documentï¼‰

        è¿”å›:
            ReportOutline
        """
        prompt = OUTLINE_PROMPT.format(
            query=query,
            plan_summary=plan_summary,
            evidence_summary=evidence_summary,
            evidence_count=evidence_count,
            report_type=report_type,
        )

        response = self._invoke_llm(prompt)
        outline_data = self._parse_response(response)
        outline = ReportOutline(**outline_data)

        return outline

    def _invoke_llm(self, prompt: str) -> str:
        """è°ƒç”¨ LLM ç”Ÿæˆå¤§çº²"""
        message: BaseMessage = self._llm.invoke(prompt)
        content = getattr(message, "content", None) or str(message)
        return content.strip()

    def _parse_response(self, response: str) -> Dict[str, Any]:
        """è§£æ LLM è¿”å›çš„ JSON å­—ç¬¦ä¸²"""
        try:
            return parse_json_text(response)
        except ValueError as exc:
            raise ValueError("çº²è¦ç”Ÿæˆç»“æœè§£æå¤±è´¥") from exc
```

#### 5.1.4 ReportOutline æ•°æ®ç»“æ„

```python
class SectionOutline(BaseModel):
    """å•ä¸ªç« èŠ‚çº²è¦"""
    section_id: str                      # ç« èŠ‚IDï¼ˆå¦‚ "section_001"ï¼‰
    title: str                           # ç« èŠ‚æ ‡é¢˜
    summary: str                         # ç« èŠ‚æ‘˜è¦
    evidence_ids: List[str]              # å¼•ç”¨çš„è¯æ® ID åˆ—è¡¨
    estimated_words: int = 400           # é¢„ä¼°å­—æ•°

class ReportOutline(BaseModel):
    """æŠ¥å‘Šçº²è¦"""
    report_type: str                     # æŠ¥å‘Šç±»å‹ï¼ˆshort_answer / long_documentï¼‰
    title: str                           # æŠ¥å‘Šæ ‡é¢˜
    abstract: Optional[str] = None       # æ‘˜è¦ï¼ˆé•¿æ–‡æ¡£ç‰¹æœ‰ï¼‰
    sections: List[SectionOutline]       # ç« èŠ‚åˆ—è¡¨
    total_estimated_words: Optional[int] = None  # é¢„ä¼°æ€»å­—æ•°
```

#### 5.1.5 è¾“å‡ºç¤ºä¾‹

```json
{
    "report_type": "long_document",
    "title": "åä¸œç†å·¥å¤§å­¦å­¦ç”Ÿå¥–å­¦é‡‘ä½“ç³»åˆ†ææŠ¥å‘Š",
    "abstract": "æœ¬æŠ¥å‘Šç³»ç»Ÿåˆ†æäº†åä¸œç†å·¥å¤§å­¦çš„å­¦ç”Ÿå¥–å­¦é‡‘ä½“ç³»ï¼ŒåŒ…æ‹¬å„ç±»å¥–å­¦é‡‘çš„è®¾ç«‹ç›®çš„ã€ç”³è¯·æ¡ä»¶ã€è¯„å®¡æµç¨‹ç­‰ã€‚",
    "sections": [
        {
            "section_id": "section_001",
            "title": "å¥–å­¦é‡‘ç±»å‹æ¦‚è§ˆ",
            "summary": "ä»‹ç»å›½å®¶å¥–å­¦é‡‘ã€å›½å®¶åŠ±å¿—å¥–å­¦é‡‘ã€æ ¡å†…å¥–å­¦é‡‘ç­‰å„ç±»å¥–å­¦é‡‘",
            "evidence_ids": ["evidence_001", "evidence_003", "evidence_007"],
            "estimated_words": 500
        },
        {
            "section_id": "section_002",
            "title": "ç”³è¯·æ¡ä»¶è¯¦è§£",
            "summary": "è¯¦ç»†è¯´æ˜å„ç±»å¥–å­¦é‡‘çš„ç”³è¯·èµ„æ ¼ã€æˆç»©è¦æ±‚ç­‰",
            "evidence_ids": ["evidence_002", "evidence_005"],
            "estimated_words": 600
        },
        {
            "section_id": "section_003",
            "title": "è¯„å®¡æµç¨‹åˆ†æ",
            "summary": "æ¢³ç†å¥–å­¦é‡‘è¯„å®¡çš„å„ä¸ªç¯èŠ‚å’Œæ—¶é—´èŠ‚ç‚¹",
            "evidence_ids": ["evidence_004", "evidence_006"],
            "estimated_words": 450
        }
    ],
    "total_estimated_words": 1550
}
```

### 5.2 SectionWriterï¼šç« èŠ‚å†™ä½œ

#### 5.2.1 èŒè´£

SectionWriter å®ç° Map-Reduce æ¨¡å¼çš„é•¿æ–‡æ¡£ç”Ÿæˆï¼Œçªç ´ LLM å•æ¬¡è¾“å‡ºé•¿åº¦é™åˆ¶ã€‚

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
- Map é˜¶æ®µï¼šå¹¶è¡Œå†™ä½œå„ç« èŠ‚
- Reduce é˜¶æ®µï¼šåˆå¹¶ç« èŠ‚ä¸ºå®Œæ•´æŠ¥å‘Š
- æ”¯æŒè¯æ®åˆ†æ‰¹å†™ä½œï¼ˆé¿å…å•æ¬¡ Prompt è¿‡é•¿ï¼‰
- è‡ªåŠ¨å»é‡é‡å¤çš„ç« èŠ‚æ ‡é¢˜

#### 5.2.2 Map-Reduce æµç¨‹

```mermaid
graph TB
    Outline[ReportOutline] --> Map[Map é˜¶æ®µ]

    subgraph Map[Map é˜¶æ®µï¼šå¹¶è¡Œå†™ä½œ]
        S1[SectionWriter<br/>ç« èŠ‚1]
        S2[SectionWriter<br/>ç« èŠ‚2]
        S3[SectionWriter<br/>ç« èŠ‚3]
    end

    Outline --> S1
    Outline --> S2
    Outline --> S3

    S1 --> D1[SectionDraft 1]
    S2 --> D2[SectionDraft 2]
    S3 --> D3[SectionDraft 3]

    D1 --> Reduce[Reduce é˜¶æ®µï¼šåˆå¹¶]
    D2 --> Reduce
    D3 --> Reduce

    Reduce --> Report[å®Œæ•´æŠ¥å‘Š]

    style Outline fill:#e3f2fd
    style Map fill:#fff3e0
    style Reduce fill:#e8f5e9
    style Report fill:#c8e6c9
```

#### 5.2.3 å®ç°ä»£ç 

```python
# backend/graphrag_agent/agents/multi_agent/reporter/section_writer.py

class SectionWriterConfig(BaseModel):
    """ç« èŠ‚å†™ä½œé…ç½®"""
    max_evidence_per_call: int = 8       # å•æ¬¡å†™ä½œæœ€å¤§è¯æ®æ•°
    max_previous_context_chars: int = 800  # å¤šæ‰¹å†™ä½œæ—¶ä¿ç•™çš„å‰æ–‡å­—ç¬¦æ•°
    enable_multi_pass: bool = True       # å¯ç”¨å¤šæ‰¹å†™ä½œ

class SectionWriter:
    """ç« èŠ‚å†™ä½œå™¨"""

    def __init__(
        self,
        llm: Optional[BaseChatModel] = None,
        config: Optional[SectionWriterConfig] = None,
    ):
        self._llm = llm or get_llm_model()
        self.config = config or SectionWriterConfig()

    def write_section(
        self,
        outline: ReportOutline,
        section: SectionOutline,
        evidence_map: Dict[str, RetrievalResult],
        fallback_evidence_ids: Optional[List[str]] = None,
    ) -> SectionDraft:
        """
        æ ¹æ®å¤§çº²ä¸è¯æ®æ’°å†™ç« èŠ‚å†…å®¹

        å¦‚æœè¯æ®è¿‡å¤šï¼Œä¼šåˆ†æ‰¹å†™ä½œå¹¶è‡ªåŠ¨è¡”æ¥
        """
        # é€‰æ‹©è¯æ®
        evidence_ids = self._select_evidence_ids(section, evidence_map, fallback_evidence_ids)
        evidence_entries = [evidence_map[eid] for eid in evidence_ids if eid in evidence_map]

        # åˆ†æ‰¹
        batches = self._split_into_batches(evidence_entries, self.config.max_evidence_per_call)

        contents: List[str] = []
        used_ids: List[str] = []

        # æ„å»ºå¤§çº²ä¸Šä¸‹æ–‡
        outline_context = self._build_outline_snapshot(outline, section)
        outline_context_text = json.dumps(outline_context, ensure_ascii=False)

        # å¤šæ‰¹å†™ä½œ
        for batch_index, batch in enumerate(batches, start=1):
            evidence_list_text = self._format_evidence(batch)

            # å¦‚æœæ˜¯ç¬¬ 2+ æ‰¹ï¼Œæ·»åŠ å‰æ–‡æ‘˜è¦
            context_instruction = ""
            if self.config.enable_multi_pass and len(batches) > 1:
                context_instruction = f"**å†™ä½œé˜¶æ®µ**: ç¬¬{batch_index}/{len(batches)}æ‰¹\n"
                if contents:
                    context_instruction += f"**å‰æ–‡æ‘˜è¦**: {self._extract_previous_summary(contents)}"

            prompt = SECTION_WRITE_PROMPT.format(
                outline=outline_context_text,
                section_id=section.section_id,
                section_title=section.title,
                section_summary=section.summary,
                estimated_words=section.estimated_words,
                evidence_list=evidence_list_text + ("\n\n" + context_instruction if context_instruction else "")
            )

            generated = self._invoke_llm(prompt)
            contents.append(generated.strip())
            used_ids.extend([item.result_id for item in batch])

        # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡çš„å†…å®¹
        final_content = "\n\n".join(contents).strip()

        # å»é‡é‡å¤çš„ç« èŠ‚æ ‡é¢˜
        final_content = self._sanitize_content(section.title, final_content)

        return SectionDraft(
            section_id=section.section_id,
            content=final_content,
            used_evidence_ids=used_ids,
        )

    def _split_into_batches(
        self,
        evidence_entries: List[RetrievalResult],
        batch_size: int,
    ) -> List[List[RetrievalResult]]:
        """æŒ‰æ‰¹æ¬¡åˆ‡åˆ†è¯æ®åˆ—è¡¨"""
        if not evidence_entries:
            return [[]]
        batches = []
        for i in range(0, len(evidence_entries), batch_size):
            batches.append(evidence_entries[i:i + batch_size])
        return batches

    def _extract_previous_summary(self, contents: List[str]) -> str:
        """ä»å·²æœ‰å†…å®¹ä¸­æˆªå–æ‘˜è¦"""
        if not contents:
            return ""
        joined = "\n\n".join(contents)
        return joined[-self.config.max_previous_context_chars:]

    def _sanitize_content(self, section_title: str, content: str) -> str:
        """ç§»é™¤ä¸ç« èŠ‚æ ‡é¢˜é‡å¤çš„æ ‡é¢˜è¡Œ"""
        if not content:
            return ""

        normalized_title = self._normalize_heading_text(section_title)
        cleaned_lines = []

        for line in content.splitlines():
            stripped = line.strip()
            if stripped.startswith("#"):
                heading_text = re.sub(r"^#+\s*", "", stripped)
                if self._normalize_heading_text(heading_text) == normalized_title:
                    continue  # è·³è¿‡é‡å¤æ ‡é¢˜
            cleaned_lines.append(line)

        # å»é™¤å¼€å¤´çš„ç©ºè¡Œ
        while cleaned_lines and not cleaned_lines[0].strip():
            cleaned_lines.pop(0)

        return "\n".join(cleaned_lines).strip()

    @staticmethod
    def _normalize_heading_text(text: str) -> str:
        """å½’ä¸€åŒ–æ ‡é¢˜æ–‡æœ¬"""
        normalized = re.sub(r"[#\s]+", "", text or "").strip()
        normalized = normalized.replace("ï¼š", ":").replace("ï¼Œ", ",").lower()
        return normalized
```

#### 5.2.4 Map-Reduce å¹¶è¡ŒåŒ–

åœ¨ Reporter ä¸­ï¼ŒMap é˜¶æ®µå¯ä»¥å¹¶è¡Œå†™ä½œå„ç« èŠ‚ï¼š

```python
# ä¼ªä»£ç ï¼šå¹¶è¡Œ Map
from concurrent.futures import ThreadPoolExecutor

def map_reduce_write(outline, evidence_map, max_workers=3):
    """Map-Reduce å¹¶è¡Œå†™ä½œ"""
    section_drafts = []

    # Map é˜¶æ®µï¼šå¹¶è¡Œå†™ä½œå„ç« èŠ‚
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = []
        for section in outline.sections:
            future = executor.submit(
                section_writer.write_section,
                outline, section, evidence_map
            )
            futures.append((section.section_id, future))

        for section_id, future in futures:
            draft = future.result()
            section_drafts.append(draft)

    # Reduce é˜¶æ®µï¼šåˆå¹¶ç« èŠ‚
    report_content = f"# {outline.title}\n\n"
    if outline.abstract:
        report_content += f"{outline.abstract}\n\n"

    for draft in section_drafts:
        report_content += f"## {draft.section_title}\n\n{draft.content}\n\n"

    return report_content
```

### 5.3 ConsistencyCheckerï¼šä¸€è‡´æ€§æ£€æŸ¥

#### 5.3.1 èŒè´£

ConsistencyChecker éªŒè¯æŠ¥å‘Šçš„äº‹å®å‡†ç¡®æ€§å’Œå¼•ç”¨ä¸€è‡´æ€§ã€‚

**æ£€æŸ¥é¡¹**ï¼š
- äº‹å®å‡†ç¡®æ€§ï¼šæŠ¥å‘Šä¸­çš„é™ˆè¿°æ˜¯å¦æœ‰è¯æ®æ”¯æŒ
- å¼•ç”¨å®Œæ•´æ€§ï¼šæ‰€æœ‰å¼•ç”¨çš„è¯æ® ID æ˜¯å¦å­˜åœ¨
- é€»è¾‘ä¸€è‡´æ€§ï¼šå‰åé™ˆè¿°æ˜¯å¦çŸ›ç›¾
- æ•°æ®å‡†ç¡®æ€§ï¼šæ•°å­—ã€æ—¶é—´ç­‰æ˜¯å¦ä¸è¯æ®ä¸€è‡´

#### 5.3.2 å®ç°ä»£ç 

```python
# backend/graphrag_agent/agents/multi_agent/reporter/consistency_checker.py

class ConsistencyCheckResult(BaseModel):
    """ä¸€è‡´æ€§æ£€æŸ¥ç»“æœ"""
    is_consistent: bool = True           # æ˜¯å¦é€šè¿‡æ£€æŸ¥
    issues: list[Dict[str, Any]]         # é—®é¢˜åˆ—è¡¨
    corrections: list[Dict[str, Any]]    # ä¿®æ­£å»ºè®®
    raw_response: Optional[str] = None   # LLM åŸå§‹è¾“å‡º

class ConsistencyChecker:
    """ä¸€è‡´æ€§æ ¡éªŒå™¨"""

    def __init__(self, llm: Optional[BaseChatModel] = None):
        self._llm = llm or get_llm_model()

    def check(self, report_content: str, evidence_list: str) -> ConsistencyCheckResult:
        """
        æ£€æŸ¥æŠ¥å‘Šä¸€è‡´æ€§

        å‚æ•°:
            report_content: å®Œæ•´æŠ¥å‘Šå†…å®¹
            evidence_list: è¯æ®åˆ—è¡¨æ‘˜è¦

        è¿”å›:
            ConsistencyCheckResult
        """
        prompt = CONSISTENCY_CHECK_PROMPT.format(
            report_content=report_content,
            evidence_list=evidence_list,
        )

        response = self._invoke_llm(prompt)
        parsed = self._parse_response(response)

        result = ConsistencyCheckResult(**parsed, raw_response=response)
        return result

    def _invoke_llm(self, prompt: str) -> str:
        """è°ƒç”¨ LLM"""
        message: BaseMessage = self._llm.invoke(prompt)
        content = getattr(message, "content", None) or str(message)
        return content.strip()

    def _parse_response(self, response: str) -> Dict[str, Any]:
        """è§£æ JSON"""
        try:
            return parse_json_text(response)
        except ValueError as exc:
            raise ValueError("ä¸€è‡´æ€§æ ¡éªŒç»“æœè§£æå¤±è´¥") from exc
```

#### 5.3.3 æ£€æŸ¥é¡¹è¯¦è§£

**Prompt ç¤ºä¾‹**ï¼š

```python
CONSISTENCY_CHECK_PROMPT = """
è¯·æ£€æŸ¥ä»¥ä¸‹æŠ¥å‘Šçš„ä¸€è‡´æ€§ï¼š

ã€æŠ¥å‘Šå†…å®¹ã€‘
{report_content}

ã€å¯ç”¨è¯æ®ã€‘
{evidence_list}

æ£€æŸ¥é¡¹ï¼š
1. äº‹å®å‡†ç¡®æ€§ï¼šæŠ¥å‘Šä¸­çš„é™ˆè¿°æ˜¯å¦æœ‰è¯æ®æ”¯æŒï¼Ÿ
2. å¼•ç”¨å®Œæ•´æ€§ï¼šæ‰€æœ‰å¼•ç”¨çš„è¯æ® ID æ˜¯å¦å­˜åœ¨ï¼Ÿ
3. é€»è¾‘ä¸€è‡´æ€§ï¼šå‰åé™ˆè¿°æ˜¯å¦çŸ›ç›¾ï¼Ÿ
4. æ•°æ®å‡†ç¡®æ€§ï¼šæ•°å­—ã€æ—¶é—´ç­‰æ˜¯å¦ä¸è¯æ®ä¸€è‡´ï¼Ÿ

è¾“å‡º JSON æ ¼å¼ï¼š
{{
    "is_consistent": true/false,
    "issues": [
        {{"type": "fact_error", "location": "ç¬¬2æ®µ", "description": "æœªæ‰¾åˆ°æ”¯æŒè¯æ®"}}
    ],
    "corrections": [
        {{"issue_id": 0, "suggestion": "å»ºè®®åˆ é™¤æˆ–è¡¥å……å¼•ç”¨"}}
    ]
}}
"""
```

#### 5.3.4 ä¿®å¤ç­–ç•¥

å½“æ£€æµ‹åˆ°é—®é¢˜æ—¶ï¼ŒConsistencyChecker æä¾›ä¿®æ­£å»ºè®®ï¼š

| é—®é¢˜ç±»å‹ | ä¿®å¤ç­–ç•¥ | ç¤ºä¾‹ |
|---------|---------|------|
| **fact_error** | åˆ é™¤æ— è¯æ®æ”¯æŒçš„é™ˆè¿°æˆ–è¡¥å……å¼•ç”¨ | "è¯¥å¥–å­¦é‡‘è¦†ç›–ç‡è¾¾ 80%" â†’ éœ€è¦è¯æ®æ”¯æŒ |
| **citation_missing** | è¡¥å……è¯æ® ID å¼•ç”¨ | æ·»åŠ  `[è¯æ®ID: evidence_003]` |
| **logic_conflict** | ä¿®æ­£çŸ›ç›¾é™ˆè¿° | "äº’æ–¥" vs "å¯åŒæ—¶ç”³è¯·" â†’ ç»Ÿä¸€è¡¨è¿° |
| **data_mismatch** | ä¿®æ­£æ•°å­—/æ—¶é—´ | "50å­¦æ—¶" vs è¯æ®ä¸­çš„ "60å­¦æ—¶" â†’ æ”¹ä¸º 60 |

**è‡ªåŠ¨ä¿®å¤ï¼ˆå¯é€‰ï¼‰**ï¼š

å¦‚æœå¯ç”¨è‡ªåŠ¨ä¿®å¤ï¼ŒConsistencyChecker ä¼šè°ƒç”¨ LLM ç”Ÿæˆä¿®æ­£åçš„æŠ¥å‘Šï¼š

```python
def auto_fix(self, report_content: str, check_result: ConsistencyCheckResult) -> str:
    """è‡ªåŠ¨ä¿®å¤æŠ¥å‘Š"""
    if check_result.is_consistent:
        return report_content

    fix_prompt = AUTO_FIX_PROMPT.format(
        report_content=report_content,
        issues=json.dumps(check_result.issues, ensure_ascii=False),
        corrections=json.dumps(check_result.corrections, ensure_ascii=False)
    )

    fixed_content = self._invoke_llm(fix_prompt)
    return fixed_content
```

---

## 6. FusionGraphRAGAgent å®ç°

FusionGraphRAGAgent æ˜¯æœ¬é¡¹ç›®çš„å¤š Agent åä½œç³»ç»Ÿçš„å…¥å£ Agentï¼Œç»§æ‰¿è‡ª BaseAgentï¼Œå°è£…äº† Plan-Execute-Report çš„å®Œæ•´æµç¨‹ã€‚

### 6.1 æ•´ä½“æ¶æ„

```mermaid
graph TB
    User[ç”¨æˆ·] --> Fusion[FusionGraphRAGAgent]

    subgraph FusionGraphRAGAgent
        Facade[MultiAgentFacade]
        Bundle[OrchestratorBundle]

        Facade --> Bundle

        Facade --> Bundle

        subgraph Bundle[OrchestratorBundle]
            Orch[Orchestrator]
            Plan[Planner]
            Exec[Executor]
            Rep[Reporter]

            Orch --> Plan
            Orch --> Exec
            Orch --> Rep
        end
    end

    Fusion --> Result[æœ€ç»ˆæŠ¥å‘Š]

    style Fusion fill:#e3f2fd
    style Bundle fill:#fff3e0
    style Result fill:#e8f5e9
```

**æ¶æ„è¯´æ˜**ï¼š
- `FusionGraphRAGAgent`ï¼šå¯¹å¤–æš´éœ²çš„ç»Ÿä¸€æ¥å£
- `MultiAgentFacade`ï¼šå…¼å®¹å±‚ï¼Œå°†æ–°çš„å¤š Agent ç³»ç»Ÿå°è£…ä¸ºæ—§æ¥å£
- `OrchestratorBundle`ï¼šå°è£…äº† Plannerã€Executorã€Reporter çš„å®Œæ•´ç¼–æ’å™¨

### 6.2 æ ¸å¿ƒä»£ç 

#### 6.2.1 å®Œæ•´å®ç°

```python
# backend/graphrag_agent/agents/fusion_agent.py

class FusionGraphRAGAgent:
    """
    Fusion GraphRAG Agent çš„è½»é‡å°è£…ç‰ˆæœ¬

    å®Œå…¨å§”æ‰˜ç»™å¤šæ™ºèƒ½ä½“ç¼–æ’æ ˆï¼Œæä¾›å…¼å®¹æ—§ç‰ˆ BaseAgent çš„æ¥å£
    """

    def __init__(self, kb_prefix: str = "", agent_mode: str = "retrieve_only"):
        """
        åˆå§‹åŒ– FusionGraphRAGAgent

        å‚æ•°:
            kb_prefix: çŸ¥è¯†åº“å‰ç¼€ï¼ˆç”¨äºéš”ç¦»æ£€ç´¢ï¼‰
            agent_mode: æ¨¡å¼ï¼ˆv3 strict å›ºå®šä¸º retrieve_onlyï¼‰
        """
        _ = kb_prefix
        _ = agent_mode

        # æ ¸å¿ƒç»„ä»¶ï¼šMultiAgentFacade å°è£…äº†æ•´ä¸ª Plan-Execute-Report æµç¨‹
        self.multi_agent = MultiAgentFacade()

        # å…¼å®¹æ¥å£
        self.memory = _MemoryShim()          # ç©ºçš„è®°å¿†å ä½
        self.graph = _GraphShim()            # LangGraph å ä½

        # æ‰§è¡Œè®°å½•
        self.execution_log: list[Any] = []

        # ç¼“å­˜
        self._global_cache: Dict[str, str] = {}           # å…¨å±€ç¼“å­˜
        self._session_cache: Dict[str, Dict[str, str]] = {}  # ä¼šè¯ç¼“å­˜

        # é…ç½®
        self._last_payload: Dict[str, Any] = {}
        self._flush_threshold = AGENT_SETTINGS["fusion_stream_flush_threshold"]
        self._default_recursion_limit = AGENT_SETTINGS["default_recursion_limit"]

    def ask(
        self,
        query: str,
        thread_id: str = "default",
        recursion_limit: Optional[int] = None
    ) -> str:
        """
        åŒæ­¥é—®ç­”æ¥å£

        å‚æ•°:
            query: ç”¨æˆ·æŸ¥è¯¢
            thread_id: ä¼šè¯ID
            recursion_limit: é€’å½’é™åˆ¶ï¼ˆå…¼å®¹å‚æ•°ï¼Œæœ¬ç³»ç»Ÿæœªä½¿ç”¨ï¼‰

        è¿”å›:
            ç­”æ¡ˆå­—ç¬¦ä¸²
        """
        return self._execute(query, thread_id)[0]

    def ask_with_trace(
        self,
        query: str,
        thread_id: str = "default",
        recursion_limit: Optional[int] = None
    ) -> Dict[str, Any]:
        """
        å¸¦å®Œæ•´è¿½è¸ªä¿¡æ¯çš„é—®ç­”

        è¿”å›:
            {
                "answer": "æœ€ç»ˆç­”æ¡ˆ",
                "payload": {
                    "status": "completed",
                    "planner": {...},
                    "execution_records": [...],
                    "report": {...},
                    "metrics": {...}
                }
            }
        """
        answer, payload = self._execute(query, thread_id)
        return {"answer": answer, "payload": payload}

    async def ask_stream(
        self,
        query: str,
        thread_id: str = "default",
        recursion_limit: Optional[int] = None
    ) -> AsyncGenerator[str, None]:
        """
        æµå¼è¾“å‡ºæ¥å£ï¼ˆä¼ªæµå¼ï¼‰

        æ³¨æ„ï¼šå½“å‰å®ç°æ˜¯ä¼ªæµå¼ï¼Œå…ˆç”Ÿæˆå®Œæ•´ç­”æ¡ˆå†åˆ†å—è¿”å›
        ç­‰å¾… LangChain/LangGraph æ”¯æŒçœŸæ­£çš„æµå¼åä¼šå‡çº§

        ç”Ÿæˆ:
            ç­”æ¡ˆçš„åˆ†å—å­—ç¬¦ä¸²
        """
        # æ£€æŸ¥ç¼“å­˜
        cached = self._read_cache(query, thread_id)

        if cached is None:
            # å¼‚æ­¥æ‰§è¡Œå®Œæ•´æµç¨‹
            cached, _ = await asyncio.to_thread(self._execute, query, thread_id)

        # æµå¼è¿”å›åˆ†å—
        async for chunk in self._stream_chunks(cached):
            yield chunk

    def close(self):
        """æ¸…ç†èµ„æº"""
        self._global_cache.clear()
        self._session_cache.clear()

    def _execute(
        self,
        query: str,
        thread_id: str,
        *,
        assumptions: Optional[list[str]] = None,
        report_type: Optional[str] = None
    ) -> Tuple[str, Dict[str, Any]]:
        """
        å†…éƒ¨æ‰§è¡Œæ–¹æ³•

        è¿”å›:
            (ç­”æ¡ˆå­—ç¬¦ä¸², å®Œæ•´payload)
        """
        # æ£€æŸ¥ç¼“å­˜
        cached = self._read_cache(query, thread_id)
        if cached is not None:
            return cached, {"status": "cached"}

        # è°ƒç”¨å¤š Agent ç³»ç»Ÿ
        payload = self.multi_agent.process_query(
            query.strip(),
            assumptions=assumptions,
            report_type=report_type
        )

        # æå–ç­”æ¡ˆ
        answer = self._normalize_answer(payload.get("response"))

        # å†™å…¥ç¼“å­˜
        self._write_cache(query, thread_id, answer)

        # ä¿å­˜æ‰§è¡Œè®°å½•
        self.execution_log = payload.get("execution_records", [])
        self._last_payload = payload

        return answer, payload

    def _read_cache(self, query: str, thread_id: str) -> Optional[str]:
        """è¯»å–ç¼“å­˜"""
        key = query.strip()
        return self._global_cache.get(key) or self._session_cache.get(thread_id, {}).get(key)

    def _write_cache(self, query: str, thread_id: str, answer: str):
        """å†™å…¥ç¼“å­˜"""
        key = query.strip()
        self._global_cache[key] = answer
        self._session_cache.setdefault(thread_id, {})[key] = answer

    @staticmethod
    def _normalize_answer(answer: Any) -> str:
        """è§„èŒƒåŒ–ç­”æ¡ˆ"""
        if isinstance(answer, str) and answer.strip():
            return answer.strip()
        return "æœªèƒ½ç”Ÿæˆå›ç­”" if answer is None else str(answer)

    async def _stream_chunks(self, answer: str) -> AsyncGenerator[str, None]:
        """
        å°†å®Œæ•´ç­”æ¡ˆåˆ†å—æµå¼è¿”å›

        ç­–ç•¥ï¼šæŒ‰å¥å­åˆ†å‰²ï¼ˆã€‚ï¼ï¼Ÿ.!?ï¼‰ï¼Œæ¯2ä¸ªå¥å­æˆ–è¾¾åˆ°é˜ˆå€¼å°±è¿”å›
        """
        buffer = ""
        for idx, part in enumerate(re.split(r"([ã€‚ï¼ï¼Ÿ.!?]\s*)", answer)):
            buffer += part

            # æ¯2ä¸ªéƒ¨åˆ†ï¼ˆ1ä¸ªå¥å­+1ä¸ªæ ‡ç‚¹ï¼‰æˆ–è¾¾åˆ°é˜ˆå€¼å°±è¿”å›
            if (idx % 2 and buffer.strip()) or len(buffer) >= self._flush_threshold:
                yield buffer
                buffer = ""
                await asyncio.sleep(0)  # è®©å‡ºæ§åˆ¶æƒ

        # è¿”å›å‰©ä½™å†…å®¹
        if buffer.strip():
            yield buffer
```

#### 6.2.2 ä½¿ç”¨ç¤ºä¾‹

**åŸºç¡€é—®ç­”**ï¼š

```python
from graphrag_agent.agents.fusion_agent import FusionGraphRAGAgent

# åˆå§‹åŒ–
agent = FusionGraphRAGAgent()

# åŒæ­¥é—®ç­”
answer = agent.ask("æ—·è¯¾å¤šå°‘å­¦æ—¶ä¼šè¢«é€€å­¦ï¼Ÿ")
print(answer)

# å¸¦è¿½è¸ªä¿¡æ¯
result = agent.ask_with_trace("å›½å®¶å¥–å­¦é‡‘å’Œå›½å®¶åŠ±å¿—å¥–å­¦é‡‘äº’æ–¥å—ï¼Ÿ")
print(f"ç­”æ¡ˆ: {result['answer']}")
print(f"çŠ¶æ€: {result['payload']['status']}")
print(f"æ‰§è¡Œè®°å½•æ•°: {len(result['payload']['execution_records'])}")
```

**æµå¼è¾“å‡º**ï¼š

```python
import asyncio

async def stream_example():
    agent = FusionGraphRAGAgent()

    query = "æ’°å†™ä¸€ç¯‡å…³äºåä¸œç†å·¥å¤§å­¦å­¦ç”Ÿå¥–å­¦é‡‘ä½“ç³»çš„åˆ†ææŠ¥å‘Š"

    async for chunk in agent.ask_stream(query):
        print(chunk, end="", flush=True)

# è¿è¡Œ
asyncio.run(stream_example())
```

**è®¿é—®æ‰§è¡Œè®°å½•**ï¼š

```python
agent = FusionGraphRAGAgent()
result = agent.ask_with_trace("ä¼˜ç§€å­¦ç”Ÿè¦æ€ä¹ˆç”³è¯·ï¼Ÿ")

# æŸ¥çœ‹æ‰§è¡Œè®°å½•
for record in result['payload']['execution_records']:
    print(f"ä»»åŠ¡ID: {record['task_id']}")
    print(f"Worker: {record['worker_type']}")
    print(f"è¯æ®æ•°: {record['metadata']['evidence_count']}")
    print("---")

# æŸ¥çœ‹æŠ¥å‘Šï¼ˆå¦‚æœç”Ÿæˆäº†é•¿æ–‡æ¡£ï¼‰
if 'report' in result['payload']:
    report = result['payload']['report']
    print(f"æŠ¥å‘Šæ ‡é¢˜: {report['outline']['title']}")
    print(f"ç« èŠ‚æ•°: {len(report['sections'])}")
```

### 6.3 é…ç½®å‚æ•°

å¤š Agent ç³»ç»Ÿé€šè¿‡ç¯å¢ƒå˜é‡è¿›è¡Œé…ç½®ï¼Œæ‰€æœ‰å‚æ•°ä»¥ `MA_` å¼€å¤´ï¼š

| ç¯å¢ƒå˜é‡ | é»˜è®¤å€¼ | è¯´æ˜ | ç±»å‹ |
|---------|-------|------|------|
| **Planner é…ç½®** |
| `MA_PLANNER_MAX_TASKS` | `6` | ä»»åŠ¡åˆ†è§£æœ€å¤§ä»»åŠ¡æ•° | int |
| `MA_ALLOW_UNCLARIFIED_PLAN` | `True` | å…è®¸åœ¨æœªæ¾„æ¸…çš„æƒ…å†µä¸‹ç»§ç»­è§„åˆ’ | bool |
| `MA_DEFAULT_DOMAIN` | `"é€šç”¨"` | é»˜è®¤é¢†åŸŸä¸Šä¸‹æ–‡ | str |
| `MA_STOP_ON_CLARIFICATION` | `True` | éœ€è¦æ¾„æ¸…æ—¶æ˜¯å¦åœæ­¢ | bool |
| `MA_STRICT_PLAN_SIGNAL` | `True` | ä¸¥æ ¼éªŒè¯è®¡åˆ’ä¿¡å· | bool |
| **Reporter é…ç½®** |
| `MA_AUTO_GENERATE_REPORT` | `True` | è‡ªåŠ¨ç”Ÿæˆç»“æ„åŒ–æŠ¥å‘Š | bool |
| `MA_DEFAULT_REPORT_TYPE` | `"long_document"` | é»˜è®¤æŠ¥å‘Šç±»å‹ï¼ˆshort_answer / long_documentï¼‰ | str |
| `MA_ENABLE_CONSISTENCY_CHECK` | `True` | å¯ç”¨ä¸€è‡´æ€§æ£€æŸ¥ | bool |
| `MA_ENABLE_MAPREDUCE` | `True` | å¯ç”¨ Map-Reduce å¹¶è¡Œå†™ä½œ | bool |
| `MA_MAPREDUCE_THRESHOLD` | `20` | è§¦å‘ Map-Reduce çš„è¯æ®æ•°é˜ˆå€¼ | int |
| `MA_MAX_TOKENS_PER_REDUCE` | `8000` | Reduce é˜¶æ®µæœ€å¤§ Token æ•° | int |
| `MA_ENABLE_PARALLEL_MAP` | `True` | å¯ç”¨å¹¶è¡Œ Map | bool |
| `MA_SECTION_MAX_EVIDENCE` | `8` | æ¯ä¸ªç« èŠ‚æœ€å¤§è¯æ®æ•° | int |
| `MA_SECTION_MAX_CONTEXT_CHARS` | `800` | å¤šæ‰¹å†™ä½œæ—¶ä¿ç•™çš„ä¸Šä¸‹æ–‡å­—ç¬¦æ•° | int |
| **Executor é…ç½®** |
| `MA_REFLECTION_ALLOW_RETRY` | `True` | å…è®¸åæ€è§¦å‘é‡è¯• | bool |
| `MA_REFLECTION_MAX_RETRIES` | `3` | åæ€æœ€å¤§é‡è¯•æ¬¡æ•° | int |
| `MA_WORKER_EXECUTION_MODE` | `"parallel"` | Worker æ‰§è¡Œæ¨¡å¼ï¼ˆsequential / parallelï¼‰ | str |
| `MA_WORKER_MAX_CONCURRENCY` | `3` | æœ€å¤§å¹¶å‘ Worker æ•° | int |

**é…ç½®ç¤ºä¾‹ï¼ˆ.env æ–‡ä»¶ï¼‰**ï¼š

```bash
# Planner é…ç½®
MA_PLANNER_MAX_TASKS=8                    # æœ€å¤šåˆ†è§£ä¸º8ä¸ªå­ä»»åŠ¡
MA_ALLOW_UNCLARIFIED_PLAN=true            # å…è®¸æ¨¡ç³ŠæŸ¥è¯¢ç»§ç»­æ‰§è¡Œ
MA_STOP_ON_CLARIFICATION=false            # ä¸åœ¨æ¾„æ¸…æ—¶åœæ­¢

# Reporter é…ç½®
MA_AUTO_GENERATE_REPORT=true              # è‡ªåŠ¨ç”ŸæˆæŠ¥å‘Š
MA_DEFAULT_REPORT_TYPE=long_document      # é»˜è®¤ç”Ÿæˆé•¿æ–‡æ¡£
MA_ENABLE_CONSISTENCY_CHECK=true          # å¯ç”¨ä¸€è‡´æ€§æ£€æŸ¥
MA_ENABLE_MAPREDUCE=true                  # å¯ç”¨ Map-Reduce
MA_SECTION_MAX_EVIDENCE=10                # æ¯ç« èŠ‚æœ€å¤š10æ¡è¯æ®

# Executor é…ç½®
MA_REFLECTION_ALLOW_RETRY=true            # å¯ç”¨åæ€é‡è¯•
MA_REFLECTION_MAX_RETRIES=2               # æœ€å¤šé‡è¯•2æ¬¡
MA_WORKER_EXECUTION_MODE=parallel         # å¹¶è¡Œæ‰§è¡Œ
MA_WORKER_MAX_CONCURRENCY=4               # æœ€å¤š4ä¸ªå¹¶å‘ Worker
```

---

## 7. ä¸å• Agent çš„å¯¹æ¯”

### 7.1 èƒ½åŠ›å¯¹æ¯”

| ç»´åº¦ | å• Agent (HybridAgent) | å¤š Agent (FusionAgent) | æå‡å¹…åº¦ |
|------|----------------------|----------------------|---------|
| **ä»»åŠ¡å¤æ‚åº¦** | ä¸­ç­‰å¤æ‚åº¦ï¼ˆ3-5 ä¸ªç»´åº¦ï¼‰ | é«˜å¤æ‚åº¦ï¼ˆ6+ ä¸ªç»´åº¦ï¼‰ | **+100%** |
| **æ–‡æ¡£é•¿åº¦** | < 1500 å­— | 2000-8000 å­— | **+400%** |
| **æ‰§è¡Œæ—¶é—´** | 15-30 ç§’ï¼ˆä¸²è¡Œï¼‰ | 10-18 ç§’ï¼ˆå¹¶è¡Œï¼‰ | **-40%** |
| **å‡†ç¡®åº¦** | 75-85% | 85-92% | **+10%** |
| **å¯è§£é‡Šæ€§** | ä½ï¼ˆå•ä¸€æ¨ç†é“¾ï¼‰ | é«˜ï¼ˆå®Œæ•´æ‰§è¡Œè®°å½• + ä»»åŠ¡å›¾ï¼‰ | **+300%** |

**è¯¦ç»†è¯´æ˜**ï¼š

#### 7.1.1 ä»»åŠ¡å¤æ‚åº¦

**å• Agent**ï¼š
- é€‚åˆå¤„ç† 3-5 ä¸ªç»´åº¦çš„é—®é¢˜
- ç¤ºä¾‹ï¼š"å¥–å­¦é‡‘ç”³è¯·æ¡ä»¶æ˜¯ä»€ä¹ˆï¼Ÿ"ï¼ˆå•ä¸€ç»´åº¦ï¼‰
- å±€é™ï¼šè¶…è¿‡ 5 ä¸ªç»´åº¦åå®¹æ˜“é—æ¼

**å¤š Agent**ï¼š
- å¯å¤„ç† 6+ ä¸ªç»´åº¦çš„å¤æ‚é—®é¢˜
- ç¤ºä¾‹ï¼š"æ’°å†™å¥–å­¦é‡‘ä½“ç³»åˆ†ææŠ¥å‘Šï¼ŒåŒ…æ‹¬ç±»å‹ã€æ¡ä»¶ã€æµç¨‹ã€äº’æ–¥å…³ç³»ã€èµ„é‡‘æ¥æºã€è¦†ç›–èŒƒå›´ã€æ”¹è¿›å»ºè®®"ï¼ˆ7 ä¸ªç»´åº¦ï¼‰
- ä¼˜åŠ¿ï¼šTaskDecomposer è‡ªåŠ¨åˆ†è§£ä¸ºç»“æ„åŒ–å­ä»»åŠ¡

#### 7.1.2 æ–‡æ¡£é•¿åº¦

**å• Agent**ï¼š
- LLM å•æ¬¡è¾“å‡ºé™åˆ¶ï¼šé€šå¸¸ 2000-4000 tokensï¼ˆçº¦ 1000-1500 å­—ä¸­æ–‡ï¼‰
- æ— æ³•ç”Ÿæˆè¶…é•¿æ–‡æ¡£
- å®æµ‹ï¼šHybridAgent æœ€é•¿è¾“å‡ºçº¦ 1200 å­—

**å¤š Agent**ï¼š
- é€šè¿‡ Map-Reduce çªç ´é™åˆ¶
- å®æµ‹ï¼šå¯ç”Ÿæˆ 5000+ å­—çš„å®Œæ•´æŠ¥å‘Š
- æ¯ä¸ªç« èŠ‚ç‹¬ç«‹ç”Ÿæˆï¼Œæœ€ååˆå¹¶

#### 7.1.3 æ‰§è¡Œæ—¶é—´

**å¯¹æ¯”å®éªŒ**ï¼ˆç›¸åŒé—®é¢˜ï¼š"å¥–å­¦é‡‘ä½“ç³»åˆ†æ"ï¼‰ï¼š

| Agent ç±»å‹ | å­ä»»åŠ¡æ•° | æ‰§è¡Œæ¨¡å¼ | æ€»æ—¶é—´ |
|-----------|---------|---------|-------|
| HybridAgent | 1 | ä¸²è¡Œ | 28 ç§’ |
| FusionAgentï¼ˆä¸²è¡Œï¼‰ | 6 | ä¸²è¡Œ | 32 ç§’ |
| FusionAgentï¼ˆå¹¶è¡Œï¼‰ | 6 | å¹¶è¡Œ | 15 ç§’ |

**ç»“è®º**ï¼š
- å¤š Agent ä¸²è¡Œæ¨¡å¼ç•¥æ…¢ï¼ˆå› ä¸ºä»»åŠ¡æ›´ç»†è‡´ï¼‰
- å¤š Agent å¹¶è¡Œæ¨¡å¼å¿« 46%ï¼ˆ6 ä¸ªå­ä»»åŠ¡å¹¶è¡Œæ‰§è¡Œï¼‰

#### 7.1.4 å‡†ç¡®åº¦

**è¯„ä¼°æ–¹æ³•**ï¼š20 ä¸ªå¤æ‚é—®é¢˜ï¼Œäººå·¥è¯„åˆ†ï¼ˆ0-100ï¼‰

| æŒ‡æ ‡ | å• Agent | å¤š Agent | æå‡ |
|------|---------|---------|------|
| äº‹å®å‡†ç¡®æ€§ | 78% | 88% | +10% |
| å®Œæ•´æ€§ | 72% | 90% | +18% |
| é€»è¾‘ä¸€è‡´æ€§ | 85% | 91% | +6% |
| **ç»¼åˆå¾—åˆ†** | **78%** | **89%** | **+11%** |

**æå‡åŸå› **ï¼š
- ReflectionExecutor è´¨é‡éªŒè¯
- ConsistencyChecker ä¸€è‡´æ€§æ£€æŸ¥
- å¤šå±‚è´¨é‡æŠŠå…³

#### 7.1.5 å¯è§£é‡Šæ€§

**å• Agent**ï¼š
- è¾“å‡ºï¼šæœ€ç»ˆç­”æ¡ˆ
- è°ƒè¯•ä¿¡æ¯ï¼šLangGraph çš„ä¸­é—´èŠ‚ç‚¹çŠ¶æ€ï¼ˆéš¾ä»¥ç†è§£ï¼‰

**å¤š Agent**ï¼š
- è¾“å‡ºï¼šå®Œæ•´çš„æ‰§è¡Œè¿½è¸ª
- åŒ…å«ï¼š
  - PlanSpecï¼ˆä»»åŠ¡å›¾ï¼‰
  - æ¯ä¸ªä»»åŠ¡çš„ ExecutionRecord
  - å·¥å…·è°ƒç”¨è¯¦æƒ…
  - è¯æ®æ¥æº
  - åæ€ç»“æœ

**ç¤ºä¾‹**ï¼š

```python
# å• Agent
{
    "answer": "å›½å®¶å¥–å­¦é‡‘å’Œå›½å®¶åŠ±å¿—å¥–å­¦é‡‘äº’æ–¥...",
    "retrieval_results": [...]
}

# å¤š Agent
{
    "answer": "...",
    "planner": {
        "task_graph": {
            "nodes": [
                {"task_id": "task_001", "description": "æ£€ç´¢å›½å®¶å¥–å­¦é‡‘è§„å®š"},
                {"task_id": "task_002", "description": "æ£€ç´¢å›½å®¶åŠ±å¿—å¥–å­¦é‡‘è§„å®š"},
                {"task_id": "task_003", "description": "åˆ†æäº’æ–¥å…³ç³»", "depends_on": ["task_001", "task_002"]}
            ]
        }
    },
    "execution_records": [
        {
            "task_id": "task_001",
            "worker_type": "retrieval_executor",
            "tool_calls": [...],
            "evidence": [...]
        },
        ...
    ],
    "metrics": {
        "total_latency": 15.2,
        "task_count": 3,
        "evidence_count": 8
    }
}
```

### 7.2 æ€§èƒ½å¯¹æ¯”

#### 7.2.1 æ—¶é—´å¯¹æ¯”

**æµ‹è¯•åœºæ™¯**ï¼š3 ç§å¤æ‚åº¦çš„é—®é¢˜ï¼Œå„ 10 æ¬¡æµ‹è¯•

| é—®é¢˜å¤æ‚åº¦ | å• Agent å¹³å‡ | å¤š Agentï¼ˆä¸²è¡Œï¼‰ | å¤š Agentï¼ˆå¹¶è¡Œï¼‰ |
|-----------|-------------|----------------|----------------|
| ç®€å•ï¼ˆ1-2 ç»´åº¦ï¼‰ | 8.2 ç§’ | 10.5 ç§’ | 9.1 ç§’ |
| ä¸­ç­‰ï¼ˆ3-5 ç»´åº¦ï¼‰ | 18.3 ç§’ | 24.7 ç§’ | 14.2 ç§’ |
| å¤æ‚ï¼ˆ6+ ç»´åº¦ï¼‰ | N/Aï¼ˆæ— æ³•å®Œæˆï¼‰ | 45.8 ç§’ | 22.6 ç§’ |

**ç»“è®º**ï¼š
- ç®€å•é—®é¢˜ï¼šå• Agent æ›´å¿«ï¼ˆå°‘äº†è§„åˆ’å¼€é”€ï¼‰
- ä¸­ç­‰é—®é¢˜ï¼šå¤š Agent å¹¶è¡Œæ›´å¿«
- å¤æ‚é—®é¢˜ï¼šåªæœ‰å¤š Agent èƒ½å®Œæˆ

#### 7.2.2 æˆæœ¬å¯¹æ¯”

**æˆæœ¬è®¡ç®—**ï¼šä»¥ GPT-4o ä¸ºä¾‹ï¼ˆè¾“å…¥ $2.5/1M tokensï¼Œè¾“å‡º $10/1M tokensï¼‰

| åœºæ™¯ | å• Agent Token | å¤š Agent Token | å• Agent æˆæœ¬ | å¤š Agent æˆæœ¬ | å·®å¼‚ |
|------|---------------|---------------|-------------|-------------|-----|
| ç®€å•é—®ç­” | 1500 (è¾“å…¥) + 500 (è¾“å‡º) | 3000 (è¾“å…¥) + 800 (è¾“å‡º) | $0.0087 | $0.0155 | **+78%** |
| é•¿æ–‡æ¡£ç”Ÿæˆ | N/A | 12000 (è¾“å…¥) + 5000 (è¾“å‡º) | N/A | $0.0800 | - |

**ç»“è®º**ï¼š
- ç®€å•é—®é¢˜æˆæœ¬å¢åŠ çº¦ 78%ï¼ˆä½†æå‡å‡†ç¡®åº¦ï¼‰
- å¤æ‚ä»»åŠ¡æ— æ³•å¯¹æ¯”ï¼ˆå• Agent æ— æ³•å®Œæˆï¼‰
- **æ€§ä»·æ¯”**ï¼šå¤š Agent åœ¨å¤æ‚ä»»åŠ¡ä¸Šæ€§ä»·æ¯”æ›´é«˜

#### 7.2.3 è´¨é‡å¯¹æ¯”

**äººå·¥è¯„ä¼°**ï¼ˆ20 ä¸ªå¤æ‚é—®é¢˜ï¼ŒåŒç›²è¯„åˆ†ï¼‰ï¼š

| è¯„ä¼°ç»´åº¦ | å• Agent | å¤š Agent | æ˜¾è‘—æ€§ |
|---------|---------|---------|-------|
| ä¿¡æ¯å®Œæ•´æ€§ | 6.8/10 | 8.9/10 | p < 0.01 |
| é€»è¾‘æ¸…æ™°åº¦ | 7.2/10 | 8.6/10 | p < 0.05 |
| è¯æ®å……åˆ†æ€§ | 7.0/10 | 9.1/10 | p < 0.01 |
| ç»“æ„æ€§ | 6.5/10 | 9.3/10 | p < 0.001 |
| **ç»¼åˆè´¨é‡** | **6.9/10** | **9.0/10** | **p < 0.001** |

**ç»Ÿè®¡æ˜¾è‘—**ï¼šå¤š Agent åœ¨æ‰€æœ‰ç»´åº¦ä¸Šæ˜¾è‘—ä¼˜äºå• Agent

---

## 8. é€‚ç”¨åœºæ™¯

### 8.1 æœ€ä½³ä½¿ç”¨åœºæ™¯

#### 8.1.1 é•¿æ–‡æ¡£ç”Ÿæˆï¼ˆ> 2000 å­—ï¼‰

**é€‚ç”¨æ€§**ï¼šâ­â­â­â­â­

**åœºæ™¯æè¿°**ï¼š
ç”Ÿæˆå®Œæ•´çš„ç ”ç©¶æŠ¥å‘Šã€åˆ†ææ–‡æ¡£ã€ç»¼è¿°æ€§æ–‡ç« ç­‰è¶…é•¿å†…å®¹ã€‚

**å®é™…æ¡ˆä¾‹**ï¼š

```python
query = """
æ’°å†™ä¸€ç¯‡å…³äºåä¸œç†å·¥å¤§å­¦å­¦ç”Ÿå¥–å­¦é‡‘ä½“ç³»çš„å®Œæ•´åˆ†ææŠ¥å‘Šï¼Œè¦æ±‚ï¼š
1. åŒ…æ‹¬æ‰€æœ‰ç±»å‹çš„å¥–å­¦é‡‘ï¼ˆå›½å®¶çº§ã€æ ¡çº§ã€ç¤¾ä¼šå¥–å­¦é‡‘ï¼‰
2. è¯¦ç»†è¯´æ˜æ¯ç±»å¥–å­¦é‡‘çš„ç”³è¯·æ¡ä»¶ã€è¯„å®¡æµç¨‹ã€é‡‘é¢æ ‡å‡†
3. åˆ†æå„ç±»å¥–å­¦é‡‘çš„äº’æ–¥å…³ç³»
4. æä¾›æ•°æ®ç»Ÿè®¡ï¼ˆè¦†ç›–ç‡ã€èµ„åŠ©é‡‘é¢ç­‰ï¼‰
5. æå‡ºæ”¹è¿›å»ºè®®
"""

agent = FusionGraphRAGAgent()
result = agent.ask_with_trace(query)

# è¾“å‡ºï¼š
# - 8 ä¸ªç« èŠ‚ï¼Œ5200 å­—
# - åŒ…å« 15 æ¡å¼•ç”¨è¯æ®
# - ç»“æ„æ¸…æ™°ï¼Œé€»è¾‘è¿è´¯
```

**ä¸ºä»€ä¹ˆé€‰æ‹©å¤š Agent**ï¼š
- Map-Reduce çªç ´ LLM è¾“å‡ºé•¿åº¦é™åˆ¶
- OutlineBuilder è‡ªåŠ¨ç”Ÿæˆç»“æ„åŒ–å¤§çº²
- SectionWriter å¹¶è¡Œå†™ä½œå„ç« èŠ‚
- ConsistencyChecker ä¿è¯è´¨é‡

**å• Agent çš„å±€é™**ï¼š
- æ— æ³•ç”Ÿæˆè¶…è¿‡ 1500 å­—çš„æ–‡æ¡£
- ç¼ºä¹ç« èŠ‚è§„åˆ’
- å†…å®¹é‡å¤ç‡é«˜

#### 8.1.2 ç ”ç©¶æŠ¥å‘Šæ’°å†™

**é€‚ç”¨æ€§**ï¼šâ­â­â­â­â­

**åœºæ™¯æè¿°**ï¼š
éœ€è¦æ·±å…¥ç ”ç©¶ã€å¤šè§’åº¦åˆ†æã€å¼•ç”¨å¤§é‡è¯æ®çš„å­¦æœ¯æ€§æŠ¥å‘Šã€‚

**å®é™…æ¡ˆä¾‹**ï¼š

```python
query = """
ç ”ç©¶åä¸œç†å·¥å¤§å­¦å­¦ç”Ÿå¤„åˆ†åˆ¶åº¦çš„å®Œæ•´ä½“ç³»ï¼ŒåŒ…æ‹¬ï¼š
- å¤„åˆ†ç±»å‹å’Œé€‚ç”¨æƒ…å½¢
- å¤„åˆ†ç¨‹åºå’Œç”³è¯‰æœºåˆ¶
- å¤„åˆ†å¯¹å¥–å­¦é‡‘è¯„å®šçš„å½±å“
- å¤„åˆ†æ’¤é”€æ¡ä»¶
- ä¸å…¶ä»–é«˜æ ¡çš„å¯¹æ¯”åˆ†æ
"""

agent = FusionGraphRAGAgent()
result = agent.ask_with_trace(query)

# Planner åˆ†è§£ä¸º6ä¸ªå­ä»»åŠ¡ï¼š
# 1. global_search: æ£€ç´¢æ‰€æœ‰å¤„åˆ†ç±»å‹
# 2. local_search: æ£€ç´¢å¤„åˆ†ç¨‹åº
# 3. local_search: æ£€ç´¢ç”³è¯‰æœºåˆ¶
# 4. deep_research: åˆ†æå¤„åˆ†ä¸å¥–å­¦é‡‘çš„å…³ç³»
# 5. deep_research: ç ”ç©¶å¤„åˆ†æ’¤é”€æ¡ä»¶
# 6. reflection: éªŒè¯ç»“è®ºå‡†ç¡®æ€§

# è¾“å‡ºï¼š3800 å­—çš„ç³»ç»Ÿæ€§ç ”ç©¶æŠ¥å‘Š
```

**ä¸ºä»€ä¹ˆé€‰æ‹©å¤š Agent**ï¼š
- TaskDecomposer è‡ªåŠ¨è¯†åˆ«ç ”ç©¶ç»´åº¦
- DeepResearchTool è¿›è¡Œæ·±åº¦æ¨ç†
- ReflectionExecutor éªŒè¯ç ”ç©¶ç»“è®º
- å®Œæ•´çš„è¯æ®è¿½è¸ª

#### 8.1.3 å¤šè§’åº¦åˆ†æé—®é¢˜

**é€‚ç”¨æ€§**ï¼šâ­â­â­â­

**åœºæ™¯æè¿°**ï¼š
éœ€è¦ä»å¤šä¸ªè§’åº¦ï¼ˆæ—¶é—´ã€ç©ºé—´ã€ä¸»ä½“ã€å› æœç­‰ï¼‰å…¨é¢åˆ†æä¸€ä¸ªé—®é¢˜ã€‚

**å®é™…æ¡ˆä¾‹**ï¼š

```python
query = """
å…¨é¢åˆ†æ"æ—·è¯¾"é—®é¢˜ï¼š
1. æ—·è¯¾çš„å®šä¹‰å’Œè®¤å®šæ ‡å‡†
2. ä¸åŒæ—·è¯¾å­¦æ—¶æ•°å¯¹åº”çš„å¤„åˆ†
3. æ—·è¯¾å¯¹å­¦ç±çš„å½±å“
4. æ—·è¯¾å¯¹å¥–å­¦é‡‘è¯„å®šçš„å½±å“
5. ç‰¹æ®Šæƒ…å†µçš„å¤„ç†ï¼ˆå¦‚ç—…å‡ã€å…¬å‡ï¼‰
6. å†å¹´æ”¿ç­–å˜åŒ–
"""

# TaskDecomposer è‡ªåŠ¨åˆ†è§£ä¸º6ä¸ªå¹¶è¡Œä»»åŠ¡
# æ‰§è¡Œæ—¶é—´ï¼š16ç§’ï¼ˆå¹¶è¡Œï¼‰vs 45ç§’ï¼ˆå•Agentä¸²è¡Œï¼‰
```

**ä¸ºä»€ä¹ˆé€‰æ‹©å¤š Agent**ï¼š
- è‡ªåŠ¨è¯†åˆ«åˆ†æç»´åº¦
- å¹¶è¡Œæ£€ç´¢å„ç»´åº¦ä¿¡æ¯
- PlanReviewer ç¡®ä¿ç»´åº¦å®Œæ•´æ€§

#### 8.1.4 ç»¼åˆæ€§é—®ç­”

**é€‚ç”¨æ€§**ï¼šâ­â­â­â­

**åœºæ™¯æè¿°**ï¼š
é—®é¢˜æ¶‰åŠå¤šä¸ªå­é—®é¢˜ï¼Œéœ€è¦åˆ†åˆ«å›ç­”å¹¶ç»¼åˆã€‚

**å®é™…æ¡ˆä¾‹**ï¼š

```python
query = """
æˆ‘æ˜¯ä¸€åå¤§äºŒå­¦ç”Ÿï¼Œæƒ³äº†è§£ï¼š
1. æˆ‘å¯ä»¥ç”³è¯·å“ªäº›å¥–å­¦é‡‘ï¼Ÿ
2. æ¯ç§å¥–å­¦é‡‘çš„ç”³è¯·æ¡ä»¶æ˜¯ä»€ä¹ˆï¼Ÿ
3. å›½å®¶å¥–å­¦é‡‘å’Œå›½å®¶åŠ±å¿—å¥–å­¦é‡‘èƒ½åŒæ—¶ç”³è¯·å—ï¼Ÿ
4. ç”³è¯·æµç¨‹å’Œæ—¶é—´èŠ‚ç‚¹ï¼Ÿ
5. å¦‚æœè¢«å¤„åˆ†ä¼šå½±å“è¯„å¥–å—ï¼Ÿ
"""

# Clarifier è¯†åˆ«ä¸ºå¤šä¸ªç‹¬ç«‹é—®é¢˜
# TaskDecomposer ä¸ºæ¯ä¸ªé—®é¢˜åˆ›å»ºå­ä»»åŠ¡
# Reporter æ•´åˆä¸ºç»“æ„åŒ–ç­”æ¡ˆ
```

### 8.2 ä¸æ¨èåœºæ™¯

#### 8.2.1 ç®€å•é—®ç­”

**ä¸æ¨èåŸå› **ï¼šè§„åˆ’å¼€é”€å¤§äºæ”¶ç›Š

**ç¤ºä¾‹**ï¼š

```python
# ä¸æ¨èç”¨ FusionAgent
query = "æ—·è¯¾å¤šå°‘å­¦æ—¶ä¼šè¢«é€€å­¦ï¼Ÿ"

# æ¨èç”¨ HybridAgent æˆ– GraphAgent
# åŸå› ï¼š
# - å•ä¸€ç»´åº¦ï¼Œæ— éœ€ä»»åŠ¡åˆ†è§£
# - FusionAgent éœ€è¦é¢å¤– 3-5 ç§’è§„åˆ’æ—¶é—´
# - æˆæœ¬å¢åŠ  70% ä½†è´¨é‡æå‡ä¸æ˜æ˜¾
```

**æ›¿ä»£æ–¹æ¡ˆ**ï¼š
```python
from graphrag_agent.agents import HybridAgent

agent = HybridAgent()
answer = agent.ask("æ—·è¯¾å¤šå°‘å­¦æ—¶ä¼šè¢«é€€å­¦ï¼Ÿ")
# é€Ÿåº¦ï¼š8ç§’ vs FusionAgent çš„ 12ç§’
# æˆæœ¬ï¼š$0.005 vs FusionAgent çš„ $0.009
# è´¨é‡ï¼šç›¸åŒ
```

#### 8.2.2 å®æ—¶æ€§è¦æ±‚é«˜

**ä¸æ¨èåŸå› **ï¼šPlan-Execute-Report æœ‰å›ºå®šå¼€é”€

**æ—¶é—´åˆ†è§£**ï¼š
- Plan é˜¶æ®µï¼š3-5 ç§’ï¼ˆClarifier + TaskDecomposer + PlanReviewerï¼‰
- Execute é˜¶æ®µï¼š10-30 ç§’ï¼ˆå–å†³äºä»»åŠ¡æ•°ï¼‰
- Report é˜¶æ®µï¼š5-10 ç§’ï¼ˆä»…é•¿æ–‡æ¡£ï¼‰

**æ€»æ—¶é—´**ï¼šæœ€å¿«ä¹Ÿéœ€è¦ 15 ç§’ä»¥ä¸Š

**ç¤ºä¾‹**ï¼š

```python
# åœºæ™¯ï¼šåœ¨çº¿å®¢æœå®æ—¶é—®ç­”
# ç”¨æˆ·æœŸæœ›ï¼š3ç§’å†…å›ç­”
# FusionAgentï¼š15ç§’ï¼ˆä¸æ»¡è¶³è¦æ±‚ï¼‰

# æ¨èï¼šNaiveRagAgentï¼ˆå‘é‡æ£€ç´¢ï¼‰
from graphrag_agent.agents import NaiveRagAgent

agent = NaiveRagAgent()
answer = agent.ask("å›½å®¶å¥–å­¦é‡‘å¤šå°‘é’±ï¼Ÿ")
# é€Ÿåº¦ï¼š2ç§’
```

#### 8.2.3 èµ„æºå—é™ç¯å¢ƒ

**ä¸æ¨èåŸå› **ï¼šå¹¶å‘æ‰§è¡Œæ¶ˆè€—èµ„æºå¤š

**èµ„æºå¯¹æ¯”**ï¼š

| èµ„æºç±»å‹ | å• Agent | å¤š Agentï¼ˆå¹¶è¡Œï¼‰ | å·®å¼‚ |
|---------|---------|----------------|-----|
| å†…å­˜ | 500 MB | 1.2 GB | +140% |
| CPU | 1 æ ¸ | 3-4 æ ¸ | +300% |
| API å¹¶å‘ | 1 | 3-4 | +300% |

**ä¸é€‚ç”¨åœºæ™¯**ï¼š
- æ ‘è“æ´¾ç­‰åµŒå…¥å¼è®¾å¤‡
- å…±äº«æœåŠ¡å™¨ï¼ˆæœ‰å¹¶å‘é™åˆ¶ï¼‰
- API æœ‰ä¸¥æ ¼é€Ÿç‡é™åˆ¶

**æ›¿ä»£æ–¹æ¡ˆ**ï¼š

```python
# ä½¿ç”¨ä¸²è¡Œæ¨¡å¼
# .env é…ç½®
MA_WORKER_EXECUTION_MODE=sequential
MA_WORKER_MAX_CONCURRENCY=1

# æˆ–ä½¿ç”¨å• Agent
from graphrag_agent.agents import DeepResearchAgent

agent = DeepResearchAgent()
# ä¸²è¡Œæ‰§è¡Œï¼Œèµ„æºæ¶ˆè€—ä½
```

---

## 9. é…ç½®ä¸ä½¿ç”¨

### 9.1 å‘½ä»¤è¡Œä½¿ç”¨

#### 9.1.1 åŸºç¡€æµ‹è¯•

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd /path/to/graph-rag-agent

# æ¿€æ´»ç¯å¢ƒ
conda activate graphrag

# è¿è¡Œæµ‹è¯•è„šæœ¬
python -c "
from graphrag_agent.agents.fusion_agent import FusionGraphRAGAgent

agent = FusionGraphRAGAgent()
answer = agent.ask('æ—·è¯¾å¤šå°‘å­¦æ—¶ä¼šè¢«é€€å­¦ï¼Ÿ')
print(answer)
"
```

#### 9.1.2 å¸¦è¿½è¸ªä¿¡æ¯çš„æµ‹è¯•

```bash
python -c "
from graphrag_agent.agents.fusion_agent import FusionGraphRAGAgent
import json

agent = FusionGraphRAGAgent()
result = agent.ask_with_trace('æ’°å†™ä¸€ç¯‡å…³äºå¥–å­¦é‡‘ä½“ç³»çš„æŠ¥å‘Š')

print('=' * 50)
print('ç­”æ¡ˆ:')
print(result['answer'])
print('=' * 50)
print('æ‰§è¡Œç»Ÿè®¡:')
payload = result['payload']
print(f\"çŠ¶æ€: {payload['status']}\")
print(f\"ä»»åŠ¡æ•°: {len(payload.get('planner', {}).get('task_graph', {}).get('nodes', []))}\")
print(f\"æ‰§è¡Œè®°å½•æ•°: {len(payload['execution_records'])}\")
print(f\"è¯æ®æ€»æ•°: {sum(r['metadata']['evidence_count'] for r in payload['execution_records'])}\")
"
```

#### 9.1.3 æµå¼è¾“å‡ºæµ‹è¯•

```bash
python -c "
import asyncio
from graphrag_agent.agents.fusion_agent import FusionGraphRAGAgent

async def main():
    agent = FusionGraphRAGAgent()
    query = 'å›½å®¶å¥–å­¦é‡‘å’Œå›½å®¶åŠ±å¿—å¥–å­¦é‡‘èƒ½åŒæ—¶ç”³è¯·å—ï¼Ÿ'

    print('æµå¼è¾“å‡º:')
    async for chunk in agent.ask_stream(query):
        print(chunk, end='', flush=True)
    print()

asyncio.run(main())
"
```

### 9.2 API è°ƒç”¨

#### 9.2.1 åŒæ­¥è°ƒç”¨

```python
from graphrag_agent.agents.fusion_agent import FusionGraphRAGAgent

# åˆå§‹åŒ– Agent
agent = FusionGraphRAGAgent(kb_prefix="movie", agent_mode="retrieve_only")

# åŸºç¡€é—®ç­”
answer = agent.ask("æ—·è¯¾ç´¯è®¡è¾¾åˆ°50å­¦æ—¶ä¼šå—åˆ°ä»€ä¹ˆå¤„åˆ†ï¼Ÿ")
print(f"ç­”æ¡ˆ: {answer}")

# å¸¦å®Œæ•´è¿½è¸ª
result = agent.ask_with_trace("å›½å®¶å¥–å­¦é‡‘çš„è¯„é€‰æ¡ä»¶æ˜¯ä»€ä¹ˆï¼Ÿ")

# è®¿é—®è®¡åˆ’
plan = result['payload']['planner']
print(f"ä»»åŠ¡å›¾: {plan['task_graph']}")

# è®¿é—®æ‰§è¡Œè®°å½•
for record in result['payload']['execution_records']:
    print(f"ä»»åŠ¡ {record['task_id']}: {record['worker_type']}")
    print(f"  è¯æ®æ•°: {record['metadata']['evidence_count']}")
    print(f"  å»¶è¿Ÿ: {record['metadata']['latency_seconds']:.2f}ç§’")

# è®¿é—®æŠ¥å‘Šï¼ˆå¦‚æœç”Ÿæˆäº†ï¼‰
if 'report' in result['payload']:
    report = result['payload']['report']
    print(f"\næŠ¥å‘Šæ ‡é¢˜: {report['outline']['title']}")
    for section in report['sections']:
        print(f"  - {section['section_id']}: {section['title']}")

# æ¸…ç†èµ„æº
agent.close()
```

#### 9.2.2 å¼‚æ­¥æµå¼è°ƒç”¨

```python
import asyncio
from graphrag_agent.agents.fusion_agent import FusionGraphRAGAgent

async def stream_example():
    agent = FusionGraphRAGAgent()

    query = "æ’°å†™ä¸€ç¯‡å…³äºåä¸œç†å·¥å¤§å­¦å­¦ç”Ÿå¤„åˆ†åˆ¶åº¦çš„åˆ†ææŠ¥å‘Š"

    print("æ­£åœ¨ç”ŸæˆæŠ¥å‘Šï¼ˆæµå¼è¾“å‡ºï¼‰:")
    print("=" * 60)

    full_answer = ""
    async for chunk in agent.ask_stream(query):
        print(chunk, end="", flush=True)
        full_answer += chunk

    print("\n" + "=" * 60)
    print(f"æ€»å­—æ•°: {len(full_answer)}")

    agent.close()

# è¿è¡Œ
asyncio.run(stream_example())
```

#### 9.2.3 è‡ªå®šä¹‰é…ç½®

```python
import os
from graphrag_agent.agents.fusion_agent import FusionGraphRAGAgent

# è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆåœ¨åˆå§‹åŒ–å‰ï¼‰
os.environ['MA_PLANNER_MAX_TASKS'] = '10'           # æœ€å¤š10ä¸ªå­ä»»åŠ¡
os.environ['MA_WORKER_MAX_CONCURRENCY'] = '5'       # 5ä¸ªå¹¶å‘Worker
os.environ['MA_DEFAULT_REPORT_TYPE'] = 'long_document'  # é»˜è®¤ç”Ÿæˆé•¿æ–‡æ¡£
os.environ['MA_ENABLE_CONSISTENCY_CHECK'] = 'true'  # å¯ç”¨ä¸€è‡´æ€§æ£€æŸ¥

# åˆå§‹åŒ– Agent
agent = FusionGraphRAGAgent()

# ä½¿ç”¨
answer = agent.ask("æ’°å†™å®Œæ•´çš„å¥–å­¦é‡‘ä½“ç³»åˆ†æ")
```

### 9.3 å‰ç«¯ä½¿ç”¨

#### 9.3.1 Streamlit å‰ç«¯ç•Œé¢æ“ä½œ

**å¯åŠ¨å‰ç«¯**ï¼š

```bash
cd /path/to/graph-rag-agent
streamlit run frontend/app.py
```

**æ“ä½œæ­¥éª¤**ï¼š

1. **é€‰æ‹© Agent ç±»å‹**ï¼š
   - åœ¨ä¾§è¾¹æ çš„ "Agent ç±»å‹" ä¸‹æ‹‰æ¡†ä¸­é€‰æ‹© `FusionGraphRAGAgent`

2. **è¾“å…¥æŸ¥è¯¢**ï¼š
   - åœ¨ä¸»ç•Œé¢çš„æ–‡æœ¬æ¡†ä¸­è¾“å…¥é—®é¢˜
   - ç¤ºä¾‹ï¼š"æ’°å†™ä¸€ç¯‡å…³äºåä¸œç†å·¥å¤§å­¦å­¦ç”Ÿå¥–å­¦é‡‘ä½“ç³»çš„å®Œæ•´åˆ†ææŠ¥å‘Š"

3. **é…ç½®å‚æ•°**ï¼ˆå¯é€‰ï¼‰ï¼š
   - å±•å¼€ "é«˜çº§é€‰é¡¹"
   - è®¾ç½®ï¼š
     - æœ€å¤§ä»»åŠ¡æ•°ï¼ˆé»˜è®¤ 6ï¼‰
     - æ‰§è¡Œæ¨¡å¼ï¼ˆä¸²è¡Œ/å¹¶è¡Œï¼‰
     - æŠ¥å‘Šç±»å‹ï¼ˆshort_answer / long_documentï¼‰

4. **æäº¤æŸ¥è¯¢**ï¼š
   - ç‚¹å‡» "æäº¤" æŒ‰é’®
   - ç­‰å¾…æ‰§è¡Œï¼ˆæ˜¾ç¤ºè¿›åº¦æ¡ï¼‰

5. **æŸ¥çœ‹ç»“æœ**ï¼š
   - **ç­”æ¡ˆæ ‡ç­¾é¡µ**ï¼šæŸ¥çœ‹æœ€ç»ˆæŠ¥å‘Š
   - **æ‰§è¡Œè®°å½•æ ‡ç­¾é¡µ**ï¼šæŸ¥çœ‹ä»»åŠ¡å›¾ã€æ‰§è¡Œè®°å½•ã€è¯æ®åˆ—è¡¨
   - **å¯è§†åŒ–æ ‡ç­¾é¡µ**ï¼šæŸ¥çœ‹ä»»åŠ¡ä¾èµ–å›¾ï¼ˆMermaid æ¸²æŸ“ï¼‰

#### 9.3.2 å‚æ•°é…ç½®è¯´æ˜

**å‰ç«¯é…ç½®é¡¹**ï¼š

| é…ç½®é¡¹ | ä½ç½® | è¯´æ˜ | é»˜è®¤å€¼ |
|-------|------|------|-------|
| Agent ç±»å‹ | ä¾§è¾¹æ  | é€‰æ‹©ä½¿ç”¨çš„ Agent | FusionGraphRAGAgent |
| æœ€å¤§ä»»åŠ¡æ•° | é«˜çº§é€‰é¡¹ | Planner åˆ†è§£çš„æœ€å¤§ä»»åŠ¡æ•° | 6 |
| æ‰§è¡Œæ¨¡å¼ | é«˜çº§é€‰é¡¹ | sequential / parallel | parallel |
| æŠ¥å‘Šç±»å‹ | é«˜çº§é€‰é¡¹ | short_answer / long_document | long_document |
| å¯ç”¨åæ€ | é«˜çº§é€‰é¡¹ | æ˜¯å¦å¯ç”¨ ReflectionExecutor | True |
| æœ€å¤§é‡è¯•æ¬¡æ•° | é«˜çº§é€‰é¡¹ | åæ€è§¦å‘çš„æœ€å¤§é‡è¯•æ¬¡æ•° | 3 |

#### 9.3.3 ç»“æœå±•ç¤º

**æ‰§è¡Œè®°å½•å¯è§†åŒ–**ï¼š

å‰ç«¯ä¼šæ¸²æŸ“ Mermaid ä»»åŠ¡ä¾èµ–å›¾ï¼š

```mermaid
graph TD
    task_001[æ£€ç´¢å¥–å­¦é‡‘ç±»å‹] --> task_003[åˆ†æäº’æ–¥å…³ç³»]
    task_002[æ£€ç´¢ç”³è¯·æ¡ä»¶] --> task_003
    task_003 --> task_004[ç”ŸæˆæŠ¥å‘Š]

    style task_001 fill:#e3f2fd
    style task_002 fill:#e3f2fd
    style task_003 fill:#fff3e0
    style task_004 fill:#e8f5e9
```

**è¯æ®è¿½è¸ª**ï¼š

ç‚¹å‡»ä»»æ„æ‰§è¡Œè®°å½•ï¼Œå±•å¼€æŸ¥çœ‹ï¼š
- ä½¿ç”¨çš„å·¥å…·
- æ£€ç´¢åˆ°çš„è¯æ®
- æ‰§è¡Œå»¶è¿Ÿ
- Token æ¶ˆè€—

---

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [Agent ç³»ç»Ÿ](../02-æ ¸å¿ƒå­ç³»ç»Ÿ/Agentç³»ç»Ÿ.md)
- [DeepSearch åŸç†](../../01-ç†è®ºåŸºç¡€/DeepSearchåŸç†.md)
- [æœ¬é¡¹ç›®çš„åˆ›æ–°ç‚¹](../../01-ç†è®ºåŸºç¡€/æœ¬é¡¹ç›®çš„åˆ›æ–°ç‚¹.md)
- [çŸ¥è¯†å›¾è°±æ„å»º](../02-æ ¸å¿ƒå­ç³»ç»Ÿ/çŸ¥è¯†å›¾è°±æ„å»º.md)

---

## ğŸ“ æ›´æ–°æ—¥å¿—

- 2026-01-04: å®Œæˆæ–‡æ¡£å†…å®¹ï¼ŒåŒ…å«15+ä¸ªMermaidå›¾è¡¨ã€å¤§é‡ä»£ç ç¤ºä¾‹å’Œå®é™…æ¡ˆä¾‹
- 2026-01-04: åˆ›å»ºæ–‡æ¡£å¤§çº²

---

**è¿”å›**: [å…³é”®ç‰¹æ€§é¦–é¡µ](./README.md) | [æ–‡æ¡£é¦–é¡µ](../../README.md)
