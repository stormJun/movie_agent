# 多记忆后端适配架构设计文档

## 1. 背景与目标

当前系统使用 **Mem0** 作为长期记忆（Long-term Memory）后端。为支持未来切换到其他记忆系统（如 Zep、PostgreSQL+pgvector 等）或同时运行多种记忆策略，需要从架构层面降低对特定实现的耦合。

**目标**：实现通过配置切换记忆后端，无需修改核心业务代码。

---

## 2. 架构概览

### 2.1 分层架构

```
┌─────────────────────────────────────────────────────────────────┐
│                      业务层 (Application)                        │
│   MemoryService: recall_context(), maybe_write()                │
├─────────────────────────────────────────────────────────────────┤
│                      端口层 (Ports)                              │
│   MemoryStorePort: search(), add(), delete(), update()          │
├─────────────────────────────────────────────────────────────────┤
│                      适配器层 (Adapters)                         │
│   ┌─────────────┐  ┌─────────────┐  ┌─────────────────────┐     │
│   │ Mem0Adapter │  │ ZepAdapter  │  │ PostgresVectorAdapter│     │
│   └─────────────┘  └─────────────┘  └─────────────────────┘     │
└─────────────────────────────────────────────────────────────────┘
```

### 2.2 两套独立的存储系统

系统中存在两套独立的记忆存储，职责明确分离：

| 系统 | 接口 | 用途 | 生命周期 | 当前实现 |
|------|------|------|---------|---------|
| **对话历史** | `ConversationStorePort` | 会话消息列表 | 会话级别 | PostgreSQL |
| **长期记忆** | `MemoryStorePort` | 语义检索记忆 | 跨会话持久化 | Mem0 |

> [!IMPORTANT]
> 这两个系统是**独立的**，不要混淆。`MemoryStorePort` 专注于**长期记忆的语义检索**，而非对话历史管理。

### 2.3 多后端并存模式

系统支持同时运行多个记忆后端，实现**冗余备份**或**策略互补**：

```python
# infrastructure/memory/composite_memory_store.py

from typing import Literal

class WriteStrategy(str, Literal["primary", "all", "fanout"]):
    PRIMARY = "primary"      # 只写主库，其他只读
    ALL = "all"              # 写全部（同步）
    FANOUT = "fanout"        # 写全部（异步，best-effort）

class CompositeMemoryStore(MemoryStorePort):
    """组合多个记忆后端，实现并行查询和冗余写入"""

    def __init__(
        self,
        *,
        stores: list[MemoryStorePort],
        write_strategy: WriteStrategy = WriteStrategy.PRIMARY,
        primary_index: int = 0,
    ):
        self._stores = stores
        self._write_strategy = write_strategy
        self._primary_index = primary_index

    async def search(
        self,
        *,
        user_id: str,
        query: str,
        top_k: int,
    ) -> list[MemoryItem]:
        """并行查询所有后端，合并结果"""
        # 1. 并发查询所有后端
        results = await asyncio.gather(
            *[store.search(user_id=user_id, query=query, top_k=top_k)
              for store in self._stores],
            return_exceptions=True,
        )

        # 2. 收集有效结果
        all_items: list[MemoryItem] = []
        for r in results:
            if isinstance(r, Exception):
                logger.warning(f"Store query failed: {r}")
                continue
            all_items.extend(r)

        # 3. 按 memory_id 去重（保留最高分）
        seen: dict[str, MemoryItem] = {}
        for item in all_items:
            if item.id not in seen or item.score > seen[item.id].score:
                seen[item.id] = item

        # 4. 按分数排序并截断
        deduped = sorted(seen.values(), key=lambda x: x.score, reverse=True)
        return deduped[:top_k]

    async def add(
        self,
        *,
        user_id: str,
        text: str,
        tags: Optional[list[str]] = None,
        metadata: Optional[dict[str, Any]] = None,
    ) -> Optional[str]:
        """根据策略写入后端"""
        primary = self._stores[self._primary_index]

        if self._write_strategy == WriteStrategy.PRIMARY:
            # 只写主库
            return await primary.add(user_id=user_id, text=text, tags=tags, metadata=metadata)

        elif self._write_strategy == WriteStrategy.ALL:
            # 同步写全部（任一失败则整体失败）
            memory_id = None
            for store in self._stores:
                mid = await store.add(user_id=user_id, text=text, tags=tags, metadata=metadata)
                if memory_id is None:
                    memory_id = mid  # 使用第一个返回的 ID
            return memory_id

        elif self._write_strategy == WriteStrategy.FANOUT:
            # 异步写全部（best-effort，不阻塞主流程）
            asyncio.create_task(self._fanout_add(user_id=user_id, text=text, tags=tags, metadata=metadata))
            return await primary.add(user_id=user_id, text=text, tags=tags, metadata=metadata)

    async def _fanout_add(self, **kwargs) -> None:
        """异步写入所有后端（忽略错误）"""
        for store in self._stores:
            try:
                await store.add(**kwargs)
            except Exception as e:
                logger.warning(f"Fanout write failed: {e}")

    async def close(self) -> None:
        """关闭所有后端连接"""
        await asyncio.gather(*[store.close() for store in self._stores], return_exceptions=True)
```

**使用示例**：

```python
# 同时使用 Mem0（生产）+ PostgreSQL（备份）
mem0 = Mem0HttpMemoryStore(base_url="...", api_key="...")
postgres = PostgresVectorAdapter(dsn="...")

composite = CompositeMemoryStore(
    stores=[mem0, postgres],
    write_strategy=WriteStrategy.FANOUT,  # 异步写备份
    primary_index=0,                       # Mem0 为主库
)
```

**⚠️ 多后端 ID 一致性挑战**：

当使用 `WriteStrategy.ALL` 或 `WriteStrategy.FANOUT` 时，不同后端生成的 `memory_id` 可能不一致，导致无法管理（删除/更新）。

**问题场景**：

```python
# ❌ 问题：并发写导致 ID 不一致
memory_id = await mem0.add(...)  # 返回 "uuid-1"
memory_id_pg = await postgres.add(...)  # 返回 "uuid-2"（不同！）

# 后续无法通过统一 ID 删除
await composite.delete(user_id="u1", memory_id="uuid-1")  # PG 删除失败
```

**解决方案：主从 ID 策略**

```python
class CompositeMemoryStore(MemoryStorePort):
    """组合多个记忆后端（带主从 ID 策略）"""

    async def add(
        self,
        *,
        user_id: str,
        text: str,
        tags: Optional[list[str]] = None,
        metadata: Optional[dict[str, Any]] = None,
    ) -> Optional[str]:
        """主从 ID 写入策略"""
        primary = self._stores[self._primary_index]

        # 阶段 1: 先写主库，获取 canonical ID
        canonical_id = await primary.add(user_id=user_id, text=text, tags=tags, metadata=metadata)
        if not canonical_id:
            return None

        # 阶段 2: 强制从库使用相同 ID
        if self._write_strategy in (WriteStrategy.ALL, WriteStrategy.FANOUT):
            for i, store in enumerate(self._stores):
                if i == self._primary_index:
                    continue

                # 方案 A: 从库支持自定义 ID（推荐）
                try:
                    await store.add(
                        user_id=user_id,
                        text=text,
                        tags=tags,
                        metadata={**(metadata or {}), "_canonical_id": canonical_id},
                        # ⚠️ 关键：传入 canonical_id 强制从库使用相同主键
                        _force_id=canonical_id,
                    )
                except TypeError:
                    # 方案 B: 从库不支持自定义 ID，需要建立映射表
                    await self._store_id_mapping(store, canonical_id, user_id, text)

        return canonical_id

    async def _store_id_mapping(
        self,
        store: MemoryStorePort,
        canonical_id: str,
        user_id: str,
        text: str,
    ) -> None:
        """存储 ID 映射（当从库不支持自定义 ID 时）"""
        # 在映射表中记录：canonical_id -> local_id
        # 查询时需要两步：
        # 1. 查映射表获取 local_id
        # 2. 用 local_id 查从库
        logger.warning(
            f"Store {type(store).__name__} does not support custom IDs, "
            "falling back to mapping table (performance penalty)"
        )
        # ... 实现映射逻辑
```

**实施建议**：

| 策略 | 适用场景 | 实现复杂度 | 性能 |
|------|---------|-----------|------|
| **WriteStrategy.PRIMARY** | 单主写，从库只读 | ✅ 简单 | ✅ 高 |
| **主从 ID + 支持自定义 ID** | 双写/备份 | ⚠️ 中等 | ✅ 高 |
| **主从 ID + 映射表** | 从库不支持自定义 ID | ❌ 复杂 | ⚠️ 低（额外查询）|
| **UUID 全局统一** | 所有后端支持 UUID | ✅ 简单 | ✅ 高 |

**简化版方案（推荐）**：

```python
# 方案 1: 只写主库（从库只读，通过数据同步工具备份）
composite = CompositeMemoryStore(
    stores=[mem0, postgres],
    write_strategy=WriteStrategy.PRIMARY,  # ✅ 最简单
    primary_index=0,
)

# 方案 2: 要求所有后端支持 UUID 主键
class UUIDMemoryStore(MemoryStorePort):
    """要求所有实现支持 UUID 主键"""

    async def add(
        self,
        *,
        user_id: str,
        text: str,
        _force_id: Optional[str] = None,  # 强制使用指定 ID
        **kwargs
    ) -> Optional[str]:
        memory_id = _force_id or str(uuid.uuid4())
        # ... 使用 memory_id 作为主键
        return memory_id
```

---

## 3. 核心接口设计

### 3.1 设计原则：接口隔离（ISP）

> [!IMPORTANT]
> **不使用 `raise NotImplementedError` 的"可选方法"设计**，因为：
> - Protocol 是静态类型契约，`raise NotImplementedError` 会打破类型安全
> - 依赖方无法在编译时判断功能是否可用
> - 违反接口隔离原则（ISP）

**正确做法**：拆分为多个独立的 Protocol，每个协议代表一组相关能力。

### 3.2 MemoryStorePort - 基础存储接口

所有记忆存储实现**必须支持**的核心能力：

```python
# application/ports/memory_store_port.py

from typing import Protocol, Optional, Any
from domain.memory import MemoryItem

class MemoryStorePort(Protocol):
    """基础记忆存储接口 - 所有实现必须支持"""

    async def search(
        self,
        *,
        user_id: str,
        query: str,
        top_k: int = 5,
    ) -> list[MemoryItem]:
        """语义搜索记忆"""
        ...

    async def add(
        self,
        *,
        user_id: str,
        text: str,
        tags: Optional[list[str]] = None,
        metadata: Optional[dict[str, Any]] = None,
    ) -> Optional[str]:
        """添加记忆，返回 memory_id"""
        ...

    async def close(self) -> None:
        """释放资源"""
        ...
```

### 3.3 MemoryManageablePort - 管理能力接口（Future Scope）

> [!NOTE]
> **YAGNI (You Aren't Gonna Need It) - 当前业务不需要**
>
> - **当前阶段（v1）**：Chat 场景只需要 `search` + `add`，**不需要实现此接口**
> - **未来阶段（v2）**：开发"记忆管理面板"时，再引入管理能力
> - **设计提前量**：接口已定义好，避免未来重构，但**现在不要空实现**

**可选的**管理能力（CRUD 扩展），用于需要记忆管理的场景（如管理界面）：

```python
# application/ports/memory_manageable_port.py（未来需要时创建）

from typing import Protocol, Optional, Any
from domain.memory import MemoryItem

class MemoryManageablePort(Protocol):
    """记忆管理能力接口 - Future Scope

    ⚠️ 当前不需要实现此接口！
    等到开发"记忆管理面板"时再实现。
    """

    async def delete(self, *, user_id: str, memory_id: str) -> bool:
        """删除指定记忆（必须带 user_id 防止跨用户越权）"""
        ...

    async def update(
        self,
        *,
        user_id: str,
        memory_id: str,
        text: str,
        metadata: Optional[dict[str, Any]] = None,
    ) -> bool:
        """更新记忆内容（必须带 user_id 防止跨用户越权）"""
        ...

    async def get_all(
        self,
        *,
        user_id: str,
        limit: int = 100,
    ) -> list[MemoryItem]:
        """获取用户所有记忆（用于管理界面）"""
        ...
```

**实施建议**：

| 阶段 | 实现范围 | 触发条件 |
|-----|---------|---------|
| **v1（当前）** | ✅ `MemoryStorePort`（search + add）<br>❌ **不实现** `MemoryManageablePort` | Chat 场景需求 |
| **v2（未来）** | ✅ `MemoryStorePort` + `MemoryManageablePort` | 需要开发管理面板时 |

**为什么现在不实现管理接口**：

1. **YAGNI 原则**：不要为不需要的功能编写代码
2. **减少测试负担**：每个管理方法都需要安全测试（越权、并发等）
3. **降低复杂度**：当前只需要关注 search/add 的稳定性
4. **避免过度设计**：接口已定义，未来实现不会有破坏性变更

### 3.4 依赖方如何使用

```python
# 只需要基础存储
from application.ports.memory_store_port import MemoryStorePort

def service(store: MemoryStorePort):
    # ✅ 可以安全调用，所有实现都支持
    await store.search(user_id="u1", query="hello")
    await store.add(user_id="u1", text="world")

# 需要管理能力
from application.ports.memory_store_port import MemoryStorePort
from application.ports.memory_manageable_port import MemoryManageablePort

def admin_service(store: MemoryStorePort & MemoryManageablePort):
    # ✅ 类型安全：编译时确保 store 支持管理能力
    await store.delete(user_id="u1", memory_id="m123")
    await store.get_all(user_id="u1")
```

### 3.5 MemoryItem 数据模型

基于实际代码 [`memory_item.py`](../../backend/domain/memory/memory_item.py)：

```python
# domain/memory/memory_item.py

from __future__ import annotations

from dataclasses import dataclass
from datetime import datetime
from typing import Optional

@dataclass(frozen=True)
class MemoryItem:
    """Long-term memory recall item (provider-agnostic)."""
    id: str
    text: str
    score: float = 0.0
    created_at: Optional[datetime] = None
    tags: tuple[str, ...] = ()
```

**关键设计点**：

1. **`frozen=True`**：不可变对象，线程安全
2. **安全的默认值**：
   - `score: float = 0.0`（不是 `None`，避免 NPE）
   - `tags: tuple[str, ...] = ()`（空元组，不是 `None`）
   - `created_at: Optional[datetime] = None`（允许为空，但类型明确）
3. **没有 `metadata` 字段**：避免 `dict = None` 的问题
   - ❌ 错误：`metadata: dict = None`（容易 NPE，类型不明确）
   - ✅ 正确：如需扩展，添加 `metadata: dict[str, Any] = field(default_factory=dict)`

**如果需要 metadata 字段**：

```python
from dataclasses import dataclass, field
from typing import Any

@dataclass(frozen=True)
class MemoryItem:
    id: str
    text: str
    score: float = 0.0
    created_at: Optional[datetime] = None
    tags: tuple[str, ...] = ()
    metadata: dict[str, Any] = field(default_factory=dict)  # ✅ 使用 factory
```

**为什么不用 `metadata: dict = None`**：

```python
# ❌ 错误：容易 NPE
item = MemoryItem(id="1", text="hello")
if item.metadata:  # 必须检查 None
    print(item.metadata["key"])  # 否则 TypeError

# ✅ 正确：默认空 dict，直接使用
item = MemoryItem(id="1", text="hello")
print(item.metadata.get("key"))  # 返回 None，不报错
```

---

## 4. 适配器实现

### 4.1 Mem0 HTTP 适配器（当前主力实现）

基于现有 [`mem0_http_memory_store.py`](../../backend/infrastructure/memory/mem0_http_memory_store.py)，这是一个**生产就绪**的实现：

**核心特性**：
- ✅ 完整的 aiohttp 会话管理（延迟创建、超时控制）
- ✅ Authorization headers 支持
- ✅ 多种响应格式容错（`memories`/`data`/`results`/`items`）
- ✅ 异常处理和错误信息截断
- ✅ URL 安全拼接（`urljoin` + 规范化）

```python
# infrastructure/memory/mem0_http_memory_store.py（实际代码）

from __future__ import annotations

import logging
from datetime import datetime
from typing import Any, Optional
from urllib.parse import urljoin

import aiohttp

from application.ports.memory_store_port import MemoryStorePort
from domain.memory import MemoryItem
from infrastructure.config.settings import (
    MEM0_ADD_PATH,
    MEM0_API_KEY,
    MEM0_BASE_URL,
    MEM0_SEARCH_PATH,
    MEM0_TIMEOUT_S,
)

logger = logging.getLogger(__name__)

def _join(base: str, path: str) -> str:
    """安全的 URL 拼接"""
    base = (base or "").rstrip("/") + "/"
    path = (path or "").lstrip("/")
    return urljoin(base, path)

class Mem0HttpMemoryStore(MemoryStorePort):
    """mem0 HTTP client (best-effort; schema tolerant).

    特性：
    - 自动延迟创建 aiohttp.ClientSession
    - 支持 Bearer Token 认证
    - 容错多种响应格式（开源/SaaS/self-hosted）
    - 完整的异常处理和错误信息
    """

    def __init__(
        self,
        *,
        base_url: str = MEM0_BASE_URL,
        api_key: str = MEM0_API_KEY,
        timeout_s: float = MEM0_TIMEOUT_S,
        search_path: str = MEM0_SEARCH_PATH,
        add_path: str = MEM0_ADD_PATH,
    ) -> None:
        self._base_url = (base_url or "").strip()
        self._api_key = (api_key or "").strip()
        self._timeout_s = float(timeout_s or 10.0)
        self._search_url = _join(self._base_url, search_path)
        self._add_url = _join(self._base_url, add_path)
        self._session: aiohttp.ClientSession | None = None

    def _headers(self) -> dict[str, str]:
        """构建请求头（支持 Bearer Token）"""
        headers = {"content-type": "application/json"}
        if self._api_key:
            headers["authorization"] = f"Bearer {self._api_key}"
        return headers

    async def _get_session(self) -> aiohttp.ClientSession:
        """延迟创建 session（避免 event loop 问题）"""
        if self._session is not None and not self._session.closed:
            return self._session
        timeout = aiohttp.ClientTimeout(total=self._timeout_s)
        self._session = aiohttp.ClientSession(timeout=timeout)
        return self._session

    @staticmethod
    def _parse_items(payload: Any) -> list[MemoryItem]:
        """容错解析多种响应格式"""
        # 接受多种响应格式：
        # - {"memories": [...]} / {"data": [...]} / {"results": [...]}
        # - [...]
        if isinstance(payload, dict):
            for key in ("memories", "data", "results", "items"):
                if key in payload and isinstance(payload[key], list):
                    payload = payload[key]
                    break

        items: list[MemoryItem] = []
        if not isinstance(payload, list):
            return items

        for raw in payload:
            if not isinstance(raw, dict):
                continue
            mid = str(raw.get("id") or raw.get("memory_id") or raw.get("_id") or "")
            text = str(raw.get("text") or raw.get("content") or raw.get("memory") or "")
            score = float(raw.get("score") or raw.get("similarity") or 0.0)
            # ... tags / created_at 处理 ...
            items.append(MemoryItem(id=mid or text[:16], text=text, score=score, ...))
        return items

    async def search(self, *, user_id: str, query: str, top_k: int) -> list[MemoryItem]:
        """搜索记忆（带完整错误处理）"""
        if not self._base_url:
            return []
        session = await self._get_session()
        payload = {"user_id": str(user_id), "query": str(query), "limit": int(top_k)}
        async with session.post(self._search_url, json=payload, headers=self._headers()) as resp:
            if resp.status >= 400:
                text = await resp.text()
                raise RuntimeError(f"mem0 search failed ({resp.status}): {text[:200]}")
            data = await resp.json(content_type=None)
        return self._parse_items(data)

    async def add(self, *, user_id: str, text: str, **kwargs) -> Optional[str]:
        """添加记忆（带完整错误处理）"""
        if not self._base_url:
            return None
        session = await self._get_session()
        payload: dict[str, Any] = {"user_id": str(user_id), "text": str(text)}
        if kwargs.get("tags"):
            payload["tags"] = list(kwargs["tags"])
        if kwargs.get("metadata"):
            payload["metadata"] = dict(kwargs["metadata"])
        async with session.post(self._add_url, json=payload, headers=self._headers()) as resp:
            if resp.status >= 400:
                text_resp = await resp.text()
                raise RuntimeError(f"mem0 add failed ({resp.status}): {text_resp[:200]}")
            data = await resp.json(content_type=None)
        if isinstance(data, dict):
            mid = data.get("id") or data.get("memory_id") or data.get("data", {}).get("id")
            if mid:
                return str(mid)
        return None

    async def close(self) -> None:
        """关闭连接"""
        if self._session is not None and not self._session.closed:
            await self._session.close()
        self._session = None
```

**关键设计点**：
1. **会话管理**：`_get_session()` 延迟创建，避免 __init__ 时 event loop 未就绪
2. **认证支持**：`_headers()` 自动添加 `Authorization: Bearer <key>`
3. **容错解析**：`_parse_items()` 接受多种响应格式，兼容不同 mem0 版本
4. **错误截断**：`{text[:200]}` 避免日志过载
5. **配置隔离**：所有配置来自 `infrastructure.config.settings`，不在代码里 `os.getenv()`

**类型注解提示**：在依赖注入时，可以明确声明实现的能力：

```python
# 注入为只读存储
store: MemoryStorePort = Mem0HttpMemoryStore(...)

# 注入为完整管理能力（如果实现了 MemoryManageablePort）
full_store: MemoryStorePort & MemoryManageablePort = Mem0HttpMemoryStore(...)
```

### 4.2 空实现适配器（只实现基础功能）

```python
# infrastructure/memory/null_memory_store.py

from typing import Any, Optional

class NullMemoryStore(MemoryStorePort):
    """空实现 - 只实现基础存储，不支持管理功能"""

    async def search(self, *, user_id: str, query: str, top_k: int) -> list[MemoryItem]:
        return []

    async def add(
        self,
        *,
        user_id: str,
        text: str,
        tags: Optional[list[str]] = None,
        metadata: Optional[dict[str, Any]] = None,
    ) -> Optional[str]:
        # ✅ 签名与 MemoryStorePort 完全一致（不用 **kwargs）
        return None

    async def close(self) -> None:
        pass

    # ⚠️ 不实现 MemoryManageablePort
    # 如果依赖方需要管理能力，类型检查器会在编译时报错
```

**类型安全的依赖注入**：

```python
# ✅ 正确：NullMemoryStore 满足 MemoryStorePort
store: MemoryStorePort = NullMemoryStore()

# ❌ 编译错误：NullMemoryStore 不支持管理能力
admin: MemoryManageablePort = NullMemoryStore()  # 类型检查失败
```

### 4.3 PostgreSQL 适配器（未来扩展）

> [!WARNING]
> **⚠️ 以下代码是"伪实现"，仅供接口设计参考，不可直接用于生产！**
>
> 缺少的关键实现：
> - ❌ 数据库 schema（表结构、索引、向量维度）
> - ❌ Embedding 服务集成（`_embed()` 方法）
> - ❌ 连接池管理（asyncpg/pgxpool 初始化）
> - ❌ 迁移脚本（DDL、版本管理）
> - ❌ TTL/过期策略
> - ❌ 事务一致性保证
>
> **架构决策建议**：
> - 方案 A：PostgreSQL + pgvector（单库，所有数据在一起）
> - 方案 B：PostgreSQL（元数据）+ Milvus/Qdrant（专用向量库）
> - **决策前先评估**：查询性能、运维成本、数据量级、是否需要混合检索

```python
# infrastructure/memory/postgres_vector_adapter.py（伪实现 - 仅供参考）

from typing import Any, Optional

class PostgresVectorAdapter(MemoryStorePort, MemoryManageablePort):
    """PostgreSQL + pgvector 本地向量存储（伪实现）"""

    def __init__(self, dsn: str, embedding_model: str):
        self._pool = None  # ⚠️ 未初始化连接池
        self._embedding_model = embedding_model

    async def _embed(self, text: str) -> list[float]:
        """⚠️ 未实现：需要调用 embedding 服务"""
        raise NotImplementedError("需要集成 embedding 服务")

    # === MemoryStorePort 实现 ===

    async def search(self, *, user_id: str, query: str, top_k: int) -> list[MemoryItem]:
        # ⚠️ 伪代码：假设表已存在、embedding 已生成
        embedding = await self._embed(query)
        sql = """
            SELECT id, text, 1 - (embedding <=> $1) as score
            FROM memories
            WHERE user_id = $2
            ORDER BY embedding <=> $1
            LIMIT $3
        """
        rows = await self._pool.fetch(sql, embedding, user_id, top_k)
        return [MemoryItem(id=r["id"], text=r["text"], score=r["score"]) for r in rows]

    async def add(
        self,
        *,
        user_id: str,
        text: str,
        tags: Optional[list[str]] = None,
        metadata: Optional[dict[str, Any]] = None,
    ) -> Optional[str]:
        # ⚠️ 伪代码：未处理 tags/metadata 存储
        embedding = await self._embed(text)
        sql = """
            INSERT INTO memories (user_id, text, embedding)
            VALUES ($1, $2, $3)
            RETURNING id
        """
        row = await self._pool.fetchval(sql, user_id, text, embedding)
        return str(row) if row else None

    async def close(self) -> None:
        if self._pool:
            await self._pool.close()

    # === MemoryManageablePort 实现 ===

    async def delete(self, *, user_id: str, memory_id: str) -> bool:
        """删除记忆（DB 层强制 user_id 约束防止越权）"""
        sql = "DELETE FROM memories WHERE id = $1 AND user_id = $2"
        status = await self._pool.execute(sql, memory_id, user_id)
        return status.split(" ")[-1] == "1"

    async def update(
        self,
        *,
        user_id: str,
        memory_id: str,
        text: str,
        metadata: Optional[dict[str, Any]] = None,
    ) -> bool:
        """更新记忆（DB 层强制 user_id 约束防止越权）"""
        sql = """
            UPDATE memories
            SET text = $1, embedding = $2, updated_at = NOW()
            WHERE id = $3 AND user_id = $4
        """
        embedding = await self._embed(text)
        status = await self._pool.execute(sql, text, embedding, memory_id, user_id)
        return status.split(" ")[-1] == "1"

    async def get_all(self, *, user_id: str, limit: int = 100) -> list[MemoryItem]:
        """获取用户所有记忆（管理界面用）"""
        sql = """
            SELECT id, text, 0.0 as score
            FROM memories
            WHERE user_id = $1
            ORDER BY created_at DESC
            LIMIT $2
        """
        rows = await self._pool.fetch(sql, user_id, limit)
        return [MemoryItem(id=r["id"], text=r["text"], score=r["score"]) for r in rows]
```

**实施前必须补齐的工作**：

1. **Schema 设计**
   ```sql
   CREATE TABLE memories (
       id UUID PRIMARY KEY,
       user_id VARCHAR NOT NULL,
       text TEXT NOT NULL,
       embedding vector(1536),  -- 假设 OpenAI embedding
       created_at TIMESTAMPTZ DEFAULT NOW(),
       updated_at TIMESTAMPTZ DEFAULT NOW()
   );

   CREATE INDEX idx_memories_user_id ON memories(user_id);
   CREATE INDEX idx_memories_embedding ON memories USING ivfflat (embedding vector_cosine_ops);
   ```

2. **Embedding 集成**
   ```python
   async def _embed(self, text: str) -> list[float]:
       # 调用 OpenAI/本地模型生成向量
       response = await self._embedding_client.embed(text)
       return response.embedding
   ```

3. **连接池管理**
   ```python
   async def __aenter__(self):
       self._pool = await asyncpg.create_pool(dsn)
       return self
   ```

4. **迁移脚本**（使用 Alembic 或类似工具）

5. **TTL 策略**（可选：定时任务清理过期数据）

---

## 5. 工厂模式与依赖注入

### 5.1 工厂实现

```python
# infrastructure/memory/factory.py

from enum import Enum

class MemoryProvider(str, Enum):
    MEM0 = "mem0"
    POSTGRES = "postgres"
    NULL = "null"

class MemoryStoreFactory:
    """记忆存储工厂 - 根据配置创建适配器"""

    @staticmethod
    def create(provider: str) -> MemoryStorePort:
        """创建基础存储实例（所有配置来自 settings）"""
        match provider:
            case "mem0":  # ✅ 字符串匹配（provider 是 str 类型）
                from infrastructure.memory.mem0_http_memory_store import Mem0HttpMemoryStore
                from infrastructure.config.settings import (
                    MEM0_BASE_URL,
                    MEM0_API_KEY,
                    MEM0_TIMEOUT_S,
                    MEM0_SEARCH_PATH,
                    MEM0_ADD_PATH,
                )
                return Mem0HttpMemoryStore(
                    base_url=MEM0_BASE_URL,
                    api_key=MEM0_API_KEY,
                    timeout_s=MEM0_TIMEOUT_S,
                    search_path=MEM0_SEARCH_PATH,
                    add_path=MEM0_ADD_PATH,
                )

            case "postgres":
                from infrastructure.memory.postgres_vector_adapter import PostgresVectorAdapter
                from infrastructure.config.settings import POSTGRES_DSN
                return PostgresVectorAdapter(dsn=POSTGRES_DSN)

            case _:
                from infrastructure.memory.null_memory_store import NullMemoryStore
                return NullMemoryStore()

    @staticmethod
    def create_with_management(provider: str) -> MemoryStorePort & MemoryManageablePort | None:
        """创建支持管理能力的存储实例，如果不支持则返回 None"""
        match provider:
            case "mem0":  # ✅ 字符串匹配
                # Mem0 支持管理能力（如果后端实现了相应 API）
                return MemoryStoreFactory.create(provider)  # type: ignore

            case "postgres":
                # PostgreSQL 支持管理能力
                return MemoryStoreFactory.create(provider)  # type: ignore

            case _:
                # NULL 不支持管理能力
                return None
```

**配置集中管理原则**：

```python
# infrastructure/config/settings.py（集中所有配置）

from os import getenv
from typing import Literal

# === 全局开关 ===
MEMORY_ENABLE: bool = getenv("MEMORY_ENABLE", "true").lower() == "true"
MEMORY_PROVIDER: Literal["mem0", "postgres", "null"] = getenv("MEMORY_PROVIDER", "mem0")

# === Mem0 配置 ===
MEM0_BASE_URL: str = getenv("MEM0_BASE_URL", "http://localhost:8080")
MEM0_API_KEY: str = getenv("MEM0_API_KEY", "")
MEM0_TIMEOUT_S: float = float(getenv("MEM0_TIMEOUT_S", "10.0"))
# ⚠️ 默认路径与代码一致（backend/infrastructure/config/settings.py）
MEM0_SEARCH_PATH: str = getenv("MEM0_SEARCH_PATH", "/v1/memories/search")
MEM0_ADD_PATH: str = getenv("MEM0_ADD_PATH", "/v1/memories")

# === PostgreSQL 配置（未来）===
POSTGRES_DSN: str = getenv(
    "POSTGRES_DSN",
    "postgresql://postgres:postgres@localhost:5433/graphrag_chat"
)
```

**优点**：
- ✅ 所有配置在一处定义，易于维护
- ✅ 类型安全（Literal、类型注解）
- ✅ 有默认值，减少 .env 配置量
- ✅ 避免工厂代码散落 `os.getenv()`

### 5.2 依赖注入（兼容现有 @lru_cache 架构）

> [!NOTE]
> **项目现有依赖注入基于 `@lru_cache`，全面重构为 lifespan 风险太大**
> - 短期方案：保持 `@lru_cache` + `shutdown_dependencies` 钩子
> - 长期优化：逐步迁移到 lifespan（按需）

**方案 A：最小改动（推荐）**

```python
# server/api/rest/dependencies.py

from functools import lru_cache
from infrastructure.memory.factory import MemoryStoreFactory
from infrastructure.config.settings import MEMORY_ENABLE, MEMORY_PROVIDER

@lru_cache(maxsize=1)
def _build_memory_store() -> MemoryStorePort:
    """构建记忆存储实例（单例，利用 lru_cache）"""
    if not MEMORY_ENABLE:
        from infrastructure.memory.null_memory_store import NullMemoryStore
        return NullMemoryStore()

    return MemoryStoreFactory.create(MEMORY_PROVIDER)

# 应用关闭时清理资源
async def shutdown_dependencies() -> None:
    """关闭所有依赖连接"""
    store = _build_memory_store()
    await store.close()
    # 清除 cache，避免下次启动时复用旧连接
    _build_memory_store.cache_clear()
```

> [!IMPORTANT]
> **@lru_cache 方案的关键约束：不要在 `__init__` 中创建 async 对象**
>
> **当前代码库的正确实现**（`backend/infrastructure/memory/mem0_http_memory_store.py:50-62`）：
> ```python
> def __init__(self, ...) -> None:
>     # ✅ 正确：只存储配置，不创建 session
>     self._session: aiohttp.ClientSession | None = None
>
> async def _get_session(self) -> aiohttp.ClientSession:
>     # ✅ 正确：延迟创建 session（首次使用时）
>     if self._session is None or self._session.closed:
>         self._session = aiohttp.ClientSession(timeout=timeout)
>     return self._session
> ```
>
> **如果错误实现会怎样**：
> ```python
> def __init__(self, ...) -> None:
>     # ❌ 错误：在 __init__ 中创建 async 对象
>     self._session = aiohttp.ClientSession()  # 会逼你重构为 lifespan！
> ```
>
> **后果**：
> - `@lru_cache` 在模块导入时调用 `__init__`
> - 此时 event loop 未就绪 → "attached to a different loop" 错误
> - uvicorn reload 时旧连接未关闭 → 资源泄漏
>
> **总结**：使用 `@lru_cache` 方案时，**所有需要 async 初始化的资源（aiohttp/asyncpg/连接池）都必须延迟创建**！
>
> **代码库验证**（`backend/server/`）：
> - ✅ `api/rest/dependencies.py:55` - `@lru_cache(maxsize=1)` 缓存 `_build_memory_store()`
> - ✅ `api/rest/dependencies.py:191-194` - `shutdown_dependencies()` 调用 `store.close()`
> - ✅ `main.py:22-25` - `@app.on_event("shutdown")` 触发清理
> - ✅ `infrastructure/memory/mem0_http_memory_store.py:50-62` - 延迟初始化 session

**方案 B：FastAPI Lifespan（长期目标）**

```python
# server/main.py（如未来需要重构）

from contextlib import asynccontextmanager
from fastapi import FastAPI
from infrastructure.memory.factory import MemoryStoreFactory

@asynccontextmanager
async def lifespan(app: FastAPI):
    """管理记忆存储的生命周期"""
    from infrastructure.config.settings import MEMORY_ENABLE, MEMORY_PROVIDER

    if MEMORY_ENABLE:
        store = MemoryStoreFactory.create(MEMORY_PROVIDER)
    else:
        from infrastructure.memory.null_memory_store import NullMemoryStore
        store = NullMemoryStore()

    app.state.memory_store = store

    yield

    # Shutdown
    await app.state.memory_store.close()


app = FastAPI(lifespan=lifespan)
```

**多 worker 场景注意事项**：

```python
# uvicorn 启动时指定 workers
# uvicorn server.main:app --workers 4 --host 0.0.0.0 --port 8324

# 每个 worker 有独立的进程空间和 lru_cache
# - @lru_cache: 每个 worker 各自缓存（✅ 正确）
# - app.state: 每个 worker 各自独立（✅ 正确）
# - 全局变量: 所有 worker 共享（❌ 错误）
```

**迁移路径**：

| 阶段 | 方案 | 触发条件 |
|-----|------|---------|
| **当前** | `@lru_cache` + `shutdown_dependencies` | 最小改动 |
| **优化期** | 混合模式：lru_cache 读 + lifespan 写 | 需要更复杂的生命周期管理 |
| **长期** | 完全 lifespan + `app.state` | 全面重构依赖注入时 |

### 5.3 API 路由中的使用示例

```python
# server/api/rest/memory.py

from fastapi import Depends
from application.ports.memory_store_port import MemoryStorePort
from server.api.rest.dependencies import _build_memory_store

# 基础存储依赖
@router.post("/memories/search")
async def search_memories(
    query: str,
    store: MemoryStorePort = Depends(_build_memory_store),
):
    return await store.search(user_id=current_user.id, query=query)

# 写入依赖
@router.post("/memories/add")
async def add_memory(
    text: str,
    store: MemoryStorePort = Depends(_build_memory_store),
):
    memory_id = await store.add(user_id=current_user.id, text=text)
    return {"memory_id": memory_id}
```

### 5.4 配置项

```bash
# .env
MEMORY_ENABLE=true
MEMORY_PROVIDER=mem0           # mem0 | postgres | null

# Mem0 配置
MEM0_BASE_URL=http://localhost:8080
MEM0_API_KEY=your-api-key

# PostgreSQL 配置（未来）
# PG_DSN=postgresql://user:pass@localhost/memories
```

---

## 6. 关于 Agent 框架（Letta/MemGPT）

> [!NOTE]
> Letta（原 MemGPT）采用完全不同的范式：**Memory as Agent**。Agent 自主管理记忆，而非外部 API 调用。

| 维度 | Mem0 (当前) | Letta (Agent 范式) |
|------|------------|-------------------|
| **架构** | Memory as a Service | Memory as an Agent |
| **控制权** | 开发者完全控制 | Agent 自主管理 |
| **检索方式** | `search(query)` 返回列表 | 询问 Agent，Agent 决定回答 |
| **适配难度** | ✅ 简单 | ⚠️ 需要范式转换 |

**当前策略**：基于 Mem0 的 Service 模式实现。如未来需要 Letta 支持，需重新评估接口设计。

---

## 7. 实施计划（分阶段）

### v1.0 - Chat 场景（当前阶段）

**目标**：支持基础的记忆检索和写入

- [x] `MemoryStorePort` 接口定义（search + add + close）
- [x] `Mem0HttpMemoryStore` 适配器（生产就绪）
- [x] `NullMemoryStore` 降级实现
- [x] `MemoryService` 业务层编排
- [x] 依赖注入：`@lru_cache` + `shutdown_dependencies`
- [x] 配置管理：`infrastructure.config.settings`

**不实现**：
- ❌ `MemoryManageablePort`（delete/update/get_all）- 留待 v2
- ❌ `CompositeMemoryStore` - 留待需要高可用时
- ❌ PostgreSQL 适配器 - 按需实现

### v1.5 - 可选增强（按需）

当遇到以下需求时，再实现对应功能：

**需求 A：需要记忆管理面板**
- [ ] 实现 `MemoryManageablePort`
- [ ] Mem0 应用层安全校验（第 9.4 节）
- [ ] 管理界面 API（list/delete/update）

**需求 B：需要高可用/备份**
- [ ] 实现 `CompositeMemoryStore`
- [ ] 主从 ID 策略（第 2.3 节）
- [ ] 配置改为 `MEMORY_PROVIDERS=mem0,postgres`

**需求 C：需要降级到本地存储**
- [ ] PostgreSQL + pgvector 适配器（第 4.3 节）
- [ ] Schema 设计 + 迁移脚本

### v2.0 - 完整功能（未来）

- [ ] 多后端并存 + 故障自动切换
- [ ] 记忆 TTL/过期策略
- [ ] 性能监控 + 告警
- [ ] 生命周期管理迁移到 lifespan（可选）

### 实施优先级总结

| 优先级 | 任务 | 触发条件 | 风险 |
|-------|------|---------|-----|
| **P0 (v1)** | `MemoryStorePort` + Mem0 适配器 | ✅ 已完成 | 低 |
| **P0 (v1)** | @lru_cache 依赖注入 | ✅ 已完成 | 低 |
| **P1 (v1.5)** | `MemoryManageablePort` | 需要管理面板时 | 中（安全）|
| **P1 (v1.5)** | `CompositeMemoryStore` | 需要高可用时 | 中（ID 一致性）|
| **P2 (v1.5)** | PostgreSQL 适配器 | 需要本地存储时 | 高（Schema 设计）|
| **P3 (v2)** | Lifespan 重构 | 需要更复杂生命周期 | 高（破坏性变更）|

---

## 8. 切换后端指南

### 从 Mem0 切换到 PostgreSQL

1. 实现 `PostgresVectorAdapter`（参考文档第 4.3 节）
2. 修改配置：
   ```bash
   MEMORY_PROVIDER=postgres
   POSTGRES_DSN=postgresql://user:pass@localhost:5433/graphrag_chat
   ```
3. 数据迁移（如需要）

### 添加新后端

1. 实现 `MemoryStorePort` 接口
2. 在 `MemoryStoreFactory.create()` 添加 case
3. 添加相关配置项
4. 测试验证

---

## 9. 安全与多租户隔离

### 9.1 Defense-in-Depth 原则

所有涉及"写/改/删/管理列表"的操作**必须**在存储层强制执行 `user_id` 约束：

```python
# ❌ 错误示例（容易越权）
async def delete(self, *, memory_id: str) -> bool:
    await db.execute("DELETE FROM memories WHERE id = $1", memory_id)

# ✅ 正确示例（DB 层强制隔离）
async def delete(self, *, user_id: str, memory_id: str) -> bool:
    status = await db.execute(
        "DELETE FROM memories WHERE id = $1 AND user_id = $2",
        memory_id, user_id
    )
    return status.split(" ")[-1] == "1"  # 检查是否真的删除了行
```

### 9.2 接口安全规则

| 操作类型 | 是否需要 user_id | 理由 |
|---------|-----------------|------|
| `search` | ✅ 必需 | 租户隔离，只返回当前用户的记忆 |
| `add` | ✅ 必需 | 绑定记忆到用户 |
| `delete` | ✅ 必需 | **防止跨用户误删/越权删除** |
| `update` | ✅ 必需 | **防止跨用户越权修改** |
| `get_all` | ✅ 必需 | 管理界面也需隔离，只能看自己的记忆 |

### 9.3 返回值设计建议

`delete` / `update` 方法应返回 `bool` 表示操作是否真的影响了行：

```python
async def delete(self, *, user_id: str, memory_id: str) -> bool:
    """
    返回 True 表示确实删除了 1 行
    返回 False 表示 memory_id 不存在或不属于该用户（防止枚举攻击）
    """
```

这样上层可以区分"真的删除了"和"本来就不存在"，同时不泄露其他用户的数据。

### 9.4 Mem0 API 的应用层安全校验

> [!IMPORTANT]
> **Mem0 API 可能不支持原子性安全校验（即 `DELETE /memories/{id}` 无法同时校验 `user_id`）**
>
> 解决方案：在 Adapter 层实现"先校验后删除"的两阶段安全策略

**问题场景**：

```python
# ❌ 危险：假设 Mem0 DELETE API 只接受 memory_id，不校验 user_id
async def delete(self, *, memory_id: str) -> bool:
    # 如果用户 A 知道了用户 B 的 memory_id，可以直接删除！
    await self._session.delete(f"/memories/{memory_id}")
```

**应用层安全校验实现**：

```python
# infrastructure/memory/mem0_http_memory_store.py

class Mem0HttpMemoryStore(MemoryStorePort, MemoryManageablePort):
    """Mem0 HTTP client（带应用层安全校验）"""

    async def delete(self, *, user_id: str, memory_id: str) -> bool:
        """删除记忆（应用层两阶段安全校验）"""
        # 阶段 1: GET 校验归属
        get_url = _join(self._base_url, f"/memories/{memory_id}")
        async with self._session.get(get_url, headers=self._headers()) as resp:
            if resp.status == 404:
                # 记忆不存在 -> 返回 False（不泄露是否属于其他用户）
                return False
            if resp.status >= 400:
                text = await resp.text()
                raise RuntimeError(f"mem0 get failed ({resp.status}): {text[:200]}")

            data = await resp.json(content_type=None)
            # 检查 user_id 是否匹配
            memory_user_id = data.get("user_id") or data.get("metadata", {}).get("user_id")
            if memory_user_id != user_id:
                # 记忆存在但不属于该用户 -> 记录安全日志并返回 False
                logger.warning(
                    f"Security: user {user_id} attempted to delete memory {memory_id} "
                    f"owned by {memory_user_id}"
                )
                return False

        # 阶段 2: DELETE 删除
        delete_url = _join(self._base_url, f"/memories/{memory_id}")
        async with self._session.delete(delete_url, headers=self._headers()) as resp:
            if resp.status >= 400:
                text = await resp.text()
                raise RuntimeError(f"mem0 delete failed ({resp.status}): {text[:200]}")
            return resp.status == 200

    async def update(
        self,
        *,
        user_id: str,
        memory_id: str,
        text: str,
        metadata: Optional[dict[str, Any]] = None,
    ) -> bool:
        """更新记忆（应用层两阶段安全校验）"""
        # 阶段 1: GET 校验归属（逻辑同 delete）
        get_url = _join(self._base_url, f"/memories/{memory_id}")
        async with self._session.get(get_url, headers=self._headers()) as resp:
            if resp.status == 404:
                return False
            data = await resp.json(content_type=None)
            memory_user_id = data.get("user_id") or data.get("metadata", {}).get("user_id")
            if memory_user_id != user_id:
                logger.warning(
                    f"Security: user {user_id} attempted to update memory {memory_id} "
                    f"owned by {memory_user_id}"
                )
                return False

        # 阶段 2: PATCH 更新
        patch_url = _join(self._base_url, f"/memories/{memory_id}")
        payload = {"text": text}
        if metadata:
            payload["metadata"] = metadata
        async with self._session.patch(patch_url, json=payload, headers=self._headers()) as resp:
            return resp.status == 200
```

**性能权衡**：

| 操作 | 额外开销 | 是否可接受 | 理由 |
|------|---------|-----------|------|
| `delete` | +1 次 GET 请求 | ✅ 是 | 删除操作频率远低于读取，安全优先 |
| `update` | +1 次 GET 请求 | ✅ 是 | 更新操作频率远低于读取，安全优先 |

**优化建议**：

1. **如果 Mem0 后端未来支持原子校验**：
   ```python
   # 修改为单次请求
   payload = {"user_id": user_id, "memory_id": memory_id}
   await self._session.post("/memories/delete", json=payload)
   ```

2. **安全日志监控**：
   - 对"越权尝试"（user_id 不匹配）进行告警
   - 统计异常用户，必要时封禁

3. **性能监控**：
   - 记录 delete/update 的耗时（包括两次请求）
   - 如超过阈值，考虑优化或缓存

### 9.5 实现检查清单

- [ ] 接口层：所有修改类方法签名包含 `user_id` 参数
- [ ] 存储层：SQL 查询使用 `WHERE id = ? AND user_id = ?`
- [ ] 测试：覆盖跨用户操作场景（用户 A 不能删除用户 B 的记忆）
- [ ] API 层：从认证中间件提取 `user_id` 并传递到存储层

---

## 10. 设计原则总结

| 原则 | 实现方式 | 解决的问题 |
|------|---------|-----------|
| **接口隔离（ISP）** | `MemoryStorePort` + `MemoryManageablePort` 分离 | 避免 `NotImplementedError`，类型安全 |
| **YAGNI** | v1 只实现 `search/add`，管理接口留待 v2 | 避免过度设计，降低复杂度 |
| **依赖倒置** | 业务层依赖接口，不依赖具体实现 | 可替换后端实现 |
| **延迟加载** | 工厂中使用 `match` + 延迟导入 | 减少启动依赖 |
| **配置集中管理** | 所有配置在 `infrastructure.config.settings` | 避免 `os.getenv()` 散落各处 |
| **配置驱动** | 通过 `MEMORY_PROVIDER` 环境变量切换实现 | 零代码切换后端 |
| **优雅降级** | `NullMemoryStore` 保证系统稳定 | 记忆功能故障不影响主流程 |
| **Defense-in-Depth** | 应用层两阶段校验 + DB 层 `WHERE id = ? AND user_id = ?` | 防止跨用户越权 |
| **兼容性优先** | 保持 `@lru_cache` + `shutdown_dependencies` | 最小改动，逐步优化 |
| **多后端并存** | `CompositeMemoryStore` + 主从 ID 策略 | 冗余备份、策略互补 |

### 关键改进点（落地版）

1. **分阶段实施（YAGNI）**
   - ❌ 错误：v1 就实现所有管理接口（delete/update/get_all）
   - ✅ 正确：v1 只实现 `search/add`，v2 再按需添加管理能力

2. **不使用 `raise NotImplementedError`**
   - ❌ 错误：Protocol 中声明"可选方法" + `raise NotImplementedError`
   - ✅ 正确：拆分为多个独立的 Protocol（`MemoryStorePort` + `MemoryManageablePort`）

3. **兼容性优先（生命周期管理）**
   - ❌ 错误：全面重构为 lifespan（破坏性大）
   - ✅ 正确：保持 `@lru_cache` + `shutdown_dependencies`，长期再优化

4. **安全是默认行为**
   - ❌ 错误：API 层鉴权后，存储层信任调用者
   - ✅ 正确：应用层两阶段校验（GET + DELETE），即使 API 有 bug 也能防护

5. **数据结构安全的默认值**
   - ❌ 错误：`metadata: dict = None`（容易 NPE）
   - ✅ 正确：`metadata: dict[str, Any] = field(default_factory=dict)` 或省略

6. **配置集中管理**
   - ❌ 错误：代码中到处 `os.getenv("XXX")`
   - ✅ 正确：所有配置在 `infrastructure.config.settings` 统一定义

7. **文件名与代码对齐**
   - ❌ 错误：文档写 `mem0_adapter.py`，实际是 `mem0_http_memory_store.py`
   - ✅ 正确：文档链接使用相对路径，文件名与实际代码一致

8. **适配器代码可直接落地**
   - ❌ 错误：伪代码忽略 session 管理、headers、异常处理
   - ✅ 正确：参考 `Mem0HttpMemoryStore` 的生产实现（`_get_session()` / `_headers()` / `_parse_items()`）

9. **多后端 ID 一致性**
   - ❌ 错误：并发写导致 ID 不一致，无法管理
   - ✅ 正确：主从 ID 策略（主库生成 ID，从库强制使用相同 ID）

10. **match-case 类型匹配**
    - ❌ 错误：`match provider: case MemoryProvider.MEM0:`（永远匹配不上）
    - ✅ 正确：`match provider: case "mem0":`（字符串匹配）

11. **工厂模式缺失**
    - ❌ 错误：`dependencies.py` 硬编码 `Mem0HttpMemoryStore()`
    - ✅ 正确：引入 `MemoryStoreFactory.create(MEMORY_PROVIDER)`

12. **配置分层混乱**
    - ❌ 错误：所有配置堆在 `infrastructure.config.settings`
    - ✅ 正确：业务语义在 `config/settings`，连接参数在 `infrastructure/config/settings`

13. **aiohttp session 并发竞态**
    - ❌ 错误：懒初始化无锁，高并发可能创建多个 session
    - ✅ 正确：加 `asyncio.Lock` 或使用 lifespan 一次性创建

14. **CompositeMemoryStore 任务洪泛**
    - ❌ 错误：`asyncio.create_task` 每次写入都起任务
    - ✅ 正确：有界队列 + 后台 worker + 限流

15. **数据模型不一致**
    - ❌ 错误：文档有 `metadata`，代码里没有
    - ✅ 正确：对齐 MemoryItem，或为管理面板单独设计 DTO

### 实施优先级（更新）

| 优先级 | 阶段 | 任务 | 影响 | 状态 |
|-------|-----|------|-----|------|
| **P0** | v1.0 | `MemoryStorePort`（search + add）| ✅ 已完成 | 已完成 |
| **P0** | v1.0 | @lru_cache 依赖注入 | ✅ 已完成 | 已完成 |
| **P0** | v1.0 | 引入 MemoryStoreFactory | **必须修复** | 🚧 待修复 |
| **P0** | v1.0 | 修复 aiohttp session 并发竞态 | **资源泄漏风险** | 🚧 待修复 |
| **P1** | v1.5 | `MemoryManageablePort` | 需要管理面板时 | 按需 |
| **P1** | v1.5 | Mem0 应用层安全校验 | 实现管理接口时 | 按需 |
| **P1** | v1.5 | `CompositeMemoryStore` | 需要高可用时 | 按需 |
| **P2** | v1.5 | PostgreSQL 适配器 | 需要本地存储时 | 按需 |
| **P2** | v1.5 | 配置分层重构 | 可维护性 | 🚧 建议 |
| **P2** | v1.5 | 对齐 MemoryItem 数据模型 | 避免混淆 | 🚧 建议 |
| **P3** | v2.0 | Lifespan 重构 | 按需（可选）| 按需 |

---

## 🔧 代码层面修复方案

### 问题 11：引入 MemoryStoreFactory

**当前问题**（`backend/server/api/rest/dependencies.py:56-64`）：
```python
# ❌ 硬编码，不支持 MEMORY_PROVIDER 切换
@lru_cache(maxsize=1)
def _build_memory_store():
    from infrastructure.memory import Mem0HttpMemoryStore, NullMemoryStore
    if not MEMORY_ENABLE:
        return NullMemoryStore()
    return Mem0HttpMemoryStore()  # 写死 Mem0
```

**修复方案**：
```python
# backend/infrastructure/memory/factory.py（新建）

from enum import Enum
from application.ports.memory_store_port import MemoryStorePort

class MemoryProvider(str, Enum):
    MEM0 = "mem0"
    NULL = "null"

class MemoryStoreFactory:
    """记忆存储工厂"""

    @staticmethod
    def create(provider: str) -> MemoryStorePort:
        match provider:
            case "mem0":
                from infrastructure.memory.mem0_http_memory_store import Mem0HttpMemoryStore
                from infrastructure.config.settings import (
                    MEM0_BASE_URL,
                    MEM0_API_KEY,
                    MEM0_TIMEOUT_S,
                )
                return Mem0HttpMemoryStore(
                    base_url=MEM0_BASE_URL,
                    api_key=MEM0_API_KEY,
                    timeout_s=MEM0_TIMEOUT_S,
                )
            case _:
                from infrastructure.memory.null_memory_store import NullMemoryStore
                return NullMemoryStore()

# backend/server/api/rest/dependencies.py（修改）
from infrastructure.memory.factory import MemoryStoreFactory
from config.settings import MEMORY_ENABLE, MEMORY_PROVIDER

@lru_cache(maxsize=1)
def _build_memory_store() -> MemoryStorePort:
    """✅ 使用工厂模式，支持通过 MEMORY_PROVIDER 切换后端"""
    if not MEMORY_ENABLE:
        from infrastructure.memory.null_memory_store import NullMemoryStore
        return NullMemoryStore()
    return MemoryStoreFactory.create(MEMORY_PROVIDER)
```

### 问题 12：配置分层重构

**当前问题**：配置散落在多个 `settings.py`

**修复方案**：明确职责边界

| 配置类型 | 位置 | 示例 |
|---------|------|------|
| **业务语义开关** | `backend/config/settings.py` | `MEMORY_ENABLE`, `MEMORY_PROVIDER`, `MEMORY_WRITE_MODE` |
| **后端连接参数** | `backend/infrastructure/config/settings.py` | `MEM0_BASE_URL`, `MEM0_API_KEY`, `MEM0_TIMEOUT_S` |
| **数据库 DSN** | `backend/config/database.py` | `POSTGRES_HOST`, `POSTGRES_PORT`, `POSTGRES_DB` |

**原则**：
- `server/` 层只依赖 `config/settings`（业务语义）
- `infrastructure/` 层依赖 `infrastructure/config/settings`（技术细节）

### 问题 13：修复 aiohttp session 并发竞态

**当前问题**（`backend/infrastructure/memory/mem0_http_memory_store.py:58-63`）：
```python
# ❌ 并发竞态：两个协程可能同时看到 _session is None
async def _get_session(self) -> aiohttp.ClientSession:
    if self._session is not None and not self._session.closed:
        return self._session
    # 竞态窗口！
    self._session = aiohttp.ClientSession(timeout=timeout)
    return self._session
```

**修复方案**：
```python
class Mem0HttpMemoryStore(MemoryStorePort):
    def __init__(self, ...) -> None:
        # ...
        self._session: aiohttp.ClientSession | None = None
        self._lock = asyncio.Lock()  # ✅ 添加锁

    async def _get_session(self) -> aiohttp.ClientSession:
        # ✅ 双重检查 + 锁，避免竞态
        if self._session is not None and not self._session.closed:
            return self._session

        async with self._lock:
            # 再次检查（可能其他协程已经创建）
            if self._session is not None and not self._session.closed:
                return self._session

            timeout = aiohttp.ClientTimeout(total=self._timeout_s)
            self._session = aiohttp.ClientSession(timeout=timeout)
            return self._session
```

### 问题 14：修复 CompositeMemoryStore 任务洪泛

**当前问题**（`docs/03-架构设计/多记忆后端适配架构设计.md:129`）：
```python
# ❌ 每次写入都起任务，流量大时堆积
async def add(self, **kwargs):
    asyncio.create_task(self._fanout_add(**kwargs))  # 无界任务
```

**修复方案**：
```python
# infrastructure/memory/composite_memory_store.py

import asyncio
from collections import deque

class CompositeMemoryStore(MemoryStorePort):
    """组合多个记忆后端（带任务队列）"""

    def __init__(self, *, max_queue_size: int = 100, num_workers: int = 2):
        self._stores = ...
        # ✅ 有界队列 + 后台 worker
        self._write_queue: asyncio.Queue = asyncio.Queue(maxsize=max_queue_size)
        self._workers = []
        self._num_workers = num_workers

    async def _start_workers(self):
        """启动后台 worker"""
        for i in range(self._num_workers):
            task = asyncio.create_task(self._worker(f"worker-{i}"))
            self._workers.append(task)

    async def _worker(self, name: str):
        """后台 worker：从队列取任务并执行"""
        while True:
            try:
                coro = await self._write_queue.get()
                if coro is None:  # 毒丸，退出
                    break
                await coro
            except Exception as e:
                logger.warning(f"[{name}] Write task failed: {e}")

    async def add(self, *, user_id: str, text: str, **kwargs):
        """主库同步写，从库异步写入队列"""
        primary = self._stores[self._primary_index]
        memory_id = await primary.add(user_id=user_id, text=text, **kwargs)

        # ✅ 把从库写入任务放入队列（不阻塞主流程）
        for i, store in enumerate(self._stores):
            if i == self._primary_index:
                continue
            try:
                await self._write_queue.put(store.add(user_id=user_id, text=text, **kwargs))
            except asyncio.QueueFull:
                logger.warning(f"Write queue full, dropping backup write to {store}")

        return memory_id

    async def close(self):
        """关闭：停止 worker + drain 队列"""
        # 发送毒丸
        for _ in range(self._num_workers):
            await self._write_queue.put(None)

        # 等待 worker 退出
        await asyncio.gather(*self._workers, return_exceptions=True)

        # 关闭所有 store
        await asyncio.gather(*[s.close() for s in self._stores], return_exceptions=True)
```

### 问题 15：对齐 MemoryItem 数据模型

**当前状态**：
- 文档：`metadata: dict[str, Any] = field(default_factory=dict)`
- 代码：`backend/domain/memory/memory_item.py` 没有 metadata 字段

**修复方案**：

**选项 A：扩展 MemoryItem（推荐）**
```python
# backend/domain/memory/memory_item.py

from dataclasses import dataclass, field
from typing import Optional, Any

@dataclass(frozen=True)
class MemoryItem:
    """Long-term memory recall item (provider-agnostic)."""
    id: str
    text: str
    score: float = 0.0
    created_at: Optional[datetime] = None
    tags: tuple[str, ...] = ()
    metadata: dict[str, Any] = field(default_factory=dict)  # ✅ 添加
```

**选项 B：管理面板使用独立 DTO**
```python
# backend/domain/memory/memory_dto.py

@dataclass
class MemoryItemDTO:
    """记忆管理面板专用的 DTO（包含额外字段）"""
    id: str
    text: str
    score: float
    created_at: Optional[datetime]
    tags: tuple[str, ...]
    metadata: dict[str, Any]  # canonical_id, source, TTL 等
    user_id: str  # 管理界面需要展示所有者

    @classmethod
    def from_memory_item(cls, item: MemoryItem, user_id: str, **extra_metadata):
        return cls(
            id=item.id,
            text=item.text,
            score=item.score,
            created_at=item.created_at,
            tags=item.tags,
            metadata={**item.metadata, **extra_metadata},
            user_id=user_id,
        )
```

**推荐**：选项 A（扩展 MemoryItem），因为：
- metadata 对多后端合并、canonical_id 追踪都很重要
- 管理面板可以直接使用，无需转换
- 向后兼容（default_factory 保证现有代码不受影响）

### 核心落地建议（更新）

#### 立即修复（P0）

1. **引入 MemoryStoreFactory**：让 `dependencies.py` 支持通过 `MEMORY_PROVIDER` 切换后端
2. **修复 aiohttp session 并发竞态**：添加 `asyncio.Lock` 避免高并发下创建多个 session

#### 近期优化（P1-P2）

3. **对齐 MemoryItem 数据模型**：添加 `metadata` 字段（推荐）
4. **配置分层重构**：明确业务语义 vs 连接参数的职责边界
5. **实现 MemoryManageablePort**：需要管理面板时
6. **CompositeMemoryStore 任务队列**：需要高可用时（避免任务洪泛）

#### 长期目标（P3）

7. **迁移到 FastAPI lifespan**：按需（可选）

---

## ✅ 文档与代码库对照

| 文档章节 | 代码文件 | 状态 |
|---------|---------|------|
| 第 5.1 节 - 工厂模式 | ❌ 不存在 | **需要创建** `factory.py` |
| 第 5.2 节 - 依赖注入 | `dependencies.py:56` | **需要修改** 引入工厂 |
| 第 4.1 节 - Mem0 适配器 | `mem0_http_memory_store.py:58` | **需要修复** 并发竞态 |
| 第 2.3 节 - CompositeMemoryStore | ❌ 不存在 | 按需实现 |
| 第 3.5 节 - MemoryItem | `memory_item.py` | **建议对齐** 添加 metadata |

**文档现在是一个"渐进式实施指南 + 代码层面修复方案"！** 🎯
