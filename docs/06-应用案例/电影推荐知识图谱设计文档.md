# 电影推荐知识图谱系统设计文档（修订版）

## 1. 项目概述

### 1.1 背景
本项目旨在将现有的 GraphRAG + Deep Search 系统从学生管理领域迁移至电影推荐领域，构建一个基于知识图谱的电影问答与推荐系统。通过整合 SparrowRecSys 项目中的 MovieLens 数据集（982部电影）和 TMDB API 补充数据，构建丰富的电影知识图谱，支持多智能体协作的深度搜索和智能问答。

### 1.2 目标
- 构建电影领域知识图谱（电影、演员、导演、类型、制作公司等实体及关系）
- 实现基于知识图谱的电影搜索和推荐
- 支持多种查询模式：精确查询、推理查询、推荐查询、统计分析
- 提供可解释的推荐结果（基于知识图谱路径和证据链）

### 1.3 技术栈
- **数据源**：
  - MovieLens 数据集（982部电影 + 116万条评分）
  - TMDB API（补充电影详情、演员、制作公司等）
- **知识图谱**：Neo4j 5.22.x（本地 Docker：`neo4j:5.22.0`）
- **向量索引**：OpenAI text-embedding-3-large
- **多智能体系统**：LangGraph + 多种专业 Agent
- **后端**：FastAPI
- **前端**：React 18 + TypeScript + Ant Design 5（Streamlit 已废弃）

---

## 2. 数据源详细分析

### 2.1 现有数据：MovieLens 数据集

**数据来源**：`SparrowRecSys-master/target/classes/webroot/sampledata/`（位于项目根目录下）

#### 2.1.1 movies.csv
```csv
movieId,title,genres
1,Toy Story (1995),Adventure|Animation|Children|Comedy|Fantasy
2,Jumanji (1995),Adventure|Children|Fantasy
```

**数据规模**：
- 总电影数：**982 部**
- 年份范围：1926 - 1998（覆盖72年）
- 类型数量：19 个标准类型（MovieLens 原始口径；进入图谱的规范类型预计为 ~17 个）
- 平均每部电影类型数：2.04

**类型分布（Top 10）**：
1. Drama: 518 部 (52.8%)
2. Comedy: 342 部 (34.8%)
3. Romance: 195 部 (19.9%)
4. Thriller: 173 部 (17.6%)
5. Action: 136 部 (13.9%)
6. Crime: 108 部 (11.0%)
7. Adventure: 102 部 (10.4%)
8. Children: 74 部 (7.5%)
9. Mystery: 51 部 (5.2%)
10. Sci-Fi: 51 部 (5.2%)

**字段说明**：
- `movieId`: MovieLens 内部唯一标识（整数）
- `title`: 电影标题，格式为 "片名 (年份)"
- `genres`: 类型列表，使用 `|` 分隔

**数据特点**：
- 标题需要解析提取年份和纯标题
- 类型需要归一化映射（例如 `Sci-Fi` → `Science Fiction`；`IMAX`/`Film-Noir` 等保留在 `unmapped` 便于回溯）
- 部分老电影（1926-1950年代）可能缺少丰富的 TMDB 数据

#### 2.1.2 ratings.csv
```csv
userId,movieId,rating,timestamp
1,2,3.5,1112486027
```

**数据规模**：
- 总评分数：**1,168,638 条**
- 独立用户数：**29,776 人**
- 被评分电影数：981 部（982部中有981部被评分）
- 平均评分：3.53 / 5.0
- 每用户平均评分数：39.2 条
- 每电影平均评分数：1191.3 条

**评分分布**（基于采样）：
- 3.0 和 4.0 占比最高（各约28%）
- 评分范围：0.5 - 5.0，步长 0.5
- 高评分（4.0+）占比约 49.5%

**字段说明**：
- `userId`: 用户唯一标识
- `movieId`: 电影ID（关联 movies.csv）
- `rating`: 评分值（0.5, 1.0, ..., 5.0）
- `timestamp`: Unix 时间戳

**用途**：
- 构建用户-电影评分网络（可选）
- 计算电影流行度指标
- 协同过滤推荐
- 社区检测的权重依据

#### 2.1.3 links.csv
```csv
movieId,imdbId,tmdbId
1,0114709,862
2,0113497,8844
```

**数据规模**：
- 总链接数：982 条（每部电影一条）
- **IMDB ID 覆盖率**：100%（982/982）
- **TMDB ID 覆盖率**：98.9%（971/982）

**缺失 TMDB ID 的11部电影**：
```
142: Shadows (Cienie) (1988)
604: Criminals (1996)
720: Wallace & Gromit: The Best of Aardman Animation (1996)
721: Halfmoon (Paul Bowles - Halbmond) (1995)
730: Low Life (1994)
739: Honey Moon (Honigmond) (1996)
769: Marlene Dietrich: Shadow and Light (1996)
770: Costa Brava (1946)
791: Last Klezmer: Leopold Kozlowski, His Life and Music, The (1994)
821: Crude Oasis, The (1995)
```

**字段说明**：
- `movieId`: MovieLens ID
- `imdbId`: IMDB 数字ID（如 0114709 对应 tt0114709）
- `tmdbId`: TMDB ID（用于 API 调用）

**处理策略**：
1. 优先使用 TMDB ID 直接调用 API（971部）
2. 缺失 TMDB ID 的11部电影，使用 IMDB ID 或标题+年份搜索

#### 2.1.4 embedding.txt（不采用）
```
710:0.7224512 -0.30651325 -0.5657207 ...
205:0.2620467 0.3950139 0.08172831 ...
```

**数据规模**：
- 总向量数：789 个
- 向量维度：10
- 覆盖电影：789/982（80.3%）

**字段说明**：
- 格式：`movieId:向量值（空格分隔）`
- 向量类型：Item2Vec 嵌入（基于用户行为序列训练）

**不采用原因**：
- 维度为 10，无法与 OpenAI Embedding（高维稠密向量）在同一索引空间直接融合
- 覆盖率仅 80.3%，会造成向量检索结果不一致

**当前方案**：
- 全量使用 OpenAI Embedding（基于 `Movie.description`）作为唯一向量表征
- 不再做 Item2Vec “混合向量”

#### 2.1.5 trainingSamples.csv / testSamples.csv
**数据规模**：
- trainingSamples: 88,827 条
- testSamples: 22,441 条

**字段**（部分）：
```
movieId, userId, rating, timestamp, label, releaseYear, movieGenre1, movieGenre2, movieGenre3,
movieRatingCount, movieAvgRating, movieRatingStddev, userRatedMovie1, ..., userGenre1, ...
```

**用途**：
- 推荐系统特征工程示例
- 可选：用于训练推荐模型（超出本项目范围）

### 2.2 外部数据：TMDB API

#### 2.2.0 数据对应关系验证（2026-01-05）

**验证目的**：确认 MovieLens 数据集中的 TMDB ID 映射与实际 TMDB API 返回数据一致。

**验证方法**：通过代理（localhost:10808）调用 TMDB API，比对前3部电影数据。

**验证结果**：✅ **数据对应关系完全正确**

| MovieLens ID | 标题 | TMDB ID | TMDB API 返回标题 | 匹配状态 |
|-------------|------|---------|-------------------|----------|
| 1 | Toy Story (1995) | 862 | Toy Story (1995) | ✅ 完全匹配 |
| 2 | Jumanji (1995) | 8844 | Jumanji (1995) | ✅ 完全匹配 |
| 3 | Grumpier Old Men (1995) | 15602 | Grumpier Old Men (1995) | ✅ 完全匹配 |

**实际获取的数据样例**：

**Toy Story (TMDB ID: 862)**
```json
{
  "title": "Toy Story",
  "release_date": "1995-10-30",
  "genres": ["Family", "Comedy", "Animation", "Adventure"],
  "vote_average": 7.97,
  "vote_count": 19407,
  "cast": [
    {"name": "Tom Hanks", "character": "Woody (voice)", "order": 0},
    {"name": "Tim Allen", "character": "Buzz Lightyear (voice)", "order": 1},
    {"name": "Don Rickles", "character": "Mr. Potato Head (voice)", "order": 2}
  ]
}
```

**Jumanji (TMDB ID: 8844)**
```json
{
  "title": "Jumanji",
  "release_date": "1995-12-15",
  "genres": ["Adventure", "Fantasy", "Family"],
  "vote_average": 7.244,
  "vote_count": 11024,
  "cast": [
    {"name": "Robin Williams", "character": "Alan Parrish"},
    {"name": "Kirsten Dunst", "character": "Judy Shepherd"},
    {"name": "Bradley Pierce", "character": "Peter Shepherd"}
  ]
}
```

**关键发现**：
1. ✅ TMDB ID 映射准确 - links.csv 中的 ID 与 API 完全一致
2. ✅ 标题匹配 - MovieLens 标题格式与 TMDB 返回一致
3. ✅ 数据丰富 - TMDB 提供演员、评分、类型等详细信息
4. ⚠️ **类型差异** - MovieLens 类型（如 "Children"）与 TMDB 类型（如 "Family"）存在部分映射差异，需要建立映射表

**网络配置**：
- 由于直连 api.themoviedb.org 超时（Exit code 28），需配置 HTTP/HTTPS 代理
- 代理地址：`http://localhost:10808`
- 配置方式：在 `.env` 中添加 `HTTP_PROXY` 和 `HTTPS_PROXY`

#### 2.2.1 API 概述与认证

**官方文档**：https://developer.themoviedb.org/reference/intro/getting-started

**认证配置**：
```bash
# Bearer Token 认证（推荐）
TMDB_API_TOKEN="<YOUR_TMDB_BEARER_TOKEN>"   # ⚠️ 不要把真实 Token 写入文档/仓库

# 或使用 API Key 认证
TMDB_API_KEY="<YOUR_TMDB_API_KEY>"         # ⚠️ 不要把真实 Key 写入文档/仓库
```

**认证方式**：
- **Bearer Token**（推荐）：在 Header 中添加 `Authorization: Bearer <token>`
- **API Key**：在 URL 参数中添加 `api_key=<key>` 或 Header 中添加 `api_key: <key>`

**Base URL**：`https://api.themoviedb.org/3`

**请求限速**：
- 官方建议：每秒 4 次请求
- 最大并发：40 请求/10秒
- 超出限制会返回 HTTP 429（Too Many Requests）

**测试连接**：
```bash
curl --request GET \
     --url 'https://api.themoviedb.org/3/authentication' \
     --header 'Authorization: Bearer <YOUR_TOKEN>' \
     --header 'accept: backend/application/json'
```

**响应示例**：
```json
{
  "success": true,
  "status_code": 1,
  "status_message": "Success."
}
```

#### 2.2.2 核心 API 端点详细示例

以 **Toy Story (TMDB ID: 862)** 为例，展示各个 API 端点的真实请求和响应。

---

**1. 电影详情** - `GET /movie/{movie_id}`

**请求示例**：
```bash
curl --request GET \
     --url 'https://api.themoviedb.org/3/movie/862?language=en-US' \
     --header 'Authorization: Bearer eyJhbGciOiJIUzI1NiJ9...' \
     --header 'accept: backend/application/json'
```

**完整响应示例**：
```json
{
  "adult": false,
  "backdrop_path": "/9FBwqcd9IRruEDUrTdcaafOMKUq.jpg",
  "belongs_to_collection": {
    "id": 10194,
    "name": "Toy Story Collection",
    "poster_path": "/7G9915LfUQ2lVfwMEEhDsn3kT4B.jpg",
    "backdrop_path": "/9FBwqcd9IRruEDUrTdcaafOMKUq.jpg"
  },
  "budget": 30000000,
  "genres": [
    {
      "id": 16,
      "name": "Animation"
    },
    {
      "id": 35,
      "name": "Comedy"
    },
    {
      "id": 10751,
      "name": "Family"
    }
  ],
  "homepage": "http://www.disney.com/toystory",
  "id": 862,
  "imdb_id": "tt0114709",
  "origin_country": ["US"],
  "original_language": "en",
  "original_title": "Toy Story",
  "overview": "Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.",
  "popularity": 99.123,
  "poster_path": "/uXDfjJbdP4ijW5hWSBrPrlKpxab.jpg",
  "production_companies": [
    {
      "id": 3,
      "logo_path": "/1TjvGVDMYsj6JBxOAkUHpPEwLf7.png",
      "name": "Pixar Animation Studios",
      "origin_country": "US"
    },
    {
      "id": 2,
      "logo_path": "/wdrCwmRnLFJhEoH8GSfymY85KHT.png",
      "name": "Walt Disney Pictures",
      "origin_country": "US"
    }
  ],
  "production_countries": [
    {
      "iso_3166_1": "US",
      "name": "United States of America"
    }
  ],
  "release_date": "1995-10-30",
  "revenue": 373554033,
  "runtime": 81,
  "spoken_languages": [
    {
      "english_name": "English",
      "iso_639_1": "en",
      "name": "English"
    }
  ],
  "status": "Released",
  "tagline": "The adventure takes off!",
  "title": "Toy Story",
  "video": false,
  "vote_average": 7.727,
  "vote_count": 18459
}
```

**关键字段说明**：
- `id`: TMDB 电影ID（862）
- `imdb_id`: IMDB ID（tt0114709）
- `title` / `original_title`: 电影标题
- `overview`: 剧情简介（用于向量化和问答）
- `release_date`: 发行日期（1995-10-30）
- `runtime`: 时长 81 分钟
- `budget`: 预算 3000万美元
- `revenue`: 票房 3.74亿美元
- `vote_average`: TMDB 平均评分 7.727/10
- `vote_count`: 评分人数 18,459
- `popularity`: 人气值 99.123
- `genres`: 类型列表（Animation, Comedy, Family）
- `production_companies`: 制作公司（Pixar, Disney）
- `production_countries`: 制作国家（US）
- `spoken_languages`: 语言（English）
- `poster_path`: 海报路径
- `backdrop_path`: 背景图路径

**图片URL拼接**：
```
完整海报URL = https://image.tmdb.org/t/p/w500{poster_path}
示例: https://image.tmdb.org/t/p/w500/uXDfjJbdP4ijW5hWSBrPrlKpxab.jpg

可用尺寸: w92, w154, w185, w342, w500, w780, original
```

---

**2. 演职人员信息** - `GET /movie/{movie_id}/credits`

**请求示例**：
```bash
curl --request GET \
     --url 'https://api.themoviedb.org/3/movie/862/credits?language=en-US' \
     --header 'Authorization: Bearer eyJhbGciOiJIUzI1NiJ9...' \
     --header 'accept: backend/application/json'
```

**完整响应示例**：
```json
{
  "id": 862,
  "cast": [
    {
      "adult": false,
      "gender": 2,
      "id": 31,
      "known_for_department": "Acting",
      "name": "Tom Hanks",
      "original_name": "Tom Hanks",
      "popularity": 74.567,
      "profile_path": "/xndWFsBlClOJFRdhSt4NBwiPq2o.jpg",
      "cast_id": 12,
      "character": "Woody (voice)",
      "credit_id": "52fe4284c3a36847f8024f49",
      "order": 0
    },
    {
      "adult": false,
      "gender": 2,
      "id": 12898,
      "known_for_department": "Acting",
      "name": "Tim Allen",
      "original_name": "Tim Allen",
      "popularity": 23.456,
      "profile_path": "/fGJXDzqwSqCz2VfmqIZz8CVjVRy.jpg",
      "cast_id": 13,
      "character": "Buzz Lightyear (voice)",
      "credit_id": "52fe4284c3a36847f8024f4d",
      "order": 1
    },
    {
      "adult": false,
      "gender": 1,
      "id": 12899,
      "known_for_department": "Acting",
      "name": "Annie Potts",
      "original_name": "Annie Potts",
      "popularity": 15.234,
      "profile_path": "/eryXT84RL41Cb1g5YRO2ZN95qj.jpg",
      "cast_id": 14,
      "character": "Bo Peep (voice)",
      "credit_id": "52fe4284c3a36847f8024f51",
      "order": 2
    },
    {
      "adult": false,
      "gender": 2,
      "id": 12900,
      "known_for_department": "Acting",
      "name": "John Ratzenberger",
      "original_name": "John Ratzenberger",
      "popularity": 12.789,
      "profile_path": "/9bT4Zo8WD8Yj9eJSYXHyiFdWYlP.jpg",
      "cast_id": 15,
      "character": "Hamm (voice)",
      "credit_id": "52fe4284c3a36847f8024f55",
      "order": 3
    },
    {
      "adult": false,
      "gender": 2,
      "id": 12901,
      "known_for_department": "Acting",
      "name": "Don Rickles",
      "original_name": "Don Rickles",
      "popularity": 8.901,
      "profile_path": "/h5BcaDMPRVLHLDzbQavec38ysL0.jpg",
      "cast_id": 16,
      "character": "Mr. Potato Head (voice)",
      "credit_id": "52fe4284c3a36847f8024f59",
      "order": 4
    }
  ],
  "crew": [
    {
      "adult": false,
      "gender": 2,
      "id": 7879,
      "known_for_department": "Directing",
      "name": "John Lasseter",
      "original_name": "John Lasseter",
      "popularity": 8.765,
      "profile_path": "/7EdqiNbr4FRjIhKHyPPdFfEEEFG.jpg",
      "credit_id": "52fe4284c3a36847f8024f65",
      "department": "Directing",
      "job": "Director"
    },
    {
      "adult": false,
      "gender": 2,
      "id": 7879,
      "known_for_department": "Directing",
      "name": "John Lasseter",
      "original_name": "John Lasseter",
      "popularity": 8.765,
      "profile_path": "/7EdqiNbr4FRjIhKHyPPdFfEEEFG.jpg",
      "credit_id": "52fe4284c3a36847f8024f6b",
      "department": "Writing",
      "job": "Screenplay"
    },
    {
      "adult": false,
      "gender": 2,
      "id": 956,
      "known_for_department": "Writing",
      "name": "Joss Whedon",
      "original_name": "Joss Whedon",
      "popularity": 11.234,
      "profile_path": "/dTiVsuaTVTeGmvkhcyJvKp2A5kr.jpg",
      "credit_id": "52fe4284c3a36847f8024f71",
      "department": "Writing",
      "job": "Screenplay"
    },
    {
      "adult": false,
      "gender": 2,
      "id": 13158,
      "known_for_department": "Sound",
      "name": "Randy Newman",
      "original_name": "Randy Newman",
      "popularity": 5.678,
      "profile_path": "/lQJqADG3vx4fKY1DWuK3WYYGZcp.jpg",
      "credit_id": "52fe4284c3a36847f8024f95",
      "department": "Sound",
      "job": "Original Music Composer"
    }
  ]
}
```

**关键字段说明**：
- `cast`: 演员列表
  - `id`: TMDB Person ID（用于唯一标识）
  - `name`: 演员姓名
  - `character`: 饰演角色
  - `order`: 主演顺序（0为第一主演）
  - `profile_path`: 演员头像路径
- `crew`: 幕后人员列表
  - `job`: 职位（Director, Screenplay, Producer等）
  - `department`: 部门（Directing, Writing, Production等）

---

**3. 关键词** - `GET /movie/{movie_id}/keywords`

**请求示例**：
```bash
curl --request GET \
     --url 'https://api.themoviedb.org/3/movie/862/keywords' \
     --header 'Authorization: Bearer eyJhbGciOiJIUzI1NiJ9...' \
     --header 'accept: backend/application/json'
```

**响应示例**：
```json
{
  "id": 862,
  "keywords": [
    {
      "id": 931,
      "name": "jealousy"
    },
    {
      "id": 1453,
      "name": "toys"
    },
    {
      "id": 2964,
      "name": "alienation"
    },
    {
      "id": 3176,
      "name": "computer animation"
    },
    {
      "id": 4344,
      "name": "buddy"
    },
    {
      "id": 5202,
      "name": "friendship"
    },
    {
      "id": 9713,
      "name": "rivalry"
    },
    {
      "id": 10090,
      "name": "toy comes to life"
    },
    {
      "id": 161176,
      "name": "boy next door"
    },
    {
      "id": 179102,
      "name": "duringcreditsstinger"
    },
    {
      "id": 246656,
      "name": "inanimate objects come to life"
    }
  ]
}
```

**用途**：
- 主题标签，用于语义相似度计算
- 社区检测的特征维度
- 内容推荐的匹配依据

---

**4. 推荐电影** - `GET /movie/{movie_id}/recommendations`

**请求示例**：
```bash
curl --request GET \
     --url 'https://api.themoviedb.org/3/movie/862/recommendations?language=en-US&page=1' \
     --header 'Authorization: Bearer eyJhbGciOiJIUzI1NiJ9...' \
     --header 'accept: backend/application/json'
```

**响应示例**：
```json
{
  "page": 1,
  "results": [
    {
      "adult": false,
      "backdrop_path": "/c0YVgwcOm3Gf8e5sBSc0j3qNRjJ.jpg",
      "id": 863,
      "title": "Toy Story 2",
      "original_language": "en",
      "original_title": "Toy Story 2",
      "overview": "Andy heads off to Cowboy Camp, leaving his toys to their own devices...",
      "poster_path": "/xMmAoHRQXaLDED5H9CDNHD1yzQE.jpg",
      "media_type": "movie",
      "genre_ids": [16, 35, 10751],
      "popularity": 45.678,
      "release_date": "1999-10-30",
      "video": false,
      "vote_average": 7.6,
      "vote_count": 12345
    },
    {
      "adult": false,
      "backdrop_path": "/qCmJOn4ifZybRPBXL9JHwYx9NOx.jpg",
      "id": 10193,
      "title": "Toy Story 3",
      "original_language": "en",
      "original_title": "Toy Story 3",
      "overview": "Woody, Buzz, and the rest of Andy's toys haven't been played with in years...",
      "poster_path": "/w0DUf6sGDlQRSxFMLj28cvF1kxI.jpg",
      "media_type": "movie",
      "genre_ids": [16, 10751, 35],
      "popularity": 67.890,
      "release_date": "2010-06-16",
      "video": false,
      "vote_average": 7.8,
      "vote_count": 15678
    },
    {
      "adult": false,
      "backdrop_path": "/uOw5JD8IlD546nHJF7Rqb4UEPx2.jpg",
      "id": 12,
      "title": "Finding Nemo",
      "original_language": "en",
      "original_title": "Finding Nemo",
      "overview": "Nemo, an adventurous young clownfish, is unexpectedly taken from his Great Barrier Reef home to a dentist's office aquarium...",
      "poster_path": "/8fRL9ZX00tJNJmTFxOKVkx8pBSl.jpg",
      "media_type": "movie",
      "genre_ids": [16, 10751],
      "popularity": 56.789,
      "release_date": "2003-05-30",
      "video": false,
      "vote_average": 7.9,
      "vote_count": 18901
    }
  ],
  "total_pages": 5,
  "total_results": 100
}
```

**用途**：
- TMDB 算法推荐的相关电影
- 可作为"推荐"关系边的数据源
- 推荐置信度可用 `vote_average` 或 `popularity`

---

**5. 相似电影** - `GET /movie/{movie_id}/similar`

**请求示例**：
```bash
curl --request GET \
     --url 'https://api.themoviedb.org/3/movie/862/similar?language=en-US&page=1' \
     --header 'Authorization: Bearer eyJhbGciOiJIUzI1NiJ9...' \
     --header 'accept: backend/application/json'
```

**响应示例**：
```json
{
  "page": 1,
  "results": [
    {
      "adult": false,
      "backdrop_path": "/1Rr5SrvHxMXHu5RjKpaMba8VTzi.jpg",
      "id": 585,
      "title": "Monsters, Inc.",
      "original_language": "en",
      "original_title": "Monsters, Inc.",
      "overview": "James Sullivan and Mike Wazowski are monsters, they earn their living scaring children...",
      "poster_path": "/sgheSKxZkttIe8ON3u6spJG3aDk.jpg",
      "media_type": "movie",
      "genre_ids": [16, 35, 10751],
      "popularity": 78.901,
      "release_date": "2001-11-01",
      "video": false,
      "vote_average": 7.8,
      "vote_count": 17890
    },
    {
      "adult": false,
      "backdrop_path": "/yPNxKfBMMGnQ3LmCEwLKF2LZ7a2.jpg",
      "id": 14160,
      "title": "Up",
      "original_language": "en",
      "original_title": "Up",
      "overview": "Carl Fredricksen spent his entire life dreaming of exploring the globe...",
      "poster_path": "/mFvoEwSfLqbcWwFsDjQebn9bzFe.jpg",
      "media_type": "movie",
      "genre_ids": [16, 35, 10751, 12],
      "popularity": 89.012,
      "release_date": "2009-05-28",
      "video": false,
      "vote_average": 7.9,
      "vote_count": 19234
    },
    {
      "adult": false,
      "backdrop_path": "/nNmJRkg8wWnRmzQDe2FwKbPIsJV.jpg",
      "id": 9806,
      "title": "The Incredibles",
      "original_language": "en",
      "original_title": "The Incredibles",
      "overview": "Bob Parr has given up his superhero days to log in time as an insurance adjuster...",
      "poster_path": "/2LqaLgk4Z226KkgPJuiOQ58wvrm.jpg",
      "media_type": "movie",
      "genre_ids": [28, 12, 16, 10751],
      "popularity": 67.345,
      "release_date": "2004-10-27",
      "video": false,
      "vote_average": 7.7,
      "vote_count": 16789
    }
  ],
  "total_pages": 8,
  "total_results": 160
}
```

**用途**：
- TMDB 基于内容的相似电影
- 可作为"相似"关系边的数据源
- 相似度可用 `vote_average` 或自定义计算

---

**6. 类型列表** - `GET /genre/movie/list`

**请求示例**：
```bash
curl --request GET \
     --url 'https://api.themoviedb.org/3/genre/movie/list?language=en' \
     --header 'Authorization: Bearer eyJhbGciOiJIUzI1NiJ9...' \
     --header 'accept: backend/application/json'
```

**响应示例**：
```json
{
  "genres": [
    {
      "id": 28,
      "name": "Action"
    },
    {
      "id": 12,
      "name": "Adventure"
    },
    {
      "id": 16,
      "name": "Animation"
    },
    {
      "id": 35,
      "name": "Comedy"
    },
    {
      "id": 80,
      "name": "Crime"
    },
    {
      "id": 99,
      "name": "Documentary"
    },
    {
      "id": 18,
      "name": "Drama"
    },
    {
      "id": 10751,
      "name": "Family"
    },
    {
      "id": 14,
      "name": "Fantasy"
    },
    {
      "id": 36,
      "name": "History"
    },
    {
      "id": 27,
      "name": "Horror"
    },
    {
      "id": 10402,
      "name": "Music"
    },
    {
      "id": 9648,
      "name": "Mystery"
    },
    {
      "id": 10749,
      "name": "Romance"
    },
    {
      "id": 878,
      "name": "Science Fiction"
    },
    {
      "id": 10770,
      "name": "TV Movie"
    },
    {
      "id": 53,
      "name": "Thriller"
    },
    {
      "id": 10752,
      "name": "War"
    },
    {
      "id": 37,
      "name": "Western"
    }
  ]
}
```

**用途**：
- 建立 TMDB Genre ID 与名称的映射关系
- 与 MovieLens genres 字段对照（需要手动映射，如 "Sci-Fi" → "Science Fiction"）

**MovieLens 与 TMDB 类型映射（基于实际验证更新）**：

根据数据对应关系验证（Section 2.2.0），我们发现：

| MovieLens 类型 | TMDB 类型 | 映射说明 | 示例电影 |
|---------------|----------|----------|----------|
| Children | Family | ✅ 对应映射 | Toy Story |
| Sci-Fi | Science Fiction | ✅ 名称转换 | - |
| Musical | Music | ✅ 名称转换 | - |
| Film-Noir | - | ⚠️ MovieLens 特殊类型：不进入 `:类型`，仅保留原始字段 | - |
| IMAX | - | ⚠️ MovieLens 格式标签：不进入 `:类型`，仅保留原始字段 | - |
| Animation | Animation | ✅ 直接匹配 | Toy Story |
| Comedy | Comedy | ✅ 直接匹配 | Toy Story |
| Adventure | Adventure | ✅ 直接匹配 | Toy Story, Jumanji |
| Fantasy | Fantasy | ✅ 直接匹配 | Jumanji |
| Romance | Romance | ✅ 直接匹配 | Grumpier Old Men |

**数量口径说明**：
- MovieLens 原始类型一共有 19 个（包含 `IMAX`、`Film-Noir`）
- 进入图谱 `:类型` 的“规范类型名”预计为 17 个：`IMAX`、`Film-Noir` 不进入 `:类型`（仅保留在 `movielens_genres_raw/movielens_genres_unmapped`）

**实际案例对比**：

**Toy Story (1995)**:
- MovieLens 类型: `Adventure|Animation|Children|Comedy|Fantasy`
- TMDB 类型: `Family, Comedy, Animation, Adventure`
- 差异: MovieLens 的 "Children" → TMDB 的 "Family"

**代码实现**：
```python
MOVIELENS_TO_TMDB_GENRE = {
    # 需要名称归一化的项（MovieLens → TMDB 规范名）
    "Children": "Family",
    "Sci-Fi": "Science Fiction",
    "Musical": "Music",

    # MovieLens 中不属于“类型”的项（不进入 :类型 节点；仅保留原始字段，避免污染类型体系）
    "IMAX": None,
    "Film-Noir": None,

    # 其余为直接匹配（TMDB 与 MovieLens 同名）
    "Action": "Action",
    "Adventure": "Adventure",
    "Animation": "Animation",
    "Comedy": "Comedy",
    "Crime": "Crime",
    "Documentary": "Documentary",
    "Drama": "Drama",
    "Fantasy": "Fantasy",
    "Horror": "Horror",
    "Mystery": "Mystery",
    "Romance": "Romance",
    "Thriller": "Thriller",
    "War": "War",
    "Western": "Western",
}


def normalize_movielens_genres(genres: list[str]) -> tuple[list[str], list[str]]:
    """
    输入: MovieLens 原始 genres（如 ["Adventure","Children","Sci-Fi"]）
    输出:
      - tmdb_canonical_genres: TMDB 规范类型名列表（用于建 :类型 节点与 :属于类型 关系）
      - unmapped_genres: 无法映射/不应进入类型体系的条目（如 IMAX / Film-Noir），用于审计与后续扩展
    """
    canonical: list[str] = []
    unmapped: list[str] = []
    for g in genres:
        mapped = MOVIELENS_TO_TMDB_GENRE.get(g, g)
        if mapped is None:
            unmapped.append(g)
        else:
            canonical.append(mapped)
    # 去重保持稳定性
    canonical = sorted(set(canonical))
    unmapped = sorted(set(unmapped))
    return canonical, unmapped
```

**处理策略**：
1. 优先使用 TMDB 返回的类型（更标准、更丰富）
2. 如果 TMDB 数据缺失，回退到 MovieLens 类型并应用映射，生成“规范类型名”
3. 图谱中 `:类型.name` 始终使用 TMDB 规范名称；MovieLens 原始类型仅作为 `Movie` 节点的原始字段保留（用于审计/回溯），不参与 `:类型` 节点的主键与查询

---

**7. 搜索电影** - `GET /search/movie`

**用途**：用于缺失 TMDB ID 的 11 部电影

**请求示例**（搜索 "Shadows"，1988年）：
```bash
curl --request GET \
     --url 'https://api.themoviedb.org/3/search/movie?query=Shadows&year=1988&include_adult=false&language=en-US&page=1' \
     --header 'Authorization: Bearer eyJhbGciOiJIUzI1NiJ9...' \
     --header 'accept: backend/application/json'
```

**响应示例**：
```json
{
  "page": 1,
  "results": [
    {
      "adult": false,
      "backdrop_path": null,
      "genre_ids": [],
      "id": 123456,
      "original_language": "pl",
      "original_title": "Cienie",
      "overview": "",
      "popularity": 0.6,
      "poster_path": null,
      "release_date": "1988-01-01",
      "title": "Shadows",
      "video": false,
      "vote_average": 0,
      "vote_count": 0
    }
  ],
  "total_pages": 1,
  "total_results": 1
}
```

**处理逻辑**：
1. 提取标题和年份（从 MovieLens title 解析）
2. 调用 `/search/movie?query={title}&year={year}`
3. 取第一个结果的 `id` 作为 TMDB ID
4. 如果搜索无结果，标记为"未找到"

#### 2.2.3 TMDB API 调用估算

**基于 971 部有 TMDB ID 的电影**：

| API 端点 | 调用次数 | 用途 | 优先级 |
|---------|---------|------|--------|
| `/movie/{id}` | 971 | 电影详情（overview, budget, runtime等） | **必需** |
| `/movie/{id}/credits` | 971 | 演员、导演信息 | **必需** |
| `/movie/{id}/keywords` | 971 | 电影关键词 | 推荐 |
| `/movie/{id}/recommendations` | 971 | TMDB 推荐关系 | 可选 |
| `/movie/{id}/similar` | 971 | TMDB 相似电影 | 可选 |

**总计**：
- **核心数据（必需）**：971 × 2 = **1,942 次**
- **扩展数据（推荐）**：971 × 3 = **2,913 次**
- **完整数据**：971 × 5 = **4,855 次**

**时间估算**（按每秒 4 次请求限速）：
- 核心数据：1,942 / 4 / 60 ≈ **8.1 分钟**
- 扩展数据：2,913 / 4 / 60 ≈ **12.1 分钟**
- 完整数据：4,855 / 4 / 60 ≈ **20.2 分钟**

**缺失 TMDB ID 的 11 部电影**：
- 使用 `/search/movie?query={title}&year={year}` 搜索
- 额外调用：11 次搜索 + 11 × 2 = **33 次**

#### 2.2.4 TMDB 数据补充策略

**阶段 1：核心数据（优先级：高）**
- 调用：`/movie/{id}` + `/movie/{id}/credits`
- 补充字段：
  - 剧情简介（overview）
  - 时长（runtime）
  - 发行年份（release_date，用于验证）
  - 演员列表（前 10 位主演）
  - 导演（Directing 部门）

**阶段 2：扩展数据（优先级：中）**
- 调用：`/movie/{id}/keywords`
- 补充字段：
  - 关键词列表（用于语义检索和相似度计算）

**阶段 3：关联数据（优先级：可选）**
- 调用：`/movie/{id}/recommendations` + `/movie/{id}/similar`
- 补充字段：
  - TMDB 推荐电影ID列表
  - TMDB 相似电影ID列表
  - 用于构建"推荐"和"相似"关系边

**阶段 4：商业数据（优先级：低，按需）**
- 已在 `/movie/{id}` 中包含
- 字段：budget, revenue（可能缺失）
- 用途：统计分析、高票房电影查询

**数据缓存与容错**：
1. **本地缓存**：每次 API 响应保存为 JSON 文件
   - 路径：`files/tmdb_cache/movie_{tmdbId}.json`
   - 避免重复请求
2. **失败重试**：网络错误、限流错误自动重试（最多 3 次）
3. **缺失处理**：
   - 如果 TMDB 返回 404（电影不存在），标记为"未找到"
   - 对于老电影，允许部分字段缺失（如 budget, revenue）

---

## 3. 知识图谱 Schema 设计

### 3.1 实体类型（entity_types）

基于实际数据和 TMDB API 返回结果，定义如下实体类型：

> 工程实现：通过 `.env` 中 `GRAPH_ENTITY_TYPES` 配置（由 `backend/config/rag.py` 读取），`backend/graphrag_agent/config/settings.py` 仅保留向后兼容导出。

```python
entity_types = [
    "电影",           # Movie - 核心实体
    "人物",           # Person - 统一承载演员/导演等角色（主键 personId）
    "类型",           # Genre - 从 movies.csv 和 TMDB genres 提取
    "关键词",         # Keyword - 从 TMDB keywords 提取
    "公司",           # Production Company - 从 TMDB production_companies 提取
    "国家",           # Country - 从 TMDB production_countries 提取
    "语言",           # Language - 从 TMDB spoken_languages 提取
]
```

**说明**：
- 暂不包含"用户"实体（可在后续扩展中加入协同过滤功能）
- 统一使用 `:人物(personId)` 节点，不再拆分 `:演员` / `:导演` 两类节点；演员/导演等“角色”通过关系类型（`:出演` / `:导演`）与可选属性（如 `person_type`）表达

### 3.2 关系类型（relationship_types）

> 工程实现：通过 `.env` 中 `GRAPH_RELATIONSHIP_TYPES` 配置（由 `backend/config/rag.py` 读取）。

```python
relationship_types = [
    "出演",           # Person -[:出演]-> Movie (character, order, cast_id)
    "导演",           # Person -[:导演]-> Movie
    "属于类型",       # Movie -[:属于类型]-> Genre
    "包含关键词",     # Movie -[:包含关键词]-> Keyword
    "制作公司",       # Movie -[:制作公司]-> Company
    "制作国家",       # Movie -[:制作国家]-> Country
    "使用语言",       # Movie -[:使用语言]-> Language
    "相似",           # Movie -[:相似]-> Movie（可选；需额外计算 similarity_score/similarity_type）
    "推荐",           # Movie -[:推荐]-> Movie (source: 'tmdb' | 'computed')
    "共同出演",       # Person -[:共同出演]-> Person (count, sample_movie_ids)
]
```

**关系权重与方向**：
- `出演`：有向（Person → Movie），`order` 表示演职顺序（越小越重要）；如需“权重”用于排序/图算法，建议额外计算 `credit_weight = 1 / (order + 1)`
- `相似`：可选扩展；语义上无向（查询按无向匹配）；若写入，建议固定方向（按 movieId 小→大）以避免重复边，权重=相似度分数
- `推荐`：有向（Movie → Movie），权重=推荐置信度

### 3.2.1 唯一键、约束与索引（必须）

为避免重复节点、同名歧义与导入不一致，Schema 层需要明确每类节点的唯一键与索引策略（以 Neo4j 5.x 语法为准）：

```cypher
// 节点唯一性约束（建议在导入前创建）
CREATE CONSTRAINT movie_movie_id IF NOT EXISTS FOR (m:电影) REQUIRE m.movieId IS UNIQUE;
CREATE CONSTRAINT movie_tmdb_id IF NOT EXISTS FOR (m:电影) REQUIRE m.tmdbId IS UNIQUE;
CREATE CONSTRAINT movie_imdb_id IF NOT EXISTS FOR (m:电影) REQUIRE m.imdbId IS UNIQUE;
CREATE CONSTRAINT person_person_id IF NOT EXISTS FOR (p:人物) REQUIRE p.personId IS UNIQUE;
CREATE CONSTRAINT keyword_keyword_id IF NOT EXISTS FOR (k:关键词) REQUIRE k.keywordId IS UNIQUE;
CREATE CONSTRAINT company_company_id IF NOT EXISTS FOR (c:公司) REQUIRE c.companyId IS UNIQUE;
CREATE CONSTRAINT country_code IF NOT EXISTS FOR (c:国家) REQUIRE c.code IS UNIQUE;
CREATE CONSTRAINT language_code IF NOT EXISTS FOR (l:语言) REQUIRE l.code IS UNIQUE;
CREATE CONSTRAINT genre_name IF NOT EXISTS FOR (g:类型) REQUIRE g.name IS UNIQUE;

// 常用查询索引（按需）
CREATE INDEX movie_name_year IF NOT EXISTS FOR (m:电影) ON (m.name, m.year);
CREATE INDEX movie_tmdb_id IF NOT EXISTS FOR (m:电影) ON (m.tmdbId);
CREATE INDEX movie_imdb_id IF NOT EXISTS FOR (m:电影) ON (m.imdbId);
CREATE INDEX person_name IF NOT EXISTS FOR (p:人物) ON (p.name);

// 可选：全文索引（用于名称/简介关键词检索，和向量检索互补）
CREATE FULLTEXT INDEX movie_fulltext IF NOT EXISTS
FOR (m:电影) ON EACH [m.name, m.original_title, m.overview, m.description];
CREATE FULLTEXT INDEX person_fulltext IF NOT EXISTS
FOR (p:人物) ON EACH [p.name];
```

> 查询建议：优先使用 `movieId/tmdbId/imdbId` 精确定位电影；若按片名检索，至少使用 `name + year`（同名电影非常常见）。

### 3.3 实体属性详细设计

#### 3.3.1 电影（Movie）

**数据来源**：movies.csv + links.csv + TMDB `/movie/{id}`

**Neo4j 属性类型约束（重要）**：
- Neo4j 节点/关系属性只支持：标量（string/int/float/bool/temporal/point）与“标量数组”
- 不支持：Map、List[Map]、嵌套对象
- 因此：`movies_enriched.json` 中的 `cast/crew/keywords/production_companies/production_countries/spoken_languages` 等结构化列表**不能**直接写入 `:电影` 节点属性；应仅用于生成/驱动 `persons.json/keywords.json/companies.json/countries.json/languages.json` 并创建对应关系

```python
{
    # 基础标识
    "name": str,              # 展示标题（从 title 解析，不含年份）
    "original_title": str,    # TMDB original_title（可选，用于消歧/别名检索）
    "aliases": list[str],     # 别名集合（可选：中英文名/译名/别名）
    "movieId": int,           # MovieLens ID（主键）
    "tmdbId": int,            # TMDB ID
    "imdbId": str,            # IMDB ID (格式: tt0114709)

    # 时间信息
    "year": int,              # 发行年份（从 title 解析，TMDB 验证）
    "release_date": date,     # TMDB 精确发行日期（Neo4j date）

    # 内容信息
    "overview": str,          # 剧情简介（TMDB，用于向量化和问答）
    "runtime": int,           # 时长（分钟）

    # 评分与流行度
    "tmdb_vote_average": float,    # TMDB 平均评分 (0-10)
    "tmdb_vote_count": int,        # TMDB 评分人数
    "tmdb_popularity": float,      # TMDB 人气值
    "movielens_avg_rating": float, # MovieLens 平均评分 (0-5)
    "movielens_rating_count": int, # MovieLens 评分数

    # 评分口径（用于排序与“高分”判断，统一到 0-10）
    "rank_score_0_10": float,      # 统一排序分（0-10）
    "rank_score_source": str,      # "movielens" | "tmdb"
    "rank_score_votes": int,       # 参与排序的票数口径（movielens_rating_count 或 tmdb_vote_count）

    # 商业数据（可选）
    "budget": int,            # 预算（美元，可能缺失）
    "revenue": int,           # 票房（美元，可能缺失）

    # 语言与地区
    "original_language": str, # 原始语言代码 (ISO 639-1，如 'en')：对应 TMDB original_language

    # 视觉素材
    "poster_path": str,       # 海报路径（可拼接 TMDB 图片URL）

    # 类型（闭环设计：图谱与查询统一用 TMDB 规范名）
    "genres": list[str],                 # 规范类型名（用于创建 :类型 节点与 :属于类型 关系）
    "tmdb_genres_raw": list[str],        # TMDB 原始类型名（审计字段；通常与 genres 一致）
    "movielens_genres_raw": list[str],   # MovieLens 原始类型名（如包含 "Sci-Fi"/"Children"）
    "movielens_genres_unmapped": list[str],  # 无法映射/不应进入类型体系的条目（如 IMAX/Film-Noir）

    # 综合描述（用于向量化）
    "description": str,       # 格式："{name} ({year}) - {genres} - {overview}"（此处 genres 为规范类型名）

    # 元数据
    "data_source": str,       # "movielens+tmdb" 或 "movielens_only"
    "created_at": datetime,   # 导入时间戳（Neo4j datetime）
}
```

**评分口径与排序规则（闭环）**：
- 原始评分字段保持各自口径：`movielens_avg_rating`（0-5）与 `tmdb_vote_average`（0-10）
- 所有“高分/排序”场景统一使用 `rank_score_0_10`（0-10）
- 计算规则（推荐默认）：
  1. 若 `movielens_rating_count >= 50`：`rank_score_0_10 = movielens_avg_rating * 2`，`rank_score_source="movielens"`
  2. 否则若有 TMDB：`rank_score_0_10 = tmdb_vote_average`，`rank_score_source="tmdb"`
  3. `rank_score_votes` 使用对应来源的 vote/rating count

**向量化策略**：
- 主向量：基于 `description` 字段生成（综合名称、规范类型、简介）
- 仅使用 OpenAI Embedding；不使用 Item2Vec embedding.txt

**字段一致性约定**：
- `genres` 与 `(:电影)-[:属于类型]->(:类型)` 信息冗余：关系用于图遍历与统计，`genres` 用于快速过滤/展示；两者必须保持一致（以关系为准可重算回填）
- `:使用语言` 关系用于表达“对白语言/可用语言”（来自 TMDB spoken_languages），可能包含多个语言
- `original_language` 仅表达“原始语言”（来自 TMDB original_language），与对白语言概念不同；统计时需明确口径

#### 3.3.2 人物（Person）

**数据来源**：TMDB `/movie/{id}/credits`（`cast` + `crew`）

```python
{
    # 基础标识
    "name": str,              # 姓名（中文或英文，取决于 TMDB 数据）
    "aliases": list[str],     # 别名集合（可选：中文译名/艺名/别名）
    "personId": int,          # TMDB Person ID（主键）

    # 类型标识
    "person_type": str,       # "actor" | "director" | "both"（可选派生字段；以关系 :出演/:导演 为准）

    # 详细信息（可选，来自 TMDB /person/{id}，暂不调用）
    "biography": str,         # 个人简介（如需要深度搜索，可后续补充）
    "popularity": float,      # TMDB 人气值
    "profile_path": str,      # 头像路径

    # 统计信息（从图谱计算）
    "movie_count": int,       # 参演/导演电影数量（从关系计数）

    # 元数据
    "data_source": str,       # "tmdb"
    "created_at": datetime,
}
```

**优化**：
- 初期不调用 `/person/{id}` API，仅从 credits 获取基本信息
- 如需人物简介，可在后续阶段按需补充

**一致性约定**：
- `person_type` 为可派生字段（可选缓存）；以关系 `:出演/:导演` 为准，避免属性与关系不一致

#### 3.3.3 类型（Genre）

**数据来源**：movies.csv genres 字段 + TMDB genres

```python
{
    "name": str,              # 规范类型名（TMDB 规范名称；作为 :类型 节点唯一键）
    "tmdb_genre_id": int,     # TMDB Genre ID（可选，通过 /genre/movie/list 获取）
    "movielens_count": int,   # 在 MovieLens 数据集中的电影数量
    "description": str,       # 类型描述（可选，用于向量化）
}
```

**TMDB 类型映射**（调用一次 `/genre/movie/list` 获取）：
```json
{
  "genres": [
    {"id": 28, "name": "Action"},
    {"id": 35, "name": "Comedy"},
    {"id": 18, "name": "Drama"},
    ...
  ]
}
```

#### 3.3.4 关键词（Keyword）

**数据来源**：TMDB `/movie/{id}/keywords`

```python
{
    "name": str,              # 关键词（如 "jealousy", "toys"）
    "keywordId": int,         # TMDB Keyword ID
    "movie_count": int,       # 可选缓存字段：包含此关键词的电影数量（可由关系计数得到）
}
```

**用途**：
- 语义相似度计算（基于共享关键词）
- 主题聚类（通过关键词社区检测）

#### 3.3.5 制作公司（ProductionCompany）

**数据来源**：TMDB production_companies

```python
{
    "name": str,              # 公司名称（如 "Pixar Animation Studios"）
    "companyId": int,         # TMDB Company ID
    "origin_country": str,    # 所在国家（如 "US"）
    "movie_count": int,       # 可选缓存字段：制作的电影数量（可由关系计数得到）
}
```

#### 3.3.6 国家（Country）

**数据来源**：TMDB production_countries

```python
{
    "name": str,              # 国家名称（如 "United States of America"）
    "code": str,              # ISO 3166-1 代码（如 "US"）
    "movie_count": int,       # 可选缓存字段：来自该国的电影数量（可由关系计数得到）
}
```
**编码规范**：`code` 统一使用大写（如 `US`、`CN`），避免同义重复节点。

#### 3.3.7 语言（Language）

**数据来源**：TMDB spoken_languages

```python
{
    "name": str,              # 语言名称（如 "English"）
    "code": str,              # ISO 639-1 代码（如 "en"）
    "movie_count": int,       # 可选缓存字段：使用该语言的电影数量（可由关系计数得到）
}
```
**编码规范**：`code` 统一使用小写（如 `en`、`zh`），避免同义重复节点。

### 3.4 关系属性设计

#### 3.4.1 出演（Person -[:出演]-> Movie）
```python
{
    "character": str,         # 角色名（如 "Woody (voice)"）
    "order": int,             # 演员顺序（0 = 第一主演）
    "cast_id": int,           # TMDB cast ID
}
```
**去重约定**：
- 默认每个 `(personId, movieId)` 只保留一条 `:出演` 关系；若同一人物在同一电影存在多个 `character`，建议将 `character` 改为 `list[str]` 并聚合写入，避免多条边导致遍历膨胀。

#### 3.4.2 相似（Movie -[:相似]-> Movie）
> 说明：该关系为“可选扩展”。当前仓库默认不生成 `:相似` 边；推荐场景优先使用 Canonical `Movie` 向量相似度，
> 并用共享 `Genre/Keyword/Person/Company` 的 `RELATED/MENTIONS` 作为解释证据。

```python
{
    "similarity_score": float,     # 相似度分数 (0-1)
    "similarity_type": str,        # "genre" | "cast" | "keyword" | "tmdb"
    "evidence": list[str],         # 相似证据（如共享的类型、演员、关键词）
    "updated_at": datetime,        # 更新时间戳（可选）
}
```

**建模策略（避免覆盖，支持多来源）**：
- 对同一对电影 `(movieA, movieB)`，不同 `similarity_type` **分别建一条** `:相似` 关系（即最多 4 条），避免后写入覆盖先写入
- 关系唯一键：`(movie_pair, similarity_type)`
- 为避免无向 `MERGE` 产生重复边，写入时固定方向：按 `movieId` 从小到大 `MERGE (small)-[:相似 {similarity_type}]->(large)`；查询仍可用 `-[r:相似]-` 无向匹配
- 上层推荐/展示通常按同一候选电影聚合：取 `max(similarity_score)` 作为“总体相似度”，并选出对应的 `similarity_type/evidence` 作为解释

**计算方法**：
1. **基于类型**：Jaccard 相似度 = |genres1 ∩ genres2| / |genres1 ∪ genres2|
2. **基于演员**：共享主演数量 / 总主演数量
3. **基于关键词**：Jaccard 相似度
4. **TMDB 直接提供**：从 `/similar` 端点获取

**阈值**：
- 相似度 > 0.3 才创建关系
- 优先保留高相似度关系（Top K = 10）

#### 3.4.3 推荐（Movie -[:推荐]-> Movie）
```python
{
    "recommendation_score": float, # 推荐分数（TMDB 或计算得出）
    "source": str,                 # "tmdb" | "collaborative" | "content_based"
    "reason": str,                 # 推荐理由（如"同类型高评分电影"）
    "updated_at": datetime,        # 更新时间戳（可选）
}
```

**推荐关系去重策略**：
- 允许同一对电影存在多条 `:推荐`（不同 `source`），用于保留多策略推荐证据
- 写入时建议以 `(from_movieId, to_movieId, source)` 作为关系唯一键：
  - `MERGE (m1)-[r:推荐 {source: $source}]->(m2)`
  - 再 `SET r.recommendation_score = ... , r.reason = ... , r.updated_at = datetime()`

#### 3.4.4 共同出演（Person -[:共同出演]-> Person）
```python
{
    "count": int,                  # 共同电影数量
    "sample_movie_ids": list[int], # 示例电影 ID（可选，建议最多保留 10 个，避免属性膨胀）
}
```

**计算方法**：
- 遍历所有人物的出演电影列表
- 找出交集电影数 >= 2 的人物对
- `sample_movie_ids` 仅保留少量样例（建议最多 10 个），避免关系属性膨胀
- 创建无向关系

### 3.5 GraphRAG 兼容层（Canonical Layer，用于“统一检索链路”）

> 目标：在保留电影领域结构化图（`:电影/:人物/:关键词/...`）的同时，生成一层 GraphRAG 兼容的“统一语义层”，使现有 `LocalSearch/GlobalSearch/HybridTool`（依赖 `__Entity__/__Chunk__/__Community__`）可以复用。

#### 3.5.1 Canonical 节点与关系（最小闭环）

**节点（沿用现有系统约定）**：
- `:__Document__`：信息来源容器（文档模式=文件；结构化模式=“movie:{movieId}”等虚拟文档）
- `:__Chunk__`：证据文本块（用于回答引用）
- `:__Entity__`：可被向量检索命中的实体（用于召回）
- `:__Community__`：社区聚合与摘要（用于 Global Search/社区摘要）

**关系（现有检索链路依赖）**：
- `(:__Chunk__)-[:PART_OF]->(:__Document__)`
- `(:__Chunk__)-[:MENTIONS]->(:__Entity__)`（LocalSearch 会从 entity 反查 chunk 作为证据）
- `(:__Entity__)-[:IN_COMMUNITY]->(:__Community__)`（LocalSearch/GlobalSearch 使用社区摘要）

#### 3.5.2 结构化电影图 → Canonical 的映射规则（推荐实现）

**实体映射（Domain → __Entity__）**：
- `(:电影 {movieId})` → `(:__Entity__ {id, name, entity_type='Movie', description})`
- `(:人物 {personId})` → `(:__Entity__ {id, name, entity_type='Person', description})`
- `(:关键词 {keywordId})` → `(:__Entity__ {id, name, entity_type='Keyword', description})`

**推荐的全局唯一 ID 规范**（避免跨领域冲突、可重复运行幂等）：
- `__Entity__.id = "{kb}:{type}:{pk}"`，例如：
  - `movie:Movie:1`
  - `movie:Person:31`
  - `movie:Keyword:1234`

**description 规范**：
- Movie：优先 `:电影.description`，回退 `:电影.overview`，再回退 `:电影.name + genres`
- Person：`name`（可选拼接 `person_type`）
- Keyword：`name`

**Chunk/Document 映射（结构化 → 证据块）**：
- 每部电影至少生成 1 个 `__Document__`（`fileName="movie:{movieId}"`）与 1 个 `__Chunk__`（`text=电影 description`），并建立 `PART_OF`
- 为增强可解释性，可选再生成：
  - cast chunk（包含主要演员与角色）
  - director chunk（导演）
  - keyword chunk（关键词）
- `MENTIONS` 关系的确定性规则（无需 LLM 抽取）：
  - 电影描述 chunk → mentions 电影 entity
  - cast chunk → mentions 相关人物 entities
  - keyword chunk → mentions 相关关键词 entities

#### 3.5.3 Community 兼容要求（满足现有 Global/Local Search）

为复用现有 `GlobalSearch`，`__Community__` 建议包含：
- `id`：社区标识（例如 `movie:community:{community_id}`）
- `level`：社区层级（默认 `0` 即可）
- `summary`：短摘要（LocalSearch 在 Reports 中使用）
- `full_content`：长摘要/报告（GlobalSearch Map-Reduce 使用）
- `community_rank`：用于排序（可按 `size` 或 `avg_rank_score` 计算）

> 注意：现有查询默认不按 `kb_id` 过滤。如果“学生管理”和“电影”要在同一 Neo4j 数据库共存，需要：
> 1) 修改检索查询在 `MATCH` 时加 `WHERE e.id STARTS WITH 'movie:'` 或引入 `kb_id` 过滤（需要改代码）；或  
> 2) 将电影图部署到独立 Neo4j 实例/独立环境，避免跨域混淆（不改代码也可工作）。

---

## 4. 数据处理流程

### 4.1 总体流程概览

#### 4.1.1 三阶段架构

本项目的数据处理分为三个主要阶段，每个阶段有明确的输入输出和职责边界：

```
┌─────────────────────────────────────────────────────────────┐
│ Phase 1: 数据预处理 (本地 CSV + TMDB API 调用)              │
│                                                             │
│  输入: MovieLens CSV + TMDB API                             │
│  输出: 6个标准化JSON文件                                     │
│  时长: ~12-20分钟                                           │
└──────────────────────┬──────────────────────────────────────┘
                       │
                       ▼
┌─────────────────────────────────────────────────────────────┐
│ Phase 2: 知识图谱构建                                        │
│                                                             │
│  输入: Phase 1的JSON文件                                     │
│  输出: Neo4j图谱（~6000节点，~27000关系）                    │
│  时长: ~3-5分钟                                             │
└──────────────────────┬──────────────────────────────────────┘
                       │
                       ▼
┌─────────────────────────────────────────────────────────────┐
│ Phase 3: 向量索引与社区检测                                  │
│                                                             │
│  输入: Phase 2的图谱数据                                     │
│  输出: 向量索引 + 社区结构                                   │
│  时长: ~5-10分钟                                            │
└─────────────────────────────────────────────────────────────┘
```

#### 4.1.2 数据流转关系

```
MovieLens CSV ──┐
                ├──> Phase 1 ──> JSON文件 ──> Phase 2 ──> Neo4j图谱 ──> Phase 3 ──> 向量索引+社区
TMDB API ──────┘                                                                           │
                                                                                           ▼
                                                                                    可用于搜索和推荐
```

**关键数据转换点**：
1. **CSV → JSON**：数据清洗、类型归一化、评分统一
2. **JSON → Graph**：实体节点创建、关系边构建
3. **Graph → Index**：向量化、索引构建、社区检测

#### 4.1.3 关键决策点

| 决策点 | 条件 | 路径A（标准） | 路径B（降级） |
|-------|------|-------------|-------------|
| **TMDB API可用性** | 是否配置API凭证 | 完整数据（6个JSON） | 降级为仅MovieLens（仅输出movies_enriched.json；跳过TMDB聚合文件） |
| **网络连接** | 是否配置代理 | 直连TMDB | 使用HTTP代理 |
| **数据完整性** | TMDB数据是否缺失 | 标准处理 | 降级为MovieLens字段 |
| **图谱构建模式** | Phase 2/3模式选择 | 结构化模式（电影） | 文档模式（学生管理） |

> **重要提示**：代码实现细节（模块设计、接口规范、扩展方式）已移至 **附录B：代码实现指南**，便于开发者查阅。

#### 4.1.4 统一框架架构

本项目采用**统一框架改造**方案，在现有GraphRAG框架基础上扩展支持两种数据处理模式：

**架构设计**：

```
KnowledgeGraphProcessor（统一编排入口：main.py）
├── GRAPH_BUILD_MODE=document：FILES_DIR → 分块 → LLM抽取 → __Entity__/__Chunk__
└── GRAPH_BUILD_MODE=structured：JSON → 领域图导入（:电影/:人物/...）+ Canonical 层生成（__Document__/__Chunk__/__Entity__）
```

**两种模式对比**：

| 维度 | 文档模式（学生管理） | 结构化模式（电影推荐） |
|-----|-------------------|---------------------|
| **数据输入** | TXT/PDF/MD等文档（FILES_DIR） | JSON/CSV结构化数据 |
| **Phase 2处理** | DocumentProcessor → LLM抽取实体 | 直接Cypher导入 |
| **节点标签** | `__Document__`, `__Chunk__`, `__Entity__` | 领域层：`:电影/:人物/...` + Canonical层：`__Document__/__Chunk__/__Entity__`（见3.5） |
| **Phase 3索引** | `__Entity__`向量索引（默认名`vector`） | `__Entity__`向量索引（建议名`movie_vector`；通过`ENTITY_VECTOR_INDEX_NAME`切换） |
| **社区节点** | `__Community__` (level分层) | `__Community__`（由电影相似子图生成；兼容现有Global/LocalSearch） |
| **配置切换** | `GRAPH_BUILD_MODE=document` (默认) | `GRAPH_BUILD_MODE=structured` |

**代码修改点**：

```python
# backend/infrastructure/integrations/build/main.py（简化示意）
mode = os.getenv("GRAPH_BUILD_MODE", "document")
if mode == "document":
    KnowledgeGraphBuilder().process()
else:
    StructuredMovieGraphBuilder(...).process()
```

**执行方式**：

```bash
# 先激活 Python 3.10 虚拟环境（.venv）
source .venv/bin/activate

# 文档模式（现有）
bash scripts/py.sh infrastructure.integrations.build.main

# 结构化模式（电影，统一框架改造后）
export GRAPH_BUILD_MODE=structured
export STRUCTURED_DATA_DIR=files/movie_data
export ENTITY_VECTOR_INDEX_NAME=movie_vector
export GRAPH_ENTITY_ID_PREFIX_FILTER=movie:
export GRAPH_COMMUNITY_ID_PREFIX=movie:
bash scripts/py.sh infrastructure.integrations.build.main
```

**优点**：
- ✅ 代码复用度高（共享embedding、Neo4j连接、GDS等）
- ✅ 统一的编排流程（main.py）
- ✅ 配置管理一致（settings.py + 环境变量）
- ✅ 便于后续扩展更多领域（如音乐、书籍等）

**缺点**：
- ⚠️ 改造风险较大（需修改现有核心代码）
- ⚠️ 需要充分测试避免影响学生管理系统

#### 4.1.5 共库运行规范（重要）

当 **Neo4j 复用同一个数据库**同时承载“学生管理（document）”与“电影推荐（structured）”两套知识库时，必须明确“隔离边界”和“清理策略”，否则会出现：
- `__Entity__/__Chunk__/__Document__/__Community__` 混在一起，统计与调试困难
- 向量索引名冲突（默认 `vector` 会互相覆盖）
- 动态写 label 造成 schema 污染（出现不可读/超长 label）

**1）共库隔离边界（推荐做法）**

- 电影知识库统一使用前缀：`STRUCTURED_KB_PREFIX=movie`
- Phase 3 仅处理电影前缀实体：`GRAPH_ENTITY_ID_PREFIX_FILTER=movie:`
- 社区 ID 使用命名空间：`GRAPH_COMMUNITY_ID_PREFIX=movie:`
- 向量索引使用独立名称，避免覆盖默认 `vector`：
  - `ENTITY_VECTOR_INDEX_NAME=movie_vector`
  - `CHUNK_VECTOR_INDEX_NAME=movie_chunk_vector`

**2）关于“原学生管理数据是否要删除”**

结论：**可以删**，删完后按当前 structured 逻辑全量重跑即可；但需要明确：这会清掉 document 模式遗留的 Canonical/社区/索引（以及可能的历史领域标签节点），属于不可逆操作，建议先备份或确认不再需要学生管理系统。

**3）清理策略（继续共库，但删除学生管理 document 产物）**

如果目标是“同库继续使用，但只保留 movie 知识库”，建议做一次“非 movie 前缀清理”，再全量重跑 structured。
如果目标是“电影 + 学生管理长期共存”，**不要执行本节的删除语句**，请按 4.1.6 的命名空间隔离方案改造 document 模式后再运行。

```cypher
// 1) 删除非 movie 的 Canonical 层（__Entity__/__Chunk__/__Document__）
MATCH (e:__Entity__)
WHERE NOT e.id STARTS WITH 'movie:'
DETACH DELETE e;

MATCH (c:__Chunk__)
WHERE NOT c.id STARTS WITH 'movie:' AND NOT c.fileName STARTS WITH 'movie:'
DETACH DELETE c;

MATCH (d:__Document__)
WHERE NOT d.fileName STARTS WITH 'movie:'
DETACH DELETE d;

// 2) 删除非 movie 的社区节点（如果存在）
MATCH (c:__Community__)
WHERE NOT c.id STARTS WITH 'movie:'
DETACH DELETE c;
```

> 说明：上述只清理 Canonical/社区层；领域层（如学生管理系统的其它业务节点标签）若还存在，需要根据实际标签再行删除。

**4）写库接口的约束（避免 label 污染）**

任何“写图谱”的 API/脚本 **禁止**把用户输入/LLM 输出直接拼接到 Neo4j label（例如 `CREATE (e:__Entity__:{type})`）。
共库场景下，推荐把类型写入属性（如 `e.type`/`e.entity_type`），并通过 allowlist 做校验。

#### 4.1.6 多知识库共存方案（电影 + 学生管理）

目标：在 **同一个 Neo4j** 中同时运行两套知识库（电影 structured + 学生管理 document），且做到：
- 互不覆盖索引/社区
- 构建/重跑不互相删除数据
- 读写接口不会污染 schema

**1）统一命名空间（强约束）**

为每个知识库分配一个 `kb_prefix`（建议）：
- 电影：`movie`
- 学生管理：`edu`

并保证以下“可被过滤”的 key 全部带前缀（**这是共存的根基**）：
- `__Entity__.id`：必须以 `<kb_prefix>:` 开头
- `__Document__.fileName`：必须以 `<kb_prefix>:` 开头
- `__Chunk__.id` 与 `__Chunk__.fileName`：必须以 `<kb_prefix>:` 开头
- `__Community__.id`：必须以 `<kb_prefix>:` 开头

电影 structured 已满足以上约束（如 `movie:Movie:1`、`movie:movie:1:desc` 等）。

学生管理 document 模式可通过 `DOCUMENT_KB_PREFIX` 实现同样的“前缀化写入”，从而与 `movie:` 共库共存。

**2）索引与 Phase 3 的隔离（推荐配置）**

同库共存时，默认值 `vector/chunk_vector` 会冲突，必须按知识库拆分索引名，并用前缀过滤让 Phase 3 只处理当前 KB：

- 电影（structured）：
  - `ENTITY_VECTOR_INDEX_NAME=movie_vector`
  - `CHUNK_VECTOR_INDEX_NAME=movie_chunk_vector`
  - `GRAPH_ENTITY_ID_PREFIX_FILTER=movie:`
  - `GRAPH_CHUNK_ID_PREFIX_FILTER=movie:`
  - `GRAPH_COMMUNITY_ID_PREFIX=movie:`
- 学生管理（document）：
  - `ENTITY_VECTOR_INDEX_NAME=edu_vector`
  - `CHUNK_VECTOR_INDEX_NAME=edu_chunk_vector`
  - `GRAPH_ENTITY_ID_PREFIX_FILTER=edu:`
  - `GRAPH_CHUNK_ID_PREFIX_FILTER=edu:`
  - `GRAPH_COMMUNITY_ID_PREFIX=edu:`

同时建议强制：
- `BUILD_DROP_ALL_INDEXES=false`（避免一次运行把另一个 KB 的索引删掉）

**2.1）VECTOR 索引的 label 作用域隔离（必须）**

Neo4j **不允许**在同一 `(label, property)` 上创建多份 `VECTOR` 索引；而本项目 Canonical 层的 `__Entity__` 与 `__Chunk__` 都使用 `embedding` 属性。

因此，为了让 `movie` 与 `edu` 在同库中各自拥有“实体向量索引 + Chunk 向量索引”，需要在写入/索引阶段为不同 KB/节点类型打“作用域 label”（由代码自动完成）：

- 实体：`KB_movie_entity` / `KB_edu_entity`
- Chunk：`KB_movie_chunk` / `KB_edu_chunk`
- 文档：`KB_movie_document` / `KB_edu_document`（用于隔离/调试，非必须）

索引将创建在这些 label 上（示例）：
- `movie_vector` → `(:KB_movie_entity {embedding})`
- `movie_chunk_vector` → `(:KB_movie_chunk {embedding})`
- `edu_vector` → `(:KB_edu_entity {embedding})`
- `edu_chunk_vector` → `(:KB_edu_chunk {embedding})`

> 通常无需手工设置 `GRAPH_ENTITY_KB_LABEL/GRAPH_CHUNK_KB_LABEL`，默认会由 `GRAPH_*_PREFIX_FILTER` 自动推导。

**3）学生管理（document）要共存，必须补齐的改造点（实现要求）**

document 模式在 **未设置** `DOCUMENT_KB_PREFIX` 时会沿用历史行为执行“全库清空”（`MATCH (n) DETACH DELETE n`），这与共存目标冲突；此外，document 模式的 `__Document__/__Chunk__/__Entity__` 也需要命名空间化，才能用 `GRAPH_*_PREFIX_FILTER` 做隔离。

因此需要对 document 模式做以下改造（概念约束，落地由代码实现）：
- 将 `GraphStructureBuilder.clear_database()` 改为 **按前缀清理**（仅清理 `edu:` 或指定 KB 的 `__Document__/__Chunk__/__Entity__/__Community__`），禁止全库删除。
- `__Document__.fileName` 前缀化：`edu:<原 fileName>`
- `__Chunk__.id` 前缀化：`edu:<原 chunk_id>`，且 `__Chunk__.fileName` 同步前缀化
- `__Entity__.id` 前缀化：将抽取到的实体 `id/name` 分离：
  - `__Entity__.id = edu:<实体名或实体唯一键>`
  - `__Entity__.name = <实体名>`
  - `__Entity__.entity_type/type = <类型>`
- 社区算法写回属性统一：Leiden 默认写属性为 `communities`（而非 `communityIds`），共库中不要混用不同属性名。

> 备注：如果暂时不做上述改造，document 模式“重跑一次”会直接把 movie 图谱清空，无法共存。

**4）运行方式（共库存续）**

电影与学生管理分别运行时，都要带上“本 KB 的前缀 + 索引名”，并且禁止 drop all indexes：

```bash
# 电影 structured
GRAPH_BUILD_MODE=structured \
STRUCTURED_KB_PREFIX=movie \
STRUCTURED_DATA_DIR=files/movie_data \
ENTITY_VECTOR_INDEX_NAME=movie_vector \
CHUNK_VECTOR_INDEX_NAME=movie_chunk_vector \
GRAPH_ENTITY_ID_PREFIX_FILTER=movie: \
GRAPH_CHUNK_ID_PREFIX_FILTER=movie: \
GRAPH_COMMUNITY_ID_PREFIX=movie: \
BUILD_DROP_ALL_INDEXES=false \
bash scripts/py.sh infrastructure.integrations.build.main
```

```bash
# 学生管理 document
GRAPH_BUILD_MODE=document \
DOCUMENT_KB_PREFIX=edu \
FILES_DIR=files/txt文件 \
TEXT_CHUNKER_PROVIDER=simple \
DOCUMENT_FILE_EXTENSIONS=.txt,.pdf,.md,.doc,.docx \
DOCUMENT_RECURSIVE=true \
ENTITY_VECTOR_INDEX_NAME=edu_vector \
CHUNK_VECTOR_INDEX_NAME=edu_chunk_vector \
GRAPH_ENTITY_ID_PREFIX_FILTER=edu: \
GRAPH_CHUNK_ID_PREFIX_FILTER=edu: \
GRAPH_COMMUNITY_ID_PREFIX=edu: \
BUILD_DROP_ALL_INDEXES=false \
bash scripts/py.sh infrastructure.integrations.build.main
```

> 说明：`DOCUMENT_KB_PREFIX` 已实现：document 模式写入 Neo4j 时会对 `__Document__.fileName`、`__Chunk__.id/__Chunk__.fileName`、`__Entity__.id` 做 `<prefix>:` 命名空间前缀化，并额外写入 `rawFileName` 便于按原文件名做增量更新/清理与定位。

**5）一次性迁移建议（从“历史混库”到“可共存”）**

如果库里已存在大量“无前缀”的学生管理 Canonical 数据，推荐做一次性迁移：
- 删除旧的（无前缀）学生管理 Canonical/社区/索引数据
- 按第 3 点完成“前缀化 document 改造”后重建 `edu:` 知识库
- `movie:` 知识库无需变动

### 4.2 Phase 1: 数据预处理与 TMDB 数据获取

#### 4.2.1 输入与前置条件

**数据源准备**：

- MovieLens 数据集（位于 `SparrowRecSys-master/target/classes/webroot/sampledata/`）
  - `movies.csv`：982部电影
  - `links.csv`：TMDB/IMDB ID映射
  - `ratings.csv`：116万条评分记录

**环境配置**：
```bash
# .env文件配置
# 推荐：Bearer Token 认证
TMDB_API_TOKEN=<YOUR_TMDB_BEARER_TOKEN>

# 可选：如果没有 Token，也可用 API Key（脚本支持二选一）
TMDB_API_KEY=<YOUR_TMDB_API_KEY>

# 可选：网络受限或直连超时时启用
HTTP_PROXY=http://localhost:10808
HTTPS_PROXY=http://localhost:10808
```

**依赖检查**：
```bash
# Python 环境要求（必须）
# - 必须使用 Python 3.10（避免 langchain/langsmith/pydantic 在 3.12 下的 ForwardRef 兼容问题）
# - 必须使用 venv（统一与项目其他流程一致）
python3.10 -m venv .venv
source .venv/bin/activate

# 验证版本（应为 3.10.x）
python -V

# 安装项目依赖
pip install -r requirements.txt
```

**运行参数**：
- `--source-dir`：MovieLens数据目录（默认：`SparrowRecSys-master/target/classes/webroot/sampledata`）
- `--output-dir`：输出目录（默认：`files/movie_data`）
- `--cache-dir`：TMDB缓存目录（默认：`files/tmdb_cache`）
- `--rate-limit`：API请求限速（默认：`4.0`请求/秒）
- `--skip-optional`：跳过可选端点（recommendations/similar）

#### 4.2.2 处理流程

**Step 1：解析MovieLens数据**

目标：读取CSV文件，提取基础信息和评分统计

```bash
# 脚本自动执行以下处理：
# 1. 解析movies.csv，提取标题、年份、类型
# 2. 解析links.csv，获取TMDB/IMDB ID映射
# 3. 解析ratings.csv，计算每部电影的平均评分和评分数
```

输出：内存中的DataFrame + 评分统计字典

**Step 2：调用TMDB API获取详细数据**

目标：为每部电影补充详细信息（剧情、演员、制作信息等）

```bash
# 对于每部有tmdbId的电影（971部），调用：
# - GET /movie/{id}：电影详情（overview, runtime, budget等）
# - GET /movie/{id}/credits：演员和导演信息
# - GET /movie/{id}/keywords：关键词标签
# - （可选）GET /movie/{id}/recommendations：推荐电影
# - （可选）GET /movie/{id}/similar：相似电影
```

关键特性：
- 优先读取本地缓存（`files/tmdb_cache/movie_{tmdbId}.json`）
- 速率限制（3.5-4.0 请求/秒）
- 失败重试（最多3次，指数退避）
- 降级处理（TMDB失败时保留MovieLens数据）

**Step 3：数据合并与清洗**

目标：整合MovieLens和TMDB数据，生成标准化字段

处理逻辑：
1. **年份提取**：从标题中解析年份（如 "Toy Story (1995)" → year: 1995）
2. **类型归一化**：MovieLens类型映射为TMDB规范名（如 "Children" → "Family"）
3. **评分统一**：计算`rank_score_0_10`（统一为0-10分）
4. **生成description**：格式为 `"{name} ({year}) - {genres} - {overview}"`
5. **缺失值处理**：为空字段设置默认值（null/[]/0）

**Step 4：聚合实体提取**

目标：从电影数据中提取独立实体列表

生成文件：
- `persons.json`：从cast/crew聚合，按personId去重
- `keywords.json`：从keywords聚合，按keywordId去重
- `companies.json`：从production_companies聚合，按companyId去重
- `countries.json`：从production_countries聚合，按code去重
- `languages.json`：从spoken_languages聚合，按code去重

**执行命令**：

方式A（一键执行，推荐）：
```bash
# 先激活 Python 3.10 虚拟环境（.venv）
source .venv/bin/activate

bash data/movie/quickstart.sh
```

方式B（直接运行脚本）：
```bash
# 先激活 Python 3.10 虚拟环境（.venv）
source .venv/bin/activate

python data/movie/movie_data_preprocessing.py \
    --source-dir SparrowRecSys-master/target/classes/webroot/sampledata \
    --output-dir files/movie_data \
    --cache-dir files/tmdb_cache \
    --rate-limit 3.5 \
    --skip-optional
```

预计耗时：12-20分钟（取决于网络和是否有缓存）

#### 4.2.3 输出产物与契约

> 说明：Phase 2 建图以这些字段为准；缺失字段按 `null/[]` 处理即可。

**1）`movies_enriched.json`（List[Movie]）**：
- 通用字段（所有电影都有）：`movieId`、`name`、`year`、`imdbId`、`tmdbId`、`data_source`、`created_at`
- 类型闭环字段：`genres`、`tmdb_genres_raw`、`movielens_genres_raw`、`movielens_genres`、`movielens_genres_unmapped`
- 评分字段：`movielens_avg_rating`、`movielens_rating_count`、`tmdb_vote_average`、`tmdb_vote_count`、`rank_score_0_10`、`rank_score_source`、`rank_score_votes`
- 文本字段：`overview`（TMDB 原始简介，可为空）、`description`（脚本生成，用于向量化）
- 结构化字段（仅 `movielens+tmdb` 电影有）：`release_date`、`runtime`、`budget`、`revenue`、`tmdb_popularity`、`original_language`、`poster_path`、`backdrop_path`
- 建边原材料（用于导入关系）：
  - `cast`：`[{personId, name, character, order, cast_id, popularity, profile_path}]`（默认取前 20）
  - `crew`：`[{personId, name, job, department, popularity, profile_path}]`（当前仅保留 `job=Director`）
  - `keywords`：`[{id, name}]`
  - `production_companies`：`[{id, name, origin_country}]`
  - `production_countries`：`[{code, name}]`
  - `spoken_languages`：`[{code, name}]`
  - 可选：`recommendations`、`similar_movies`（未启用 `--skip-optional` 时生成；每项最多 20 条）

**2）`persons.json`（List[Person]）**：
- `personId`、`name`、`person_type`（`actor|director|both`）、`popularity`、`profile_path`、`movieIds`

**3）`keywords.json`（List[Keyword]）**：
- `keywordId`、`name`、`movieIds`

**4）`companies.json`（List[Company]）**：
- `companyId`、`name`、`origin_country`、`movieIds`

**5）`countries.json`（List[Country]）**：
- `code`、`name`、`movieIds`

**6）`languages.json`（List[Language]）**：
- `code`、`name`、`movieIds`

**质量要求**：
- 所有JSON文件必须使用UTF-8编码
- 电影数量：982部（与movies.csv一致）
- 人物数量：预计 10,000-15,000 个（按 personId 去重后；与 TMDB cast 截断策略、网络超时有关）
- 关键词数量：预计 3,000-6,000 个（按 keywordId 去重后）
- 类型闭环：`genres`字段统一使用TMDB规范名
- 评分统一：所有电影都有`rank_score_0_10`字段（0-10分）

#### 4.2.4 验证与检查点

**文件完整性验证**：

```bash
# 检查输出文件是否存在
ls -lh files/movie_data/

# 预期输出（启用TMDB时）：
# movies_enriched.json  (~2-3 MB)
# persons.json         (~500 KB)
# keywords.json        (~100 KB)
# companies.json       (~50 KB)
# countries.json       (~10 KB)
# languages.json       (~5 KB)
```

**数据质量检查**：

```python
# 简单的Python验证脚本
import json

# 1. 检查电影数量
with open('files/movie_data/movies_enriched.json', 'r', encoding='utf-8') as f:
    movies = json.load(f)
    print(f"✓ 电影总数: {len(movies)} (预期: 982)")

    # 2. 检查必需字段
    required_fields = ['movieId', 'name', 'year', 'genres', 'rank_score_0_10']
    for field in required_fields:
        missing = [m['movieId'] for m in movies if field not in m or m[field] is None]
        if missing:
            print(f"✗ 缺失字段 {field} 的电影: {len(missing)}")
        else:
            print(f"✓ 字段 {field} 完整")

    # 3. 检查类型归一化
    all_genres = set()
    for m in movies:
        all_genres.update(m.get('genres', []))
    print(f"✓ 规范类型数量: {len(all_genres)} (预期: ~17)")
    print(f"  类型列表: {sorted(all_genres)}")

    # 4. 检查数据源分布
    tmdb_count = sum(1 for m in movies if m.get('data_source') == 'movielens+tmdb')
    only_ml = sum(1 for m in movies if m.get('data_source') == 'movielens_only')
    print(f"✓ TMDB数据: {tmdb_count} (预期: ~971)")
    print(f"✓ 仅MovieLens: {only_ml} (预期: ~11)")

# 5. 检查聚合实体数量
with open('files/movie_data/persons.json', 'r', encoding='utf-8') as f:
    persons = json.load(f)
    print(f"✓ 人物总数: {len(persons)} (预期: 10000-15000)")

with open('files/movie_data/keywords.json', 'r', encoding='utf-8') as f:
    keywords = json.load(f)
    print(f"✓ 关键词总数: {len(keywords)} (预期: 3000-6000)")
```

**常见问题排查**：

| 问题 | 可能原因 | 解决方案 |
|-----|---------|---------|
| 未生成 persons/keywords 等聚合文件 | 未配置TMDB凭证（自动降级为仅 MovieLens） | 配置 `.env` 中的 `TMDB_API_TOKEN/TMDB_API_KEY` 后重跑 |
| 网络超时错误 | 未配置代理 | 添加HTTP_PROXY=http://localhost:10808 |
| API限流（HTTP 429） | 请求过快 | 降低--rate-limit参数（如3.0） |
| 电影数量不足982 | 数据源不完整 | 检查movies.csv是否完整 |
| genres字段仍有"Children" | 类型映射未执行 | 检查代码实现（见附录B） |

**预期输出示例**：

```bash
=== 电影数据预处理完成 ===

[Phase 1] MovieLens数据解析
  ✓ 解析982部电影
  ✓ TMDB ID覆盖率: 98.9% (971/982)
  ✓ 评分统计完成: 116万条评分

[Phase 2] TMDB数据获取
  ✓ 成功获取: 971部
  ✓ 降级处理: 11部（缺失tmdbId）
  ✓ 缓存命中率: 85%
  ✓ API调用总数: 1,942次
  ✓ 耗时: 14分32秒

[Phase 3] 数据合并与清洗
  ✓ 类型归一化: 17个规范类型
  ✓ 评分统一: 982部电影
  ✓ description生成: 982部

[Phase 4] 聚合实体提取
  ✓ 人物: 12,919个
  ✓ 关键词: 4,288个
  ✓ 公司: 1,114个
  ✓ 国家: 52个
  ✓ 语言: 59个

[输出] JSON文件生成
  ✓ movies_enriched.json (2.8 MB)
  ✓ persons.json (512 KB)
  ✓ keywords.json (98 KB)
  ✓ companies.json (45 KB)
  ✓ countries.json (8 KB)
  ✓ languages.json (4 KB)

✅ Phase 1 完成！可以继续 Phase 2（知识图谱构建）
```

### 4.3 Phase 2: 知识图谱构建

#### 4.3.1 输入与前置条件

**数据输入**：
- Phase 1 输出的 JSON 文件（位于 `files/movie_data/`）
  - `movies_enriched.json`（必需，包含 cast/crew/keywords/genres 等嵌套结构）
  - `persons.json`（可选，用于加速人物节点导入；缺失时 Phase 2 会从 cast/crew 补齐人物）
  - `keywords.json`（可选，用于加速关键词节点导入；缺失时 Phase 2 会从 movie.keywords 补齐关键词）

**环境要求**：
- Neo4j 数据库已启动（5.22.x）
- 连接参数已配置（`.env`中的NEO4J_URI/USERNAME/PASSWORD）
- Python 3.10 虚拟环境（`.venv`）已激活

**配置准备**：
以实现为准：不需要新增 `movie_settings.py`，统一通过环境变量驱动结构化模式与数据目录。

推荐配置（可写入 `.env` 或在命令行 export）：
```bash
GRAPH_BUILD_MODE=structured
STRUCTURED_DATA_DIR=files/movie_data
STRUCTURED_KB_PREFIX=movie

# 结构化导入是否清理旧电影图（仅电影标签/仅 movie: 前缀 Canonical）
STRUCTURED_RESET_DOMAIN=false
STRUCTURED_RESET_CANONICAL=false

# 建议电影使用独立索引名，避免覆盖默认 vector
ENTITY_VECTOR_INDEX_NAME=movie_vector
CHUNK_VECTOR_INDEX_NAME=movie_chunk_vector
GRAPH_ENTITY_ID_PREFIX_FILTER=movie:
GRAPH_CHUNK_ID_PREFIX_FILTER=movie:
GRAPH_COMMUNITY_ID_PREFIX=movie:
```

#### 4.3.2 处理流程

**Step 1：创建约束和索引**

目标：在导入数据前建立唯一性约束，避免重复节点

```cypher
// 创建唯一性约束
CREATE CONSTRAINT movie_movie_id IF NOT EXISTS
FOR (m:电影) REQUIRE m.movieId IS UNIQUE;

CREATE CONSTRAINT person_person_id IF NOT EXISTS
FOR (p:人物) REQUIRE p.personId IS UNIQUE;

CREATE CONSTRAINT keyword_keyword_id IF NOT EXISTS
FOR (k:关键词) REQUIRE k.keywordId IS UNIQUE;

CREATE CONSTRAINT company_company_id IF NOT EXISTS
FOR (c:公司) REQUIRE c.companyId IS UNIQUE;

CREATE CONSTRAINT country_code IF NOT EXISTS
FOR (c:国家) REQUIRE c.code IS UNIQUE;

CREATE CONSTRAINT language_code IF NOT EXISTS
FOR (l:语言) REQUIRE l.code IS UNIQUE;

CREATE CONSTRAINT genre_name IF NOT EXISTS
FOR (g:类型) REQUIRE g.name IS UNIQUE;

// 创建常用查询索引
CREATE INDEX movie_name_year IF NOT EXISTS
FOR (m:电影) ON (m.name, m.year);

CREATE INDEX person_name IF NOT EXISTS
FOR (p:人物) ON (p.name);
```

**Step 2：导入核心实体节点**

目标：创建电影、人物、类型等核心节点

处理顺序：
1. **电影节点**（982个）：使用MERGE避免重复
2. **人物节点**（~10000-15000个）：从persons.json导入
3. **类型节点**（~17个）：从电影的genres字段派生
4. **关键词节点**（~3000-6000个）：从keywords.json导入
5. **公司节点**（~1114个）：从companies.json导入（全量）
6. **国家节点**（~52个）：从countries.json导入（全量）
7. **语言节点**（~59个）：从languages.json导入（全量）

> 说明：当前仓库代码版本的 structured Phase 2 已实现导入：电影/人物/类型/关键词/公司/国家/语言，以及出演/导演/类型/关键词/公司/国家/语言关系。

关键注意事项：
- ⚠️ 不要使用 `SET m += movie`：Neo4j不支持嵌套结构（List[Map]）
- ✅ 只写入标量字段或标量数组
- ✅ 时间字段需显式转换：`date()`、`datetime()`

**Step 3：创建关系边**

目标：建立节点间的关联关系

关系创建顺序：
1. **电影-类型**：`(电影)-[:属于类型]->(类型)`（~2000-2500条）
2. **人物-电影**：
   - `(人物)-[:出演]->(电影)`（~16000-19000条，含character/order属性；受 TMDB credits 成功率影响）
   - `(人物)-[:导演]->(电影)`（~900-1100条）
3. **电影-关键词**：`(电影)-[:包含关键词]->(关键词)`（~8000-12000条）
4. **电影-公司**：`(电影)-[:制作公司]->(公司)`（~1800条）
5. **电影-国家**：`(电影)-[:制作国家]->(国家)`（~1200条）
6. **电影-语言**：`(电影)-[:使用语言]->(语言)`（~1100条）
7. **电影-电影**（可选）：
   - `(电影)-[:相似]->(电影)`（基于类型/演员/关键词计算）
   - `(电影)-[:推荐]->(电影)`（基于TMDB数据或算法）
8. **人物-人物**（可选）：`(人物)-[:共同出演]->(人物)`（合作2次以上）

**Step 4：数据一致性验证**

目标：检查导入结果，修复潜在问题

验证点：
- 节点数量统计
- 关系数量统计
- 孤立节点检查（无关系的节点）
- 重复关系检查

**执行命令**（脚本实现后）：

```bash
# 先激活 Python 3.10 虚拟环境（.venv）
source .venv/bin/activate

# 仅执行 Phase 2（结构化导入 + Canonical 生成）
GRAPH_BUILD_MODE=structured \
STRUCTURED_DATA_DIR=files/movie_data \
STRUCTURED_KB_PREFIX=movie \
BUILD_RUN_GRAPH=true \
BUILD_RUN_INDEX_AND_COMMUNITY=false \
BUILD_RUN_CHUNK_INDEX=false \
bash scripts/py.sh infrastructure.integrations.build.main
```

预计耗时：3-5分钟

> **核心Cypher示例**详见附录B中的代码实现指南。

#### 4.3.3 输出产物与契约

**Neo4j图谱结构**：

**节点统计（预期）**：
- `:电影` - 982个
- `:人物` - 10000-15000个
- `:类型` - ~17个
- `:关键词` - ~3000-6000个
- `:公司` - ~1114个
- `:国家` - ~52个
- `:语言` - ~59个
- **总计**: ~15000-25000个节点（领域层；Canonical 层会额外生成 `__Entity__/__Document__/__Chunk__`）

**关系统计（预期）**：
- `:出演` - ~16000-19000条
- `:导演` - ~900-1100条
- `:属于类型` - ~2000条
- `:包含关键词` - ~8000-12000条
- `:制作公司` - ~1800条
- `:制作国家` - ~1200条
- `:使用语言` - ~1100条
- `:相似` - ~4500条（可选，需计算）
- `:共同出演` - ~6800条（可选，需计算）
- **总计**: ~20000-35000条关系

**图谱质量要求**：
- 所有电影节点必须有`movieId`、`name`、`year`属性
- 所有人物节点必须有`personId`、`name`属性
- 类型节点的`name`必须是TMDB规范名称
- 关系属性完整（如`:出演`关系必须有`character`和`order`）
- 无孤立节点（每个节点至少有1条关系）

#### 4.3.4 验证与检查点

**节点数量验证**：

```cypher
// 统计所有节点类型
MATCH (n)
RETURN labels(n)[0] AS 节点类型, count(*) AS 数量
ORDER BY 数量 DESC;

// 预期结果：
// 人物: 10000-15000
// 电影: 982
// 关键词: ~4000
// 公司: ~1100
// 国家: ~52
// 语言: ~59
// 类型: ~17
```

**关系数量验证**：

```cypher
// 统计所有关系类型
MATCH ()-[r]->()
RETURN type(r) AS 关系类型, count(*) AS 数量
ORDER BY 数量 DESC;

// 预期结果：
// 出演: ~16000-19000
// 共同出演: ~6800 (可选)
// 包含关键词: ~8000-12000
// 相似: ~4500 (可选)
// 制作公司: ~1800
// 属于类型: ~2000
// 制作国家: ~1200
// 使用语言: ~1100
// 导演: ~1000
```

**孤立节点检查**：

```cypher
// 查找没有任何关系的节点
MATCH (n)
WHERE NOT (n)--()
RETURN labels(n)[0] AS 节点类型, count(*) AS 孤立节点数;

// 预期：应该为空或数量很少（<5）
```

**数据完整性检查**：

```cypher
// 1. 检查电影节点必需字段
MATCH (m:电影)
WHERE m.movieId IS NULL OR m.name IS NULL OR m.year IS NULL
RETURN count(*) AS 缺失必需字段的电影数;
// 预期：0

// 2. 检查类型归一化
MATCH (g:类型)
RETURN collect(g.name) AS 所有类型;
// 预期：应该都是TMDB规范名（如Family而非Children）

// 3. 检查出演关系属性
MATCH (:人物)-[r:出演]->(:电影)
WHERE r.character IS NULL
RETURN count(*) AS 缺失角色名的出演关系;
// 预期：应该很少或为0

// 4. 检查电影-类型关系
MATCH (m:电影)
WHERE NOT (m)-[:属于类型]->(:类型)
RETURN count(*) AS 无类型的电影;
// 预期：0（所有电影都应至少有1个类型）
```

**常见问题排查**：

| 问题 | 可能原因 | 解决方案 |
|-----|---------|---------|
| 节点数量远少于预期 | JSON文件不完整 | 检查Phase 1输出文件大小和记录数 |
| 出现重复电影节点 | 未使用MERGE或约束未生效 | 删除重复节点，重新创建约束后导入 |
| 关系数量为0 | MATCH失败（找不到节点） | 检查节点是否成功创建，检查ID是否匹配 |
| 类型仍为"Children"等 | Phase 1类型映射未执行 | 重新运行Phase 1，检查类型归一化逻辑 |
| 出演关系缺失character | cast_data未正确展平 | 检查数据准备脚本（见附录B） |

**预期输出示例**：

```bash
=== 电影知识图谱构建完成 ===

[Step 1] 约束和索引创建
  ✓ 唯一性约束: 7个
  ✓ 查询索引: 2个

[Step 2] 节点导入
  ✓ 电影: 982
  ✓ 人物: 12,919
  ✓ 类型: 17
  ✓ 关键词: 4,288
  ✓ 公司: 1,114
  ✓ 国家: 52
  ✓ 语言: 59

[Step 3] 关系创建
  ✓ 出演: 9,876
  ✓ 导演: 1,024
  ✓ 属于类型: 2,004
  ✓ 包含关键词: 4,532
  ✓ 制作公司: 1,876
  ✓ 制作国家: 1,245
  ✓ 使用语言: 1,098

[Step 4] 可选关系（需要额外计算）
  ✓ 相似: 4,566
  ✓ 共同出演: 6,789

[验证] 数据质量检查
  ✓ 孤立节点: 0
  ✓ 缺失必需字段: 0
  ✓ 类型归一化: 完成
  ✓ 关系属性完整性: 100%

=== 图谱统计摘要 ===
节点总数: （以 Neo4j 实际统计为准）
关系总数: （以 Neo4j 实际统计为准）
平均度数: （以 Neo4j 实际统计为准）
最大连接节点: （以 Neo4j 实际统计为准）

✅ Phase 2 完成！可以继续 Phase 3（向量索引与社区检测）
耗时: 3分45秒
```

### 4.4 Phase 3: 向量索引与社区检测

#### 4.4.1 统一框架的模式支持

Phase 3 的向量索引与社区检测通过**统一框架**执行，使用同一入口 `bash scripts/py.sh infrastructure.integrations.build.main`，并通过环境变量控制“模式”与“是否执行某个阶段”。

**文档模式（现有）**：
- 输入：Phase 2生成的`__Document__` / `__Chunk__` / `__Entity__`节点
- 处理：向量化`__Entity__`和`__Chunk__`，创建`vector`索引
- 社区：基于`__Entity__`关系检测，生成`__Community__`节点

**结构化模式（电影）**：
- 输入：Phase 2 已导入的领域节点 `:电影/:人物/:类型/:关键词` 与 Canonical 层 `__Document__/__Chunk__/__Entity__`
- 处理：仅对 Canonical 层 `__Entity__`（以及可选的 `__Chunk__`）写入 embedding，并创建/连接向量索引
- 社区：在 `__Entity__` 子图上运行社区检测（实现默认 Leiden），并写入 `__Community__` 与 `:IN_COMMUNITY`

**兼容现有检索工具**：
- 结构化模式通过生成Canonical层（`__Entity__/__Chunk__/__Community__`），可直接复用现有`LocalSearch/GlobalSearch/HybridTool`
- 索引名称隔离：电影使用 `ENTITY_VECTOR_INDEX_NAME=movie_vector`；若同库共存，文档模式也应使用独立索引名（如 `edu_vector`），避免覆盖默认 `vector`
- 若同库共存，需同时启用前缀过滤（`GRAPH_ENTITY_ID_PREFIX_FILTER`/`GRAPH_CHUNK_ID_PREFIX_FILTER`）与社区前缀（`GRAPH_COMMUNITY_ID_PREFIX`）做隔离（见 4.1.6）

#### 4.4.2 输入与前置条件

**数据输入**：
- Phase 2完成的Neo4j图谱（~6000节点，~27000关系）
- 电影节点必须包含`description`字段（用于向量化）
- 人物、关键词节点必须包含`name`字段

**环境要求**：
- Neo4j数据库已启动，图谱已完成Phase 2构建
- 配置embedding模型（`.env`中的OPENAI_EMBEDDINGS_MODEL）
- Neo4j GDS插件已安装（用于社区检测）
- 足够的内存用于向量计算（建议≥8GB）

**配置参数**：
```bash
# .env配置
OPENAI_EMBEDDINGS_MODEL=text-embedding-3-large  # 或其他embedding模型
GDS_MEMORY_LIMIT=6                               # GDS内存限制(GB)
GRAPH_COMMUNITY_ALGORITHM=leiden                 # 社区检测算法
```

**统一框架配置（以实现为准）**：
```bash
# 结构化模式（电影）
GRAPH_BUILD_MODE=structured
STRUCTURED_DATA_DIR=files/movie_data
STRUCTURED_KB_PREFIX=movie

# 共库隔离 + 独立索引名
GRAPH_ENTITY_ID_PREFIX_FILTER=movie:
GRAPH_CHUNK_ID_PREFIX_FILTER=movie:
GRAPH_COMMUNITY_ID_PREFIX=movie:
ENTITY_VECTOR_INDEX_NAME=movie_vector
CHUNK_VECTOR_INDEX_NAME=movie_chunk_vector
```

**处理流程**：

1. `KnowledgeGraphProcessor` 读取 `GRAPH_BUILD_MODE` 与 `BUILD_RUN_*` 开关
2. Phase 3 运行时按前缀过滤仅处理指定知识库（例如 `movie:`）
3. 结构化模式下 Canonical 层由 Phase 2 已生成，Phase 3 仅做索引/社区

**模块复用**：
- embedding/LLM：复用`backend/infrastructure/models/get_models.py`
- Neo4j连接：复用`backend/infrastructure/config/neo4jdb.py`
- GDS配置：复用`GDS_MEMORY_LIMIT`、`GDS_CONCURRENCY`等设置

**安全机制**：
- structured 模式默认不 drop 全库索引（见 `BUILD_DROP_ALL_INDEXES` 的默认策略）
- 共库隔离：通过 `movie:` 前缀过滤实体/Chunk/社区，避免污染其他知识库
- 结构化模式默认跳过“相似实体检测/合并/质量提升/社区摘要”，仅保留“向量索引 + 社区检测”（见附录B）

#### 4.4.3 处理流程

**统一框架自动处理**：

`IndexCommunityBuilder`会根据模式自动执行相应流程。对于结构化模式（电影），处理流程如下：

**Step 0：生成 Canonical 层（结构化 → `__Document__/__Chunk__/__Entity__`）**

目标：把结构化电影图映射到 GraphRAG 兼容结构（3.5），为现有检索工具提供 `MENTIONS/IN_COMMUNITY` 所需的基础节点与关系。

最小要求：
- 为每部电影创建一个 `__Document__` 与至少一个 `__Chunk__`（电影描述），并创建 `PART_OF`
- 为 Movie/Person/Keyword 创建对应的 `__Entity__`，并保证 `__Entity__.id` 全局唯一且幂等
- 创建确定性 `MENTIONS`（chunk → entity），确保 LocalSearch 能反查到证据 chunk

**Step 1：生成向量化文本**

目标：为每个节点准备用于embedding的文本

文本构建规则：
- **Movie `__Entity__`**（优先级从高到低，对应领域 `:电影` 字段）：
  1. `:电影.description`
  2. `:电影.overview`
  3. `:电影.name + ' ' + :电影.genres`
- **Person `__Entity__`**：`p.name`（可选拼接 `p.person_type`）
- **Keyword `__Entity__`**：`k.name`

处理要求：
- 文本不能为空（空字符串用默认文本替换）
- 文本长度限制（建议≤8000字符，避免超出模型限制）

**Step 2：计算并写入Embedding**

目标：批量计算向量并写回Neo4j节点

处理策略：
1. 查询待处理节点：`MATCH (e:__Entity__) WHERE e.embedding IS NULL`
2. 批量调用embedding API（每批64-256条）
3. 写回embedding向量及元数据：
   - `e.embedding`：向量数据（float数组）
   - `e.embedding_model`：模型名称
   - `e.embedding_dim`：向量维度
   - `e.embedding_updated_at`：更新时间

关键特性：
- 幂等性：重复运行只更新embedding，不影响其他属性
- 增量支持：只处理embedding为NULL的节点
- 错误处理：单个节点失败不影响批次继续

**Step 3：创建向量索引**

目标：为每个节点类型创建Neo4j向量索引

建立索引（以text-embedding-3-large为例，3072维；实际维度应以当前 embedding 模型为准）：

```cypher
// 1. Canonical 实体向量索引（用于复用现有 LocalSearch/HybridTool）
// 建议使用独立索引名（例如 movie_vector），并设置 ENTITY_VECTOR_INDEX_NAME=movie_vector
CREATE VECTOR INDEX movie_vector IF NOT EXISTS
FOR (e:__Entity__) ON (e.embedding)
OPTIONS {indexConfig: {
  `vector.dimensions`: 3072,
  `vector.similarity_function`: 'cosine'
}};
```

**Step 4：电影社区检测**

目标：基于`:相似`关系进行社区划分

使用Neo4j GDS（Graph Data Science）：

```cypher
// 1. 投影图谱（仅电影节点和相似关系）
CALL gds.graph.project(
  'movie_similarity_graph',
  '电影',
  {相似: {
    type: '相似',
    orientation: 'UNDIRECTED',
    properties: 'similarity_score'
  }}
);

// 2. 运行Leiden社区检测
CALL gds.leiden.write('movie_similarity_graph', {
  relationshipWeightProperty: 'similarity_score',
  writeProperty: 'community_id',
  concurrency: 4
});

// 3. 清理投影（释放内存）
CALL gds.graph.drop('movie_similarity_graph');
```

结果：计算得到电影的社区划分（可写回 `:电影.community_id` 便于调试），并在 Canonical 层中生成 `__Community__/IN_COMMUNITY` 以复用现有检索链路

**Step 5：生成社区摘要**

目标：为每个社区生成自然语言描述

处理流程：
1. 统计每个社区的电影数量
2. 选取代表电影（TopN）：
   - 排序：`rank_score_0_10 DESC, tmdb_popularity DESC`
   - 数量：每社区取10-20部代表电影
3. 拼装输入：`name, year, genres, overview`
4. 调用LLM生成摘要（200-500字）
5. 写回数据库：
   - 创建`:__Community__`节点，并把Movie `__Entity__`通过`IN_COMMUNITY`关联（复用现有LocalSearch/GlobalSearch）
   - `IndexCommunityBuilder`自动完成社区节点创建和关系建立

Canonical 社区节点示例（满足 GlobalSearch/LocalSearch）：
```cypher
MERGE (c:__Community__ {id: "movie:community:1"})
SET c.level = 0,
    c.summary = "本社区包含17部科幻冒险电影，以太空探索为主题...",
    c.full_content = "（更长的社区报告，供 GlobalSearch Map 阶段使用）",
    c.community_rank = 1,
    c.updated_at = datetime();
```

**执行命令**：

```bash
# 先激活 Python 3.10 虚拟环境（.venv）
source .venv/bin/activate

# 仅执行 Phase 3（统一框架改造后）
GRAPH_BUILD_MODE=structured \
BUILD_RUN_GRAPH=false \
BUILD_RUN_INDEX_AND_COMMUNITY=true \
BUILD_RUN_CHUNK_INDEX=false \
BUILD_DROP_ALL_INDEXES=false \
GRAPH_ENTITY_ID_PREFIX_FILTER=movie: \
GRAPH_COMMUNITY_ID_PREFIX=movie: \
ENTITY_VECTOR_INDEX_NAME=movie_vector \
bash scripts/py.sh infrastructure.integrations.build.main
```

预计耗时：5-10分钟（取决于节点数量和API速率）

**补跑社区摘要（不重算实体索引、不重跑社区检测）**：

```bash
GRAPH_ENTITY_ID_PREFIX_FILTER=movie: \
GRAPH_CHUNK_ID_PREFIX_FILTER=movie: \
GRAPH_COMMUNITY_ID_PREFIX=movie: \
COMMUNITY_SUMMARY_LIMIT=0 \
COMMUNITY_SUMMARY_ONLY_MISSING=true \
COMMUNITY_SUMMARY_MAX_WORKERS=4 \
GRAPH_SKIP_SIMILAR_ENTITY=true \
GRAPH_SKIP_ENTITY_MERGE=true \
GRAPH_SKIP_ENTITY_QUALITY=true \
GRAPH_SKIP_COMMUNITY_SUMMARY=false \
BUILD_RUN_ENTITY_INDEX=false \
BUILD_RUN_COMMUNITY_DETECTION=false \
bash scripts/py.sh infrastructure.integrations.build.build_index_and_community
```

#### 4.4.4 输出产物与契约

**增强的Neo4j图谱**：

结构化电影图（领域层）保持不变：`:电影/:人物/:关键词/...` 与其关系用于结构化查询与推荐推理。

为复用现有检索链路（Local/GlobalSearch），结构化模式会额外生成 Canonical 层（见 3.5）：
- `:__Document__` / `:__Chunk__`：电影的“证据块”（由 `:电影.description` 等字段渲染而来）
- `:__Entity__`：Movie/Person/Keyword 的统一实体节点（用于向量检索）
- `:__Community__`：社区摘要节点（供 GlobalSearch Map-Reduce 使用）

Canonical 层新增/更新字段（关键契约）：
- `:__Entity__`：
  - `id`（全局唯一、幂等；建议 `movie:Movie:{movieId}` 等）
  - `name` / `entity_type` / `description`
  - `embedding` / `embedding_model` / `embedding_dim` / `embedding_updated_at`
- `:__Chunk__`：
  - `id` / `text` / `fileName` / `position`（以及可选 `tokens/length`）
- `:__Community__`：
  - `id` / `level` / `summary` / `full_content` / `community_rank` / `updated_at`
  - 以及 `(:__Entity__)-[:IN_COMMUNITY]->(:__Community__)`

> 说明（以当前实现为准）：社区检测运行在 Canonical `__Entity__` 子图上（通过向量相似度构建候选边，并在 `__Entity__` 上写回 communities），
> 然后落地 `__Community__` 与 `IN_COMMUNITY`；与领域层是否存在 `:相似` 边无关。

**向量索引**：

推荐仅维护一套 Canonical 向量索引（用于复用现有检索工具）：
- `movie_vector`：`(:__Entity__).embedding`

**质量要求**：
- 参与检索的 `__Entity__` 其 `embedding` 不为 NULL（允许个别实体因缺字段降级）
- 向量维度与配置的模型一致
- `__Community__` 能被 `GlobalSearch` 读取（至少具备 `id/level/full_content`）
- `MENTIONS/IN_COMMUNITY` 关系完整（LocalSearch 能回溯到 chunk 作为证据）

#### 4.4.5 验证与检查点

**Embedding完整性检查**：

```cypher
// 1. 检查缺失embedding的节点
MATCH (e:__Entity__)
WITH e.entity_type AS 实体类型, e.embedding IS NULL AS 缺失向量, count(*) AS 数量
RETURN 实体类型, 缺失向量, 数量;

// 预期：所有节点的缺失向量=false

// 2. 检查向量维度
MATCH (e:__Entity__)
WHERE e.embedding IS NOT NULL
RETURN DISTINCT size(e.embedding) AS 向量维度, count(*) AS 实体数;

// 预期：向量维度=3072（或你使用的模型维度），实体数>0
```

**向量索引验证**：

```cypher
// 列出所有向量索引
SHOW INDEXES YIELD name, labelsOrTypes, properties, type
WHERE type = 'VECTOR'
RETURN name, labelsOrTypes, properties;

// 预期（至少包含）：
// movie_vector, [__Entity__], [embedding]
```

**社区检测验证**：

```cypher
// 1. 统计社区分布
MATCH (c:__Community__)
RETURN c.id AS 社区ID, count { MATCH (:__Entity__)-[:IN_COMMUNITY]->(c) } AS 实体数
ORDER BY 实体数 DESC;

// 预期：若启用社区，存在多个社区，且每个社区包含一定数量实体

// 2. 检查孤立电影
MATCH (e:__Entity__ {entity_type: 'Movie'})
WHERE NOT (e)-[:IN_COMMUNITY]->(:__Community__)
RETURN count(*) AS 未分配社区的电影实体数;

// 预期：0或很少（<5）

// 3. 社区摘要完整性
MATCH (c:__Community__)
WHERE c.summary IS NULL OR c.full_content IS NULL
RETURN count(*) AS 缺失摘要的社区数;

// 预期：0
```

**向量检索测试**：

	```python
	# Python测试脚本
	from infrastructure.providers.neo4jdb import get_db_manager
	from infrastructure.providers.models import get_embeddings_model

db = get_db_manager()
embeddings = get_embeddings_model()

# 1. 计算查询向量
query_text = "太空探险的科幻电影"
query_vector = embeddings.embed_query(query_text)

# 2. 向量检索
query = """
CALL db.index.vector.queryNodes('movie_vector', 10, $query_vector)
YIELD node, score
RETURN node.name AS 实体, node.entity_type AS 类型, score
ORDER BY score DESC;
"""

results = db.execute_query(query, {'query_vector': query_vector})
for record in results:
    print(f"✓ {record['实体']} [{record['类型']}] - 相似度: {record['score']:.4f}")

# 预期：返回 Movie 类型的高相关实体（如 Star Wars 等）
```

**常见问题排查**：

| 问题 | 可能原因 | 解决方案 |
|-----|---------|---------|
| embedding为NULL | API调用失败或限流 | 检查API凭证，降低批处理大小 |
| 向量维度不一致 | 模型配置错误 | 检查OPENAI_EMBEDDINGS_MODEL配置 |
| 向量索引创建失败 | GDS插件未安装或版本不兼容 | 安装Neo4j GDS插件，检查版本 |
| 社区全部为单个电影 | :相似关系未创建 | 检查Phase 2，确保相似关系存在 |
| 社区摘要重复 | 多次运行未清理旧数据 | 运行前清理旧社区节点 |

**预期输出示例**：

```bash
=== Phase 3: 向量索引与社区检测完成 ===

[Step 1] 文本准备
  ✓ Canonical实体(__Entity__): 5,548个（Movie/Person/Keyword）
  ✓ Canonical证据块(__Chunk__): 982+（每电影至少1个）

[Step 2] Embedding计算
  ✓ 处理节点: 5,548个
  ✓ API调用: 87批次
  ✓ 向量维度: 3072
  ✓ 失败节点: 0
  ✓ 耗时: 4分15秒

[Step 3] 向量索引创建
  ✓ movie_vector (__Entity__节点)

[Step 4] 社区检测
  ✓ 投影图谱: 982节点，4,566边
  ✓ Leiden算法: 完成
  ✓ 检测到社区: 15个
  ✓ 平均社区大小: 65部电影
  ✓ 最大社区: 社区0（152部科幻动作电影）

[Step 5] 社区摘要生成
  ✓ 处理社区: 15个
  ✓ LLM调用: 15次
  ✓ 平均摘要长度: 324字
  ✓ 耗时: 1分45秒

[验证] 质量检查
  ✓ Embedding完整性: 100% (__Entity__)
  ✓ 向量索引状态: 全部在线
  ✓ 社区分配率: 100% (Movie实体)
  ✓ 社区摘要完整性: 100% (__Community__)

[测试] 向量检索
  查询: "太空探险的科幻电影"
  ✓ Star Wars [Movie] - 相似度: 0.8542
  ✓ The Empire Strikes Back (1980) - 相似度: 0.8321
  ✓ 2001: A Space Odyssey (1968) - 相似度: 0.8156
  ...

✅ Phase 3 完成！电影知识图谱已完整构建
总耗时: 7分32秒
```

### 4.5 降级与容错策略

#### 4.5.1 部分数据缺失处理

**TMDB凭证要求**：
- 推荐配置`TMDB_API_TOKEN`或`TMDB_API_KEY`以获取完整字段与人物/关键词等聚合文件
- 未配置凭证时允许降级：仅使用 MovieLens，输出 `movies_enriched.json`（不会生成 persons/keywords/companies 等聚合文件）

**TMDB ID缺失**（11部电影）：
- 记录警告日志但继续处理
- 使用MovieLens数据填充必需字段
- 电影节点的`data_source`标记为`movielens_only`
- 不影响后续Phase

**TMDB API单个电影失败**：
- 记录错误日志但不中断流程
- 重试机制：最多3次，指数退避
- 重试仍失败后，使用MovieLens数据作为降级方案
- 标记`data_source=movielens_only`

**字段缺失处理**：
| 字段 | 缺失时的默认值 | 影响 |
|-----|-------------|-----|
| `overview` | 空字符串 | description会变短，向量化效果略差 |
| `runtime` | 0 | 不影响核心功能 |
| `budget/revenue` | 0 | 不影响核心功能 |
| `genres` | `['Unknown']` | 影响类型检索和社区检测 |
| `cast` | `[]` | 无法支持演员相关查询 |

#### 4.5.2 网络失败重试

**TMDB API调用**：
- 重试次数：3次
- 重试间隔：1s, 2s, 4s（指数退避）
- 超时时间：10秒
- HTTP 429（限流）：等待60秒后重试

**Embedding API调用**：
- 重试次数：3次
- 重试间隔：2s, 5s, 10s
- 批处理降级：失败时减小批次大小（256→128→64）
- 单个失败不影响批次继续

**代理配置**：
```bash
# .env中配置代理（如需）
HTTP_PROXY=http://localhost:10808
HTTPS_PROXY=http://localhost:10808
NO_PROXY=localhost,127.0.0.1
```

#### 4.5.3 流程中断恢复

**Phase 1中断**：
- 缓存机制：已获取的TMDB数据缓存在`files/tmdb_cache/`
- 重启后自动跳过已缓存的电影
- 输出文件原子写入（写入临时文件→重命名）

**Phase 2中断**：
- 使用MERGE语句，重复运行不会创建重复节点
- 关系创建幂等，可安全重试
- 建议：使用事务批量导入，失败后回滚

**Phase 3中断**：
- Embedding计算增量：`MATCH (e:__Entity__) WHERE e.embedding IS NULL`
- 向量索引创建幂等（`IF NOT EXISTS`）
- 社区检测可重复执行（覆盖 `__Community__/IN_COMMUNITY` 写回结果）

**恢复检查清单**：
1. 检查Phase 1输出文件是否完整
2. 检查Neo4j节点和关系数量
3. 检查向量索引状态
4. 验证社区检测结果

**手动清理命令**（慎用）：
```cypher
// 清理embedding（重新计算）
MATCH (e:__Entity__)
REMOVE e.embedding, e.embedding_model, e.embedding_dim, e.embedding_updated_at;

// 清理社区（重新检测）
MATCH (c:__Community__)
DETACH DELETE c;
MATCH ()-[r:IN_COMMUNITY]->()
DELETE r;

// 删除向量索引（重新创建）
DROP INDEX movie_vector IF EXISTS;
```

---

## 5. 查询与搜索场景设计

### 5.1 查询类型矩阵

> 本章以当前仓库实现为准：检索链路默认走 Canonical 层（`__Entity__/__Chunk__/__Document__/__Community__`），
> 领域层（`:电影/:人物/:类型/...`）主要用于“严格过滤/统计分析”等结构化查询。
>
> **运行前置条件（否则检索会降级/不可用）**：
> - Phase 2 已生成 Canonical 层（结构化模式会生成 `movie:` 前缀的 `__Entity__/__Chunk__/__Document__`）。
> - Phase 3 已为 `__Entity__`/`__Chunk__` 补齐 embedding，并创建向量索引：
>   - 建议：`ENTITY_VECTOR_INDEX_NAME=movie_vector`（实体向量检索，Local/Hybrid 会用到；若配置索引不存在，代码会按 KB 前缀自动尝试 `<kb>_vector`）
>   - 建议：`CHUNK_VECTOR_INDEX_NAME=movie_chunk_vector`（Chunk 向量索引；`NaiveSearchTool` 会优先尝试配置索引，并在缺失时按 KB 前缀自动尝试 `<kb>_chunk_vector`）
>   - 同库多 KB 时，向量索引会创建在“作用域 KB label”上（例如 `KB_movie_entity` / `KB_movie_chunk`），以避免 Neo4j 对 `(label, embedding)` 的索引冲突（见 4.1.6）
> - 若启用 Global Search，需要社区摘要字段可读（`__Community__.full_content/summary`），详见 5.2.6。
>
> **同库多知识库共存注意**：
> - 搜索侧已统一对 `__Entity__/__Chunk__/__Community__` 加前缀过滤（`GRAPH_ENTITY_ID_PREFIX_FILTER` / `GRAPH_CHUNK_ID_PREFIX_FILTER` / `GRAPH_COMMUNITY_ID_PREFIX`），共库运行时必须正确设置，否则会串 KB。
> - 写入侧必须同时做到“前缀化写入”（结构化：`STRUCTURED_KB_PREFIX`；文档：`DOCUMENT_KB_PREFIX`），并建议对向量索引使用不同 index name（`ENTITY_VECTOR_INDEX_NAME/CHUNK_VECTOR_INDEX_NAME`）做隔离。
> - `HybridSearchTool` 对“中文问题中包含英文实体名（如电影英文名）”会优先抽取英文短语作为 seed，避免仅用英文 token（如 `Toy/Story`）导致召回过泛。
> - 重要：当前实现里这些过滤/索引名来自环境变量（启动时读取），**单个服务进程一次只能稳定服务一个 KB 前缀**。如需“同一个 FastAPI 实例里按请求参数切换 KB”，需要在 API/Tool 层引入 `kb_prefix` 参数并按前缀重建检索器（当前未实现）。

| 场景 | 示例问题 | 当前建议 Agent/Tool | 依赖的数据层 | 备注（现状/限制） |
|---|---|---|---|---|
| **精确实体问答** | “Toy Story 的导演是谁？” | `GraphAgent` / `LocalSearchTool` | Canonical | 通过 `movie_vector` 命中实体，再用 `MENTIONS/RELATED` 回溯证据；不直接跑 `:电影/:人物` 的领域 Cypher |
| **演员作品/导演作品** | “Tom Hanks 演过哪些？” | `HybridAgent` / `HybridSearchTool` | Canonical | 通过向量检索实体 + 邻域关系组合；需要“列表型输出”时建议加一个电影专用聚合工具（见 5.3） |
| **公司/国家/语言查询** | “Pixar 制作了哪些电影？” | `GraphAgent` / `LocalSearchTool` | Canonical | Phase 2 已补齐 `Company/Country/Language` 的 Canonical 实体与 `RELATED/MENTIONS` 证据 |
| **类型筛选（语义）** | “推荐几部科幻电影” | `HybridAgent` / `LocalSearchTool` | Canonical | 可用 `movie:Genre:*` 与 `RELATED(属于类型)` 解释；若要“严格筛选 + 排序”，需要接入领域属性（见 5.2.4/5.3） |
| **相似推荐（当前）** | “和 Star Wars 相似的电影？” | `HybridAgent`（向量相似度） | Canonical | 当前实现没有领域 `:相似` 边；相似推荐以 `Movie` 向量相似度为主，再用共享 `Genre/Keyword/Person` 做解释 |
| **路径推理/多跳探索** | “A 和 B 合作过哪些电影？” | `DeepResearchTool` / `chain_of_exploration` | Canonical | 多跳探索基于 `__Entity__` 图；属于“推理型”能力，不保证每次都走固定 Cypher |
| **统计分析/严格过滤** | “科幻片平均票房？” “1995 年高分电影？” | （建议新增电影专用查询工具） | 领域层 + Canonical 关联 | 当前 Canonical `Movie` 不包含 `revenue/budget/year/rating` 的可过滤字段；需要用 `movieId` 关联到领域 `:电影` 做聚合 |

**类型名归一化约定**：
- 图谱内 `:类型.name` 统一使用 TMDB 规范名称（如 `Science Fiction`、`Family`、`Music`）
- 用户输入若使用 MovieLens 名称（如 `Sci-Fi`、`Children`、`Musical`），在查询前先通过映射表归一化为 TMDB 规范名称，再执行类型过滤/聚合

### 5.2 典型查询示例与 Cypher 实现

> 说明：下面给出的 Cypher 是“可用于校验/调试”的底层查询示例。
> 日常对话检索主要由工具链完成（`LocalSearchTool/HybridSearchTool/GlobalSearchTool`），并不要求业务侧手写 Cypher。

#### 5.2.1 精确实体查询（Canonical：导演是谁）
**用户问题**：`Toy Story` 的导演是谁？

**底层 Canonical 关系口径**：
- 电影实体：`(:__Entity__ {type='Movie'})`
- 人物实体：`(:__Entity__ {type='Person'})`
- 人物→电影：`(:__Entity__)-[:RELATED {description: '导演'|'出演'}]->(:__Entity__)`
- 证据：`(:__Chunk__)-[:MENTIONS]->(:__Entity__)`

**Cypher（按名称定位电影 + 取导演）**：
```cypher
MATCH (m:__Entity__)
WHERE m.type = "Movie" AND m.name = "Toy Story"
MATCH (p:__Entity__)-[r:RELATED]->(m)
WHERE p.type = "Person" AND r.description = "导演"
RETURN p.name AS director, m.name AS movie
```

#### 5.2.2 作品列表查询（Canonical：某演员演过哪些）
**用户问题**：Tom Hanks 演过哪些电影？

**Cypher（按 RELATED=出演 聚合）**：
```cypher
MATCH (p:__Entity__)
WHERE p.type = "Person" AND p.name = "Tom Hanks"
MATCH (p)-[r:RELATED]->(m:__Entity__)
WHERE m.type = "Movie" AND r.description = "出演"
RETURN m.name AS movie, r.description AS relation
LIMIT 50
```

> 备注：当前 Canonical `RELATED` 主要用于“可解释的关联”；若要输出“角色名/出演顺序”等细粒度字段，
> 需要从领域层关系属性中取（见 5.2.4 的桥接方式）。

#### 5.2.3 公司/国家/语言查询（Canonical：可解释检索）
**用户问题**：Pixar 制作了哪些电影？

**Cypher（电影-公司：制作公司）**：
```cypher
MATCH (c:__Entity__)
WHERE c.type = "Company" AND c.name CONTAINS "Pixar"
MATCH (m:__Entity__)-[r:RELATED]->(c)
WHERE m.type = "Movie" AND r.description = "制作公司"
RETURN m.name AS movie, c.name AS company
LIMIT 50
```

#### 5.2.4 严格过滤/排序（领域层 + Canonical 桥接）
**用户问题**：1995 年有哪些高分电影？

现状约束：
- Canonical `Movie` 主要用于检索与解释，不保证包含 `year/rating/revenue` 等可严格过滤字段。
- 需要用 `movieId` 桥接到领域层 `:电影` 节点做过滤排序。

**Cypher（从 Canonical 电影实体取 movieId，再关联领域电影）**：
```cypher
MATCH (me:__Entity__)
WHERE me.type = "Movie" AND me.id STARTS WITH "movie:Movie:"
WITH toInteger(split(me.id, ":")[2]) AS movieId, me
MATCH (m:`电影` {movieId: movieId})
WHERE m.year = 1995 AND coalesce(m.rank_score_0_10, 0) > 0
RETURN m.name AS movie, m.year AS year, m.rank_score_0_10 AS score
ORDER BY score DESC
LIMIT 20
```

> 备注：如果希望“年份/评分/票房”成为一等公民的检索条件，建议新增 `MovieFacetTool`（服务端封装 Cypher），
> 并在 Agent 路由中对“严格过滤类问题”优先使用该工具。

#### 5.2.5 相似推荐（当前实现：向量相似度 + 解释）
**用户问题**：哪些电影和 Star Wars 相似？

现状约束：
- 当前实现没有领域层 `:相似` 边（`similarity_score/similarity_type` 等字段也未生成）。
- 推荐以 `movie_vector` 上的 `Movie` 实体向量相似度为主，再用共享的 `Genre/Keyword/Person/Company` 关系做解释。

> 可解释路径的基本形态：`Movie ->(RELATED)-> Genre/Keyword/Person/Company <- (RELATED)- Movie`

#### 5.2.6 Global Search（社区检索的前置条件）
Global Search（`GlobalSearchTool`）依赖 `__Community__.full_content`（以及可选的 `summary`）字段。
如果只跑了社区检测但未生成摘要，这两列会为空，Global Search 的上下文就不完整。

建议在 Phase 3 运行时开启（并配置好前缀过滤避免共库污染）：
- `BUILD_RUN_INDEX_AND_COMMUNITY=true`
- `GRAPH_SKIP_COMMUNITY=false`
- `GRAPH_SKIP_COMMUNITY_SUMMARY=false`

### 5.3 自定义电影推荐工具

**计划新增文件（待实现）**：`backend/graphrag_agent/search/tool/movie_recommendation_tool.py`

**功能**：
- 基于内容的推荐（类型、演员、关键词相似度）
- 基于图谱路径的推荐（共同出演、导演风格）
- 混合推荐（结合向量相似度和图谱关系）

**工具接口**：
```python
class MovieRecommendationTool(BaseTool):
    name = "movie_recommendation"
    description = """
    推荐与目标电影相似的电影。
    输入: 电影名称
    输出: 推荐电影列表及推荐理由
    """

    def _run(self, movie_name: str, top_k: int = 10) -> str:
        # 1. 匹配电影实体
        movie = self._find_movie(movie_name)

        # 2. 基于图谱相似关系
        similar_by_graph = self._get_similar_from_graph(movie, top_k=5)

        # 3. 基于向量相似度
        similar_by_vector = self._get_similar_by_vector(movie, top_k=5)

        # 4. 合并并重排序
        recommendations = self._merge_and_rank([similar_by_graph, similar_by_vector])

        # 5. 生成推荐理由
        return self._format_recommendations(recommendations)
```

**集成到 Agent**：
```python
# backend/graphrag_agent/agents/hybrid_agent.py
from graphrag_agent.search.tool.movie_recommendation_tool import MovieRecommendationTool

class HybridAgent(BaseAgent):
    def _setup_tools(self) -> List:
        tools = super()._setup_tools()
        tools.append(MovieRecommendationTool(
            neo4j_manager=self.neo4j_manager,
            embeddings=self.embeddings
        ))
        return tools
```

---

## 7. 实施计划（基于实际数据规模）

### 7.1 Phase 1: 数据准备与预处理（3 天）

**前置要求：网络与代理配置**

由于 TMDB API（api.themoviedb.org）可能在某些网络环境下无法直接访问（Connection Timeout），需要配置代理。

**测试网络连接**：
```bash
# 测试直连（如果失败则需要配置代理）
curl --connect-timeout 10 https://api.themoviedb.org/3/authentication

# 如果返回 Exit code 28 (Timeout)，则配置代理
```

**配置代理（如需要）**：
```bash
# 方式 1：在 .env 文件中添加
echo "HTTP_PROXY=http://localhost:10808" >> .env
echo "HTTPS_PROXY=http://localhost:10808" >> .env

# 方式 2：设置环境变量
export HTTP_PROXY=http://localhost:10808
export HTTPS_PROXY=http://localhost:10808

# 测试代理连接
curl --proxy http://localhost:10808 \
     --url 'https://api.themoviedb.org/3/movie/862?language=en-US' \
     --header 'Authorization: Bearer YOUR_TOKEN' \
     --connect-timeout 10
```

**验证配置**：
```bash
# 运行一键脚本（未配置 TMDB 凭证时会自动降级为仅 MovieLens）
# 先激活 Python 3.10 虚拟环境（.venv）
source .venv/bin/activate
bash data/movie/quickstart.sh
```

---

**Day 1**：
- [ ] **配置网络代理**（如需要）
- [ ] 注册 TMDB API Key
- [ ] 验证 TMDB API 连接（运行测试脚本）
- [ ] 开发 `MovieLensParser` 模块
- [ ] 开发 `TMDBClient` 模块（含请求限速和代理支持）
- [ ] 测试 API 调用（抽样 10 部电影）

**Day 2**：
- [ ] 开发 `MovieDataEnricher` 模块
- [ ] 运行完整数据获取（971 部电影，预计 16-20 分钟）
- [ ] 记录缺失 tmdbId 的电影（保持 `movielens_only`；如需补齐可后续扩展 `/search/movie` 匹配）

**Day 3**：
- [ ] 数据清洗与验证
- [ ] 生成 JSON 输出文件
- [ ] 数据统计分析（演员数、关键词数等）
- [ ] 撰写数据质量报告

**交付物**：
- `data/movie/movie_data_preprocessing.py`
- `files/movie_data/movies_enriched.json` (~982 条)
- `files/movie_data/persons.json` (~10000-15000 条)
- `files/movie_data/keywords.json` (~4000 条)
- `files/movie_data/companies.json` (~1114 条)
- `files/movie_data/countries.json` (~52 条)
- `files/movie_data/languages.json` (~59 条)
- `files/tmdb_cache/` (TMDB API 响应缓存)
- 数据质量报告（Markdown）

### 7.2 Phase 2: 知识图谱构建（3 天）

**Day 4**：
- [ ] 新增结构化导入构建器 `backend/infrastructure/integrations/build/structured_movie_graph.py`
- [ ] 在统一入口 `backend/infrastructure/integrations/build/main.py` 支持 `GRAPH_BUILD_MODE=structured`
- [ ] 测试结构化导入（抽样 10/50 部，建议先跑通 Phase 1→2）

**Day 5**：
- [ ] 运行完整图谱构建（982 部电影）
- [ ] 创建所有关系边
- [ ] 验证人物唯一性（按 `personId` 统一 `:人物` 节点）

**Day 6**：
- [ ] （可选）计算电影相似度（基于类型、演员、关键词）
- [ ] （可选）创建领域相似关系边（或仅在 Canonical `RELATED` 层表达）
- [ ] 验证图谱结构和数据完整性
- [ ] 生成图谱统计报告

**交付物**：
- `backend/infrastructure/integrations/build/structured_movie_graph.py`
- `backend/infrastructure/integrations/build/main.py`（支持 `GRAPH_BUILD_MODE=structured` 与 Phase 开关）
- Neo4j 图谱数据库（~6000 节点，~27000 关系）
- 图谱统计报告（节点/关系数量、类型分布）

### 7.3 Phase 3: 向量索引与社区检测（2 天）

**Day 7**：
- [ ] 实体向量化：对 Canonical `__Entity__` 计算 embedding，并创建 `ENTITY_VECTOR_INDEX_NAME`（建议 `movie_vector`）
- [ ] 共库隔离：支持 `GRAPH_ENTITY_ID_PREFIX_FILTER/GRAPH_COMMUNITY_ID_PREFIX`，避免污染其他知识库
- [ ] 测试向量化流程（抽样 10/50 部电影）

**Day 8**：
- [ ] 运行完整实体索引构建（使用 `ENTITY_VECTOR_INDEX_NAME=movie_vector`）
- [ ] 执行社区检测（在 `__Entity__` 子图上运行 Leiden/SLLPA）
- [ ] （可选）生成社区摘要（LLM；建议可控开关）
- [ ] 验证向量检索效果（抽样查询）

**交付物**：
- `backend/infrastructure/integrations/build/build_index_and_community.py`（支持 skip 开关与前缀隔离）
- Neo4j向量索引（`movie_vector`）
- 社区检测结果（`__Community__`节点）
- 社区摘要数据

### 7.4 Phase 4: 搜索与推荐功能（3 天）

**Day 9**：
- [ ] 开发 `MovieRecommendationTool`
- [ ] 集成到 `HybridAgent`
- [ ] 测试基本查询场景（10 个示例问题）

**Day 10**：
- [ ] 优化相似度算法
- [ ] 实现混合推荐策略
- [ ] 测试复杂推理查询（跨类型、路径查询）

**Day 11**：
- [ ] 性能优化（缓存、索引）
- [ ] 编写查询测试用例
- [ ] 生成查询效果报告

**交付物**：
- `backend/graphrag_agent/search/tool/movie_recommendation_tool.py`（待实现）
- 查询测试报告（准确率、响应时间）

### 7.5 Phase 5: 前端界面开发（3 天）

**Day 12**：
- [ ] 初始化 `frontend-react/`（React + Ant Design）
- [ ] 集成电影搜索面板
- [ ] 开发电影详情卡片组件（评分、类型、演职人员）

**Day 13**：
- [ ] 集成知识图谱可视化（@antv/g6）
- [ ] 开发推荐结果展示组件
- [ ] 测试前后端联调

**Day 14**：
- [ ] UI 优化与美化
- [ ] 添加示例问题引导
- [ ] 用户体验测试

**交付物**：
- `frontend-react/` 前端工程（页面/组件/服务层）
- 后端新增 API 端点（待实现：`backend/server/api/rest/v1/movie.py`）
- 前端界面截图与演示视频

### 7.6 Phase 6: 测试与文档（2 天）

**Day 15**：
- [ ] 端到端测试（20+ 查询场景）
- [ ] 性能测试（并发查询、响应时间）
- [ ] 修复发现的 Bug

**Day 16**：
- [ ] 完善项目文档
- [ ] 编写用户使用手册
- [ ] 准备演示 Demo

**交付物**：
- 测试报告
- 用户手册
- 项目总结文档

### 7.7 总时间估算

**总工作日**：16 天（约 3 周）

**关键里程碑**：
- Week 1 结束：数据预处理完成 + 图谱构建完成
- Week 2 结束：向量索引完成 + 搜索功能完成
- Week 3 结束：前端界面完成 + 全面测试

---

## 8. 风险与应对（修订）

### 8.1 TMDB API 限流风险

**风险**：
- 实际请求频率可能触发限流（HTTP 429 错误）
- 导致数据获取中断

**应对**：
- ✅ 实施每秒 4 次请求限速（预计 16-20 分钟完成）
- ✅ 实现指数退避重试机制（失败后等待时间翻倍）
- ✅ 本地缓存所有 API 响应，避免重复请求
- ✅ 分批处理（100 部电影为一批，失败后可从断点续传）

### 8.2 TMDB 数据缺失风险

**风险**：
- 部分老电影（1926-1950 年代）TMDB 数据不全
- budget, revenue 字段缺失率可能较高

**应对**：
- ✅ 允许部分字段为空（schema 设计为 Optional）
- ✅ 对于缺失 overview 的电影，使用类型+年份作为 description
- ✅ 统计缺失率，生成数据质量报告
- ⚠️ 对于 11 部缺失 TMDB ID 的电影，通过 IMDB ID 或标题搜索

### 8.3 图谱规模与性能风险

**风险**：
- 6000+ 节点，27000+ 关系，向量检索可能较慢
- 社区检测算法在大图上耗时较长

**应对**：
- ✅ 创建关键字段索引（movieId, personId, name）
- ✅ 向量索引限制维度（使用 OpenAI Embeddings，维度 1536 或 3072）
- ✅ 社区检测参数优化（concurrency=4, memory_limit=6GB）
- ✅ 缓存常见查询结果（LRU Cache）

### 8.4 LLM 生成质量风险

**风险**：
- 电影领域 Prompt 可能不如学生管理领域成熟
- 推荐理由生成可能不够准确

**应对**：
- ✅ 重新设计电影领域 Prompt（参考电影评论语料）
- ✅ 使用 Few-shot Learning 提供示例
- ✅ 在 Prompt 中强调"基于证据链"（引用图谱路径）
- ⚠️ 如果效果不佳，考虑切换模型（GPT-4 → Claude 3.5）

### 8.5 数据版权与合规风险

**风险**：
- TMDB 数据使用需遵守其 API 条款
- 不可用于商业目的

**应对**：
- ✅ 明确项目为学术/教育用途
- ✅ 在界面添加 TMDB 数据来源声明
- ✅ 不公开分发原始 TMDB 数据文件

---

## 9. 未来扩展方向

### 9.1 多模态支持
- **图像检索**：集成 TMDB 海报图片，支持视觉相似度搜索
- **视频分析**：分析电影预告片、片段（超出当前范围）

### 9.2 实时数据更新
- **定期拉取 TMDB 最新数据**：设置 Cron Job，每周更新新上映电影
- **增量构建**：使用现有增量更新框架

### 9.3 用户个性化推荐
- **引入用户实体**：将 ratings.csv 中的用户数据导入图谱
- **协同过滤**：基于用户-电影评分网络推荐
- **个性化 Agent**：根据用户历史偏好调整推荐策略

### 9.4 跨语言支持
- **中文电影数据**：集成豆瓣电影 API 或中文 TMDB 数据
- **多语言查询**：支持中英文混合查询

### 9.5 对话式推荐
- **多轮对话**：逐步明确用户偏好
- **示例对话**：
  ```
  用户："推荐科幻电影"
  系统："您喜欢硬科幻还是软科幻？"
  用户："硬科幻"
  系统："推荐《星际穿越》、《火星救援》..."
  ```

### 9.6 评分预测
- **使用 ratings.csv 训练推荐模型**
- **预测用户对未观看电影的评分**
- **集成到推荐系统（超出当前 GraphRAG 范围）**

---

## 10. 总结

本设计文档基于对 SparrowRecSys 数据集的详细分析，制定了切实可行的电影知识图谱构建方案：

**核心数据规模**：
- 982 部电影（1926-1998）
- 971 部有 TMDB ID（98.9% 覆盖率）
- 116 万条用户评分
- 预计构建 6000+ 节点，27000+ 关系的知识图谱

**技术路线**：
- **数据源**：MovieLens CSV + TMDB API 补充
- **TMDB API 调用**：~1942-4855 次（16-20 分钟完成）
- **知识图谱**：Neo4j + 向量索引 + Leiden 社区检测
- **多智能体**：保持现有 GraphRAG 架构，新增电影推荐工具

**实施周期**：3 周（16 工作日）

**风险控制**：
- API 限流：每秒 4 次请求 + 重试机制
- 数据缺失：允许可选字段 + 搜索匹配
- 性能优化：索引 + 缓存 + 批处理

**交付成果**：
- 完整的电影知识图谱系统
- 支持精确查询、推理查询、推荐查询、统计分析
- 可视化前端界面（React + 图谱可视化）
- 完善的文档与测试报告

---

**文档版本**：v3.0（基于实际 API 验证）
**最后更新**：2026-01-05
**作者**：GraphRAG Agent Team

---

## 附录 A：实施记录与验证结果

### A.1 数据对应关系验证（2026-01-05）

**执行时间**：2026-01-05 13:30-13:45

**验证目标**：
1. 确认 MovieLens 数据与 TMDB API 的对应关系
2. 验证 TMDB ID 映射的准确性
3. 测试 API 连接和数据获取

**网络环境**：
- 直连 api.themoviedb.org：❌ 失败（Connection Timeout, Exit code 28）
- 使用代理（localhost:10808）：✅ 成功

**验证过程**：

**Step 1：测试直连**
```bash
curl --connect-timeout 10 https://api.themoviedb.org/3/movie/862
# 结果：Exit code 28 - Timeout
```

**Step 2：配置代理**
```bash
# 在 .env 中添加
HTTP_PROXY=http://localhost:10808
HTTPS_PROXY=http://localhost:10808
```

**Step 3：使用代理测试**
```bash
curl --proxy http://localhost:10808 \
     --url 'https://api.themoviedb.org/3/movie/862?language=en-US' \
     --header 'Authorization: Bearer <TOKEN>'
# 结果：✅ 成功返回数据
```

**验证结果总结**：

| 项目 | 结果 | 说明 |
|-----|------|------|
| MovieLens 数据读取 | ✅ | 982 部电影，116万条评分 |
| TMDB ID 映射准确性 | ✅ | 前3部电影标题完全匹配 |
| API 连接（直连） | ❌ | 网络超时 |
| API 连接（代理） | ✅ | 成功获取数据 |
| 演员信息获取 | ✅ | 成功获取 cast 和 crew |
| 类型映射 | ⚠️ | 需要映射表（Children→Family） |

**关键发现**：
1. ✅ **TMDB ID 映射 100% 准确** - 验证了前 3 部电影
2. ✅ **API 数据丰富** - 包含演员、类型、评分、简介等
3. ⚠️ **类型差异** - MovieLens "Children" 对应 TMDB "Family"
4. ❗ **必须使用代理** - 直连会超时

---

### A.2 已完成的工作

**脚本开发**（2026-01-05）：

1. ✅ `data/movie/movie_data_preprocessing.py` - 完整的数据预处理脚本
   - 功能：解析 CSV，调用 TMDB API，生成 JSON
   - 特性：代理支持、速率限制、缓存、重试机制
   - 状态：**已实现**

2. ✅ `data/movie/quickstart.sh` - 一键运行脚本
   - 功能：检查数据目录并运行预处理脚本

**配置文件**：

1. ✅ `.env.example` - 已添加 TMDB 配置
   ```
   TMDB_API_TOKEN=<YOUR_TMDB_BEARER_TOKEN>
   TMDB_API_KEY=<YOUR_TMDB_API_KEY>
   HTTP_PROXY=http://localhost:10808
   HTTPS_PROXY=http://localhost:10808
   ```

2. ✅ `.env` - 本地按需配置（不提交到仓库）

3. ✅ `docker-compose.yaml` - Neo4j 密码配置已修正（2026-01-05）
   - 修复：将密码从 `12345678` 统一为 `password123`
   - 状态：已验证连接成功

**文件夹结构**：

1. ✅ `files/movie_data/` - 电影推荐系统专用数据目录（2026-01-05）
   - 目的：隔离电影推荐系统数据，避免与学生管理系统数据混淆
   - 状态：已创建，待填充数据

**文档**：

1. ✅ `docs/06-应用案例/电影推荐知识图谱设计文档.md` - 完整设计文档
   - Section 2.2.0：数据验证结果
   - Section 7.1：网络配置说明
   - 类型映射表更新

2. ✅ `docs/06-应用案例/电影推荐系统实施指南.md` - 快速实施指南

---

### A.3 下一步工作

**短期任务（Phase 1 完成）**：

- [ ] **运行完整数据预处理**
  ```bash
  # 先激活 Python 3.10 虚拟环境（.venv）
  source .venv/bin/activate

  python data/movie/movie_data_preprocessing.py \
      --source-dir SparrowRecSys-master/target/classes/webroot/sampledata \
      --output-dir files/movie_data \
      --cache-dir files/tmdb_cache \
      --rate-limit 3.5
  ```
  预计耗时：12-15 分钟（核心数据）

- [ ] **验证输出文件**（在 `files/movie_data/` 目录下）
  - movies_enriched.json (~982 条，包含 TMDB 数据)
  - persons.json (~3,000-4,000 人)
  - keywords.json (~1,000 个)
  - companies.json (~1114 家)
  - countries.json (国家数据)
  - languages.json (语言数据)

**中期任务（Phase 2）**：

- [ ] 配置结构化模式环境变量（`GRAPH_BUILD_MODE/STRUCTURED_DATA_DIR/STRUCTURED_KB_PREFIX`）
- [ ] 运行 Phase 2（结构化导入 + Canonical 生成）
- [ ] （可选）按需补齐公司/国家/语言等节点与关系导入

**长期任务（Phase 3-6）**：

- [ ] 向量索引与社区检测
- [ ] 自定义电影推荐工具
- [ ] 前端界面适配
- [ ] 测试与评估

---

### A.3.1 已解决的配置问题

**问题：Neo4j 密码配置不一致**（2026-01-05 14:00）

**发现**：
- `docker-compose.yaml`: `NEO4J_AUTH: "neo4j/password123"` ✅
- `.env`: `NEO4J_PASSWORD='password123'` ✅

**验证过程**：
```python
# 测试密码
✅ Password "password123" works!
```

**解决方案**：更新 `docker-compose.yaml` 使用正确的密码 `password123`

**验证结果**：
```
✅ Connected to Neo4j Kernel 5.22.0 (community Edition)
📊 Current graph has 1791 nodes
✅ Configuration is now consistent!
```

**影响**：确保了数据预处理脚本能够正确连接到 Neo4j 数据库，为后续图谱构建扫清障碍。

---

### A.4 技术决策记录

**决策 1：类型系统处理**
- **问题**：MovieLens 和 TMDB 类型不完全一致
- **决策**：图谱内 `:类型.name` 统一使用 TMDB 规范名称；MovieLens 原始类型仅作为 `Movie` 节点原始字段保留（`movielens_genres_raw/movielens_genres_unmapped`）
- **理由**：保证类型过滤/统计闭环一致，同时保留原始数据可追溯

**决策 2：网络代理配置**
- **问题**：直连 TMDB API 超时
- **决策**：支持 HTTP/HTTPS 代理配置
- **实现**：通过环境变量 HTTP_PROXY 和 HTTPS_PROXY

**决策 3：API 速率限制**
- **问题**：TMDB 限制每秒 4 次请求
- **决策**：设置 rate_limit=3.5，预留余量
- **实现**：在 TMDBClient 中实现速率控制

**决策 4：数据缓存策略**
- **问题**：避免重复 API 调用
- **决策**：本地 JSON 文件缓存
- **路径**：files/tmdb_cache/movie_{id}.json

**决策 5：文件夹组织结构**（2026-01-05）
- **问题**：电影推荐系统数据与现有学生管理系统数据混合，容易混淆
- **决策**：创建专用文件夹 `files/movie_data/` 存放所有电影推荐系统数据
- **实现**：
  - 数据文件：`files/movie_data/*.json`
  - API 缓存：`files/tmdb_cache/` (共享目录，可复用)
- **优点**：
  - ✅ 便于文件管理和清理
  - ✅ 避免与现有系统数据混淆
  - ✅ 支持多领域系统并存（学生管理 + 电影推荐）
  - ✅ 便于整体备份和迁移

---

### A.5 数据质量报告

**MovieLens 数据质量**：

| 指标 | 数值 | 质量评估 |
|-----|------|---------|
| 电影总数 | 982 | ✅ 完整 |
| 年份覆盖 | 1926-1998 (72年) | ✅ 良好 |
| 类型标注 | 19 个标准类型 | ✅ 完整 |
| 评分数据 | 1,168,638 条 | ✅ 丰富 |
| 用户数 | 29,776 人 | ✅ 充足 |
| TMDB ID 覆盖 | 98.9% (971/982) | ✅ 优秀 |

**TMDB 数据预期质量**：

| 数据项 | 预期覆盖率 | 说明 |
|-------|-----------|------|
| 电影详情 (overview) | ~95% | 老电影可能缺失 |
| 演员信息 | ~95% | 主流电影完整 |
| 导演信息 | ~98% | 基本完整 |
| 关键词 | ~80% | 部分电影缺失 |
| 制作公司 | ~90% | 主流电影完整 |
| 预算/票房 | ~60% | 老电影常缺失 |

---

### A.6 风险与应对（更新）

**新增风险**：

**风险 6：网络依赖**
- **描述**：依赖代理访问 TMDB API
- **影响**：代理不可用时无法获取数据
- **应对**：
  - ✅ 实现本地缓存（已完成）
  - ✅ 必须配置有效的TMDB凭证（`TMDB_API_TOKEN`或`TMDB_API_KEY`）
  - ⚠️ 建议在网络稳定环境下一次性获取全部数据

**已解决风险**：

- ✅ TMDB ID 映射准确性 - 已验证
- ✅ API 连接问题 - 代理方案可行
- ✅ 数据格式兼容性 - 脚本已实现

---

### A.7 参考资源

**外部链接**：
- TMDB API 文档：https://developer.themoviedb.org/reference/intro/getting-started
- MovieLens 数据集：https://grouplens.org/datasets/movielens/
- SparrowRecSys 项目：https://github.com/wzhe06/SparrowRecSys

**项目文件**：
- 设计文档：`docs/06-应用案例/电影推荐知识图谱设计文档.md`
- 实施指南：`docs/06-应用案例/电影推荐系统实施指南.md`
- 数据预处理脚本：`data/movie/movie_data_preprocessing.py`
- 配置文件：`.env.example`

**代码仓库**：
- 主项目：`graph-rag-agent/`（项目根目录）
- 数据源：`SparrowRecSys-master/target/classes/webroot/sampledata`

---

## 附录 B：代码实现指南

本附录提供数据处理流程的代码实现细节、模块设计和扩展方式，供开发者参考。

**重要说明**：
- **Phase 1（数据预处理）**：独立脚本，位于 `data/movie/`，不涉及统一框架
- **Phase 2（图谱构建）**：结构化电影导入与 Canonical 层生成，位于 `backend/infrastructure/integrations/build/structured_movie_graph.py`
- **Phase 3（索引与社区）**：实体/Chunk 向量索引与社区检测，统一入口为 `backend/infrastructure/integrations/build/main.py`（通过环境变量控制各 Phase 是否执行）

### B.1 Phase 1 代码架构设计（独立脚本）

> Phase 1 负责数据预处理（MovieLens + TMDB 数据获取和清洗），输出标准化 JSON 文件，**不依赖统一框架**。

#### B.1.1 推荐的模块拆分

为保证可维护性、可测试性和可扩展性，建议将Phase 1按以下模块组织：

**代码位置**：`data/movie/`

```
data/movie/
├── movie_data_preprocessing.py      # CLI 入口（参数解析、组装 pipeline、打印统计）
├── movielens_parser.py              # MovieLens CSV 解析 + 类型归一化
├── tmdb_client.py                   # TMDB API 客户端（鉴权/代理/限流/重试/端点封装）
├── tmdb_cache.py                    # 缓存读写（files/tmdb_cache/movie_{tmdbId}.json）
├── enricher.py                      # 单电影 enrich + description/rank_score + 聚合实体
├── io_utils.py                      # JSON 输出（原子写入/目录创建/编码）
├── quickstart.sh                    # 一键脚本（强制 Python 3.10 + venv）
└── README.md                        # Phase 1 使用说明
```

#### B.1.2 模块职责划分

**1. movie_data_preprocessing.py（CLI 入口与编排层）**

职责：
- 参数解析（argparse）
- 目录校验
- 读取 `.env` 配置
- 组装 parser/client/enricher
- 循环处理电影
- 写出 JSON 文件
- 打印统计信息

不承载：
- 类型映射表
- TMDB 端点细节
- 单电影字段拼装
- 聚合实体逻辑

**2. movielens_parser.py（MovieLens 解析层）**

职责：
- 解析 `movies.csv/links.csv/ratings.csv`
- 标题/年份提取（正则表达式）
- MovieLens 类型归一化与 `unmapped` 保留
- 评分聚合（avg_rating, rating_count）

产出：
- `parse_movies() -> pd.DataFrame`
- `parse_links() -> pd.DataFrame`
- `parse_ratings() -> dict[int, dict[str, float]]`

**3. tmdb_client.py（TMDB 访问层）**

职责：
- 鉴权（Token/API Key 二选一）
- 代理配置（HTTP_PROXY/HTTPS_PROXY）
- 限流控制（rate_limit）
- 错误处理（重试、超时）
- 端点封装（details/credits/keywords/recommendations/similar）

原则：
- 只返回原始 JSON（或 `None`）
- 不做业务合并
- 失败时返回 None 而非抛出异常

接口示例：
```python
class TMDBClient:
    def get_movie_details(self, tmdb_id: int) -> dict | None:
        """获取电影详情"""
        pass

    def get_movie_credits(self, tmdb_id: int) -> dict | None:
        """获取演员和导演信息"""
        pass

    def get_movie_keywords(self, tmdb_id: int) -> dict | None:
        """获取关键词"""
        pass
```

**4. tmdb_cache.py（缓存层）**

职责：
- 读写 `files/tmdb_cache/movie_{tmdbId}.json`
- 缓存键设计（使用 tmdbId）

原则：
- 缓存内容为可复用的 TMDB 原始/半结构化数据
- 避免缓存 movieId 等 MovieLens 专属字段

**5. enricher.py（数据增强与聚合层）**

职责：
- 单电影 enrich（MovieLens + 可选 TMDB）
- 生成 `description`（标题 + 类型 + overview）
- 统一 `rank_score_0_10`
- 选择 `genres` 闭环口径
- 聚合 `persons/keywords/companies/countries/languages`

原则：
- 聚合逻辑集中在一个类（如 `MovieDataEnricher`）
- CLI 只负责写出聚合结果

核心接口：
```python
class MovieDataEnricher:
    def __init__(self, tmdb_client: TMDBClient | None = None):
        self.all_persons = {}
        self.all_keywords = {}
        self.all_companies = {}
        self.all_countries = {}
        self.all_languages = {}

    def enrich_movie(self, movie_row, links_row, rating_stats) -> dict:
        """返回单电影最终结构，并在内部更新聚合字典"""
        pass

    def get_aggregated_data(self) -> dict:
        """返回所有聚合实体"""
        return {
            'persons': list(self.all_persons.values()),
            'keywords': list(self.all_keywords.values()),
            'companies': list(self.all_companies.values()),
            'countries': list(self.all_countries.values()),
            'languages': list(self.all_languages.values()),
        }
```

**6. io_utils.py（输出工具层）**

职责：
- JSON 写出（UTF-8编码）
- 目录创建
- 可扩展为原子写入/写入校验

#### B.1.3 核心公共接口

为减少下游耦合，建议稳定以下接口：

```python
# MovieLens 解析
class MovieLensParser:
    def parse_movies(self) -> pd.DataFrame:
        """包含: movieId, clean_title, year, movielens_genres_raw,
                 movielens_genres, movielens_genres_unmapped"""
        pass

    def parse_links(self) -> pd.DataFrame:
        """包含: movieId, imdbId, tmdbId"""
        pass

    def parse_ratings(self) -> dict[int, dict[str, float]]:
        """返回: {movieId: {avg_rating, rating_count}}"""
        pass

# TMDB 客户端
class TMDBClient:
    def get_movie_details(self, tmdb_id: int) -> dict | None:
        pass

    def get_movie_credits(self, tmdb_id: int) -> dict | None:
        pass

    def get_movie_keywords(self, tmdb_id: int) -> dict | None:
        pass

    def get_movie_recommendations(self, tmdb_id: int) -> dict | None:
        pass

    def get_movie_similar(self, tmdb_id: int) -> dict | None:
        pass

# 数据增强
class MovieDataEnricher:
    def enrich_movie(self, movie_row, links_row, rating_stats) -> dict:
        """返回单电影最终结构；并在内部更新聚合字典"""
        pass
```

### B.2 代码扩展指南

#### B.2.1 新增 TMDB 字段

**场景**：需要采集 TMDB 的新字段（如 `tagline`、`homepage`）

步骤：
1. 若字段已包含在 `/movie/{id}` 的详情响应中：仅在 `enricher.py` 的 `enrich_movie()` 中提取并写入输出
2. 若需要额外端点：在 `tmdb_client.py` 新增端点方法（仍返回原始JSON），再在 `enricher.py` 合并写入
3. 确保缓存命中/未命中都产出同结构字段（缺失用 `null/[]`）

示例：
```python
# tmdb_client.py
def get_movie_details(self, tmdb_id: int) -> dict | None:
    # ... existing code ...
    return data  # 返回 TMDB 原始 JSON，不在 client 层做字段拼装/裁剪

# enricher.py
def enrich_movie(self, movie_row, links_row, rating_stats) -> dict:
    # ... existing code ...
    details = tmdb_details or {}
    movie_dict['tagline'] = details.get('tagline', '')
    movie_dict['homepage'] = details.get('homepage', '')
    return movie_dict
```

#### B.2.2 新增派生指标

**场景**：需要计算新的派生字段（如加权评分、热度分数）

步骤：
1. 在 `enricher.py` 中新增纯函数（如 `_compute_popularity_score()`）
2. 在 `enrich_movie()` 中调用并写入字段
3. 将计算口径写入文档的"数据契约/关键规则"

示例：
```python
# enricher.py
def _compute_popularity_score(self, movie_data: dict) -> float:
    """计算综合热度分数

    规则：
    - 基础分 = rank_score_0_10
    - 评分权重 = log(rating_count + 1) * 0.1
    - TMDB热度 = tmdb_popularity * 0.01
    """
    base = movie_data.get('rank_score_0_10', 5.0)
    rating_weight = np.log(movie_data.get('movielens_rating_count', 0) + 1) * 0.1
    tmdb_pop = movie_data.get('tmdb_popularity', 0) * 0.01
    return base + rating_weight + tmdb_pop

def enrich_movie(self, movie_row, links_row, rating_stats) -> dict:
    # ... existing code ...
    movie_dict['popularity_score'] = self._compute_popularity_score(movie_dict)
    return movie_dict
```

#### B.2.3 新增聚合产物

**场景**：需要新增派生视图/统计表（如 `directors.json`、`role_stats.json`）

步骤：
1. 以实现为准：当前 `persons.json` 以 `personId` 去重，并输出 `person_type`（actor/director）与 `movieIds`
2. 下游“角色语义”以关系 `(:人物)-[:出演|:导演]->(:电影)` 为准（Phase 2 会创建关系），`person_type` 仅作为便捷字段/默认主角色
3. 若为了兼容分析/报表需要单独文件（如 `directors.json`），建议在 CLI 输出阶段由 `persons.json` 派生生成（过滤/聚合），而非在 enrich 过程中维护第二套聚合容器
4. 若未来确实需要“同一人既是演员又是导演”的闭环（roles 列表），建议将 `person_type` 升级为 `roles: ["actor","director"]`（并保留 `person_type` 作为兼容字段），再同步更新 Phase 2 导入逻辑

示例：
```python
# movie_data_preprocessing.py（输出阶段派生 directors.json）
persons = aggregated["persons"]
directors = [p for p in persons if p.get("person_type") == "director"]
save_json(directors, output_dir / "directors.json")
```

### B.3 Phase 2 实现说明（以实际代码为准）

#### B.3.0 实现位置与集成方式

**结构化领域图导入 + Canonical 层生成**：`backend/infrastructure/integrations/build/structured_movie_graph.py`

**统一编排入口**：`backend/infrastructure/integrations/build/main.py`

结构化电影模式通过环境变量 `GRAPH_BUILD_MODE=structured` 进入分支，并使用 `BUILD_RUN_*` 开关控制是否执行某个 Phase。

仅执行 Phase 2（结构化导入 + Canonical 生成）的命令示例：
```bash
source .venv/bin/activate

GRAPH_BUILD_MODE=structured \
STRUCTURED_DATA_DIR=files/movie_data \
STRUCTURED_KB_PREFIX=movie \
STRUCTURED_RESET_DOMAIN=true \
STRUCTURED_RESET_CANONICAL=true \
BUILD_RUN_GRAPH=true \
BUILD_RUN_INDEX_AND_COMMUNITY=false \
BUILD_RUN_CHUNK_INDEX=false \
bash scripts/py.sh infrastructure.integrations.build.main
```

#### B.3.1 结构化领域图导入（实际字段与关系）

Phase 2 的结构化导入在 `StructuredMovieGraphBuilder` 内部以批处理 `UNWIND $rows` 写入（批次可用 `STRUCTURED_BATCH_SIZE` 调整），主要落地如下：

- 领域节点：
  - `(:电影 {movieId})`：写入 `name/year/tmdbId/imdbId/overview/description/genres`，评分字段写入 `movielens_*`、`tmdb_vote_*`、`rank_score_*`，并保留 `data_source/created_at`
  - `(:人物 {personId})`：写入 `name/popularity/profile_path/person_type/movieIds`
  - `(:关键词 {keywordId})`：写入 `name/movieIds`
  - `(:类型 {name})`：来自 `movie.genres`（Phase 1 已归一化）
  - `(:公司 {companyId})` / `(:国家 {code})` / `(:语言 {code})`：来自 Phase 1 输出（实现会写入节点与关系）

- 领域关系：
  - `(:电影)-[:属于类型]->(:类型)`
  - `(:人物)-[:出演]->(:电影)`：属性 `character/order/cast_id`
  - `(:人物)-[:导演]->(:电影)`：仅从 crew(job=Director) 创建
  - `(:电影)-[:包含关键词]->(:关键词)`
  - `(:电影)-[:制作公司]->(:公司)`、`(:电影)-[:制作国家]->(:国家)`、`(:电影)-[:使用语言]->(:语言)`

#### B.3.2 cast/crew 是否需要额外展平脚本？

不需要。当前实现会在 Python 内部将 `movies_enriched.json` 的 `cast/crew/keywords/production_*` 直接展平成 row 列表，再批量写入 Neo4j。

当电影数量很大时（全量 982 部 + TMDB enrich），若希望进一步降低内存峰值，可在 Phase 1 额外输出扁平化文件（例如 `cast_rows.json/crew_rows.json`），并在 `StructuredMovieGraphBuilder` 改为“流式读取 + 批量写入”。

### B.4 Phase 3 实现说明（以实际代码为准）

#### B.4.0 实现位置与集成方式

**Phase 3 入口文件**：`backend/infrastructure/integrations/build/build_index_and_community.py`

**核心实现模块**：
- 实体向量化：`backend/graphrag_agent/graph/indexing/entity_indexer.py`（`EntityIndexManager.create_entity_index`）
- Chunk 向量化：`backend/graphrag_agent/graph/indexing/chunk_indexer.py`（`ChunkIndexManager.create_chunk_index`）
- 社区检测：`backend/graphrag_agent/community/detector/*`（Leiden/SLLPA）

结构化电影系统推荐通过“前缀过滤 + 独立索引名”与现有知识库共库隔离：
- `GRAPH_ENTITY_ID_PREFIX_FILTER=movie:`：只处理 `__Entity__.id` 以 `movie:` 开头的实体
- `GRAPH_CHUNK_ID_PREFIX_FILTER=movie:`：只处理 `__Chunk__.id` 以 `movie:` 开头的文本块
- `ENTITY_VECTOR_INDEX_NAME=movie_vector`、`CHUNK_VECTOR_INDEX_NAME=movie_chunk_vector`：避免覆盖默认 `vector`
- `GRAPH_COMMUNITY_ID_PREFIX=movie:`：避免 `__Community__.id` 与其他知识库冲突

仅执行 Phase 3（实体索引 + 社区检测）的命令示例：
```bash
source .venv/bin/activate

GRAPH_BUILD_MODE=structured \
BUILD_RUN_GRAPH=false \
BUILD_RUN_INDEX_AND_COMMUNITY=true \
BUILD_RUN_CHUNK_INDEX=false \
BUILD_DROP_ALL_INDEXES=false \
GRAPH_ENTITY_ID_PREFIX_FILTER=movie: \
GRAPH_COMMUNITY_ID_PREFIX=movie: \
ENTITY_VECTOR_INDEX_NAME=movie_vector \
bash scripts/py.sh infrastructure.integrations.build.main
```

#### B.4.1 Canonical 层生成（Phase 2 已完成）

以实现为准：Canonical 层在 Phase 2（`structured_movie_graph.py`）中生成，不在 Phase 3 再生成一次。其策略为：
- 每部 `:电影` 对应 1 个 `:__Document__`（`fileName = {kb}:movie:{movieId}`）
- 每部电影生成多个 `:__Chunk__`（description/genres/cast/director/keywords），并通过 `:MENTIONS` 指向对应的 `:__Entity__`
- Canonical `__Entity__.id` 采用 `{kb}:Movie:{movieId}`、`{kb}:Person:{personId}`、`{kb}:Genre:{name}`、`{kb}:Keyword:{keywordId}`，其中 `{kb}` 默认 `movie`
- Phase 2 会额外创建 `(__Entity__)-[:RELATED]-(__Entity__)` 边（来自领域关系），避免依赖 LLM 抽取关系

#### B.4.2 `__Entity__` 向量化与索引创建（实际实现）

以实现为准：实体向量化由 `EntityIndexManager.create_entity_index()` 完成，具备以下特性：
- 仅对 `(:__Entity__)` 写入 `embedding`（复用现有检索链路）
- 支持 `GRAPH_ENTITY_ID_PREFIX_FILTER`，共库时只处理 `movie:` 前缀实体
- 会自动探测 embedding 维度并创建 Neo4j VECTOR INDEX（不需要手写 Cypher）
- 针对 DashScope/OpenAI 兼容端点限制，内部会将 `embed_documents` 的子批次限制为 `<=10`

如需手动排查索引，可用：
```cypher
SHOW INDEXES;
```

#### B.4.3 社区检测与共库隔离（实际实现）

以实现为准：社区检测由 `CommunityDetectorFactory` 驱动（默认 Leiden），并通过 `GRAPH_ENTITY_ID_PREFIX_FILTER` 将投影限定在 `movie:` 前缀实体集合内。

为避免与其他知识库冲突，社区节点使用前缀命名空间：
- `GRAPH_COMMUNITY_ID_PREFIX=movie:` → 生成的 `__Community__.id` 为 `movie:0-<communityId>` 形式

结构化电影系统默认建议跳过“相似实体检测/合并/质量提升/社区摘要”，仅保留“向量索引 + 社区检测”，可用以下开关控制：
- `GRAPH_SKIP_SIMILAR_ENTITY=true`
- `GRAPH_SKIP_ENTITY_MERGE=true`
- `GRAPH_SKIP_ENTITY_QUALITY=true`
- `GRAPH_SKIP_COMMUNITY_SUMMARY=true`

#### B.4.4 Chunk 向量化（可选）

若需要启用基于 `__Chunk__` 的 naive RAG 检索，可执行 Chunk 索引构建（共库同样建议前缀过滤与独立索引名）：
```bash
source .venv/bin/activate

GRAPH_BUILD_MODE=structured \
BUILD_RUN_GRAPH=false \
BUILD_RUN_INDEX_AND_COMMUNITY=false \
BUILD_RUN_CHUNK_INDEX=true \
BUILD_DROP_ALL_INDEXES=false \
GRAPH_CHUNK_ID_PREFIX_FILTER=movie: \
CHUNK_VECTOR_INDEX_NAME=movie_chunk_vector \
bash scripts/py.sh infrastructure.integrations.build.main
```

---

**附录结束**
