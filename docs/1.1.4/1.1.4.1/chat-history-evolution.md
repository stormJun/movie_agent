# å¯¹è¯å†å²ç®¡ç†æ¼”è¿›æ–¹æ¡ˆè®¾è®¡

**ç‰ˆæœ¬**: 1.1.4.1  
**çŠ¶æ€**: è®¾è®¡ä¸­  
**ä½œè€…**: AI Assistant  
**æ—¥æœŸ**: 2026-01-23

---

## 1. èƒŒæ™¯ä¸åŠ¨æœº

### 1.1 å½“å‰å®ç°ï¼ˆBaselineï¼‰

åœ¨ v1.1.4 ä¸­ï¼Œæˆ‘ä»¬å®ç°äº†åŸºç¡€çš„å¯¹è¯å†å²æ³¨å…¥æœºåˆ¶ï¼š

```python
# å½“å‰æµç¨‹
history = await conversation_store.list_messages(limit=6, desc=True)
history.reverse()  # æ—¶é—´æ­£åº
prompt = build_prompt(system + history + current_message)
```

**ä¼˜ç‚¹**ï¼š
- âœ… ç®€å•ç›´æ¥ï¼Œæ˜“äºç†è§£å’Œç»´æŠ¤
- âœ… è§£å†³äº†åŸºæœ¬çš„ä¸Šä¸‹æ–‡ä¸¢å¤±é—®é¢˜
- âœ… å¯¹çŸ­ä¼šè¯ï¼ˆ< 10 è½®ï¼‰æ•ˆæœè‰¯å¥½

**å±€é™æ€§**ï¼š
- âŒ **å›ºå®šçª—å£ç›²åŒº**ï¼šè¶…å‡º N æ¡çš„å†å²è¢«é—å¿˜ï¼ˆå¦‚ç”¨æˆ·åœ¨ç¬¬ 1 è½®æåˆ°çš„é‡è¦ä¿¡æ¯ï¼‰
- âŒ **Token æµªè´¹**ï¼šæ¯æ¬¡éƒ½ä¼ é€’å®Œæ•´çš„å†å²æ¶ˆæ¯ï¼Œå³ä½¿å†…å®¹é‡å¤æˆ–æ— å…³
- âŒ **æ—¶é—´åè§**ï¼šåªæŒ‰æ—¶é—´åˆ‡ç‰‡ï¼Œä¸è€ƒè™‘è¯­ä¹‰ç›¸å…³æ€§ï¼ˆç”¨æˆ·å¯èƒ½è·³å›ä¹‹å‰çš„è¯é¢˜ï¼‰
- âŒ **æ‰©å±•æ€§å·®**ï¼šéšç€å¯¹è¯å˜é•¿ï¼Œæˆæœ¬çº¿æ€§å¢é•¿

### 1.2 æ¼”è¿›ç›®æ ‡

æ„å»ºä¸€ä¸ª**å¯æ‰©å±•ã€é«˜æ•ˆã€æ™ºèƒ½**çš„å¯¹è¯è®°å¿†ç³»ç»Ÿï¼Œæ”¯æŒï¼š
1. **é•¿æœŸä¸Šä¸‹æ–‡ä¿ç•™**ï¼šå³ä½¿å¯¹è¯è¶…è¿‡ 100 è½®ï¼Œå…³é”®ä¿¡æ¯ä¸ä¸¢å¤±
2. **æˆæœ¬ä¼˜åŒ–**ï¼šé™ä½ Token æ¶ˆè€—ï¼Œæå‡å“åº”é€Ÿåº¦
3. **è¯­ä¹‰æ„ŸçŸ¥**ï¼šæ ¹æ®ç›¸å…³æ€§è€Œéæ—¶é—´æ£€ç´¢å†å²
4. **æ¶æ„å¥å£®æ€§**ï¼šå‡å°‘æ‰‹åŠ¨å‚æ•°ä¼ é€’ï¼Œé™ä½ç»´æŠ¤æˆæœ¬

---

## 2. ä¸‰é˜¶æ®µæ¼”è¿›æ–¹æ¡ˆ

### Phase 1: è®°å¿†å‹ç¼©ä¸æ‘˜è¦ (Memory Summarization)

#### 2.1.1 æ ¸å¿ƒè®¾è®¡ç†å¿µ

é‡‡ç”¨ **æ»‘åŠ¨çª—å£ + å†å²æ‘˜è¦** ç­–ç•¥ï¼Œé€šè¿‡å¯¹è¯å†å²çš„åˆ†å±‚å‹ç¼©æ¥è§£å†³é•¿å¯¹è¯çš„ Token æµªè´¹å’Œä¸Šä¸‹æ–‡ä¸¢å¤±é—®é¢˜ã€‚

**æ ¸å¿ƒæ€æƒ³ï¼š**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æœ€ç»ˆ Prompt ç»“æ„                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [System Prompt]                         â”‚
â”‚  [å¯¹è¯èƒŒæ™¯æ‘˜è¦]: å‹ç¼©çš„å…¨å±€ä¸Šä¸‹æ–‡         â”‚
â”‚  [æœ€è¿‘çª—å£]: æœ€è¿‘ 6 æ¡åŸå§‹å¯¹è¯ï¼ˆä¿æŒç»†èŠ‚ï¼‰ â”‚
â”‚  [å½“å‰æ¶ˆæ¯]                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ä¿¡æ¯å±‚çº§ï¼š**
- **æ‘˜è¦å±‚ï¼ˆé•¿æœŸè®°å¿†ï¼‰**ï¼šä¿ç•™å…¨å±€èƒŒæ™¯ã€ç”¨æˆ·åå¥½ã€å…³é”®å†³ç­–
  - ç¤ºä¾‹ï¼š"ç”¨æˆ·è®¨è®ºäº†90å¹´ä»£ç§‘å¹»ç”µå½±ï¼Œç‰¹åˆ«å…³æ³¨è¯ºå…°å¯¼æ¼”ä½œå“ï¼Œä¸å–œæ¬¢ææ€–ç‰‡"
- **çª—å£å±‚ï¼ˆçŸ­æœŸè®°å¿†ï¼‰**ï¼šä¿ç•™æœ€è¿‘å¯¹è¯çš„å®Œæ•´ç»†èŠ‚
  - åŒ…å«æœ€è¿‘ 3 è½®å¯¹è¯ï¼ˆ6 æ¡æ¶ˆæ¯ï¼‰
  - ç¡®ä¿å½“å‰è¯é¢˜çš„ä¸Šä¸‹æ–‡è¿ç»­æ€§

**å…³é”®é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ**

åœ¨å®ç° Phase 1 ä¹‹å‰ï¼Œå¿…é¡»è§£å†³ä»¥ä¸‹**å››ä¸ªå…³é”®é—®é¢˜**ï¼Œå¦åˆ™ä¼šå¯¼è‡´æ‘˜è¦è¾¹ç•Œæ¼‚ç§»ã€æ— æ³•è½åœ°æˆ–æ€§èƒ½é—®é¢˜ï¼š

| é—®é¢˜ | åŸå›  | è§£å†³æ–¹æ¡ˆ |
|------|------|---------|
| **1. UUID v4 ä¸æ”¯æŒæ—¶é—´åº** | `WHERE id > since_message_id` åœ¨ UUID v4 ä¸‹ä¼šæ¼æ¶ˆæ¯/ä¹±åº/ä¸å¹‚ç­‰ | ä½¿ç”¨ `(created_at, id)` å¤åˆæ¸¸æ ‡åˆ†é¡µï¼š`WHERE created_at > $1 OR (created_at = $1 AND id > $2)` |
| **2. current_message_id ä¸å¯ç”¨** | `append_message()` æœ¬èº«å·²è¿”å› UUIDï¼Œä½† Handler æ²¡æ¥ä½ï¼Œä»ç”¨ `content == message` å»é‡ | Handler æ¥ä½ `append_message()` è¿”å›çš„ UUIDï¼ŒæŒ‰ ID æ’é™¤è€Œä¸æ˜¯ content |
| **3. Partial æ¶ˆæ¯åœ¨ç”Ÿäº§ç¯å¢ƒä¸å¯è¯†åˆ«** | `debug.partial` åªåœ¨ debug=True æ—¶å­˜åœ¨ï¼Œç”Ÿäº§ç¯å¢ƒæ–­è¿ä¼šè½åº“"åŠæˆª answer"ä½†æ— ä»»ä½•æ ‡è®° | æ·»åŠ ä¸ debug æ— å…³çš„ `messages.completed` å­—æ®µï¼Œæ‘˜è¦åªå¤„ç† `completed=True` çš„æ¶ˆæ¯ |
| **4. å¼‚æ­¥è§¦å‘ç¼ºå°‘çœŸå®æ‰¿è½½** | **å½“å‰ä»£ç æ²¡æœ‰ä»»ä½• summarizer/task manager å®ç°**ï¼Œ`background_tasks.add_task` åœ¨æµå¼åœºæ™¯ä¼šä¸¢å¤± | å®ç° `SummaryTaskManager` è¿›ç¨‹å†…é˜Ÿåˆ—æˆ– DB job è¡¨ + workerï¼ˆ**ä¸ä¾èµ–æµå¼è¯·æ±‚ä¸Šä¸‹æ–‡**ï¼‰ |

**ç«‹å³è¡ŒåŠ¨æ¸…å•**ï¼š
1. [ ] ä¿®æ”¹ `messages` è¡¨ï¼šæ·»åŠ  `completed` å­—æ®µï¼ˆä¸ debug æ— å…³ï¼‰
2. [ ] Handler æ¥ä½ `append_message()` çš„è¿”å›å€¼ï¼ˆ**å®ƒæœ¬æ¥å°±è¿”å› UUID**ï¼‰
3. [ ] å®ç° `(created_at, id)` å¤åˆæ¸¸æ ‡ï¼ˆä¸æ˜¯å•ä¸€ `since_message_id`ï¼‰
4. [ ] å®ç° `SummaryTaskManager`ï¼ˆä¸æ˜¯ç®€å• `background_tasks`ï¼‰

**å®æ–½é¡ºåº**ï¼ˆæŒ‰ä¾èµ–å…³ç³»ï¼‰ï¼š

**ç¬¬1æ­¥ï¼šä¿®æ”¹æ•°æ®æ¨¡å‹**ï¼ˆ1å°æ—¶ï¼‰
```sql
-- messages è¡¨ï¼šæ·»åŠ å®Œæˆæ ‡è®°
ALTER TABLE messages ADD COLUMN completed BOOLEAN DEFAULT true;

-- conversation_summaries è¡¨ï¼šä½¿ç”¨å¤åˆè¦†ç›–ç‚¹
ALTER TABLE conversation_summaries
  ADD COLUMN covered_through_created_at TIMESTAMP,
  ADD COLUMN covered_through_message_id UUID;

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_messages_created_id ON messages(created_at, id);
```

**ç¬¬2æ­¥ï¼šä¿®æ”¹ Handler é€»è¾‘**ï¼ˆ2å°æ—¶ï¼‰
```python
# âœ… append_message() æœ¬èº«å·²ç»è¿”å› UUIDï¼ˆä¸éœ€è¦ä¿®æ”¹æ¥å£ï¼‰
# backend/infrastructure/persistence/postgres/conversation_store.py:44-65
async def append_message(...) -> UUID:
    msg_id = uuid4()
    ...
    return msg_id  # âœ… å·²ç»è¿”å› UUID

# âŒ å½“å‰é—®é¢˜ï¼šHandler æ²¡æœ‰æ¥ä½è¿”å›å€¼
# backend/application/chat/handlers/chat_handler.py:159
await self.store.append_message(...)  # è¿”å›å€¼è¢«å¿½ç•¥

# âœ… è§£å†³æ–¹æ¡ˆï¼šHandler æ¥ä½è¿”å›å€¼
current_message_id = await self.store.append_message(...)

# âœ… åç»­é€»è¾‘ä½¿ç”¨ current_message_id æ’é™¤
new_messages = [msg for msg in messages if msg["id"] != current_message_id]

# ConversationSummaryStorePort: ä½¿ç”¨å¤åˆæ¸¸æ ‡ï¼ˆæ–°å¢æ¥å£ï¼‰
async def list_messages_since(
    conversation_id: str,
    since_created_at: datetime | None,
    since_message_id: str | None,
    limit: int | None = 50
) -> list[dict]:
    ...
```

**ç¬¬3æ­¥ï¼šå®ç°åå°ä»»åŠ¡**ï¼ˆ3å°æ—¶ï¼‰

**SummaryTaskManager è¿›ç¨‹å†…é˜Ÿåˆ—**ï¼ˆæ¨èï¼Œå¿«é€Ÿå®ç°ï¼‰

```python
# backend/infrastructure/tasks/summary_task_manager.py
import asyncio
from typing import Optional

class SummaryTaskManager:
    """æ‘˜è¦ä»»åŠ¡ç®¡ç†å™¨ï¼ˆè¿›ç¨‹å†…é˜Ÿåˆ—ï¼‰

    âš ï¸ è®¾è®¡è¯´æ˜ï¼š
    - ä¸ä½¿ç”¨ FastAPI background_tasks.add_task()ï¼ˆæµå¼å“åº”ç»“æŸæ—¶ä¼šä¸¢å¤±ä»»åŠ¡ï¼‰
    - Worker åœ¨åº”ç”¨å¯åŠ¨æ—¶åˆ›å»ºï¼Œä¸æ˜¯åœ¨æµå¼è¯·æ±‚ä¸­æŒ‰éœ€åˆ›å»ºï¼ˆé¿å…ä¾èµ–è¯·æ±‚ä¸Šä¸‹æ–‡ï¼‰
    - ä»»åŠ¡åœ¨ç‹¬ç«‹ worker ä¸­æ‰§è¡Œï¼Œä¸æµå¼å“åº”å®Œå…¨è§£è€¦
    - æœåŠ¡é‡å¯ä¼šä¸¢å¤±é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡ï¼ˆç”Ÿäº§ç¯å¢ƒå¯å‡çº§ä¸º DB job è¡¨å®ç°æŒä¹…åŒ–ï¼‰
    """

    def __init__(self, max_concurrent: int = 10):
        self.queue = asyncio.Queue()
        self.workers = []
        self.max_concurrent = max_concurrent
        self.summarizer = None  # ç”±å¤–éƒ¨æ³¨å…¥

    async def start(self):
        """å¯åŠ¨åå° workerï¼ˆåº”ç”¨å¯åŠ¨æ—¶è°ƒç”¨ï¼Œä¸æ˜¯åœ¨æµå¼è¯·æ±‚ä¸­ï¼‰"""
        for i in range(self.max_concurrent):
            worker = asyncio.create_task(self._worker(f"worker-{i}"))
            self.workers.append(worker)

    async def _worker(self, name: str):
        """åå° workerï¼šæŒç»­å¤„ç†é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡ï¼ˆç‹¬ç«‹äºæµå¼è¯·æ±‚ç”Ÿå‘½å‘¨æœŸï¼‰"""
        while True:
            try:
                task = await self.queue.get()
                conversation_id, retry_count = task

                try:
                    await self.summarizer.try_trigger_update(conversation_id)
                except Exception as e:
                    # é‡è¯•é€»è¾‘ï¼ˆæŒ‡æ•°é€€é¿ï¼‰
                    if retry_count < 3:
                        await asyncio.sleep(2 ** retry_count)
                        await self.queue.put((conversation_id, retry_count + 1))

                self.queue.task_done()
            except asyncio.CancelledError:
                break
            except Exception as e:
                await asyncio.sleep(1)

    async def enqueue(self, conversation_id: str):
        """å°†æ‘˜è¦ä»»åŠ¡åŠ å…¥é˜Ÿåˆ—ï¼ˆä¸ç­‰å¾…å®Œæˆï¼Œç«‹å³è¿”å›ï¼‰"""
        await self.queue.put((conversation_id, 0))

# å…¨å±€å•ä¾‹ï¼ˆåº”ç”¨ç”Ÿå‘½å‘¨æœŸå†…å”¯ä¸€ï¼‰
summary_task_manager = SummaryTaskManager()

# backend/server/main.pyï¼ˆåº”ç”¨å¯åŠ¨æ—¶å¯åŠ¨ workerï¼‰
@app.on_event("startup")
async def startup():
    from backend.graphrag_agent.agents.summary import ConversationSummarizer

    # æ³¨å…¥ä¾èµ–
    summary_task_manager.summarizer = ConversationSummarizer(
        summary_store=summary_store,
        message_store=message_store,
        llm_factory=llm_factory
    )

    # âš ï¸ å…³é”®ï¼šåœ¨åº”ç”¨å¯åŠ¨æ—¶å¯åŠ¨ workerï¼Œè€Œä¸æ˜¯åœ¨æµå¼è¯·æ±‚ä¸­
    await summary_task_manager.start()
    logger.info("æ‘˜è¦ä»»åŠ¡ç®¡ç†å™¨å·²å¯åŠ¨")

@app.on_event("shutdown")
async def shutdown():
    # åœæ­¢æ‰€æœ‰ worker
    for worker in summary_task_manager.workers:
        worker.cancel()
    await asyncio.gather(*summary_task_manager.workers, return_exceptions=True)
```

**ç¬¬4æ­¥ï¼šä¿®æ”¹ Handler é€»è¾‘**ï¼ˆ2å°æ—¶ï¼‰

```python
# backend/application/chat/handlers/stream_handler.py
# âœ… ä¿®æ”¹æµå¼å¤„ç†é€»è¾‘ï¼Œæ”¯æŒ completed å­—æ®µå’Œæ‘˜è¦è§¦å‘

async def stream_response(message: str, conversation_id: str):
    """æµå¼å“åº”å¹¶è¿”å›å®ŒæˆçŠ¶æ€"""
    full_response = ""

    try:
        # æµå¼ç”Ÿæˆä¸­...
        async for chunk in llm.stream():
            full_response += chunk
            yield chunk

        # âœ… æ­£å¸¸å®Œæˆï¼šæ˜ç¡®æ ‡è®°ä¸ºå®Œæˆ
        message_id = await self.store.append_message(
            conversation_id=conversation_id,
            role="assistant",
            content=full_response,
            metadata={
                "completed": True,  # âœ… ä¸ debug æ— å…³
                "debug": {...} if self.debug else {}
            }
        )

        # âœ… è§¦å‘åå°æ‘˜è¦ï¼ˆä»…å½“æ­£å¸¸å®Œæˆæ—¶ï¼‰
        if self.completed_normally:
            from backend.infrastructure.tasks.summary_task_manager import summary_task_manager
            await summary_task_manager.enqueue(conversation_id)

        # âœ… è¿”å›å®ŒæˆçŠ¶æ€
        return StreamResponse(
            completed_normally=True,
            message_id=message_id,
            content=full_response
        )

    except Exception as e:
        # âš ï¸ å¼‚å¸¸ä¸­æ–­ï¼šæ˜ç¡®æ ‡è®°ä¸ºæœªå®Œæˆ
        await self.store.append_message(
            conversation_id=conversation_id,
            role="assistant",
            content=full_response,  # ä¸å®Œæ•´
            metadata={
                "completed": False,  # âœ… ä¸ debug æ— å…³
                "error": str(e),
                "debug": {...} if self.debug else {}
            }
        )

        # âœ… ä¸è§¦å‘æ‘˜è¦ï¼ˆæµå¼ä¸­æ–­ï¼‰
        return StreamResponse(
            completed_normally=False,
            message_id=None,
            content=full_response
        )
```

**ç¬¬5æ­¥ï¼šæµ‹è¯•éªŒè¯**ï¼ˆ2å°æ—¶ï¼‰
- æµ‹è¯•é‡å¤å†…å®¹åœºæ™¯
- æµ‹è¯•å¹¶å‘æ›´æ–°
- æµ‹è¯• partial è¿‡æ»¤ï¼ˆ**åŒ…æ‹¬ç”Ÿäº§ç¯å¢ƒ debug=False åœºæ™¯**ï¼‰
- æµ‹è¯•æœåŠ¡é‡å¯ï¼ˆä»»åŠ¡ä¸¢å¤±ï¼‰
- æµ‹è¯•æµå¼ä¸­æ–­ï¼ˆ**éªŒè¯æ‘˜è¦ä¸åŒ…å«æœªå®Œæˆæ¶ˆæ¯**ï¼‰

**æ€»è®¡**ï¼šçº¦10å°æ—¶ï¼ˆ1ä¸ªå¼€å‘æ—¥ï¼‰



**é—®é¢˜1è¯¦è§£ï¼šè¦†ç›–èŒƒå›´ä¸ç¨³å®šï¼ˆè¾¹ç•Œä¼šæ¼‚ç§»/é‡å¤æ‘˜è¦ï¼‰**

**ç°æœ‰å®ç°çš„é—®é¢˜**ï¼š

å½“å‰ä»£ç çš„å¤„ç†é¡ºåºå­˜åœ¨æ ¹æœ¬æ€§ç¼ºé™·ï¼š

```python
# ç¬¬1æ­¥ï¼šå…ˆå†™å…¥å½“å‰ç”¨æˆ·æ¶ˆæ¯
await conversation_store.append_message(
    conversation_id=conversation_id,
    role="user",
    content=current_message  # ä¾‹å¦‚ï¼š"æ¨èç”µå½±"
)

# ç¬¬2æ­¥ï¼šå†è¯»å–å†å²æ¶ˆæ¯ï¼ˆåŒ…å«åˆšå†™å…¥çš„ï¼‰
history = await conversation_store.list_messages(limit=6, desc=True)

# ç¬¬3æ­¥ï¼šç”¨å†…å®¹åŒ¹é…æ’é™¤å½“å‰æ¶ˆæ¯
for msg in history:
    if msg.get("content") == current_message:  # âš ï¸ ç”¨ content == message å»é‡
        history.remove(msg)
```

**é—®é¢˜åœºæ™¯ç¤ºä¾‹**ï¼š

```
å¯¹è¯å†å²ï¼š
1. user: "æ¨èç”µå½±"
2. assistant: "æ¨èã€Šæ˜Ÿé™…ç©¿è¶Šã€‹..."
3. user: "æ¨èç”µå½±"  â† é‡å¤é—®é¢˜
4. assistant: "æ¨èã€Šé»‘å®¢å¸å›½ã€‹..."
5. user: "æ¨èç”µå½±"  â† å½“å‰æ¶ˆæ¯ï¼ˆåˆšappendçš„ï¼‰

è¯»å–å†å²ï¼ˆlimit=6ï¼‰ï¼š
[æ¶ˆæ¯5: user="æ¨èç”µå½±", æ¶ˆæ¯4, æ¶ˆæ¯3: user="æ¨èç”µå½±", æ¶ˆæ¯2, æ¶ˆæ¯1]

ç”¨ content == current_message æ’é™¤ï¼š
ä¼šåŒæ—¶åˆ é™¤ æ¶ˆæ¯5 å’Œ æ¶ˆæ¯3 âŒ

ç»“æœï¼š
- æ¶ˆæ¯3 è¢«é”™è¯¯æ’é™¤ â†’ æ‘˜è¦è¾¹ç•Œæ¼‚ç§»
- ä¸‹æ¬¡æ‘˜è¦æ—¶ï¼Œæ¶ˆæ¯3 åˆä¼šè¢«åŒ…å« â†’ é‡å¤æ‘˜è¦
```

**å¯¼è‡´çš„é—®é¢˜**ï¼š
1. **è¾¹ç•Œæ¼‚ç§»**ï¼šåº”è¯¥åŒ…å«åœ¨æ‘˜è¦ä¸­çš„å†å²æ¶ˆæ¯è¢«é”™è¯¯æ’é™¤
2. **é‡å¤æ‘˜è¦**ï¼šåŒä¸€æ‰¹æ¶ˆæ¯åœ¨ä¸åŒè½®æ¬¡è¢«é‡å¤æ‘˜è¦
3. **æ‘˜è¦ä¸ä¸€è‡´**ï¼šæ‘˜è¦èŒƒå›´æ— æ³•ç²¾ç¡®å®šä¹‰å’Œå¤ç°

**è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨ (created_at, message_id) æ¸¸æ ‡åˆ†é¡µä½œä¸ºè¦†ç›–ç‚¹**

**âš ï¸ å…³é”®é—®é¢˜ï¼šUUID ä¸æ”¯æŒæ—¶é—´åºæ¯”è¾ƒ**

```python
# âŒ é”™è¯¯åšæ³•ï¼ˆæ–‡æ¡£ä¹‹å‰çš„å†™æ³•ï¼‰
new_messages = await store.list_messages_since(
    conversation_id=conversation_id,
    since_message_id=last_covered_id,  # UUID v4ï¼ˆéšæœºï¼‰
    limit=None
)

# å¯¹åº”çš„ SQLï¼š
# WHERE id > last_covered_id  -- âš ï¸ é”™è¯¯ï¼UUID v4 ä¸æ”¯æŒæ—¶é—´åº
```

**é—®é¢˜**ï¼š
- å½“å‰ `messages` è¡¨çš„ `id` æ˜¯ **UUID v4ï¼ˆ`gen_random_uuid()`ï¼‰**ï¼Œéšæœºç”Ÿæˆ
- **ä¸å­˜åœ¨"æ›´å¤§ ID = æ›´æ–°æ¶ˆæ¯"çš„è¯­ä¹‰**
- `WHERE id > last_covered_id` ä¼šï¼š
  - æ¼æ¶ˆæ¯ï¼šåæ’å…¥çš„æ¶ˆæ¯å¯èƒ½æœ‰æ›´å°çš„ UUID
  - ä¹±åºï¼šè¿”å›çš„æ¶ˆæ¯é¡ºåºä¸ç¬¦åˆæ—¶é—´
  - ä¸å¹‚ç­‰ï¼šåŒä¸€è¦†ç›–ç‚¹æ¯æ¬¡è¿”å›ä¸åŒç»“æœ

**æ­£ç¡®æ–¹æ¡ˆï¼šä½¿ç”¨ (created_at, id) æ¸¸æ ‡åˆ†é¡µ**

```python
# 1. æ•°æ®æ¨¡å‹ï¼šå­˜å‚¨å¤åˆè¦†ç›–ç‚¹
CREATE TABLE conversation_summaries (
    ...
    covered_through_message_id UUID,     -- âœ… è¦†ç›–ç‚¹çš„æ¶ˆæ¯ IDï¼ˆtie-breakï¼‰
    covered_through_created_at TIMESTAMP, -- âœ… è¦†ç›–ç‚¹çš„æ—¶é—´æˆ³ï¼ˆä¸»åºï¼‰
    ...
)

# 2. æ‘˜è¦ç”Ÿæˆï¼šåŸºäº (created_at, id) å¢é‡è·å–
last_covered_at = summary.get("covered_through_created_at")  # ä¾‹å¦‚ï¼š2024-01-01 10:00:00
last_covered_id = summary.get("covered_through_message_id")  # ä¾‹å¦‚ï¼šmsg-3-id

# âœ… æ­£ç¡®çš„æ¸¸æ ‡åˆ†é¡µï¼ˆcreated_at ä¸»åºï¼Œid tie-breakï¼‰
new_messages = await store.list_messages_since(
    conversation_id=conversation_id,
    since_created_at=last_covered_at,
    since_message_id=last_covered_id,
    limit=None
)

# å¯¹åº”çš„ SQLï¼ˆå…³é”®ç‚¹ï¼‰ï¼š
# WHERE created_at > $1  -- ä¸»åºï¼šæ—¶é—´æˆ³ä¹‹å
#    OR (created_at = $1 AND id > $2)  -- tie-breakï¼šåŒä¸€æ—¶é—´æˆ³å†…ï¼ŒID æ›´å¤§
# ORDER BY created_at ASC, id ASC
```

**ä¸ºä»€ä¹ˆè¿™æ ·è®¾è®¡**ï¼š

| å­—æ®µ | ä½œç”¨ | ä¸ºä»€ä¹ˆå¿…éœ€ |
|------|------|-----------|
| `created_at` | ä¸»åº | ä¿è¯æ—¶é—´å…ˆåï¼Œæ”¯æŒ `>` æ¯”è¾ƒ |
| `id` | Tie-break | å¤„ç†åŒä¸€æ¯«ç§’å†…çš„å¤šæ¡æ¶ˆæ¯ |
| ä¸¤è€…ç»„åˆ | æ¸¸æ ‡åˆ†é¡µ | ç²¾å‡†ã€å¹‚ç­‰ã€ä¸æ¼æ¶ˆæ¯ |

**PostgreSQL å®ç°ç¤ºä¾‹**ï¼š

```python
class PostgresConversationSummaryStore(ConversationSummaryStorePort):
    async def list_messages_since(
        self,
        conversation_id: str,
        since_created_at: datetime | None,
        since_message_id: str | None,
        limit: int | None = 50
    ) -> list[dict]:
        """è·å–æŒ‡å®šè¦†ç›–ç‚¹ä¹‹åçš„æ–°æ¶ˆæ¯ï¼ˆæ¸¸æ ‡åˆ†é¡µï¼‰"""

        if since_created_at is None:
            # é¦–æ¬¡æ‘˜è¦ï¼šä»å¤´å¼€å§‹
            query = """
            SELECT id, role, content, created_at, metadata
            FROM messages
            WHERE conversation_id = $1
            ORDER BY created_at ASC, id ASC
            LIMIT $2
            """
            return await self.db.fetch(query, conversation_id, limit)

        # âœ… æ¸¸æ ‡åˆ†é¡µï¼š(created_at, id) å¤åˆæ¡ä»¶
        query = """
        SELECT id, role, content, created_at, metadata
        FROM messages
        WHERE conversation_id = $1
          AND (
              created_at > $2  -- ä¸»åºï¼šæ—¶é—´æˆ³ä¹‹å
              OR (created_at = $2 AND id > $3)  -- tie-break
          )
        ORDER BY created_at ASC, id ASC
        LIMIT $4
        """
        return await self.db.fetch(
            query,
            conversation_id,
            since_created_at,
            since_message_id,
            limit
        )
```

**åœºæ™¯ç¤ºä¾‹**ï¼š

```
messages è¡¨æ•°æ®ï¼š
id (UUID v4)          | created_at          | content
----------------------|---------------------|----------
uuid-a (è¾ƒå°)         | 2024-01-01 10:00:00 | msg-1
uuid-b (è¾ƒå¤§)         | 2024-01-01 10:00:00 | msg-2  (åŒä¸€æ¯«ç§’)
uuid-c (è¾ƒå°)         | 2024-01-01 10:00:01 | msg-3
uuid-d (è¾ƒå¤§)         | 2024-01-01 10:00:01 | msg-4  (åŒä¸€æ¯«ç§’)

è¦†ç›–ç‚¹ï¼š(2024-01-01 10:00:00, uuid-a)

âŒ é”™è¯¯ï¼šWHERE id > uuid-a
ç»“æœï¼š[uuid-b, uuid-d]  -- æ¼æ‰ uuid-cï¼ˆæ—¶é—´æ›´æ—©ä½† ID æ›´å°ï¼‰

âœ… æ­£ç¡®ï¼šWHERE created_at > '2024-01-01 10:00:00'
          OR (created_at = '2024-01-01 10:00:00' AND id > uuid-a)
ç»“æœï¼š[uuid-b, uuid-c, uuid-d]  -- å®Œæ•´ï¼Œæ­£ç¡®çš„æ—¶é—´åº
```

**3. æ’é™¤å½“å‰æ¶ˆæ¯ï¼šæŒ‰ message_id**

**âš ï¸ å…³é”®é—®é¢˜**ï¼š`append_message()` æœ¬èº«å·²è¿”å› UUIDï¼Œä½† Handler æ²¡æ¥ä½è¿”å›å€¼ã€‚

**ç°æœ‰ä»£ç çš„é—®é¢˜**ï¼š
```python
# backend/application/chat/handlers/chat_handler.py:159
async def handle(self, message: str):
    await self.store.append_message(...)  # âŒ å¿½ç•¥äº†è¿”å›å€¼ï¼ˆå®ƒæœ¬æ¥å°±è¿”å› UUIDï¼‰

    # backend/application/chat/handlers/chat_handler.py:211
    history = await self.store.list_messages(...)
    for msg in history:
        if msg.get("content") == message:  # âŒ ç”¨ content å»é‡
            history.remove(msg)
```

**âš ï¸ å…³é”®äº‹å®**ï¼š`append_message()` **æœ¬æ¥å°±è¿”å› UUID**ï¼Œä¸éœ€è¦ä¿®æ”¹æ¥å£ï¼

```python
# backend/infrastructure/persistence/postgres/conversation_store.py:44-65
async def append_message(
    self,
    *,
    conversation_id: UUID,
    role: str,
    content: str,
    citations: Optional[Dict[str, Any]] = None,
    debug: Optional[Dict[str, Any]] = None,
) -> UUID:  # âœ… å·²ç»è¿”å› UUIDï¼Œä¸éœ€è¦ä¿®æ”¹ï¼
    msg_id = uuid4()
    self._messages.setdefault(conversation_id, []).append({
        "id": msg_id,
        "conversation_id": conversation_id,
        "role": role,
        "content": content,
        "created_at": datetime.utcnow(),
        "citations": citations,
        "debug": debug,
    })
    return msg_id  # âœ… å·²ç»è¿”å› UUID
```

**è§£å†³æ–¹æ¡ˆï¼šHandler æ¥ä½è¿”å›å€¼**

```python
async def handle(self, message: str, conversation_id: str):
    # ç¬¬1æ­¥ï¼šå†™å…¥å½“å‰ user æ¶ˆæ¯ï¼Œæ‹¿åˆ° ID
    current_message_id = await self.store.append_message(
        conversation_id=conversation_id,
        role="user",
        content=message
    )

    # ç¬¬2æ­¥ï¼šè·å–å¾…æ‘˜è¦æ¶ˆæ¯ï¼ˆåŸºäºè¦†ç›–ç‚¹ï¼‰
    new_messages = await self.summary_store.list_messages_since(
        conversation_id=conversation_id,
        since_created_at=last_covered_at,
        since_message_id=last_covered_id,
        limit=None
    )
    
    # ç¬¬3æ­¥ï¼šæ’é™¤å½“å‰æ¶ˆæ¯ï¼ˆæŒ‰ IDï¼‰
    new_messages = [msg for msg in new_messages if msg["id"] != current_message_id]
    
    # ç¬¬4æ­¥ï¼šä¼ é€’ ID åˆ°åç»­æµç¨‹
    response = await self.executor.generate(message, current_message_id=current_message_id)
    
    return response
```

**å¤‡é€‰æ–¹æ¡ˆï¼šè°ƒæ•´æµç¨‹é¡ºåºï¼ˆå…ˆè¯»å†å²ï¼Œå†å†™å…¥ï¼‰**

```python
async def handle(self, message: str, conversation_id: str):
    # ç¬¬1æ­¥ï¼šå…ˆè¯»å†å²ï¼ˆä¸åŒ…å«å½“å‰æ¶ˆæ¯ï¼‰
    new_messages = await self.summary_store.list_messages_since(
        conversation_id=conversation_id,
        since_created_at=last_covered_at,
        since_message_id=last_covered_id,
        limit=None
    )

    # ç¬¬2æ­¥ï¼šç”Ÿæˆå“åº”ï¼ˆä½¿ç”¨æ—§å†å²ï¼‰
    response = await self.executor.generate(message, history=new_messages)

    # ç¬¬3æ­¥ï¼šå†™å…¥å½“å‰ user æ¶ˆæ¯ï¼ˆç”Ÿæˆå®Œæˆåï¼‰
    await self.store.append_message(
        conversation_id=conversation_id,
        role="user",
        content=message
    )

    return response
```

**æ–¹æ¡ˆå¯¹æ¯”**ï¼š

| ç»´åº¦ | æ¨èæ–¹æ¡ˆï¼šæ¥ä½è¿”å›å€¼ | å¤‡é€‰æ–¹æ¡ˆï¼šè°ƒæ•´æµç¨‹ |
|------|----------------|-------------|
| **ä¼˜ç‚¹** | æµç¨‹æ¸…æ™°ï¼Œç¬¦åˆç°æœ‰é€»è¾‘ | ä¸éœ€è¦ä¿®æ”¹æ¥å£ |
| **ç¼ºç‚¹** | éœ€è¦ä¿®æ”¹ Handler ä»£ç  | å“åº”ç”Ÿæˆä¸åŒ…å«å½“å‰æ¶ˆæ¯ |
| **æ¨è** | âœ… æ¨èï¼ˆç®€å•ç›´æ¥ï¼‰ | å¤‡é€‰æ–¹æ¡ˆ |

**å®ç°æ£€æŸ¥æ¸…å•**ï¼š
- [ ] âœ… **`append_message()` æœ¬èº«å·²ç»è¿”å› UUIDï¼Œä¸éœ€è¦ä¿®æ”¹æ¥å£**
- [ ] Handler ä¿ç•™ `current_message_id` å¹¶ä¼ é€’åˆ°æ‘˜è¦é€»è¾‘
- [ ] æ‘˜è¦ç”Ÿæˆä½¿ç”¨ `[msg for msg in new_messages if msg["id"] != current_message_id]` æ’é™¤
- [ ] å»é™¤æ‰€æœ‰ `content == message` çš„åˆ¤æ–­é€»è¾‘ï¼ˆ**å½»åº•ç§»é™¤ content å»é‡**ï¼‰

**4. ä¿å­˜å¤åˆè¦†ç›–ç‚¹**

```python
# âœ… æ›´æ–°è¦†ç›–ç‚¹æ—¶ï¼ŒåŒæ—¶å­˜å‚¨æ—¶é—´æˆ³å’Œ ID
await store.save_summary_upsert(
    conversation_id=conversation_id,
    summary=new_summary_text,
    covered_through_created_at=new_messages[-1]["created_at"],  # âœ… æ—¶é—´æˆ³
    covered_through_message_id=new_messages[-1]["id"],           # âœ… ID
    covered_count=previous_count + len(new_messages)
)
```

**å…³é”®ä¼˜åŠ¿**ï¼š
- âœ… **ç²¾å‡†åˆ‡ç‰‡**ï¼š`created_at > ... OR (created_at = ... AND id > ...)` ä¿è¯è¾¹ç•Œç¨³å®š
- âœ… **å¹‚ç­‰æ€§**ï¼šåŒä¸€è¦†ç›–ç‚¹æ¯æ¬¡è¿”å›ç›¸åŒç»“æœ
- âœ… **ä¸æ¼æ¶ˆæ¯**ï¼šæ­£ç¡®å¤„ç†åŒä¸€æ¯«ç§’å†…çš„å¤šæ¡æ¶ˆæ¯
- âœ… **å†…å®¹æ— å…³**ï¼šå³ä½¿æœ‰é‡å¤å†…å®¹ï¼Œä¹Ÿä¸ä¼šè¯¯åˆ 
- âœ… **å¯è¿½æº¯**ï¼šæ¸…æ™°çŸ¥é“æ‘˜è¦è¦†ç›–åˆ°å“ªä¸ªæ—¶é—´ç‚¹å’Œå“ªæ¡æ¶ˆæ¯

**å®ç°æ£€æŸ¥æ¸…å•**ï¼š
- [ ] æ•°æ®è¡¨å¢åŠ  `covered_through_created_at` å’Œ `covered_through_message_id` å­—æ®µ
- [ ] æ‘˜è¦ç”Ÿæˆä½¿ç”¨æ¸¸æ ‡åˆ†é¡µ `(created_at, id)` å¤åˆæ¡ä»¶
- [ ] æ’é™¤å½“å‰æ¶ˆæ¯ä½¿ç”¨ `message_id` æ¯”è¾ƒï¼ˆä¸æ˜¯ `content`ï¼‰
- [ ] å»é™¤æ‰€æœ‰ `content == message` çš„åˆ¤æ–­é€»è¾‘
- [ ] ï¼ˆé•¿æœŸæ–¹æ¡ˆï¼‰è€ƒè™‘æ”¹ç”¨ UUID v7 / ULID ä½œä¸ºæ¶ˆæ¯ IDï¼ˆæ”¯æŒæ—¶é—´åºï¼‰

**é—®é¢˜3è¯¦è§£ï¼šæ€§èƒ½ä¸å¹¶å‘é£é™©ï¼ˆåŒæ­¥æ‹–æ…¢è¯·æ±‚ã€å¹¶å‘è¦†ç›–ã€partialæ±¡æŸ“ï¼‰**

**âš ï¸ å½“å‰ä»£ç çŠ¶æ€**ï¼š
- **æ²¡æœ‰ä»»ä½• summarizer/task manager å®ç°**
- **æ²¡æœ‰ä»»ä½•æ‘˜è¦è§¦å‘é€»è¾‘**
- **æµå¼ä¸­æ–­ä¼šæ±¡æŸ“æ‘˜è¦ï¼ˆç”Ÿäº§ç¯å¢ƒæ— æ ‡è®°ï¼‰**

**åŸè®¾è®¡çš„ä¸‰ä¸ªæ ¸å¿ƒé—®é¢˜**ï¼š

**é—®é¢˜Aï¼šåŒæ­¥ç”Ÿæˆæ‘˜è¦ä¼šæ‹–æ…¢ç”¨æˆ·è¯·æ±‚**

```python
# âŒ é—®é¢˜ä»£ç ï¼šåŒæ­¥ç”Ÿæˆï¼ˆé˜»å¡ä¸»è¯·æ±‚ï¼‰
async def handle_message(user_message: str):
    # 1. ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
    await store.append_message(user_message)

    # 2. åŒæ­¥ç”Ÿæˆæ‘˜è¦ï¼ˆâš ï¸ é˜»å¡å“åº”ï¼‰
    if should_summarize():
        summary = await generate_summary(...)  # è€—æ—¶ 2-5 ç§’
        await store.save_summary(summary)

    # 3. ç”Ÿæˆå›å¤
    response = await generate_response(user_message)

    return response  # ç”¨æˆ·ç­‰å¾…æ—¶é—´ = ç”Ÿæˆæ‘˜è¦ + ç”Ÿæˆå›å¤
```

**å½±å“**ï¼š
- ç”¨æˆ·æ„ŸçŸ¥å»¶è¿Ÿï¼š2-5 ç§’ï¼ˆæ‘˜è¦ç”Ÿæˆæ—¶é—´ï¼‰
- ç”¨æˆ·ä½“éªŒå·®ï¼šæ¯æ¬¡è¾¾åˆ°é˜ˆå€¼éƒ½è¦ç­‰å¾…
- èµ„æºæµªè´¹ï¼šæ‘˜è¦å¤±è´¥ä¼šå¯¼è‡´æ•´ä¸ªè¯·æ±‚å¤±è´¥

**é—®é¢˜Bï¼šç®€å• UNIQUE çº¦æŸæ— æ³•é˜²æ­¢å¹¶å‘è¦†ç›–**

```sql
-- âŒ é—®é¢˜è®¾è®¡ï¼šä»…æœ‰ UNIQUE çº¦æŸ
CREATE TABLE conversation_summaries (
    conversation_id UUID PRIMARY KEY,  -- UNIQUE çº¦æŸ
    summary TEXT,
    ...
);
```

**å¹¶å‘åœºæ™¯ç¤ºä¾‹**ï¼š

```
æ—¶é—´çº¿ï¼š
T1: è¯·æ±‚A è¯»å–æ‘˜è¦ (version=1, covered_id=msg-10)
T2: è¯·æ±‚B è¯»å–æ‘˜è¦ (version=1, covered_id=msg-10)
T3: è¯·æ±‚A ç”Ÿæˆæ–°æ‘˜è¦ (version=2, covered_id=msg-15)
T4: è¯·æ±‚B ç”Ÿæˆæ–°æ‘˜è¦ (version=2, covered_id=msg-20)
T5: è¯·æ±‚A å†™å…¥æ‘˜è¦ (covered_id=msg-15) âœ…
T6: è¯·æ±‚B å†™å…¥æ‘˜è¦ (covered_id=msg-20) âœ…

ç»“æœï¼š
- è¯·æ±‚A çš„æ‘˜è¦è¢«è¯·æ±‚B è¦†ç›–
- æ¶ˆæ¯ 11-15 çš„æ‘˜è¦ä¸¢å¤±
- æ‘˜è¦ä¸ä¸€è‡´ï¼ˆå®é™…è¦†ç›–åˆ° msg-20ï¼Œä½†ç‰ˆæœ¬å·è¿˜æ˜¯ 2ï¼‰
```

**é—®é¢˜Cï¼šPartial æ¶ˆæ¯æ±¡æŸ“æ‘˜è¦ï¼ˆç”Ÿäº§ç¯å¢ƒä¸å¯è¯†åˆ«ï¼‰**

**âš ï¸ å½“å‰ä»£ç æ²¡æœ‰ä»»ä½• completed æ ‡è®°æœºåˆ¶**ï¼š

```python
# backend/application/chat/handlers/stream_handler.py:245-252
# å®é™…æƒ…å†µï¼šæµç»“æŸåä¸€æ¬¡æ€§è½åº“ï¼Œä¸æ˜¯"æµå¼è¿‡ç¨‹ä¸­ä¸æ–­è½åº“"

async def stream_response(message: str):
    full_response = ""

    try:
        # æµå¼ç”Ÿæˆä¸­...
        async for chunk in llm.stream():
            full_response += chunk
            yield chunk

        # âš ï¸ æµç»“æŸåä¸€æ¬¡æ€§è½åº“ï¼ˆä¸æ˜¯è¿‡ç¨‹ä¸­ï¼‰
        await store.append_message(
            conversation_id,
            "assistant",
            full_response,  # å®Œæ•´å“åº”
            metadata={
                "debug": {"partial": True} if self.debug else {}  # âš ï¸ åªåœ¨ debug=True æ—¶æœ‰ partial æ ‡è®°
            }
        )

    except Exception as e:
        # âš ï¸ æ–­è¿æ—¶ä¹Ÿä¼šè½åº“"åŠæˆª assistant"
        await store.append_message(
            conversation_id,
            "assistant",
            full_response,  # ä¸å®Œæ•´
            metadata={
                "debug": {"partial": True, "error": str(e)} if self.debug else {}  # âš ï¸ é debug æ²¡æœ‰ä»»ä½•æ ‡è®°
            }
        )
        raise
```

**å…³é”®é—®é¢˜**ï¼š

| åœºæ™¯ | Debug=True | Debug=Falseï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰ |
|------|-----------|---------------------|
| æ­£å¸¸å®Œæˆ | æœ‰ `debug.partial=True` | æ— æ ‡è®° âœ… |
| æµå¼ä¸­æ–­ | æœ‰ `debug.partial=True + error` | **æ— æ ‡è®°** âŒ |
| æ‘˜è¦è¿‡æ»¤ | âœ… å¯ä»¥è¿‡æ»¤ | âŒ **æ— æ³•è¿‡æ»¤**ï¼ˆæ²¡æœ‰æ ‡è®°ï¼‰ |

**å®é™…åæœ**ï¼š
- ç”Ÿäº§ç¯å¢ƒçš„æ–­è¿åœºæ™¯ä¼šè½åº“"åŠæˆª assistant"ï¼Œä½† **æ²¡æœ‰ä»»ä½• partial æ ‡è®°**
- æ‘˜è¦ç”Ÿæˆæ— æ³•è¯†åˆ«è¿™äº›ä¸å®Œæ•´çš„æ¶ˆæ¯
- æ‘˜è¦ä¼šè¢«æ±¡æŸ“ï¼ŒåŒ…å«ä¸å®Œæ•´çš„ assistant å†…å®¹

**é—®é¢˜åœºæ™¯**ï¼š

```
å¯¹è¯æµç¨‹ï¼ˆç”Ÿäº§ç¯å¢ƒï¼Œdebug=Falseï¼‰ï¼š
1. user: "æ¨èç”µå½±"
2. assistant: (å¼€å§‹æµå¼ç”Ÿæˆ) "æˆ‘æ¨èã€Šæ˜Ÿé™…ç©¿è¶Šã€‹ï¼Œå®ƒæ˜¯è¯ºå…°å¯¼æ¼”çš„..."
3. [ç½‘ç»œä¸­æ–­/LLMè¶…æ—¶]
4. æµå¼å¼‚å¸¸ï¼Œè§¦å‘ except åˆ†æ”¯

æ•°æ®åº“è®°å½•ï¼š
messages è¡¨ï¼š
  id: uuid-xxx
  role: "assistant"
  content: "æˆ‘æ¨èã€Šæ˜Ÿé™…ç©¿è¶Šã€‹ï¼Œå®ƒæ˜¯è¯ºå…°å¯¼æ¼”çš„..."  â† ä¸å®Œæ•´
  metadata: {}  â† âš ï¸ ç©ºçš„ï¼Œæ²¡æœ‰ä»»ä½• partial æ ‡è®°ï¼

æ‘˜è¦ç”Ÿæˆï¼š
- æ— æ³•è¯†åˆ«è¿™æ˜¯ä¸å®Œæ•´çš„æ¶ˆæ¯
- æ‘˜è¦åŒ…å«ï¼š"ç”¨æˆ·è¯¢é—®äº†ç”µå½±æ¨èï¼Œç³»ç»Ÿæ¨èäº†ã€Šæ˜Ÿé™…ç©¿è¶Šã€‹"
- å®é™…ä¸Šæ¨èä¸å®Œæ•´ï¼Œæ²¡æœ‰è¯´å®Œæ•´ç†ç”±
```

**å¯¼è‡´çš„é—®é¢˜**ï¼š
1. **æ‘˜è¦æ±¡æŸ“**ï¼šåŒ…å«ä¸å®Œæ•´çš„ assistant å†…å®¹
2. **é”™è¯¯ä¿¡æ¯ä¼ æ’­**ï¼šé•¿æœŸè®°å¿†ä¸­åŒ…å«åŠæˆªä¿¡æ¯
3. **ç”¨æˆ·å›°æƒ‘**ï¼š"åˆšæ‰æåˆ°çš„ç”µå½±" ä½†å®é™…æ²¡æœ‰å®Œæ•´æ¨è
4. **æ— æ³•è¿‡æ»¤**ï¼šç”Ÿäº§ç¯å¢ƒæ²¡æœ‰ partial æ ‡è®°

---

**å®Œæ•´çš„è§£å†³æ–¹æ¡ˆ**

**âš ï¸ å®æ–½å‰çš„å…³é”®è®¤çŸ¥**ï¼š
1. **å½“å‰ä»£ç æ²¡æœ‰ä»»ä½•å®ç°**ï¼šæ²¡æœ‰ summarizerï¼Œæ²¡æœ‰ task managerï¼Œæ²¡æœ‰è§¦å‘é€»è¾‘
2. **ä¸è¦ä¾èµ–æµå¼è¯·æ±‚ä¸Šä¸‹æ–‡**ï¼š`background_tasks.add_task()` åœ¨æµå¼åœºæ™¯ä¼šä¸¢å¤±
3. **ç”Ÿäº§ç¯å¢ƒçš„é—®é¢˜æœ€ä¸¥é‡**ï¼š`debug=False` æ—¶æ–­è¿æ²¡æœ‰ä»»ä½•æ ‡è®°ï¼Œä¼šæ±¡æŸ“æ‘˜è¦

**1. ä¿®å¤æ¶ˆæ¯å®Œæˆæ ‡è®°ï¼ˆä¸ä¾èµ– debugï¼‰**

```python
# âœ… è§£å†³æ–¹æ¡ˆï¼šæ·»åŠ ä¸ debug æ— å…³çš„ completed å­—æ®µ
async def stream_response(message: str, conversation_id: str):
    full_response = ""

    try:
        # æµå¼ç”Ÿæˆä¸­...
        async for chunk in llm.stream():
            full_response += chunk
            yield chunk

        # âœ… æ­£å¸¸å®Œæˆï¼šæ˜ç¡®æ ‡è®°ï¼ˆä¸ debug æ— å…³ï¼‰
        await store.append_message(
            conversation_id,
            "assistant",
            full_response,
            metadata={
                "completed": True,  # âœ… æ–°å¢ï¼šæ˜ç¡®çš„å®Œæˆæ ‡è®°
                "debug": {...} if self.debug else {}
            }
        )

        # âœ… è¿”å›å®ŒæˆçŠ¶æ€ï¼ˆç”¨äºè§¦å‘æ‘˜è¦ï¼‰
        return StreamResponse(completed_normally=True, message_id=...)

    except Exception as e:
        # âš ï¸ å¼‚å¸¸ä¸­æ–­ï¼šæ˜ç¡®æ ‡è®°ä¸ºæœªå®Œæˆï¼ˆä¸ debug æ— å…³ï¼‰
        await store.append_message(
            conversation_id,
            "assistant",
            full_response,  # ä¸å®Œæ•´
            metadata={
                "completed": False,  # âœ… æ–°å¢ï¼šæ˜ç¡®çš„æœªå®Œæˆæ ‡è®°
                "error": str(e),
                "debug": {...} if self.debug else {}
            }
        )

        # âœ… è¿”å›å¤±è´¥çŠ¶æ€ï¼ˆä¸è§¦å‘æ‘˜è¦ï¼‰
        return StreamResponse(completed_normally=False, message_id=...)
```

**2. åå°å¼‚æ­¥ä»»åŠ¡å®ç°ï¼ˆçœŸå®çš„ä»»åŠ¡æ‰¿è½½ï¼Œä¸ä¾èµ–æµå¼è¯·æ±‚ä¸Šä¸‹æ–‡ï¼‰**

```python
# âœ… è§£å†³æ–¹æ¡ˆï¼šå¼‚æ­¥åå°ç”Ÿæˆï¼ˆçœŸå®çš„åå°ä»»åŠ¡é˜Ÿåˆ—ï¼‰
import asyncio
from typing import Optional

class SummaryTaskManager:
    """æ‘˜è¦ä»»åŠ¡ç®¡ç†å™¨ï¼ˆè¿›ç¨‹å†…é˜Ÿåˆ—ï¼‰

    âš ï¸ å…³é”®è®¾è®¡åŸåˆ™ï¼š
    - ä¸ä¾èµ–æµå¼è¯·æ±‚ä¸Šä¸‹æ–‡ï¼ˆä»»åŠ¡åœ¨ç‹¬ç«‹ worker ä¸­æ‰§è¡Œï¼‰
    - åº”ç”¨å¯åŠ¨æ—¶å¯åŠ¨ workerï¼ˆä¸æ˜¯æŒ‰éœ€åˆ›å»ºï¼‰
    - æœåŠ¡é‡å¯ä¼šä¸¢å¤±ä»»åŠ¡ï¼ˆå¯å‡çº§ä¸º DB job è¡¨ï¼‰
    """

    def __init__(self, max_concurrent: int = 10):
        self.queue = asyncio.Queue()
        self.workers = []
        self.max_concurrent = max_concurrent
        self.summarizer = None  # ç”±å¤–éƒ¨æ³¨å…¥

    async def start(self):
        """å¯åŠ¨åå° workerï¼ˆåº”ç”¨å¯åŠ¨æ—¶è°ƒç”¨ï¼‰"""
        for i in range(self.max_concurrent):
            worker = asyncio.create_task(self._worker(f"worker-{i}"))
            self.workers.append(worker)

    async def _worker(self, name: str):
        """åå° workerï¼šæŒç»­å¤„ç†é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡ï¼ˆç‹¬ç«‹äºæµå¼è¯·æ±‚ï¼‰"""
        while True:
            try:
                task = await self.queue.get()
                conversation_id, retry_count = task

                logger.info(f"[{name}] å¤„ç†æ‘˜è¦ä»»åŠ¡: {conversation_id}")

                try:
                    await self.summarizer.try_trigger_update(conversation_id)
                    logger.info(f"[{name}] æ‘˜è¦å®Œæˆ: {conversation_id}")
                except Exception as e:
                    logger.error(f"[{name}] æ‘˜è¦å¤±è´¥: {conversation_id}, {e}")

                    # é‡è¯•é€»è¾‘
                    if retry_count < 3:
                        await asyncio.sleep(2 ** retry_count)  # æŒ‡æ•°é€€é¿
                        await self.queue.put((conversation_id, retry_count + 1))

                self.queue.task_done()
            except asyncio.CancelledError:
                logger.info(f"[{name}] Worker å·²åœæ­¢")
                break
            except Exception as e:
                logger.error(f"[{name}] Worker å¼‚å¸¸: {e}")
                await asyncio.sleep(1)  # é˜²æ­¢æ— é™å¾ªç¯

    async def enqueue(self, conversation_id: str):
        """å°†æ‘˜è¦ä»»åŠ¡åŠ å…¥é˜Ÿåˆ—ï¼ˆä¸ç­‰å¾…å®Œæˆï¼‰"""
        await self.queue.put((conversation_id, 0))

# å…¨å±€å•ä¾‹
summary_task_manager = SummaryTaskManager()

# åº”ç”¨å¯åŠ¨æ—¶å¯åŠ¨ workerï¼ˆâš ï¸ å…³é”®ï¼šä¸æ˜¯åœ¨æµå¼è¯·æ±‚ä¸­å¯åŠ¨ï¼‰
@app.on_event("startup")
async def startup():
    summary_task_manager.summarizer = summarizer  # æ³¨å…¥ä¾èµ–
    await summary_task_manager.start()
    logger.info("æ‘˜è¦ä»»åŠ¡ç®¡ç†å™¨å·²å¯åŠ¨")

# âœ… åœ¨æµå¼å“åº”å®Œæˆåè§¦å‘ï¼ˆä¸ä¾èµ–æµå¼è¯·æ±‚ä¸Šä¸‹æ–‡ï¼‰
async def handle_message(user_message: str, conversation_id: str):
    # 1. ç”Ÿæˆå“åº”
    stream_response = await generate_response(user_message)

    # 2. æ”¶é›†å®Œæ•´å“åº”
    full_response = ""
    async for chunk in stream_response:
        full_response += chunk
        yield chunk  # æµå¼è¿”å›ç»™ç”¨æˆ·

    # 3. æ£€æŸ¥å®ŒæˆçŠ¶æ€
    if stream_response.completed_normally:  # âœ… ä»…æ­£å¸¸å®Œæˆæ—¶è§¦å‘
        # âœ… åŠ å…¥åå°ä»»åŠ¡é˜Ÿåˆ—ï¼ˆä¸ç­‰å¾…å®Œæˆï¼‰
        await summary_task_manager.enqueue(conversation_id)

    # 4. ç«‹å³è¿”å›ï¼ˆä¸ç­‰å¾…æ‘˜è¦ï¼‰
    return
```

**å…³é”®è®¾è®¡ç‚¹**ï¼š
- **çœŸå®çš„åå°ä»»åŠ¡**ï¼šä½¿ç”¨ `SummaryTaskManager` è¿›ç¨‹å†…é˜Ÿåˆ—ï¼Œä¸æ˜¯ç®€å•çš„ `background_tasks.add_task()`
- **ä¸ä¾èµ–æµå¼è¯·æ±‚ä¸Šä¸‹æ–‡**ï¼šWorker åœ¨åº”ç”¨å¯åŠ¨æ—¶å¯åŠ¨ï¼Œç‹¬ç«‹äºä»»ä½•æµå¼è¯·æ±‚
- **ä¸é˜»å¡ä¸»è¯·æ±‚**ï¼šæ‘˜è¦ä»»åŠ¡åœ¨åå° worker ä¸­å¤„ç†ï¼Œç«‹å³è¿”å›
- **é‡å¯ä¸¢å¤±é—®é¢˜**ï¼šè¿›ç¨‹å†…é˜Ÿåˆ—åœ¨æœåŠ¡é‡å¯æ—¶ä¼šä¸¢å¤±ä»»åŠ¡ï¼Œéœ€è¦æ ¹æ®ä¸šåŠ¡éœ€æ±‚å†³å®šæ˜¯å¦å‡çº§ä¸ºæŒä¹…åŒ–é˜Ÿåˆ—ï¼ˆRedis/DB + workerï¼‰
- **ä»…æ­£å¸¸å®Œæˆæ—¶è§¦å‘**ï¼šæ£€æŸ¥ `completed_normally`ï¼Œé¿å… partial æ±¡æŸ“

**âš ï¸ å®æ–½æ—¶çš„å…³é”®æ³¨æ„äº‹é¡¹**ï¼š
1. **å¿…é¡»åœ¨åº”ç”¨å¯åŠ¨æ—¶å¯åŠ¨ worker**ï¼ˆä¸æ˜¯åœ¨æµå¼è¯·æ±‚ä¸­æŒ‰éœ€åˆ›å»ºï¼‰
2. **å¿…é¡»æ£€æŸ¥ `completed_normally`**ï¼ˆåªå¯¹æ­£å¸¸å®Œæˆçš„å›åˆç”Ÿæˆæ‘˜è¦ï¼‰
3. **å¿…é¡»ä½¿ç”¨ `completed` å­—æ®µè¿‡æ»¤**ï¼ˆåªå¤„ç† `completed=True` çš„æ¶ˆæ¯ï¼‰
4. **ç”Ÿäº§ç¯å¢ƒï¼ˆdebug=Falseï¼‰æ˜¯æœ€ä¸¥é‡çš„åœºæ™¯**ï¼ˆæ–­è¿æ²¡æœ‰ä»»ä½•æ ‡è®°ï¼‰

**2. èŠ‚æµæœºåˆ¶ï¼ˆé¿å…é¢‘ç¹æ›´æ–°ï¼‰**

```python
# âœ… è§£å†³æ–¹æ¡ˆï¼šèŠ‚æµ + åŒé‡æ£€æŸ¥
class ConversationSummarizer:
    def __init__(self):
        self.min_messages = 10      # è§¦å‘é˜ˆå€¼
        self.update_delta = 5       # æ›´æ–°å¢é‡

    async def try_trigger_update(self, conversation_id: str):
        """å°è¯•è§¦å‘åå°æ‘˜è¦æ›´æ–°ï¼ˆå¸¦èŠ‚æµï¼‰"""

        # 1. æ£€æŸ¥æ¶ˆæ¯æ€»æ•°
        total_count = await self.summary_store.count_messages(conversation_id)
        if total_count < self.min_messages:
            return  # æœªè¾¾åˆ°é˜ˆå€¼ï¼Œä¸ç”Ÿæˆ

        # 2. è·å–å½“å‰æ‘˜è¦çŠ¶æ€ï¼ˆå¤åˆè¦†ç›–ç‚¹ï¼‰
        summary_data = await self.summary_store.get_summary(conversation_id)
        last_covered_at = summary_data.get("covered_through_created_at") if summary_data else None
        last_covered_id = summary_data.get("covered_through_message_id") if summary_data else None

        # 3. âœ… æ£€æŸ¥å¢é‡ï¼ˆä»…å½“æ–°å¢ >= 5 æ¡æ—¶æ‰è§¦å‘ï¼Œä½¿ç”¨å¤åˆæ¸¸æ ‡ï¼‰
        new_messages = await self.summary_store.list_messages_since(
            conversation_id=conversation_id,
            since_created_at=last_covered_at,  # âœ… å¤åˆæ¸¸æ ‡ï¼šæ—¶é—´æˆ³
            since_message_id=last_covered_id,  # âœ… å¤åˆæ¸¸æ ‡ï¼šID
            limit=self.update_delta + 1  # å¤šå– 1 æ¡ç”¨äºåˆ¤æ–­
        )

        if len(new_messages) < self.update_delta:
            return  # å¢é‡ä¸è¶³ï¼Œä¸æ›´æ–°

        # 4. âœ… è¿‡æ»¤æœªå®Œæˆæ¶ˆæ¯ï¼ˆä½¿ç”¨ completed å­—æ®µï¼‰
        valid_messages = [
            msg for msg in new_messages
            if (msg.metadata.get("completed", True) and  # âœ… ä¼˜å…ˆæ£€æŸ¥ completed
                 not msg.metadata.get("debug", {}).get("partial", False))  # âœ… å…¼å®¹ debug.partial
        ]

        if not valid_messages:
            return  # æ‰€æœ‰æ¶ˆæ¯éƒ½æ˜¯æœªå®Œæˆçš„ï¼Œä¸ç”Ÿæˆæ‘˜è¦

        # 5. ç”Ÿæˆå¹¶ä¿å­˜æ‘˜è¦
        await self._generate_and_save(conversation_id, summary_data, valid_messages)
```

**èŠ‚æµæ•ˆæœ**ï¼š
- æ¯ 5 æ¡æ¶ˆæ¯æ‰æ›´æ–°ä¸€æ¬¡æ‘˜è¦
- é¿å…æ¯æ¬¡è¯·æ±‚éƒ½è§¦å‘
- é™ä½æ•°æ®åº“å†™å…¥å‹åŠ›

**3. å•è°ƒé€’å¢çº¦æŸ + ä¹è§‚é”ï¼ˆé˜²æ­¢å¹¶å‘è¦†ç›–ï¼‰**

```sql
-- âœ… è§£å†³æ–¹æ¡ˆï¼šUPSERT + å•è°ƒé€’å¢çº¦æŸï¼ˆå¤åˆæ¡ä»¶ï¼‰ + ä¹è§‚é”
INSERT INTO conversation_summaries
    (conversation_id, summary, covered_through_created_at, covered_through_message_id,
     covered_message_count, summary_version)
VALUES ($1, $2, $3, $4, $5, 1)
ON CONFLICT (conversation_id) DO UPDATE SET
    summary = EXCLUDED.summary,
    covered_through_created_at = EXCLUDED.covered_through_created_at,
    covered_through_message_id = EXCLUDED.covered_through_message_id,
    covered_message_count = EXCLUDED.covered_message_count,
    summary_version = conversation_summaries.summary_version + 1,
    updated_at = NOW()
WHERE
    -- âœ… çº¦æŸ1ï¼šå•è°ƒé€’å¢ï¼ˆå¤åˆæ¡ä»¶ï¼Œåªå…è®¸è¦†ç›–ç‚¹å‰è¿›ï¼‰
    (conversation_summaries.covered_through_created_at < EXCLUDED.covered_through_created_at)
    OR (conversation_summaries.covered_through_created_at = EXCLUDED.covered_through_created_at
        AND conversation_summaries.covered_through_message_id IS DISTINCT FROM EXCLUDED.covered_through_message_id)
    AND EXCLUDED.covered_through_message_id IS NOT NULL

    -- âœ… çº¦æŸ2ï¼šä¹è§‚é”ï¼ˆç‰ˆæœ¬æ£€æŸ¥ï¼‰
    AND ($6 IS NULL OR conversation_summaries.summary_version = $6)
RETURNING summary_version;
```

**å·¥ä½œåŸç†**ï¼š

```
åœºæ™¯ï¼šä¸¤ä¸ªå¹¶å‘è¯·æ±‚

è¯·æ±‚Aï¼šcovered=(2024-01-01 10:00:00, msg-15) (version 1â†’2)
è¯·æ±‚Bï¼šcovered=(2024-01-01 10:00:05, msg-20) (version 1â†’2)

æ‰§è¡Œåºåˆ—ï¼š
1. è¯·æ±‚A å°è¯•å†™å…¥ (version 2, covered=(10:00:00, msg-15))
   - WHERE æ£€æŸ¥ï¼š10:00:00 > ä¹‹å‰çš„æ—¶é—´ âœ…
   - ç‰ˆæœ¬æ£€æŸ¥ï¼šsummary_version = 1 âœ…
   - å†™å…¥æˆåŠŸ âœ…

2. è¯·æ±‚B å°è¯•å†™å…¥ (version 2, covered=(10:00:05, msg-20))
   - WHERE æ£€æŸ¥ï¼š10:00:05 > 10:00:00 âœ…
   - ç‰ˆæœ¬æ£€æŸ¥ï¼šsummary_version = 2 âŒ (å·²ç»æ˜¯ 2 äº†)
   - å†™å…¥å¤±è´¥ï¼Œè¿”å› NULL âš ï¸

3. è¯·æ±‚B é‡è¯•ï¼ˆè¯»å–æœ€æ–°çŠ¶æ€ï¼‰
   - è¯»å–ï¼šversion=2, covered=(10:00:00, msg-15)
   - ç”Ÿæˆæ–°æ‘˜è¦ï¼šversion 2â†’3, covered=(10:00:05, msg-20)
   - ç‰ˆæœ¬æ£€æŸ¥ï¼šsummary_version = 2 âœ…
   - å†™å…¥æˆåŠŸ âœ…

ç»“æœï¼š
- âœ… æ— æ•°æ®ä¸¢å¤±
- âœ… æ‘˜è¦å•è°ƒé€’å¢ï¼ˆmsg-10 â†’ msg-15 â†’ msg-20ï¼‰
- âœ… ç‰ˆæœ¬å·è¿ç»­ï¼ˆ1 â†’ 2 â†’ 3ï¼‰
```

**4. Partial æ¶ˆæ¯è¿‡æ»¤ï¼ˆé˜²æ­¢æ‘˜è¦æ±¡æŸ“ï¼‰**

```python
# âœ… è§£å†³æ–¹æ¡ˆï¼šå¤šå±‚è¿‡æ»¤æœºåˆ¶

# ç¬¬1å±‚ï¼šæµå¼å“åº”æ ‡è®°ï¼ˆä½¿ç”¨ completed å­—æ®µï¼‰
async def stream_response(message: str, conversation_id: str):
    full_response = ""
    try:
        async for chunk in llm.stream():
            full_response += chunk
            yield chunk

        # âœ… æ­£å¸¸å®Œæˆï¼šæ˜ç¡®æ ‡è®°ä¸ºå®Œæˆ
        await store.append_message(
            conversation_id,
            "assistant",
            full_response,
            metadata={
                "completed": True,  # âœ… æ–°å¢ï¼šæ˜ç¡®çš„å®Œæˆæ ‡è®°
                "debug": {...} if self.debug else {}
            }
        )

        # âœ… è¿”å›å®ŒæˆçŠ¶æ€
        return StreamResponse(completed_normally=True, message_id=...)

    except Exception as e:
        # âš ï¸ å¼‚å¸¸ä¸­æ–­ï¼šæ˜ç¡®æ ‡è®°ä¸ºæœªå®Œæˆ
        await store.append_message(
            conversation_id,
            "assistant",
            full_response,  # ä¸å®Œæ•´
            metadata={
                "completed": False,  # âœ… æ–°å¢ï¼šæ˜ç¡®çš„æœªå®Œæˆæ ‡è®°
                "error": str(e),
                "debug": {...} if self.debug else {}
            }
        )

        # âœ… è¿”å›å¤±è´¥çŠ¶æ€
        return StreamResponse(completed_normally=False, message_id=...)
        raise

# ç¬¬2å±‚ï¼šæ‘˜è¦ç”Ÿæˆè¿‡æ»¤ï¼ˆä½¿ç”¨ completed + debug.partialï¼‰
async def try_trigger_update(self, conversation_id: str):
    new_messages = await self.summary_store.list_messages_since(
        conversation_id=conversation_id,
        since_created_at=last_covered_at,
        since_message_id=last_covered_id,
        limit=None
    )

    # âœ… è¿‡æ»¤æ‰æ‰€æœ‰æœªå®Œæˆæ¶ˆæ¯ï¼ˆä¼˜å…ˆæ£€æŸ¥ completedï¼Œå…¼å®¹ debug.partialï¼‰
    valid_messages = [
        msg for msg in new_messages
        if (msg.metadata.get("completed", True) and  # âœ… ä¼˜å…ˆæ£€æŸ¥ completed
             not msg.metadata.get("debug", {}).get("partial", False))  # âœ… å…¼å®¹ debug.partial
    ]

    if not valid_messages:
        logger.warning("æ‰€æœ‰æ¶ˆæ¯éƒ½æ˜¯æœªå®Œæˆçš„ï¼Œè·³è¿‡æ‘˜è¦ç”Ÿæˆ")
        return

    # ç¬¬3å±‚ï¼šè§¦å‘æ¡ä»¶è¿‡æ»¤
    if not stream_response.completed_normally:
        logger.warning("æµå¼æœªæ­£å¸¸å®Œæˆï¼Œä¸è§¦å‘æ‘˜è¦")
        return

    # ç”Ÿæˆæ‘˜è¦
    await self._generate_and_save(conversation_id, summary_data, valid_messages)
```

**å¤šå±‚é˜²æŠ¤**ï¼š
1. **æµå¼å“åº”æ ‡è®°**ï¼šä½¿ç”¨ `completed` å­—æ®µæ˜ç¡®æ ‡è®°æ¶ˆæ¯æ˜¯å¦å®Œæˆï¼ˆä¸ debug æ— å…³ï¼‰
2. **æ‘˜è¦è¾“å…¥è¿‡æ»¤**ï¼šè¿‡æ»¤æ‰ `completed=False` çš„æ¶ˆæ¯ï¼ˆä¼˜å…ˆæ£€æŸ¥ completedï¼Œå…¼å®¹ debug.partialï¼‰
3. **è§¦å‘æ¡ä»¶è¿‡æ»¤**ï¼šä»…åœ¨ `completed_normally=True` æ—¶è§¦å‘

**5. Advisory Lockï¼ˆå¯é€‰ï¼Œé«˜å¹¶å‘åœºæ™¯ï¼‰**

```python
# âœ… å¯é€‰æ–¹æ¡ˆï¼šPer-Conversation é”
async def try_trigger_update(self, conversation_id: str):
    # ä½¿ç”¨ PostgreSQL Advisory Lock
    lock_key = hash(f"summary:{conversation_id}") % (2^31)

    async with self.db.acquire_advisory_lock(lock_key):
        # âœ… åŒä¸€æ—¶åˆ»åªæœ‰ä¸€ä¸ªæ‘˜è¦ä»»åŠ¡åœ¨è¯¥ä¼šè¯ä¸Šè¿è¡Œ

        # åŒé‡æ£€æŸ¥ï¼šåŠ é”åå†æ¬¡ç¡®è®¤æ˜¯å¦éœ€è¦æ›´æ–°
        if not await self._should_update(conversation_id):
            return

        await self._generate_and_save(conversation_id, ...)
```

**ä½¿ç”¨åœºæ™¯**ï¼š
- é«˜å¹¶å‘ï¼šæ¯ç§’å¤šä¸ªè¯·æ±‚åˆ°è¾¾åŒä¸€ä¼šè¯
- å¼ºä¸€è‡´æ€§ï¼šç¡®ä¿æ‘˜è¦æ›´æ–°å®Œå…¨ä¸²è¡Œ
- æˆæœ¬ï¼šè½»å¾®æ€§èƒ½ä¸‹é™ï¼ˆé”ç­‰å¾…ï¼‰

---

**å®Œæ•´å®ç°ç¤ºä¾‹**

```python
# âš ï¸ ä»¥ä¸‹ä»£ç æ˜¯"é—®é¢˜3è¯¦è§£"ä¸­ ConversationSummarizer çš„ç®€åŒ–ç¤ºä¾‹
# å®Œæ•´å®ç°è¯·å‚è€ƒ"é—®é¢˜3è¯¦è§£"ï¼ˆline 827-1019ï¼‰

class ConversationSummarizer:
    """å¯¹è¯æ‘˜è¦å™¨ï¼ˆå¼‚æ­¥ + èŠ‚æµ + å¹¶å‘å®‰å…¨ï¼‰"""

    def __init__(
        self,
        summary_store: ConversationSummaryStorePort,
        message_store: ConversationStorePort,
        llm_factory,
        task_manager: SummaryTaskManager  # âœ… æ³¨å…¥ä»»åŠ¡ç®¡ç†å™¨
    ):
        self.summary_store = summary_store
        self.message_store = message_store
        self.llm = llm_factory.get_model("qwen-turbo")
        self.task_manager = task_manager  # âœ… ä½¿ç”¨ä»»åŠ¡ç®¡ç†å™¨ï¼Œä¸æ˜¯ background_tasks

    async def handle_assistant_response(
        self,
        conversation_id: str,
        assistant_message: str,
        completed_normally: bool
    ):
        """å¤„ç† assistant å“åº”ï¼ˆä¸»æµç¨‹è°ƒç”¨ï¼‰"""

        # âœ… ä»…åœ¨æ­£å¸¸å®Œæˆæ—¶è§¦å‘åå°æ‘˜è¦
        if completed_normally:
            await self.task_manager.enqueue(conversation_id)  # âœ… ä½¿ç”¨ä»»åŠ¡é˜Ÿåˆ—

    async def try_trigger_update(
        self,
        conversation_id: str,
        max_retries: int = 3
    ):
        """å¸¦é‡è¯•çš„æ‘˜è¦æ›´æ–°ï¼ˆå¤„ç†ç‰ˆæœ¬å†²çªï¼‰"""

        for attempt in range(max_retries):
            try:
                # 1. è·å–å½“å‰æ‘˜è¦çŠ¶æ€ï¼ˆå¤åˆè¦†ç›–ç‚¹ï¼‰
                summary_data = await self.summary_store.get_summary(conversation_id)
                last_covered_at = summary_data.get("covered_through_created_at") if summary_data else None
                last_covered_id = summary_data.get("covered_through_message_id") if summary_data else None

                # 2. âœ… ä½¿ç”¨å¤åˆæ¸¸æ ‡å¢é‡è·å–
                new_messages = await self.summary_store.list_messages_since(
                    conversation_id=conversation_id,
                    since_created_at=last_covered_at,  # âœ… å¤åˆæ¸¸æ ‡ï¼šæ—¶é—´æˆ³
                    since_message_id=last_covered_id,  # âœ… å¤åˆæ¸¸æ ‡ï¼šID
                    limit=None
                )

                if len(new_messages) < 5:  # èŠ‚æµé˜ˆå€¼
                    return

                # 3. âœ… è¿‡æ»¤æœªå®Œæˆæ¶ˆæ¯ï¼ˆä½¿ç”¨ completed + debug.partialï¼‰
                valid_messages = [
                    m for m in new_messages
                    if (m.metadata.get("completed", True) and  # âœ… ä¼˜å…ˆæ£€æŸ¥ completed
                         not m.metadata.get("debug", {}).get("partial", False))  # âœ… å…¼å®¹ debug.partial
                ]

                if not valid_messages:
                    return

                # 4. ç”Ÿæˆæ‘˜è¦
                new_summary = await self._generate_summary(summary_data, valid_messages)

                # 5. âœ… UPSERT ä¿å­˜ï¼ˆå¤åˆè¦†ç›–ç‚¹ + ç‰ˆæœ¬æ£€æŸ¥ï¼‰
                success = await self.summary_store.save_summary_upsert(
                    conversation_id=conversation_id,
                    summary=new_summary,
                    covered_through_created_at=valid_messages[-1]["created_at"],  # âœ… å¤åˆè¦†ç›–ç‚¹
                    covered_through_message_id=valid_messages[-1]["id"],          # âœ… å¤åˆè¦†ç›–ç‚¹
                    covered_count=(summary_data.get("covered_message_count", 0) if summary_data else 0) + len(valid_messages),
                    expected_version=summary_data.get("summary_version", None) if summary_data else None
                )

                if success:
                    logger.info(f"æ‘˜è¦æ›´æ–°æˆåŠŸ: {conversation_id}")
                    return
                else:
                    # ç‰ˆæœ¬å†²çªï¼Œé‡è¯•
                    logger.warning(f"ç‰ˆæœ¬å†²çªï¼Œé‡è¯• {attempt + 1}/{max_retries}")
                    await asyncio.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿

            except Exception as e:
                logger.error(f"æ‘˜è¦æ›´æ–°å¤±è´¥: {e}")
                if attempt == max_retries - 1:
                    raise
```

**æ–¹æ¡ˆæ€»ç»“**ï¼š

| é—®é¢˜ | è§£å†³æ–¹æ¡ˆ | æ•ˆæœ |
|------|---------|------|
| åŒæ­¥æ‹–æ…¢è¯·æ±‚ | åå°å¼‚æ­¥ç”Ÿæˆï¼ˆSummaryTaskManagerï¼‰ | âœ… ç”¨æˆ·æ— æ„ŸçŸ¥ |
| é¢‘ç¹æ›´æ–° | èŠ‚æµï¼ˆ5æ¡é˜ˆå€¼ï¼‰ | âœ… é™ä½80%æ›´æ–°é¢‘ç‡ |
| å¹¶å‘è¦†ç›– | å•è°ƒé€’å¢ + ä¹è§‚é” | âœ… é˜²æ­¢æ•°æ®ä¸¢å¤± |
| Partialæ±¡æŸ“ | å¤šå±‚è¿‡æ»¤æœºåˆ¶ï¼ˆcompleted + debug.partialï¼‰ | âœ… æ‘˜è¦å¹²å‡€å‡†ç¡® |

**å®ç°æ£€æŸ¥æ¸…å•**ï¼š
- [ ] æ‘˜è¦ç”Ÿæˆæ”¹ä¸ºåå°å¼‚æ­¥ä»»åŠ¡
- [ ] æ·»åŠ èŠ‚æµæœºåˆ¶ï¼ˆupdate_delta=5ï¼‰
- [ ] å®ç° UPSERT å•è°ƒé€’å¢çº¦æŸ
- [ ] æ·»åŠ ä¹è§‚é”ç‰ˆæœ¬æ£€æŸ¥
- [ ] âœ… **æ·»åŠ  `completed` å­—æ®µ**ï¼ˆä¸ä¾èµ– debug.partialï¼‰
- [ ] âœ… **æ‘˜è¦è¾“å…¥è¿‡æ»¤ `completed=False` çš„æ¶ˆæ¯**
- [ ] âœ… **ä»…åœ¨ `completed_normally=True` æ—¶è§¦å‘**
- [ ] âœ… **ä½¿ç”¨ `(created_at, id)` å¤åˆæ¸¸æ ‡**
- [ ] âœ… **ä½¿ç”¨ `SummaryTaskManager` è€Œä¸æ˜¯ `background_tasks`**
- [ ] ï¼ˆå¯é€‰ï¼‰æ·»åŠ  Advisory Lock
- [ ] ï¼ˆå¯é€‰ï¼‰å®ç°æŒ‡æ•°é€€é¿é‡è¯•

#### 2.1.2 è®¾è®¡åŸåˆ™ä¸å…³é”®å†³ç­–

**æ ¸å¿ƒåŸåˆ™ï¼š**
1.  **ä¿¡æ¯å±‚çº§ä¿ç•™**ï¼šæ‘˜è¦å±‚è®°å½•å…¨å±€èƒŒæ™¯ï¼ˆæ£®æ—ï¼‰ï¼Œæ»‘åŠ¨çª—å£ä¿ç•™å±€éƒ¨ç»†èŠ‚ï¼ˆæ ‘æœ¨ï¼‰ã€‚
2.  **é™ä½ä¿¡æ¯ç†µ**ï¼šé€šè¿‡å‹ç¼©é•¿æœŸå†å²ï¼Œä»…ä¿ç•™é«˜ä»·å€¼ä¿¡æ¯ï¼Œé¿å… Token æµªè´¹ã€‚
3.  **ç¬¦åˆè®¤çŸ¥æ¨¡å‹**ï¼šæ¨¡æ‹Ÿäººç±»çš„é•¿çŸ­æœŸè®°å¿†æœºåˆ¶ (Atkinson-Shiffrin Model)ã€‚

**å…³é”®å†³ç­–ï¼š**

1.  **æ¶æ„æ¨¡å¼ï¼šæ»‘åŠ¨çª—å£ + å†å²æ‘˜è¦**
    - é€‚ç”¨åœºæ™¯ï¼šé€šç”¨åœºæ™¯ï¼Œå¹³è¡¡äº†çŸ­å¯¹è¯çš„å®æ—¶æ€§å’Œé•¿å¯¹è¯çš„ä¸Šä¸‹æ–‡å®Œæ•´æ€§ã€‚

2.  **å‚æ•°é…ç½®**
    - **è§¦å‘é˜ˆå€¼ (min_messages)**: 10 æ¡ï¼ˆ5 è½®å¯¹è¯ï¼‰ã€‚ç¡®ä¿æœ‰è¶³å¤Ÿä¸Šä¸‹æ–‡ç”Ÿæˆæœ‰æ„ä¹‰çš„æ‘˜è¦ã€‚
    - **æ›´æ–°å¢é‡ (update_delta)**: 5 æ¡ã€‚å¹³è¡¡æ‘˜è¦æ–°é²œåº¦å’Œç”Ÿæˆæˆæœ¬ã€‚
    - **çª—å£å¤§å° (window_size)**: 6 æ¡ã€‚
    - **è¾¹ç•Œæ§åˆ¶**: ä½¿ç”¨ `(created_at, message_id)` å¤åˆæ¸¸æ ‡ä½œä¸ºæ‘˜è¦è¦†ç›–ç‚¹ï¼Œè€Œéä¾èµ–ä¸å¯é çš„å†…å®¹å»é‡ã€‚
    - **è¿‡æ»¤ç­–ç•¥**: æ‘˜è¦ç”Ÿæˆæ—¶å¿…é¡»è¿‡æ»¤æ‰ `completed=False` çš„æœªå®Œæˆæ¶ˆæ¯ï¼ˆæˆ– `debug.partial=True`ï¼‰ã€‚

3.  **å­˜å‚¨æ–¹æ¡ˆï¼šç‹¬ç«‹è¡¨ (conversation_summaries)**
    - æ¸…æ™°åˆ†ç¦»å…³æ³¨ç‚¹ï¼Œé¿å…æ±¡æŸ“æ ¸å¿ƒæ¶ˆæ¯è¡¨ï¼Œä¾¿äºç‹¬ç«‹ä¼˜åŒ–ç´¢å¼•ã€‚

4.  **æ¨¡å‹é€‰æ‹©ï¼šQwen (é¡¹ç›®å†…ç½®)**
    - **ä¸€è‡´æ€§**ï¼šä½¿ç”¨ä¸ä¸»å¯¹è¯ç›¸åŒçš„æ¨¡å‹ç³»åˆ—ï¼Œä¿è¯å¯¹é¢†åŸŸçŸ¥è¯†ç†è§£çš„ä¸€è‡´æ€§ã€‚
    - **æˆæœ¬ä¸æ€§èƒ½**ï¼šQwen åœ¨æ‘˜è¦ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä¸”æ— éœ€å¼•å…¥é¢å¤–çš„å¤–éƒ¨ API ä¾èµ–ã€‚

5.  **æ›´æ–°ç­–ç•¥ï¼šå¢é‡æ›´æ–°**
    - ä»…å°†"æ—§æ‘˜è¦ + æ–°å¢å¯¹è¯"å‘é€ç»™æ¨¡å‹è¿›è¡Œåˆå¹¶ï¼Œè€Œéæ¯æ¬¡å…¨é‡é‡ç®—ã€‚å¤§å¹…é™ä½ Context å¼€é”€ã€‚

#### 2.1.3 æ¶æ„ä¸æµç¨‹å¯è§†åŒ–

##### æ•°æ®æµæ¶æ„å›¾

**Phase 1 çš„æ•°æ®æµåŠ¨ä¸å­˜å‚¨ç»“æ„ï¼š**

```mermaid
flowchart LR
    subgraph Input["è¾“å…¥å±‚ - å®Œæ•´ Turn"]
        UserMsg[ç”¨æˆ·æ¶ˆæ¯ N]
        AssistMsg[Assistant å“åº” N]
        TurnEnd{{Turn å®Œæˆ?}}
    end

    subgraph Process["å¤„ç†å±‚ (å¼‚æ­¥)"]
        Queue[ä»»åŠ¡å»é‡/èŠ‚æµ<br/>ä»…åœ¨ completed_normally]
        Summ[åå°æ‘˜è¦ Worker<br/>SummaryTaskManager]
    end

    subgraph Storage["å­˜å‚¨å±‚"]
        DB[(PostgreSQL)]
        Table1[messages è¡¨<br/>å« completed å­—æ®µ]
        Table2[conversation_summaries è¡¨<br/>å¤åˆè¦†ç›–ç‚¹]
    end

    subgraph Output["è¾“å‡ºå±‚"]
        Prompt[æ„å»º Prompt<br/>Summary + Recent Window]
        LLM[ğŸ¤– LLM ç”Ÿæˆ]
    end

    UserMsg --> AssistMsg
    AssistMsg -->|æ£€æŸ¥ completed_normally| TurnEnd
    TurnEnd -->|True| Queue
    TurnEnd -->|False| End1[ç»“æŸ]

    Queue -->|æ‰¹é‡æå–å†å²| Summ
    Summ -->|UPSERT æ›´æ–°| Table2

    Table1 -.->|Read Only| Summ
    Table2 -->|æ³¨å…¥ Context| Prompt
    Prompt --> LLM

    style Summ fill:#ffe6e6
    style Queue fill:#fff4e6
    style Prompt fill:#e6f3ff
    style Table2 fill:#e6ffe6
    style TurnEnd fill:#fffacd
```

##### ç³»ç»ŸçŠ¶æ€è½¬æ¢å›¾

**å¯¹è¯æ‘˜è¦çš„çŠ¶æ€æœºï¼š**

```mermaid
stateDiagram-v2
    [*] --> NoSummary: å¯¹è¯å¼€å§‹<br/>(< 10 æ¡æ¶ˆæ¯)

    NoSummary --> GeneratingSummary: æ¶ˆæ¯æ•°è¾¾åˆ°é˜ˆå€¼<br/>(â‰¥ 10 æ¡)
    NoSummary --> NoSummary: ç»§ç»­å¯¹è¯<br/>(ä½¿ç”¨æ—¶é—´çª—å£)

    GeneratingSummary --> HasSummary: æ‘˜è¦ç”ŸæˆæˆåŠŸ
    GeneratingSummary --> NoSummary: ç”Ÿæˆå¤±è´¥<br/>(é™çº§åˆ°æ—¶é—´çª—å£)

    HasSummary --> Cached: æ–°å¢æ¶ˆæ¯ < 5 æ¡<br/>(ä½¿ç”¨ç¼“å­˜)
    HasSummary --> UpdatingSummary: æ–°å¢æ¶ˆæ¯ â‰¥ 5 æ¡<br/>(è§¦å‘æ›´æ–°)

    Cached --> Cached: ç»§ç»­å¯¹è¯<br/>(å¤ç”¨æ‘˜è¦)
    Cached --> UpdatingSummary: ç´¯ç§¯å·®å€¼è¾¾åˆ°é˜ˆå€¼

    UpdatingSummary --> HasSummary: æ›´æ–°å®Œæˆ
    UpdatingSummary --> HasSummary: æ›´æ–°å¤±è´¥<br/>(ä¿ç•™æ—§æ‘˜è¦)

    HasSummary --> [*]: å¯¹è¯ç»“æŸ
    NoSummary --> [*]: å¯¹è¯ç»“æŸ

    note right of NoSummary
        çŠ¶æ€ç‰¹å¾:
        - æ¶ˆæ¯æ•°: 0-9
        - ä¸Šä¸‹æ–‡: æœ€è¿‘ 6 æ¡
        - Token ä¼˜åŒ–: æ— 
    end note

    note right of HasSummary
        çŠ¶æ€ç‰¹å¾:
        - æ¶ˆæ¯æ•°: â‰¥ 10
        - ä¸Šä¸‹æ–‡: æ‘˜è¦ + æœ€è¿‘ 6 æ¡
        - Token ä¼˜åŒ–: 60-75%
        - covered_count: å·²æ‘˜è¦æ¶ˆæ¯æ•°
    end note
```

##### æ ¸å¿ƒæµç¨‹å›¾

**Phase 1 çš„å®Œæ•´å·¥ä½œæµç¨‹ï¼ˆæŒ‰å®Œæ•´ Turn è§¦å‘ï¼‰ï¼š**

```mermaid
flowchart TD
    Start([ç”¨æˆ·å‘é€æ¶ˆæ¯]) --> GenResp[ç”Ÿæˆ Assistant å“åº”]
    GenResp --> CheckComplete{{completed_normally?}}

    CheckComplete -->|False| EndNoSum([ä¸è§¦å‘æ‘˜è¦<br/>ç›´æ¥ç»“æŸ])

    CheckComplete -->|True| CheckMsg{æ¶ˆæ¯æ•°é‡ â‰¥ 10?}
    CheckMsg -->|å¦| GetRecent[è·å–æœ€è¿‘ 6 æ¡æ¶ˆæ¯]
    CheckMsg -->|æ˜¯| CheckSummary{æ‘˜è¦æ˜¯å¦å­˜åœ¨?}

    CheckSummary -->|å¦| GenerateSummary[ç”Ÿæˆæ–°æ‘˜è¦<br/>è¦†ç›–æ‰€æœ‰å†å² - æœ€è¿‘6æ¡]
    CheckSummary -->|æ˜¯| CheckDelta{æ–°å¢æ¶ˆæ¯ â‰¥ 5?}

    CheckDelta -->|æ˜¯| UpdateSummary[æ›´æ–°æ‘˜è¦<br/>åŒ…å«æ–°å†…å®¹]
    CheckDelta -->|å¦| UseCached[ä½¿ç”¨å·²æœ‰æ‘˜è¦]

    GenerateSummary --> SaveSummary[ä¿å­˜æ‘˜è¦åˆ°æ•°æ®åº“<br/>å¤åˆè¦†ç›–ç‚¹]
    UpdateSummary --> SaveSummary
    SaveSummary --> GetRecent
    UseCached --> GetRecent

    GetRecent --> BuildPrompt[æ„å»º Prompt:<br/>Summary + Recent Window + Current]
    BuildPrompt --> LLM[å‘é€åˆ° LLM]
    LLM --> Response([è¿”å›å“åº”])

    style GenerateSummary fill:#ffe6e6
    style UpdateSummary fill:#fff4e6
    style SaveSummary fill:#e6f3ff
    style BuildPrompt fill:#e6ffe6
```

**æ‘˜è¦ç”Ÿæˆå†³ç­–æ ‘ï¼ˆæŒ‰å®Œæ•´ Turn è§¦å‘ï¼‰ï¼š**

```mermaid
graph TD
    A[æ¥æ”¶å¯¹è¯è¯·æ±‚] --> B[ç”Ÿæˆ Assistant å“åº”]
    B --> C{{completed_normally?}}
    C -->|False| D[æµå¼ä¸­æ–­<br/>ä¸è§¦å‘æ‘˜è¦]
    C -->|True| E{æ¶ˆæ¯æ€»æ•° < 10?}

    E -->|æ˜¯| F[æ— éœ€æ‘˜è¦<br/>ç›´æ¥ä½¿ç”¨æ—¶é—´çª—å£]
    E -->|å¦| G{æ‘˜è¦å­˜åœ¨?}

    G -->|å¦| H[é¦–æ¬¡ç”Ÿæˆæ‘˜è¦<br/>æ‘˜è¦æ‰€æœ‰å†å² - æœ€è¿‘6æ¡]
    G -->|æ˜¯| I{æ¶ˆæ¯æ€»æ•° - å·²æ‘˜è¦æ•°é‡ â‰¥ 5?}

    I -->|å¦| J[ä½¿ç”¨ç¼“å­˜æ‘˜è¦<br/>æ— éœ€é‡æ–°ç”Ÿæˆ]
    I -->|æ˜¯| K[å¢é‡æ›´æ–°æ‘˜è¦<br/>åŒ…å«æ–°å¯¹è¯å†…å®¹]

    K --> L[ä¿å­˜åˆ°æ•°æ®åº“<br/>å¤åˆè¦†ç›–ç‚¹]
    J --> M[è¿”å›æ‘˜è¦å†…å®¹]
    L --> M

    D --> N[è¿”å›ç©ºæ‘˜è¦]

    style C fill:#99ff99
    style E fill:#ffcc99
    style H fill:#ffe6e6
    style G fill:#ccffff
```

##### è¯·æ±‚å¤„ç†åºåˆ—å›¾

**ç”¨æˆ·è¯·æ±‚çš„å®Œæ•´å¤„ç†æµç¨‹ï¼ˆæŒ‰å®Œæ•´ Turn è§¦å‘ï¼‰ï¼š**

```mermaid
sequenceDiagram
    participant User as ç”¨æˆ·
    participant API as ChatHandler
    participant Stream as StreamHandler
    participant TaskMgr as SummaryTaskManager
    participant Summarizer as ConversationSummarizer
    participant DB as ConversationStore
    participant LLM as LLM Service

    User->>API: å‘é€æ¶ˆæ¯
    API->>DB: ä¿å­˜ç”¨æˆ·æ¶ˆæ¯

    Note over API,Stream: æµå¼å“åº”é˜¶æ®µ
    API->>Stream: å¼€å§‹æµå¼ç”Ÿæˆ
    Stream->>LLM: æµå¼è¯·æ±‚
    LLM-->>Stream: æµå¼å“åº”
    Stream-->>API: æµå¼è¿”å›ç»™ç”¨æˆ·
    Stream->>DB: ä¿å­˜ Assistant å“åº”<br/>(completed=True/False)

    Note over Stream,TaskMgr: æ‘˜è¦è§¦å‘æ£€æŸ¥
    Stream->>Stream: æ£€æŸ¥ completed_normally
    alt completed_normally = True
        Stream->>TaskMgr: enqueue(conversation_id)
        Note right of TaskMgr: åå°å¼‚æ­¥å¤„ç†<br/>ä¸é˜»å¡å“åº”
    end

    Note over TaskManager,Summarizer: åå°æ‘˜è¦å¤„ç†ï¼ˆå¼‚æ­¥ï¼‰
    TaskMgr->>Summarizer: å¤„ç†é˜Ÿåˆ—ä»»åŠ¡

    Note over API,Summarizer: ä¸Šä¸‹æ–‡æ„å»ºé˜¶æ®µ
    API->>DB: è·å–æ¶ˆæ¯æ€»æ•°
    DB-->>API: è¿”å› count

    API->>Summarizer: should_summarize(conv_id)?
    Summarizer->>DB: count_messages(conv_id)
    Summarizer->>DB: get_summary(conv_id)

    alt æ¶ˆæ¯æ•° â‰¥ 10 ä¸”æ— æ‘˜è¦
        Summarizer->>DB: list_messages(limit=None)
        DB-->>Summarizer: æ‰€æœ‰å†å²æ¶ˆæ¯
        Summarizer->>Summarizer: æå– [æ‰€æœ‰ - æœ€è¿‘6æ¡]
        Summarizer->>LLM: ç”Ÿæˆæ‘˜è¦è¯·æ±‚
        LLM-->>Summarizer: è¿”å›æ‘˜è¦æ–‡æœ¬
        Summarizer->>DB: save_summary()
    else æ¶ˆæ¯æ•° â‰¥ 10 ä¸”æœ‰æ‘˜è¦
        Summarizer->>Summarizer: è®¡ç®— delta
        alt delta â‰¥ 5
            Summarizer->>DB: list_messages()
            Summarizer->>LLM: æ›´æ–°æ‘˜è¦
            LLM-->>Summarizer: æ–°æ‘˜è¦
            Summarizer->>DB: update_summary()
        else delta < 5
            Summarizer-->>API: ä½¿ç”¨ç¼“å­˜æ‘˜è¦
        end
    else æ¶ˆæ¯æ•° < 10
        Summarizer-->>API: è¿”å› None
    end

    API->>DB: list_messages(limit=6, desc=True)
    DB-->>API: æœ€è¿‘ 6 æ¡æ¶ˆæ¯

    Note over API,LLM: Prompt æ„å»ºä¸ç”Ÿæˆ
    API->>API: æ„å»º Prompt:
    Note over API: [System Prompt]<br/>[Summary] (å¯é€‰)<br/>[Recent Window]<br/>[Current Message]

    API->>LLM: å‘é€å®Œæ•´ Prompt
    LLM-->>API: è¿”å›å“åº”

    API-->>User: è¿”å›å“åº”

    rect rgba(255, 200, 200, 0.3)
        Note over TaskMgr,Summarizer: å¼‚æ­¥æ­¥éª¤ï¼ˆä¸é˜»å¡å“åº”ï¼‰
        TaskMgr->>Summarizer: åå°å¤„ç†æ‘˜è¦ä»»åŠ¡
        Note right of TaskMgr: å¼‚æ­¥é˜Ÿåˆ—å¤„ç†<br/>ä¸é˜»å¡ç”¨æˆ·å“åº”
    end
```

#### 2.1.4 æ•°æ®æ¨¡å‹

**æ–¹æ¡ˆï¼šç‹¬ç«‹æ‘˜è¦è¡¨**

```sql
CREATE TABLE conversation_summaries (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    conversation_id UUID NOT NULL REFERENCES conversations(id) ON DELETE CASCADE,
    summary TEXT NOT NULL,
    summary_version INT DEFAULT 1,  -- ä¹è§‚é”ç‰ˆæœ¬å·
    covered_through_message_id UUID,     -- âœ… æ‘˜è¦è¦†ç›–ç‚¹ï¼šæ¶ˆæ¯ IDï¼ˆtie-breakï¼‰
    covered_through_created_at TIMESTAMP, -- âœ… æ‘˜è¦è¦†ç›–ç‚¹ï¼šæ—¶é—´æˆ³ï¼ˆä¸»åºï¼‰
    covered_message_count INT NOT NULL,   -- ä»…ç”¨äºç»Ÿè®¡/è¾…åŠ©
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    UNIQUE(conversation_id)
);

-- ç´¢å¼•ç”¨äºé¢‘ç¹æŸ¥è¯¢
CREATE INDEX idx_summaries_conversation_id ON conversation_summaries(conversation_id);

-- âš ï¸ é‡è¦ï¼šmessages è¡¨ä¹Ÿéœ€è¦æ·»åŠ  completed å­—æ®µ
ALTER TABLE messages ADD COLUMN completed BOOLEAN DEFAULT true;
CREATE INDEX idx_messages_created_id ON messages(created_at, id);
```

**å­—æ®µè¯´æ˜ï¼š**

| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `id` | UUID | ä¸»é”® |
| `conversation_id` | UUID | å…³è”çš„å¯¹è¯ IDï¼ˆå¤–é”®ï¼‰ |
| `summary` | TEXT | å‹ç¼©åçš„å¯¹è¯æ‘˜è¦ |
| `summary_version` | INT | ä¹è§‚é”ç‰ˆæœ¬å·ï¼Œæ§åˆ¶å¹¶å‘æ›´æ–° |
| `covered_through_message_id` | UUID | âœ… æ‘˜è¦è¦†ç›–ç‚¹ï¼šæ¶ˆæ¯ IDï¼ˆtie-breakï¼Œå¤„ç†åŒä¸€æ¯«ç§’å†…çš„å¤šæ¡æ¶ˆæ¯ï¼‰ |
| `covered_through_created_at` | TIMESTAMP | âœ… æ‘˜è¦è¦†ç›–ç‚¹ï¼šæ—¶é—´æˆ³ï¼ˆä¸»åºï¼Œä¿è¯æ—¶é—´å…ˆåï¼‰ |
| `covered_message_count` | INT | å·²æ‘˜è¦çš„æ¶ˆæ¯æ•°é‡ï¼ˆè¾…åŠ©ç»Ÿè®¡ï¼‰ |
| `created_at` | TIMESTAMP | åˆ›å»ºæ—¶é—´ |
| `updated_at` | TIMESTAMP | æœ€åæ›´æ–°æ—¶é—´ |

**âš ï¸ å…³é”®è®¾è®¡ç‚¹**ï¼š
- **å¤åˆè¦†ç›–ç‚¹**ï¼š`covered_through_created_at + covered_through_message_id` ç¡®ä¿ç²¾å‡†åˆ‡ç‰‡
- **UUID v4 é™åˆ¶**ï¼šä¸èƒ½å•ç‹¬ç”¨ `message_id` è¿›è¡Œ `>` æ¯”è¾ƒï¼ˆä¼šæ¼æ¶ˆæ¯ã€ä¹±åºã€ä¸å¹‚ç­‰ï¼‰
- **SQL æŸ¥è¯¢**ï¼šå¿…é¡»ä½¿ç”¨ `WHERE created_at > $1 OR (created_at = $1 AND id > $2)` å¤åˆæ¡ä»¶
- **completed å­—æ®µ**ï¼šåœ¨ `messages` è¡¨æ·»åŠ ï¼Œç”¨äºæ ‡è®°æ¶ˆæ¯æ˜¯å¦å®Œæˆï¼ˆä¸ debug æ— å…³ï¼‰

**æµå¼ä¸­æ–­ä¸ Partial æ¶ˆæ¯å¤„ç†**ï¼š

| åœºæ™¯ | é—®é¢˜ | è§£å†³æ–¹æ¡ˆ |
|------|------|---------|
| **æµå¼ä¸­æ–­** | ç”Ÿäº§ç¯å¢ƒæ–­è¿æ—¶æ²¡æœ‰ partial æ ‡è®°ï¼ˆ`debug.partial` åªåœ¨ debug=True æ—¶å­˜åœ¨ï¼‰ | æ·»åŠ  `completed` å­—æ®µï¼ˆä¸ debug æ— å…³ï¼‰ |
| **æ‘˜è¦æ±¡æŸ“** | ä¸å®Œæ•´çš„ assistant å†…å®¹è¿›å…¥é•¿æœŸè®°å¿† | ä»…å¯¹ `completed=True` çš„å›åˆç”Ÿæˆæ‘˜è¦ |
| **é‡å¤æ‘˜è¦** | åŒä¸€ partial æ¶ˆæ¯å¤šæ¬¡æ‘˜è¦ | è§¦å‘æ¡ä»¶ï¼šä»…åœ¨ assistant æ¶ˆæ¯æ­£å¸¸è½åº“å |

**âš ï¸ å®é™…ä»£ç è¡Œä¸ºï¼ˆé‡è¦ï¼‰**ï¼š

```python
# backend/application/chat/handlers/stream_handler.py:245-252
# å®é™…æƒ…å†µï¼šæµç»“æŸåä¸€æ¬¡æ€§è½åº“ï¼Œä¸æ˜¯"æµå¼è¿‡ç¨‹ä¸­ä¸æ–­è½åº“"

async def stream_response(message: str):
    full_response = ""

    try:
        # æµå¼ç”Ÿæˆä¸­...
        async for chunk in llm.stream():
            full_response += chunk
            yield chunk

        # âš ï¸ æµç»“æŸåä¸€æ¬¡æ€§è½åº“ï¼ˆä¸æ˜¯è¿‡ç¨‹ä¸­ï¼‰
        await store.append_message(
            conversation_id,
            "assistant",
            full_response,  # å®Œæ•´å“åº”
            metadata={
                "debug": {"partial": True} if self.debug else {}  # âš ï¸ åªåœ¨ debug=True æ—¶æœ‰ partial æ ‡è®°
            }
        )

    except Exception as e:
        # âš ï¸ æ–­è¿æ—¶ä¹Ÿä¼šè½åº“"åŠæˆª assistant"
        await store.append_message(
            conversation_id,
            "assistant",
            full_response,  # ä¸å®Œæ•´
            metadata={
                "debug": {"partial": True, "error": str(e)} if self.debug else {}  # âš ï¸ é debug æ²¡æœ‰ä»»ä½•æ ‡è®°
            }
        )
```

**é—®é¢˜**ï¼šç”Ÿäº§ç¯å¢ƒï¼ˆdebug=Falseï¼‰æ–­è¿æ—¶ï¼Œæ²¡æœ‰ partial æ ‡è®°ï¼Œæ— æ³•è¯†åˆ«ä¸å®Œæ•´æ¶ˆæ¯ã€‚

**æ­£ç¡®çš„å®ç°è¦ç‚¹**ï¼š

1. **æ·»åŠ å®Œæˆæ ‡è®°ï¼ˆä¸ä¾èµ– debugï¼‰**ï¼š
   ```python
   # âœ… è§£å†³æ–¹æ¡ˆï¼šæ·»åŠ ç¨³å®šçš„"æ¶ˆæ¯æ˜¯å¦å®Œæˆ"æ ‡è®°
   async def stream_response(message: str, conversation_id: str):
       full_response = ""
   
       try:
           # æµå¼ç”Ÿæˆä¸­...
           async for chunk in llm.stream():
               full_response += chunk
               yield chunk
   
           # âœ… æ­£å¸¸å®Œæˆï¼šæ˜ç¡®æ ‡è®°
           await store.append_message(
               conversation_id,
               "assistant",
               full_response,
               metadata={
                   "completed": True,  # âœ… æ–°å¢ï¼šæ˜ç¡®çš„å®Œæˆæ ‡è®°
                   "partial": False,
                   "debug": {...} if self.debug else {}
               }
           )
   
           # âœ… è¿”å›å®ŒæˆçŠ¶æ€
           return StreamResponse(completed_normally=True, message_id=...)
   
       except Exception as e:
           # âš ï¸ å¼‚å¸¸ä¸­æ–­ï¼šæ˜ç¡®æ ‡è®°ä¸ºæœªå®Œæˆ
           await store.append_message(
               conversation_id,
               "assistant",
               full_response,  # ä¸å®Œæ•´
               metadata={
                   "completed": False,  # âœ… æ–°å¢ï¼šæ˜ç¡®çš„æœªå®Œæˆæ ‡è®°
                   "partial": True,
                   "error": str(e),
                   "debug": {...} if self.debug else {}
               }
           )
   
           # âœ… è¿”å›å¤±è´¥çŠ¶æ€
           return StreamResponse(completed_normally=False, message_id=...)
   ```

2. **æ‘˜è¦è¾“å…¥è¿‡æ»¤**ï¼š
   ```python
   async def try_trigger_update(self, conversation_id: str):
       # è·å–æ–°å¢æ¶ˆæ¯
       new_messages = await self.fetch_new_messages(conversation_id, last_covered_at, last_covered_id)
   
       # âœ… è¿‡æ»¤æ‰æœªå®Œæˆæ¶ˆæ¯ï¼ˆä½¿ç”¨ completed å­—æ®µï¼‰
       valid_messages = [
           m for m in new_messages
           if m.metadata.get("completed", True) and  # âœ… ä¼˜å…ˆæ£€æŸ¥ completed
                not m.metadata.get("debug", {}).get("partial", False)  # âœ… å…¼å®¹ debug.partial
       ]
   
       if not valid_messages:
           return  # æ‰€æœ‰æ¶ˆæ¯éƒ½æ˜¯ partialï¼Œä¸ç”Ÿæˆæ‘˜è¦
   ```

3. **è§¦å‘æ—¶æœºçº¦æŸ**ï¼š
   ```python
   # backend/application/chat/handlers/chat_handler.py
   async def handle(self, message: str, conversation_id: str):
       response_stream = await self.executor.stream(message, ...)
   
       # æ”¶é›†å®Œæ•´å“åº”
       full_response = ""
       async for chunk in response_stream:
           full_response += chunk
   
       # ä¿å­˜å®Œæ•´çš„ assistant æ¶ˆæ¯ï¼ˆæ ‡è®°ä¸ºå®Œæˆï¼‰
       await self.conversation_store.append_message(
           conversation_id=conversation_id,
           role="assistant",
           content=full_response,
           metadata={"completed": True}  # âœ… æ˜ç¡®æ ‡è®°ä¸ºå®Œæˆ
       )
   
       # âœ… è§¦å‘åå°æ‘˜è¦ï¼ˆä»…å½“æ­£å¸¸å®Œæˆæ—¶ï¼‰
       if response_stream.completed_normally:
           await summary_task_manager.enqueue(conversation_id)  # âœ… ä½¿ç”¨ä»»åŠ¡é˜Ÿåˆ—
   ```

**å¹¶å‘ä¸å¹‚ç­‰è®¾è®¡**ï¼š

| å¹¶å‘åœºæ™¯ | é—®é¢˜ | è§£å†³æ–¹æ¡ˆ |
|---------|------|---------|
| **å¤šè¯·æ±‚åŒæ—¶æ›´æ–°æ‘˜è¦** | äº’ç›¸è¦†ç›–ï¼Œä¸¢å¤±æ‘˜è¦ | UPSERT + WHERE å•è°ƒé€’å¢çº¦æŸ |
| **ç‰ˆæœ¬å†²çª** | æ—§æ‘˜è¦è¦†ç›–æ–°æ‘˜è¦ | ä¹è§‚é”ï¼ˆsummary_versionï¼‰ |
| **é‡å¤è§¦å‘** | åŒä¸€æ¶ˆæ¯å¤šæ¬¡æ‘˜è¦ | å»é‡æœºåˆ¶ï¼ˆä»… completed_normally è§¦å‘ï¼‰ |
| **é‡è¯•é£æš´** | å¤±è´¥é‡è¯•å¯¼è‡´æ•°æ®åº“å‹åŠ› | æŒ‡æ•°é€€é¿ + Advisory Lock |

**å…³é”®è®¾è®¡çº¦æŸ**ï¼š

1. **å•è°ƒé€’å¢çº¦æŸ**ï¼š
   ```sql
   WHERE (conversation_summaries.covered_through_created_at < EXCLUDED.covered_through_created_at)
      OR (conversation_summaries.covered_through_created_at = EXCLUDED.covered_through_created_at
          AND conversation_summaries.covered_through_message_id IS DISTINCT FROM EXCLUDED.covered_through_message_id)
     AND EXCLUDED.covered_through_message_id IS NOT NULL
   ```
   - åªå…è®¸è¦†ç›–ç‚¹å‰è¿›ï¼ˆå¤åˆæ¡ä»¶ï¼šcreated_at ä¸»åºï¼Œmessage_id tie-breakï¼‰
   - é˜²æ­¢æ—§æ‘˜è¦è¦†ç›–æ–°æ‘˜è¦

2. **ä¹è§‚é”ç‰ˆæœ¬æ£€æŸ¥**ï¼š
   ```sql
   AND ($5 IS NULL OR conversation_summaries.summary_version = $5)
   ```
   - CAS (Compare-And-Swap) è¯­ä¹‰
   - ç‰ˆæœ¬å†²çªæ—¶è¿”å› Falseï¼Œè§¦å‘é‡è¯•

3. **Advisory Lockï¼ˆå¯é€‰ï¼‰**ï¼š
   ```python
   async def try_trigger_update(self, conversation_id: str):
       # è·å–ä¼šè¯çº§åˆ«çš„æ’ä»–é”
       async with self.db.acquire_advisory_lock(f"summary:{conversation_id}"):
           # åŒé‡æ£€æŸ¥ï¼šå†æ¬¡ç¡®è®¤æ˜¯å¦éœ€è¦æ›´æ–°
           if not await self._should_update(conversation_id):
               return
           await self._generate_and_save(conversation_id)
   ```
   - ç¡®ä¿åŒä¸€ä¼šè¯åŒæ—¶åªæœ‰ä¸€ä¸ªæ‘˜è¦ä»»åŠ¡
   - é¿å…é‡å¤ç”Ÿæˆå’Œèµ„æºæµªè´¹

4. **å¹‚ç­‰è§¦å‘æ¡ä»¶**ï¼š
   ```python
   # âœ… ä»…åœ¨æµå¼å“åº”æ­£å¸¸ç»“æŸåè§¦å‘
   if stream_response.completed_normally:
       await summary_task_manager.enqueue(conversation_id)  # âœ… ä½¿ç”¨ä»»åŠ¡é˜Ÿåˆ—
   ```
   - è¿‡æ»¤æ‰ `completed=False` çš„æœªå®Œæˆæ¶ˆæ¯
   - é˜²æ­¢æµå¼ä¸­æ–­å¯¼è‡´çš„é‡å¤æ‘˜è¦
   - ä½¿ç”¨ `SummaryTaskManager` ç¡®ä¿ä»»åŠ¡ä¸ä¸¢å¤±

**å­˜å‚¨æ¥å£è®¾è®¡**

Phase 1 éœ€è¦ä¸“é—¨çš„æ‘˜è¦å­˜å‚¨æ¥å£ï¼Œä¸ç°æœ‰çš„ `ConversationStorePort` èŒè´£åˆ†ç¦»ã€‚

**ç°æœ‰æ¥å£çš„å±€é™**ï¼š

```python
# backend/application/ports/conversation_store_port.py
class ConversationStorePort(ABC):
    """å¯¹è¯æ¶ˆæ¯å­˜å‚¨æ¥å£

    å½“å‰åªå…³æ³¨æ¶ˆæ¯çš„å¢åˆ æŸ¥æ”¹ï¼Œä¸æ”¯æŒæ‘˜è¦åŠŸèƒ½ã€‚
    """

    @abstractmethod
    async def list_messages(
        self,
        conversation_id: str,
        limit: int | None = None,
        desc: bool = False
    ) -> list[dict]:
        """è·å–æ¶ˆæ¯åˆ—è¡¨"""
        ...

    @abstractmethod
    async def append_message(
        self,
        conversation_id: str,
        role: str,
        content: str,
        metadata: dict | None = None
    ):
        """è¿½åŠ æ¶ˆæ¯"""
        ...
```

**è®¾è®¡åŸåˆ™ï¼šæ¥å£åˆ†ç¦»**

ç›´æ¥æ‰©å±•ç°æœ‰ `ConversationStorePort` ä¼šå¯¼è‡´ï¼š
- èŒè´£æ··ä¹±ï¼šä¸€ä¸ªæ¥å£åŒæ—¶è´Ÿè´£æ¶ˆæ¯å­˜å‚¨å’Œæ‘˜è¦ç®¡ç†
- å½±å“é¢å¤§ï¼šæ‰€æœ‰å®ç°ç±»éƒ½éœ€è¦ä¿®æ”¹
- æµ‹è¯•å›°éš¾ï¼šæ‘˜è¦åŠŸèƒ½çš„æµ‹è¯•ä¼šæ±¡æŸ“æ¶ˆæ¯å­˜å‚¨çš„æµ‹è¯•

**è§£å†³æ–¹æ¡ˆï¼šæ–°å¢ `ConversationSummaryStorePort`**

```python
# backend/application/ports/conversation_summary_store_port.py
from abc import ABC, abstractmethod
from datetime import datetime
from typing import Any

class ConversationSummaryStorePort(ABC):
    """å¯¹è¯æ‘˜è¦å­˜å‚¨æ¥å£

    ä¸“é—¨è´Ÿè´£æ‘˜è¦çš„å¢åˆ æŸ¥æ”¹ï¼Œä¸æ¶ˆæ¯å­˜å‚¨è§£è€¦ã€‚
    """

    @abstractmethod
    async def get_summary(self, conversation_id: str) -> dict[str, Any] | None:
        """è·å–å¯¹è¯æ‘˜è¦

        Returns:
            {
                "summary": str,
                "covered_through_created_at": datetime,  # å¤åˆè¦†ç›–ç‚¹ï¼šæ—¶é—´æˆ³
                "covered_through_message_id": str,      # å¤åˆè¦†ç›–ç‚¹ï¼šæ¶ˆæ¯ ID
                "covered_message_count": int,
                "summary_version": int,
                "created_at": datetime,
                "updated_at": datetime
            } or None
        """
        ...

    @abstractmethod
    async def save_summary_upsert(
        self,
        conversation_id: str,
        summary: str,
        covered_through_created_at: datetime,
        covered_through_message_id: str,
        covered_count: int,
        expected_version: int | None = None
    ) -> bool:
        """ä¿å­˜æˆ–æ›´æ–°æ‘˜è¦ï¼ˆUPSERTï¼‰

        å¹¶å‘å®‰å…¨ä¿è¯ï¼š
        - ä½¿ç”¨ ON CONFLICT DO UPDATE
        - WHERE å­å¥ç¡®ä¿åªå…è®¸è¦†ç›–ç‚¹å‰è¿›ï¼ˆå¤åˆè¦†ç›–ç‚¹ï¼‰
        - ä¹è§‚é”ç‰ˆæœ¬æ£€æŸ¥

        Args:
            conversation_id: å¯¹è¯ ID
            summary: æ‘˜è¦æ–‡æœ¬
            covered_through_created_at: è¦†ç›–ç‚¹æ—¶é—´æˆ³ï¼ˆä¸»åºï¼‰
            covered_through_message_id: è¦†ç›–ç‚¹æ¶ˆæ¯ IDï¼ˆtie-breakï¼‰
            covered_count: å·²æ‘˜è¦çš„æ¶ˆæ¯æ•°é‡
            expected_version: æœŸæœ›çš„ç‰ˆæœ¬å·ï¼ˆä¹è§‚é”ï¼ŒNone è¡¨ç¤ºä¸æ£€æŸ¥ï¼‰

        Returns:
            bool: æ˜¯å¦æˆåŠŸæ›´æ–°ï¼ˆFalse è¡¨ç¤ºç‰ˆæœ¬å†²çªï¼Œéœ€è¦é‡è¯•ï¼‰
        """
        ...

    @abstractmethod
    async def count_messages(self, conversation_id: str) -> int:
        """ç»Ÿè®¡å¯¹è¯ä¸­çš„æ¶ˆæ¯æ•°é‡

        ç”¨äºåˆ¤æ–­æ˜¯å¦è¾¾åˆ°æ‘˜è¦é˜ˆå€¼ï¼ˆmin_messages = 10ï¼‰
        æ³¨æ„ï¼šè¿™é‡Œç»Ÿè®¡çš„æ˜¯ messages è¡¨ï¼Œä¸æ˜¯ conversation_summaries è¡¨
        """
        ...

    @abstractmethod
    async def list_messages_since(
        self,
        conversation_id: str,
        since_created_at: datetime | None,
        since_message_id: str | None,
        limit: int | None = 50
    ) -> list[dict[str, Any]]:
        """è·å–æŒ‡å®šè¦†ç›–ç‚¹ä¹‹åçš„æ–°æ¶ˆæ¯ï¼ˆæ¸¸æ ‡åˆ†é¡µï¼‰

        å…³é”®è®¾è®¡ï¼š
        - ä½¿ç”¨ (created_at, id) å¤åˆæ¡ä»¶è¿›è¡Œæ¸¸æ ‡åˆ†é¡µ
        - SQL: WHERE created_at > $1 OR (created_at = $1 AND id > $2)
        - é¿å… UUID v4 çš„éšæœºæ€§é—®é¢˜ï¼ˆæ¼æ¶ˆæ¯ã€ä¹±åºã€ä¸å¹‚ç­‰ï¼‰
        - å®Œå…¨ä¾èµ– message_id å”¯ä¸€æ€§ï¼Œä¸è¿›è¡Œå†…å®¹å»é‡

        Args:
            conversation_id: å¯¹è¯ ID
            since_created_at: è¦†ç›–ç‚¹æ—¶é—´æˆ³ï¼ˆNone è¡¨ç¤ºä»å¤´å¼€å§‹ï¼‰
            since_message_id: è¦†ç›–ç‚¹æ¶ˆæ¯ IDï¼ˆNone è¡¨ç¤ºä»å¤´å¼€å§‹ï¼‰
            limit: æœ€å¤§è¿”å›æ•°é‡ï¼ˆNone è¡¨ç¤ºä¸é™åˆ¶ï¼‰

        Returns:
            æŒ‰ created_at ASC, id ASC æ’åºçš„æ¶ˆæ¯åˆ—è¡¨
        """
        ...
```

**Postgres å®ç°**ï¼š

```python
# backend/infrastructure/persistence/postgres/conversation_summary_store.py
class PostgresConversationSummaryStore(ConversationSummaryStorePort):
    def __init__(self, db_pool):
        self.db = db_pool

    async def get_summary(self, conversation_id: str) -> dict[str, Any] | None:
        result = await self.db.fetchrow(
            "SELECT * FROM conversation_summaries WHERE conversation_id = $1",
            conversation_id
        )
        return dict(result) if result else None

    async def save_summary_upsert(
        self,
        conversation_id: str,
        summary: str,
        covered_through_created_at: datetime,
        covered_through_message_id: str,
        covered_count: int,
        expected_version: int | None = None
    ) -> bool:
        """å¹‚ç­‰çš„ UPSERT æ“ä½œï¼ˆå¤åˆè¦†ç›–ç‚¹ï¼‰"""
        query = """
        INSERT INTO conversation_summaries
            (conversation_id, summary, covered_through_created_at, covered_through_message_id,
             covered_message_count, summary_version)
        VALUES ($1, $2, $3, $4, $5, 1)
        ON CONFLICT (conversation_id) DO UPDATE SET
            summary = EXCLUDED.summary,
            covered_through_created_at = EXCLUDED.covered_through_created_at,
            covered_through_message_id = EXCLUDED.covered_through_message_id,
            covered_message_count = EXCLUDED.covered_message_count,
            summary_version = conversation_summaries.summary_version + 1,
            updated_at = NOW()
        WHERE
            -- å•è°ƒé€’å¢çº¦æŸï¼šåªå…è®¸è¦†ç›–ç‚¹å‰è¿›ï¼ˆå¤åˆæ¡ä»¶ï¼‰
            (conversation_summaries.covered_through_created_at < EXCLUDED.covered_through_created_at)
            OR (conversation_summaries.covered_through_created_at = EXCLUDED.covered_through_created_at
                AND conversation_summaries.covered_through_message_id IS DISTINCT FROM EXCLUDED.covered_through_message_id)
            AND EXCLUDED.covered_through_message_id IS NOT NULL
            -- ä¹è§‚é”ï¼ˆå¦‚æœæä¾›ï¼‰
            AND ($6 IS NULL OR conversation_summaries.summary_version = $6)
        RETURNING summary_version
        """

        result = await self.db.fetchrow(
            query,
            conversation_id, summary, covered_through_created_at, covered_through_message_id,
            covered_count, expected_version
        )
        return result is not None

    async def count_messages(self, conversation_id: str) -> int:
        result = await self.db.fetchval(
            "SELECT COUNT(*) FROM messages WHERE conversation_id = $1",
            conversation_id
        )
        return result

    async def list_messages_since(
        self,
        conversation_id: str,
        since_created_at: datetime | None,
        since_message_id: str | None,
        limit: int | None = 50
    ) -> list[dict[str, Any]]:
        """è·å–æŒ‡å®šè¦†ç›–ç‚¹ä¹‹åçš„æ–°æ¶ˆæ¯ï¼ˆæ¸¸æ ‡åˆ†é¡µï¼‰"""

        if since_created_at is None:
            # é¦–æ¬¡æ‘˜è¦ï¼šä»å¤´å¼€å§‹
            query = """
            SELECT id, role, content, created_at, metadata
            FROM messages
            WHERE conversation_id = $1
            ORDER BY created_at ASC, id ASC
            LIMIT $2
            """
            return await self.db.fetch(query, conversation_id, limit)

        # æ¸¸æ ‡åˆ†é¡µï¼š(created_at, id) å¤åˆæ¡ä»¶
        query = """
        SELECT id, role, content, created_at, metadata
        FROM messages
        WHERE conversation_id = $1
          AND (
              created_at > $2  -- ä¸»åºï¼šæ—¶é—´æˆ³ä¹‹å
              OR (created_at = $2 AND id > $3)  -- tie-break
          )
        ORDER BY created_at ASC, id ASC
        LIMIT $4
        """
        return await self.db.fetch(
            query,
            conversation_id,
            since_created_at,
            since_message_id,
            limit
        )
```

**ä½¿ç”¨ç¤ºä¾‹**ï¼š

```python
# backend/graphrag_agent/agents/summary.py
class ConversationSummarizer:
    def __init__(
        self,
        summary_store: ConversationSummaryStorePort,  # ä¾èµ–æ³¨å…¥
        message_store: ConversationStorePort,
        llm_factory
    ):
        self.summary_store = summary_store  # ä¸“é—¨å¤„ç†æ‘˜è¦
        self.message_store = message_store  # ä¸“é—¨å¤„ç†æ¶ˆæ¯
        self.llm = llm_factory.get_model("qwen-turbo")

    async def try_trigger_update(self, conversation_id: str):
        # ä½¿ç”¨æ‘˜è¦å­˜å‚¨
        summary = await self.summary_store.get_summary(conversation_id)
        count = await self.summary_store.count_messages(conversation_id)

        if count >= 10 and not summary:
            # é¦–æ¬¡æ‘˜è¦ï¼šè·å–æ‰€æœ‰å†å²æ¶ˆæ¯
            messages = await self.summary_store.list_messages_since(
                conversation_id, since_created_at=None, since_message_id=None
            )
            # ç”Ÿæˆæ‘˜è¦å¹¶ä¿å­˜
            await self._generate_and_save(conversation_id, messages)
```

#### 2.1.5 å®ç°é€»è¾‘

**âš ï¸ æ³¨æ„**ï¼šå®Œæ•´çš„æ¥å£å®šä¹‰å’Œå®ç°å·²åœ¨å‰é¢ç»™å‡ºï¼Œæ­¤å¤„ä»…åˆ—å‡ºå…³é”®è¦ç‚¹ã€‚

**æ­£ç¡®çš„å®ç°ä½ç½®**ï¼š
- **æ¥å£å®šä¹‰**ï¼šè¯·å‚è€ƒ 2.1.4 æ•°æ®æ¨¡å‹ä¸­çš„"å­˜å‚¨æ¥å£è®¾è®¡"éƒ¨åˆ†
- **ä½¿ç”¨å¤åˆæ¸¸æ ‡**ï¼š`list_messages_since(since_created_at, since_message_id)`
- **æ­£ç¡®çš„ SQL**ï¼š`WHERE created_at > $1 OR (created_at = $1 AND id > $2)`

**å…³é”®ä¿®æ­£è¦ç‚¹**ï¼š
1. âœ… ä½¿ç”¨ `(created_at, id)` å¤åˆæ¸¸æ ‡åˆ†é¡µï¼ˆä¸æ˜¯å•ä¸€ `since_message_id`ï¼‰
2. âœ… Handler æ¥ä½ `append_message()` è¿”å›çš„ UUIDï¼ˆ**å®ƒæœ¬æ¥å°±è¿”å› UUIDï¼Œä¸éœ€è¦ä¿®æ”¹æ¥å£**ï¼‰
3. âœ… è¿‡æ»¤é€»è¾‘ï¼š`metadata.get("completed", True) and not debug.partial`
4. âœ… åå°ä»»åŠ¡ï¼šä½¿ç”¨ `SummaryTaskManager` æˆ– DB job è¡¨
5. âœ… è§¦å‘æ¡ä»¶ï¼šä»…åœ¨ `completed_normally == True` æ—¶è§¦å‘

**â›” ä¸è¦ä½¿ç”¨**ï¼ˆè¿™äº›æ˜¯é”™è¯¯çš„ï¼‰ï¼š
- âŒ `WHERE id > since_message_id`ï¼ˆUUID v4 ä¸æ”¯æŒæ—¶é—´åºï¼‰
- âŒ `metadata.partial`ï¼ˆå®é™…æ˜¯ `debug.partial`ï¼‰
- âŒ `content == message` å»é‡ï¼ˆä¼šè¯¯åˆ é‡å¤å†…å®¹ï¼‰
- âŒ ç®€å•çš„ `background_tasks.add_task`ï¼ˆæµå¼åœºæ™¯ä¼šä¸¢å¤±ï¼‰

#### 2.1.6 æ ¸å¿ƒä»£ç å®ç° (Pseudo-Code)

**âš ï¸ é‡è¦æç¤º**ï¼šä»¥ä¸‹æ˜¯ä¿®æ­£åçš„ä»£ç ç¤ºä¾‹ï¼Œä½¿ç”¨å¤åˆæ¸¸æ ‡åˆ†é¡µã€‚

```python
class ConversationSummarizer:
    def __init__(self, summary_store: ConversationSummaryStorePort, llm_factory):
        # é€šè¿‡å·¥å‚è·å–é…ç½®çš„æ¨¡å‹ (Qwen)
        self.llm = llm_factory.get_model(config.SUMMARY_MODEL_NAME)
        self.summary_store = summary_store
        self.min_messages = 10
        self.update_delta = 5

    async def try_trigger_update(self, conversation_id: str):
        """å°è¯•è§¦å‘åå°æ‘˜è¦æ›´æ–°ï¼ˆAsync Taskï¼‰"""
        # 1. è·å–å½“å‰æ‘˜è¦çŠ¶æ€ï¼ˆå¤åˆè¦†ç›–ç‚¹ï¼‰
        summary_data = await self.summary_store.get_summary(conversation_id)
        last_covered_at = summary_data.get("covered_through_created_at") if summary_data else None
        last_covered_id = summary_data.get("covered_through_message_id") if summary_data else None

        # 2. æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ–°å¢æ¶ˆæ¯ï¼ˆä½¿ç”¨å¤åˆæ¸¸æ ‡ï¼‰
        new_messages = await self.summary_store.list_messages_since(
            conversation_id=conversation_id,
            since_created_at=last_covered_at,  # âœ… å¤åˆæ¸¸æ ‡ï¼šæ—¶é—´æˆ³
            since_message_id=last_covered_id,  # âœ… å¤åˆæ¸¸æ ‡ï¼šID
            limit=self.update_delta + 1
        )

        if len(new_messages) < self.update_delta:
            return  # å°šæœªè¾¾åˆ°æ›´æ–°é˜ˆå€¼

        # 3. è¿‡æ»¤ Partial æ¶ˆæ¯ï¼ˆä¿®æ­£ï¼šä½¿ç”¨ debug.partial æˆ– completedï¼‰
        valid_messages = [
            m for m in new_messages
            if (m.metadata.get("completed", True) and  # âœ… ä¼˜å…ˆæ£€æŸ¥ completed
                 not m.metadata.get("debug", {}).get("partial", False))  # âœ… å…¼å®¹ debug.partial
        ]

        if not valid_messages:
            return

        # 4. ç”Ÿæˆä¸ä¿å­˜ï¼ˆä½¿ç”¨å¤åˆè¦†ç›–ç‚¹ï¼‰
        await self._generate_and_save(conversation_id, summary_data, valid_messages)

    async def _generate_and_save(self, conversation_id, current_summary, new_messages):
        """ç”Ÿæˆå¹¶ä¿å­˜æ‘˜è¦ï¼ˆå¤åˆè¦†ç›–ç‚¹ï¼‰"""
        # æ‹¼æ¥æ—§æ‘˜è¦ + æ–°å¢å¯¹è¯
        context_text = self._build_context(current_summary, new_messages)

        # LLM ç”Ÿæˆ (Qwen)
        new_summary_text = await self.llm.ainvoke(self._build_prompt(context_text))

        # âœ… ä¿å­˜å¤åˆè¦†ç›–ç‚¹ï¼ˆcreated_at + idï¼‰
        await self.summary_store.save_summary_upsert(
            conversation_id=conversation_id,
            summary=new_summary_text,
            covered_through_created_at=new_messages[-1]["created_at"],  # âœ… æ—¶é—´æˆ³
            covered_through_message_id=new_messages[-1]["id"],          # âœ… ID
            covered_count=current_summary.get("covered_message_count", 0) + len(new_messages),
            expected_version=current_summary.get("version", None)
        )
```

**å…³é”®ä¿®æ­£ç‚¹**ï¼š

1. **å¤åˆæ¸¸æ ‡åˆ†é¡µ**ï¼š
   ```python
   # âœ… æ­£ç¡®ï¼šä½¿ç”¨ (created_at, id) å¤åˆæ¸¸æ ‡
   new_messages = await self.summary_store.list_messages_since(
       conversation_id=conversation_id,
       since_created_at=last_covered_at,
       since_message_id=last_covered_id,
       limit=...
   )
   
   # âŒ é”™è¯¯ï¼šå•ä¸€ since_message_idï¼ˆUUID v4 ä¸æ”¯æŒæ—¶é—´åºï¼‰
   new_messages = await self.summary_store.list_messages_since(
       conversation_id=conversation_id,
       since_message_id=last_covered_id,
       limit=...
   )
   ```

2. **Partial æ¶ˆæ¯è¿‡æ»¤**ï¼š
   ```python
   # âœ… æ­£ç¡®ï¼šæ£€æŸ¥ completed æˆ– debug.partial
   valid_messages = [
       m for m in new_messages
       if (m.metadata.get("completed", True) and
            not m.metadata.get("debug", {}).get("partial", False))
   ]
   
   # âŒ é”™è¯¯ï¼šåªæ£€æŸ¥ metadata.partialï¼ˆå®é™…å­—æ®µæ˜¯ debug.partialï¼‰
   valid_messages = [
       m for m in new_messages
       if not m.metadata.get("partial")
   ]
   ```

3. **ä¿å­˜å¤åˆè¦†ç›–ç‚¹**ï¼š
   ```python
   # âœ… æ­£ç¡®ï¼šåŒæ—¶ä¿å­˜æ—¶é—´æˆ³å’Œ ID
   await self.summary_store.save_summary_upsert(
       covered_through_created_at=new_messages[-1]["created_at"],
       covered_through_message_id=new_messages[-1]["id"],
       ...
   )
   
   # âŒ é”™è¯¯ï¼šåªä¿å­˜ ID
   await self.summary_store.save_summary_upsert(
       last_message_id=new_messages[-1]["id"],
       ...
   )
   ```
            conversation_id=conversation_id,
            since_message_id=last_covered_id,
            limit=None  # è·å–æ‰€æœ‰æ–°å¢æ¶ˆæ¯
        )
       
        # æ’é™¤å½“å‰æ­£åœ¨å¤„ç†çš„ç”¨æˆ·æ¶ˆæ¯ï¼ˆé€šè¿‡ message_idï¼‰
        if new_messages and new_messages[-1]["id"] == self.current_message_id:
            new_messages = new_messages[:-1]
       
        if not new_messages:
            return old_summary.summary
       
        # å¢é‡æ›´æ–° Prompt
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯å¯¹è¯æ‘˜è¦ä¸“å®¶ã€‚ä»¥ä¸‹æ˜¯ä¹‹å‰çš„å¯¹è¯æ‘˜è¦å’Œæ–°å¢çš„å¯¹è¯å†…å®¹ã€‚
   è¯·æ›´æ–°æ‘˜è¦ï¼Œæ•´åˆæ–°ä¿¡æ¯å¹¶ä¿æŒç®€æ´ã€‚"""),
            ("user", """ä¹‹å‰çš„æ‘˜è¦ï¼š
   {old_summary}

æ–°å¢çš„å¯¹è¯ï¼š
{new_messages}

è¯·è¾“å‡ºæ›´æ–°åçš„æ‘˜è¦ï¼š""")
        ])

        # è°ƒç”¨ LLM æ›´æ–°æ‘˜è¦
        new_summary = await self.llm.ainvoke(
            prompt.format(
                old_summary=old_summary.summary,
                new_messages=format_messages(new_messages)
            )
        )
    
        # âœ… ä¿å­˜æ›´æ–°åçš„æ‘˜è¦ï¼ˆè®°å½•å¤åˆè¦†ç›–ç‚¹ï¼‰
        await self.summary_store.save_summary_upsert(
            conversation_id=conversation_id,
            summary=new_summary.content,
            covered_through_created_at=new_messages[-1]["created_at"],  # âœ… æ—¶é—´æˆ³
            covered_through_message_id=new_messages[-1]["id"],           # âœ… ID
            covered_message_count=old_summary["covered_message_count"] + len(new_messages),
            expected_version=old_summary.get("summary_version", None)
        )
    
        return new_summary.content
```

#### 2.1.7 é›†æˆåˆ° Handler

**åœ¨ ChatHandler ä¸­é›†æˆæ‘˜è¦åŠŸèƒ½ï¼š**

```python
# backend/application/chat/handlers/chat_handler.py
async def _get_context(self, conversation_id: str) -> dict:
    """æ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆæ‘˜è¦ + æœ€è¿‘æ¶ˆæ¯ï¼‰"""

    # 1. è·å–æˆ–ç”Ÿæˆæ‘˜è¦
    summary = None
    if await self._summarizer.should_summarize(conversation_id):
        existing_summary = await self.summary_store.get_summary(conversation_id)
        if existing_summary is None:
            # é¦–æ¬¡ç”Ÿæˆ
            summary = await self._summarizer.generate_summary(conversation_id)
        else:
            # å¢é‡æ›´æ–°
            summary = await self._summarizer.update_summary(conversation_id, existing_summary)
    else:
        # ä½¿ç”¨ç°æœ‰æ‘˜è¦
        existing = await self.summary_store.get_summary(conversation_id)
        summary = existing.get("summary") if existing else None

    # 2. è·å–æœ€è¿‘æ¶ˆæ¯ï¼ˆæ—¶é—´çª—å£ï¼‰
    recent = await self.message_store.list_messages(
        conversation_id=conversation_id,
        limit=6,
        desc=True
    )
    recent.reverse()

    return {
        "summary": summary,
        "recent_history": recent
    }
```

#### 2.1.8 Prompt æ„å»ºè°ƒæ•´

**åœ¨ Prompt æ„å»ºä¸­æ³¨å…¥æ‘˜è¦ï¼š**

```python
# backend/llm/completion.py
def _build_general_prompt(
    system_message: str,
    memory_context: str | None,
    summary: str | None,  # æ–°å¢ï¼šå¯¹è¯æ‘˜è¦
    history: list[dict] | None,
    question: str
) -> ChatPromptTemplate:
    """æ„å»ºé€šç”¨å¯¹è¯ Prompt"""

    messages = [("system", system_message)]

    # 1. é•¿æœŸç”¨æˆ·è®°å¿†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if memory_context:
        messages.append(("system", f"ã€ç”¨æˆ·é•¿æœŸè®°å¿†ã€‘\n{memory_context}"))

    # 2. å¯¹è¯èƒŒæ™¯æ‘˜è¦ï¼ˆæ–°å¢ï¼‰
    if summary:
        messages.append(("system", f"ã€å¯¹è¯èƒŒæ™¯ã€‘\n{summary}"))

    # 3. æœ€è¿‘å¯¹è¯å†å²ï¼ˆæ—¶é—´çª—å£ï¼‰
    if history:
        for msg in history:
            role = "assistant" if msg.get("role") == "assistant" else "human"
            messages.append((role, msg.get("content", "")))

    # 4. å½“å‰é—®é¢˜
    messages.append(("human", question))

    return ChatPromptTemplate.from_messages(messages)
```

**ç¤ºä¾‹ Prompt è¾“å‡ºï¼š**

```
[System]: ä½ æ˜¯ç”µå½±æ¨èä¸“å®¶...

[System]: ã€ç”¨æˆ·é•¿æœŸè®°å¿†ã€‘
ç”¨æˆ·å–œæ¬¢ç§‘å¹»ç”µå½±ï¼Œç‰¹åˆ«æ˜¯è¯ºå…°å¯¼æ¼”çš„ä½œå“ã€‚ä¸å–œæ¬¢ææ€–ç‰‡ã€‚

[System]: ã€å¯¹è¯èƒŒæ™¯ã€‘
ç”¨æˆ·ä¹‹å‰è®¨è®ºäº†90å¹´ä»£ç»å…¸ç§‘å¹»ç”µå½±ï¼Œé‡ç‚¹å…³æ³¨ã€Šé»‘å®¢å¸å›½ã€‹å’Œã€Šç»ˆç»“è€…2ã€‹ã€‚
ç”¨æˆ·è¯¢é—®äº†è¿™ä¸¤éƒ¨ç”µå½±çš„æŠ€æœ¯åˆ›æ–°å’Œæ–‡åŒ–å½±å“ã€‚

[Human]: æ¨èä¸€äº›ç±»ä¼¼é£æ ¼çš„ç”µå½±

[Assistant]: åŸºäºä½ å–œæ¬¢ã€Šé»‘å®¢å¸å›½ã€‹å’Œã€Šç»ˆç»“è€…2ã€‹...

[Human]: è¿™äº›ç”µå½±æœ‰ä»€ä¹ˆå…±åŒç‚¹ï¼Ÿ

[Human]: èƒ½æ¨èä¸€äº›æ›´è¿‘æœŸçš„ä½œå“å—ï¼Ÿ
```

#### 2.1.9 ä¼˜åŠ¿åˆ†æ

**ä¸ Baseline å¯¹æ¯”ï¼š**

| æŒ‡æ ‡ | Baseline | Phase 1 (æ‘˜è¦) | æ”¹è¿› |
|------|----------|----------------|------|
| **Token æ¶ˆè€—**ï¼ˆ50è½®å¯¹è¯ï¼‰| ~8000 | ~680 | â¬‡ï¸ 91.5% |
| **ä¸Šä¸‹æ–‡è¦†ç›–** | æœ€è¿‘ 6 è½® | å…¨éƒ¨å†å²ï¼ˆå‹ç¼©ï¼‰ | âœ… å…¨å±€ |
| **å“åº”å»¶è¿Ÿ** | åŸºå‡† | ç”¨æˆ·ä¸å¯æ„Ÿï¼ˆåå°å¼‚æ­¥ï¼‰ | âœ… æ— å½±å“ |
| **å®ç°å¤æ‚åº¦** | ä½ | ä¸­ | âš ï¸ éœ€é¢å¤–ç®¡ç† |
| **é•¿å¯¹è¯è´¨é‡** | ä¿¡æ¯ä¸¢å¤± | ä¿æŒå…³é”®ä¿¡æ¯ | âœ… æ˜¾è‘—æå‡ |

**æ€§èƒ½ä¿®æ­£è¯´æ˜**ï¼š

| æŒ‡æ ‡ | ä¿®æ­£å‰ | ä¿®æ­£å | ç†ç”± |
|------|--------|--------|------|
| æ‘˜è¦ç”Ÿæˆå»¶è¿Ÿ | +50msï¼ˆé¦–æ¬¡ç”Ÿæˆï¼‰ | ç”¨æˆ·ä¸å¯æ„Ÿï¼ˆåå°å¼‚æ­¥ï¼‰ | æ‘˜è¦ç”Ÿæˆæ”¹ä¸ºåå°ä»»åŠ¡ï¼Œä¸é˜»å¡ä¸»å“åº” |
| æ‘˜è¦æ›´æ–°é¢‘ç‡ | æ¯æ¬¡ 5 æ¡ | ä»…å½“ completed_normally | é¿å…æµå¼ä¸­æ–­å¯¼è‡´é‡å¤ç”Ÿæˆ |
| æŸ¥è¯¢æ–¹å¼ | å…¨é‡æ‹‰å– messages | å¤åˆæ¸¸æ ‡åˆ†é¡µï¼ˆWHERE created_at > $t OR (created_at = $t AND id > $id) LIMIT 50ï¼‰ | é¿å…å…¨è¡¨æ‰«æï¼Œæ”¯æŒå¹‚ç­‰æŸ¥è¯¢ |
| Token å¼€é”€ | 4000ï¼ˆä¸€æ¬¡æ€§ï¼‰ | 4000ï¼ˆä¸€æ¬¡æ€§ï¼‰ | æˆæœ¬ä¸å˜ï¼Œä½†å»¶è¿Ÿå®Œå…¨éšè— |

**å…³é”®ä¼˜åŠ¿ï¼š**

1. **æˆæœ¬ä¼˜åŒ–**ï¼š
   - 50 è½®å¯¹è¯èŠ‚çœ **91.5%** Token
   - æ‘˜è¦ç”Ÿæˆæˆæœ¬ï¼š~4000 tokensï¼ˆä¸€æ¬¡æ€§ï¼‰
   - æ¯æ¬¡è¯·æ±‚æˆæœ¬ï¼š~680 tokens vs 8000 tokens

2. **ä¸Šä¸‹æ–‡ä¿ç•™**ï¼š
   - Baselineï¼šåªèƒ½è®°ä½æœ€è¿‘ 6 è½®
   - Phase 1ï¼šä¿ç•™å…¨éƒ¨å¯¹è¯çš„å…³é”®ä¿¡æ¯

3. **ç”¨æˆ·ä½“éªŒ**ï¼š
   - é•¿å¯¹è¯ä¸­ä¸ä¼šå‡ºç°"å¿˜äº†ä¹‹å‰è¯´çš„"çš„é—®é¢˜
   - Agent èƒ½è®°ä½å¯¹è¯æ—©æœŸçš„ç”¨æˆ·åå¥½

#### 2.1.10 å…³é”®è®¾è®¡å†³ç­–æ€»ç»“

| å†³ç­–ç‚¹ | é€‰æ‹© | ç†ç”± | æƒè¡¡ |
|-------|------|------|------|
| **æ¶æ„æ¨¡å¼** | æ»‘åŠ¨çª—å£ + æ‘˜è¦ | å¹³è¡¡å…¨å±€ä¸Šä¸‹æ–‡å’Œå±€éƒ¨ç»†èŠ‚ | éœ€è¦é¢å¤–çš„æ‘˜è¦ç®¡ç† |
| **è§¦å‘é˜ˆå€¼** | 10 æ¡æ¶ˆæ¯ | ç¡®ä¿æœ‰è¶³å¤Ÿä¸Šä¸‹æ–‡ï¼Œé¿å…è¿‡æ—©æ‘˜è¦ | çŸ­å¯¹è¯æ— æ‘˜è¦ä¼˜åŒ– |
| **æ›´æ–°é¢‘ç‡** | æ¯ 5 æ¡æ¶ˆæ¯ | å¹³è¡¡æ–°é²œåº¦å’Œæˆæœ¬ | å¯èƒ½æœ‰ 2-3 è½®å»¶è¿Ÿ |
| **å­˜å‚¨ç»“æ„** | ç‹¬ç«‹è¡¨ | æ¸…æ™°åˆ†ç¦»ï¼Œæ˜“æ‰©å±• | éœ€è¦ JOIN æŸ¥è¯¢ |
| **LLM é€‰æ‹©** | Qwen (é¡¹ç›®å†…ç½®) | ä¸ä¸»å¯¹è¯ä¸€è‡´ï¼Œæ— éœ€é¢å¤–ä¾èµ– | å¤ç”¨ç°æœ‰åŸºç¡€è®¾æ–½ |
| **æ›´æ–°ç­–ç•¥** | å¢é‡æ›´æ–° | é™ä½ Token æ¶ˆè€— 80% | å¯èƒ½ç´¯ç§¯è¯¯å·® |
| **çª—å£å¤§å°** | 6 æ¡æ¶ˆæ¯ | è¦†ç›–æœ€è¿‘ 3 è½®ï¼Œç¬¦åˆå·¥ä½œè®°å¿† | æ¯”çº¯æ‘˜è¦å¤š 480 tokens |
| **é™çº§ç­–ç•¥** | å¤±è´¥å›é€€åˆ°æ—¶é—´çª—å£ | ä¿è¯å¯ç”¨æ€§ | å¤±å»ä¼˜åŒ–æ•ˆæœ |

---

### Phase 2: ä¸»åŠ¨å¼æƒ…èŠ‚è®°å¿† (Active Episodic Memory)

#### 2.2.1 æ ¸å¿ƒè®¾è®¡ (ä¸»åŠ¨å¼è®°å¿†ç®¡ç†)

**æ ¸å¿ƒç†å¿µï¼šä»è¢«åŠ¨å­˜å‚¨åˆ°ä¸»åŠ¨ç®¡ç†**

ä¼ ç»Ÿå¯¹è¯ç³»ç»Ÿçš„è®°å¿†æ˜¯**è¢«åŠ¨**çš„ï¼šå†å²æ¶ˆæ¯æŒ‰æ—¶é—´é¡ºåºå­˜å‚¨ï¼Œæ£€ç´¢æ—¶ä»…é  Top-K å‘é‡ç›¸ä¼¼åº¦ã€‚è¿™ç§æ–¹å¼å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š

1. **æ— æ³•è‡ªæˆ‘ä¿®æ­£**ï¼šç”¨æˆ·è¯´"æˆ‘ä¸å†å–œæ¬¢ææ€–ç‰‡äº†"ï¼Œç³»ç»Ÿæ— æ³•æ›´æ–°æ—§çš„è®°å¿†
2. **æ— æ³•ä¸»åŠ¨å½’æ¡£**ï¼šé‡è¦å†³ç­–å’Œåå¥½å˜æ›´æ— æ³•è¢«æ ‡è®°å’Œé•¿æœŸä¿å­˜
3. **æ£€ç´¢ä¸ç²¾å‡†**ï¼šä»…ä¾èµ–å‘é‡ç›¸ä¼¼åº¦ï¼Œæ— æ³•ç†è§£"åˆšæ‰æåˆ°çš„å¯¼æ¼”"è¿™ç±»æŒ‡ä»£

Phase 2 å¼•å…¥ **ä¸»åŠ¨å¼è®°å¿†ç®¡ç†**ï¼ˆActive Episodic Memoryï¼‰ï¼Œçµæ„Ÿæ¥æºäº MemGPTï¼Œèµ‹äºˆ Agent ä»¥ä¸‹èƒ½åŠ›ï¼š

| èƒ½åŠ› | è¢«åŠ¨ç³»ç»Ÿï¼ˆPhase 1ï¼‰ | ä¸»åŠ¨ç³»ç»Ÿï¼ˆPhase 2ï¼‰ |
|------|-------------------|-------------------|
| **è®°å¿†æ›´æ–°** | âŒ åªèƒ½è¿½åŠ ï¼Œæ— æ³•ä¿®æ”¹ | âœ… `core_memory_update` è¦†ç›–æ—§å€¼ |
| **è®°å¿†æ£€ç´¢** | âš ï¸ è¢«åŠ¨ Top-K å‘é‡æœç´¢ | âœ… ä¸»åŠ¨ç†è§£ä¸Šä¸‹æ–‡ï¼ŒæŒ‰éœ€æ£€ç´¢ |
| **è®°å¿†å½’æ¡£** | âŒ æ— å½’æ¡£èƒ½åŠ› | âœ… `archival_memory_insert` ä¸»åŠ¨ä¿å­˜å…³é”®äº‹ä»¶ |
| **è®°å¿†å±‚çº§** | å•å±‚ï¼ˆæ—¶é—´åºï¼‰ | ä¸‰å±‚ï¼ˆCore + Recent + Archivalï¼‰ |

**ä¸‰å¤§æ ¸å¿ƒç»„ä»¶**ï¼š

1. **ä¸»åŠ¨å¼è®°å¿†ç®¡ç† (Active Management)**
   - èµ‹äºˆ Agent ä¿®æ”¹ã€åˆ é™¤ã€å½’æ¡£è®°å¿†çš„èƒ½åŠ›
   - ä¸å†æ˜¯"å­˜å‚¨-æ£€ç´¢"çš„å•å‘æµç¨‹ï¼Œè€Œæ˜¯"æ„ŸçŸ¥-å†³ç­–-æ“ä½œ"çš„é—­ç¯

2. **æ ¸å¿ƒè®°å¿†åŒº (Core Memory)**
   - ç»´æŠ¤ä¸€ä¸ªå§‹ç»ˆåœ¨çº¿çš„ã€ç»“æ„åŒ–çš„ç”¨æˆ·ç”»åƒ
   - ç±»ä¼¼äºäººç±»çš„"å·¥ä½œè®°å¿†"ï¼Œå§‹ç»ˆä¿æŒå¯è®¿é—®çŠ¶æ€
   - å…è®¸ Agent å®æ—¶æ›´æ–°åå¥½ã€æ„å›¾ã€ä¸Šä¸‹æ–‡

3. **ä¸¤çº§å­˜å‚¨æ¶æ„**
   - **RAM (Context)**: System Prompt + Core Memory (Profile) + Recent History
   - **Disk (Archival)**: å‘é‡å­˜å‚¨ (Vector Store) + Checkpoints

**ä¸ MemGPT çš„æ¦‚å¿µå¯¹æ¯”**ï¼š

| æ¦‚å¿µ | MemGPT | Phase 2 å®ç° |
|------|--------|-------------|
| **Core Memory** | ç”¨æˆ·ç”»åƒ + ä»»åŠ¡ä¸Šä¸‹æ–‡ | Redis/Postgres å­˜å‚¨ç»“æ„åŒ– JSON |
| **Archival Memory** | å‘é‡æ•°æ®åº“ï¼Œå­˜å‚¨é•¿æœŸæƒ…èŠ‚ | Milvus å‘é‡å­˜å‚¨ + æƒ…èŠ‚ç±»å‹æ ‡è®° |
| **Retention æœºåˆ¶** | LLM å†³å®šæ˜¯å¦å½’æ¡£ | Memory Agent ä¸»åŠ¨å†³ç­– |
| **æ£€ç´¢è§¦å‘** | å·¥å…·è°ƒç”¨ (archival_memory_search) | ä¸»åŠ¨å¼é¢„åˆ¤ + æŒ‰éœ€æ£€ç´¢ |

**å…³é”®è®¾è®¡åŸåˆ™**ï¼š

1. **å•ä¸€èŒè´£**ï¼šMemory Agent ä¸“æ³¨äºè®°å¿†ç®¡ç†ï¼Œä¸å‚ä¸å¯¹è¯ç”Ÿæˆ
2. **å¼‚æ­¥éé˜»å¡**ï¼šè®°å¿†æ“ä½œåœ¨åå°æ‰§è¡Œï¼Œä¸å½±å“æµå¼å“åº”
3. **å¯è§‚æµ‹æ€§**ï¼šæ‰€æœ‰è®°å¿†æ“ä½œéƒ½æœ‰æ—¥å¿—è®°å½•ï¼Œä¾¿äºè°ƒè¯•
4. **æ¸è¿›å¼å¢å¼º**ï¼šå¯ä»¥ä¸ Phase 1 çš„æ‘˜è¦åŠŸèƒ½å…±å­˜ï¼Œé€æ­¥è¿ç§»

#### 2.2.2 æ¶æ„ä¸æµç¨‹å›¾

**æ•´ä½“æ¶æ„å›¾**ï¼š

```mermaid
graph TB
    User[ç”¨æˆ·æ¶ˆæ¯] --> Handler[StreamHandler]

    Handler --> MemAgent[Memory Agent<br/>è®°å¿†ç®¡ç†å™¨]

    MemAgent -->|å†³ç­–| Think{éœ€è¦è®°å¿†æ“ä½œ?}

    Think -->|æ›´æ–°ç”»åƒ| CoreUpdate[core_memory_update]
    Think -->|æ£€ç´¢å†å²| ArchivalSearch[archival_memory_search]
    Think -->|å½’æ¡£å½“å‰å¯¹è¯| ArchivalInsert[archival_memory_insert]
    Think -->|æ— éœ€æ“ä½œ| Skip[è·³è¿‡]

    CoreUpdate --> CoreMem[(Core Memory<br/>Redis/Postgres)]
    ArchivalSearch --> VecStore[(Vector Store<br/>Milvus)]
    ArchivalInsert --> VecStore

    CoreMem --> Context[æ„å»ºä¸Šä¸‹æ–‡]
    VecStore --> Context
    Handler --> Recent[Recent History<br/>æœ€è¿‘6æ¡æ¶ˆæ¯]
    Recent --> Context

    Context --> LLM[LLM ç”Ÿæˆ]

    LLM --> Response[å›å¤ç”¨æˆ·]
    Response --> MemAgent
    MemAgent -.->|å¼‚æ­¥| ArchivalInsert

    style CoreMem fill:#e1f5ff
    style VecStore fill:#fff4e6
    style MemAgent fill:#f3e5f5
    style Think fill:#fff9c4
```

**è®°å¿†å†³ç­–æµç¨‹**ï¼š

```mermaid
flowchart TD
    Start([æ”¶åˆ°ç”¨æˆ·æ¶ˆæ¯]) --> Analyze[Memory Agent åˆ†ææ¶ˆæ¯]

    Analyze --> CheckIntent{æ˜¯å¦åŒ…å«<br/>åå¥½/æ„å›¾?}

    CheckIntent -->|æ˜¯| UpdateCore[æ›´æ–° Core Memory]
    CheckIntent -->|å¦| CheckRef{æ˜¯å¦åŒ…å«<br/>å†å²æŒ‡ä»£?}

    UpdateCore --> SaveCore[ä¿å­˜åˆ° Redis/Postgres]
    SaveCore --> Continue

    CheckRef -->|æ˜¯| SearchArchival[æ£€ç´¢ Archival Memory]
    CheckRef -->|å¦| CheckDecision{æ˜¯å¦ä¸º<br/>é‡è¦å†³ç­–?}

    SearchArchival --> AddContext[æ·»åŠ åˆ°ä¸Šä¸‹æ–‡]
    AddContext --> Continue

    CheckDecision -->|æ˜¯| InsertArchival[å½’æ¡£åˆ° Archival Memory]
    CheckDecision -->|å¦| Continue

    InsertArchival --> Continue

    Continue([ç»§ç»­ç”Ÿæˆå›å¤])

    style UpdateCore fill:#c8e6c9
    style SearchArchival fill:#fff9c4
    style InsertArchival fill:#ffccbc
```

**è®°å¿†ç”Ÿå‘½å‘¨æœŸçŠ¶æ€å›¾**ï¼š

```mermaid
stateDiagram-v2
    [*] --> Recent: æ¶ˆæ¯äº§ç”Ÿ
    Recent --> Core: æå–åˆ°åå¥½/æ„å›¾
    Recent --> Archival: é‡è¦å¯¹è¯ç‰‡æ®µ
    Recent --> Forgotten: è¶…å‡ºçª—å£æœªå½’æ¡£

    Core --> Core: æ›´æ–°/ä¿®æ”¹
    Core --> Archival: å®šæœŸå½’æ¡£å¿«ç…§

    Archival --> Retrieved: å‘é‡æ£€ç´¢å‘½ä¸­
    Retrieved --> Context: æ·»åŠ åˆ°å½“å‰ä¸Šä¸‹æ–‡

    Core --> [*]: ä¼šè¯ç»“æŸ
    Archival --> [*]: é•¿æœŸå­˜å‚¨

    note right of Recent
        æœ€è¿‘ 6 æ¡æ¶ˆæ¯
        æ—¶é—´çª—å£
    end note

    note right of Core
        ç”¨æˆ·ç”»åƒ
        å®æ—¶å¯ç¼–è¾‘
        å·¥ä½œè®°å¿†
    end note

    note right of Archival
        å‘é‡å­˜å‚¨
        æŒ‰æƒ…èŠ‚ç±»å‹åˆ†ç±»
        é•¿æœŸè®°å¿†
    end note
```

**ä¸Šä¸‹æ–‡æ„å»ºæµç¨‹**ï¼š

```mermaid
sequenceDiagram
    participant U as User
    participant H as Handler
    participant M as Memory Agent
    participant C as Core Memory
    participant A as Archival Memory
    participant L as LLM

    U->>H: å‘é€æ¶ˆæ¯

    H->>M: analyze(message)
    M->>M: æ£€æµ‹åˆ°"åˆšæ‰æåˆ°çš„å¯¼æ¼”"

    M->>A: archival_search("å¯¼æ¼”")
    A-->>M: è¿”å›ç›¸å…³ç‰‡æ®µ

    M->>C: æ£€æŸ¥åå¥½æ›´æ–°
    C-->>M: å½“å‰åå¥½

    M-->>H: è¿”å›è®°å¿†ä¸Šä¸‹æ–‡

    H->>H: æ„å»ºå®Œæ•´ Prompt
    Note over H: System + Core + Recent + Archival

    H->>L: generate(prompt)
    L-->>H: æµå¼å›å¤

    H-->>U: è¿”å›å›å¤

    H->>M: è®°å¿†æ›´æ–°ï¼ˆå¼‚æ­¥ï¼‰
    M->>C: core_memory_update()
    M->>A: archival_insert()
```

#### 2.2.3 æ•°æ®æ¨¡å‹

**å¤ç”¨ç°æœ‰å‘é‡å­˜å‚¨åŸºç¡€è®¾æ–½**ï¼ˆå·²æœ‰ Milvus + Postgresï¼‰

```sql
-- æ‰©å±• messages è¡¨
ALTER TABLE messages ADD COLUMN embedding vector(1536);
CREATE INDEX ON messages USING ivfflat (embedding vector_cosine_ops);
```

æˆ–è€…ä½¿ç”¨ç‹¬ç«‹çš„å‘é‡å­˜å‚¨ï¼ˆæ¨èï¼Œé¿å…æ±¡æŸ“ messages è¡¨ï¼‰ï¼š

```python
# åœ¨ Milvus ä¸­åˆ›å»ºæ–° Collection
conversation_episodes_collection = {
    "name": "conversation_episodes",
    "fields": [
        {"name": "id", "type": "VARCHAR", "is_primary": True},
        {"name": "conversation_id", "type": "VARCHAR"},
        {"name": "user_message", "type": "VARCHAR"},
        {"name": "assistant_message", "type": "VARCHAR"},
        {"name": "embedding", "type": "FLOAT_VECTOR", "dim": 1536},
        {"name": "created_at", "type": "INT64"},
    ]
}
```

#### 2.2.4 Memory Agent è®¾è®¡

**Memory Agent çš„èŒè´£**ï¼š

Memory Agent æ˜¯ä¸€ä¸ªä¸“é—¨çš„ Agentï¼Œç‹¬ç«‹äºå¯¹è¯ç”Ÿæˆæµç¨‹ï¼Œä¸“æ³¨äºè®°å¿†ç®¡ç†ã€‚å®ƒçš„æ ¸å¿ƒèŒè´£åŒ…æ‹¬ï¼š

1. **æ„ŸçŸ¥**ï¼šåˆ†æå½“å‰å¯¹è¯ï¼Œè¯†åˆ«éœ€è¦è®°å¿†çš„ä¿¡æ¯
2. **å†³ç­–**ï¼šåˆ¤æ–­æ˜¯å¦éœ€è¦æ›´æ–°/æ£€ç´¢/å½’æ¡£è®°å¿†
3. **æ‰§è¡Œ**ï¼šè°ƒç”¨ç›¸åº”çš„å·¥å…·æ‰§è¡Œè®°å¿†æ“ä½œ

**ä¸ºä»€ä¹ˆéœ€è¦ç‹¬ç«‹çš„ Memory Agentï¼Ÿ**

| æ–¹æ¡ˆ | ä¼˜ç‚¹ | ç¼ºç‚¹ |
|------|------|------|
| **åœ¨å¯¹è¯ Agent ä¸­ç›´æ¥å¤„ç†** | å®ç°ç®€å• | â€¢ æ··æ‚èŒè´£ï¼Œå¯¹è¯é€»è¾‘å¤æ‚åŒ–<br/>â€¢ æ¯æ¬¡ç”Ÿæˆéƒ½éœ€è¦è®°å¿†åˆ¤æ–­ï¼ŒToken æµªè´¹<br/>â€¢ éš¾ä»¥å•ç‹¬æµ‹è¯•å’Œä¼˜åŒ– |
| **ç‹¬ç«‹çš„ Memory Agent** âœ… | â€¢ èŒè´£åˆ†ç¦»ï¼Œä»£ç æ¸…æ™°<br/>â€¢ å¯ä»¥å¼‚æ­¥æ‰§è¡Œï¼Œä¸é˜»å¡å“åº”<br/>â€¢ å¯ç‹¬ç«‹ä¼˜åŒ–è®°å¿†ç­–ç•¥ | â€¢ éœ€è¦é¢å¤–çš„ Agent è°ƒç”¨ |

**Memory Agent çš„å†³ç­–é€»è¾‘**ï¼š

```python
# backend/graphrag_agent/agents/memory_agent.py

class MemoryAgent:
    """ä¸»åŠ¨å¼è®°å¿†ç®¡ç† Agent

    æ ¸å¿ƒè®¾è®¡åŸåˆ™ï¼š
    1. ä¸å‚ä¸å¯¹è¯ç”Ÿæˆï¼Œä»…ç®¡ç†è®°å¿†
    2. å¼‚æ­¥æ‰§è¡Œï¼Œä¸é˜»å¡æµå¼å“åº”
    3. å¯è§‚æµ‹ï¼Œæ‰€æœ‰æ“ä½œéƒ½æœ‰æ—¥å¿—
    """

    async def analyze_and_act(
        self,
        user_message: str,
        assistant_message: str,
        conversation_id: str,
        user_id: str
    ) -> list[MemoryOperation]:
        """åˆ†æå¯¹è¯å¹¶æ‰§è¡Œè®°å¿†æ“ä½œ

        Returns:
            æ‰§è¡Œçš„è®°å¿†æ“ä½œåˆ—è¡¨ï¼ˆç”¨äºæ—¥å¿—å’Œè°ƒè¯•ï¼‰
        """
        operations = []

        # 1. æ£€æµ‹åå¥½å˜æ›´
        if await self._detect_preference_change(user_message):
            new_preferences = await self._extract_preferences(user_message)
            await self.core_memory.update(user_id, "preferences", new_preferences)
            operations.append(MemoryOperation(
                type="core_update",
                field="preferences",
                value=new_preferences
            ))

        # 2. æ£€æµ‹å†å²æŒ‡ä»£
        if await self._detect_temporal_reference(user_message):
            # "åˆšæ‰"ã€"ä¹‹å‰"ç­‰å…³é”®è¯
            query = await self._extract_search_query(user_message)
            results = await self.archival_memory.search(user_id, query)
            # ç»“æœä¼šè¢«ç¼“å­˜ï¼Œä¾›ä¸‹æ¬¡å¯¹è¯ä½¿ç”¨
            await self.context_cache.set(conversation_id, "archival_context", results)
            operations.append(MemoryOperation(
                type="archival_search",
                query=query,
                results_count=len(results)
            ))

        # 3. æ£€æµ‹é‡è¦å†³ç­–
        if await self._detect_important_decision(user_message, assistant_message):
            episode = {
                "type": "decision",
                "content": f"User: {user_message}\nAssistant: {assistant_message}",
                "importance": await self._calculate_importance(user_message, assistant_message)
            }
            await self.archival_memory.insert(user_id, episode)
            operations.append(MemoryOperation(
                type="archival_insert",
                episode_type="decision",
                importance=episode["importance"]
            ))

        return operations

    async def _detect_preference_change(self, message: str) -> bool:
        """æ£€æµ‹æ˜¯å¦åŒ…å«åå¥½å˜æ›´"""
        # æ–¹æ¡ˆ1ï¼šè§„åˆ™åŒ¹é…ï¼ˆå¿«é€Ÿï¼‰
        keywords = ["ä¸å†", "æ”¹æˆ", "æ¢ä¸ª", "ä¸è¦", "å–œæ¬¢", "è®¨åŒ"]
        if any(kw in message for kw in keywords):
            return True

        # æ–¹æ¡ˆ2ï¼šLLM åˆ¤æ–­ï¼ˆå‡†ç¡®ä½†æ…¢ï¼‰
        # response = await self.llm.generate(f"åˆ¤æ–­æ¶ˆæ¯æ˜¯å¦åŒ…å«åå¥½å˜æ›´: {message}")
        # return "preference_change" in response

        return False

    async def _detect_temporal_reference(self, message: str) -> bool:
        """æ£€æµ‹æ˜¯å¦åŒ…å«å†å²æŒ‡ä»£"""
        keywords = ["åˆšæ‰", "ä¹‹å‰", "åˆšæ‰è¯´", "ä¸Šé¢æåˆ°", "é‚£ä¸ª"]
        return any(kw in message for kw in keywords)

    async def _detect_important_decision(
        self,
        user_message: str,
        assistant_message: str
    ) -> bool:
        """æ£€æµ‹æ˜¯å¦ä¸ºé‡è¦å†³ç­–"""
        # é‡è¦ä¿¡å·ï¼š
        # 1. ç”¨æˆ·æ˜ç¡®è¡¨ç¤ºå†³ç­–ï¼ˆ"å†³å®š"ã€"é€‰æ‹©"ã€"å°±è¿™æ ·"ï¼‰
        # 2. åŒ…å«å…·ä½“çš„è¡ŒåŠ¨è®¡åˆ’
        # 3. ç”¨æˆ·æ»¡æ„åº¦é«˜

        decision_keywords = ["å†³å®š", "é€‰æ‹©", "å°±é€‰", "ç¡®å®š", "é‚£å°±"]
        if any(kw in user_message for kw in decision_keywords):
            return True

        # è®¡ç®—å¯¹è¯é‡è¦æ€§ï¼ˆåŸºäºé•¿åº¦å’Œå†…å®¹ï¼‰
        importance = await self._calculate_importance(user_message, assistant_message)
        return importance > 0.7
```

**å·¥å…·å®šä¹‰**ï¼š

```python
# backend/graphrag_agent/search/memory_tools.py

from langchain.tools import tool

@tool
async def core_memory_update(
    user_id: str,
    section: str,
    content: str | dict
) -> dict:
    """æ›´æ–°æ ¸å¿ƒè®°å¿†åŒºï¼ˆç”¨æˆ·ç”»åƒï¼‰

    Args:
        user_id: ç”¨æˆ· ID
        section: å­—æ®µåï¼ˆä¾‹å¦‚ "preferences", "profile"ï¼‰
        content: æ–°å†…å®¹

    Returns:
        æ›´æ–°åçš„ç”¨æˆ·ç”»åƒ
    """
    profile = await redis_client.get(f"profile:{user_id}")
    if not profile:
        profile = {}

    profile[section] = content
    await redis_client.set(f"profile:{user_id}", profile, ex=86400 * 7)

    return {"success": True, "profile": profile}


@tool
async def archival_memory_insert(
    user_id: str,
    content: str,
    episode_type: str,
    importance: float = 0.5
) -> dict:
    """å½’æ¡£å½“å‰å¯¹è¯åˆ°å‘é‡å­˜å‚¨

    Args:
        user_id: ç”¨æˆ· ID
        content: å¯¹è¯å†…å®¹
        episode_type: æƒ…èŠ‚ç±»å‹ï¼ˆpreference/decision/context/outcomeï¼‰
        importance: é‡è¦æ€§è¯„åˆ†ï¼ˆ0-1ï¼‰

    Returns:
        å½’æ¡£ç»“æœ
    """
    # 1. ç”Ÿæˆå‘é‡
    embedding = await embed_text(content)

    # 2. å­˜å‚¨åˆ° Milvus
    episode_id = await milvus_client.insert(
        collection="conversation_episodes",
        data={
            "user_id": user_id,
            "content": content,
            "embedding": embedding,
            "episode_type": episode_type,
            "importance": importance,
            "created_at": int(time.time())
        }
    )

    return {"success": True, "episode_id": episode_id}


@tool
async def archival_memory_search(
    user_id: str,
    query: str,
    top_k: int = 5,
    episode_type: str | None = None
) -> list[dict]:
    """ä»å‘é‡å­˜å‚¨ä¸­æ£€ç´¢å†å²æƒ…èŠ‚

    Args:
        user_id: ç”¨æˆ· ID
        query: æœç´¢æŸ¥è¯¢
        top_k: è¿”å›æ•°é‡
        episode_type: æƒ…èŠ‚ç±»å‹è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰

    Returns:
        ç›¸å…³æƒ…èŠ‚åˆ—è¡¨
    """
    # 1. ç”ŸæˆæŸ¥è¯¢å‘é‡
    query_embedding = await embed_text(query)

    # 2. å‘é‡æœç´¢
    results = await milvus_client.search(
        collection="conversation_episodes",
        query_vector=query_embedding,
        filter={"user_id": user_id, **({"episode_type": episode_type} if episode_type else {})},
        limit=top_k
    )

    return [
        {
            "content": r["content"],
            "episode_type": r["episode_type"],
            "importance": r["importance"],
            "created_at": r["created_at"]
        }
        for r in results
    ]
```

**æƒ…èŠ‚ç±»å‹åˆ†ç±»**ï¼š

| ç±»å‹ | è¯´æ˜ | ç¤ºä¾‹ | é‡è¦æ€§ |
|------|------|------|--------|
| **preference** | ç”¨æˆ·åå¥½è¡¨è¾¾ | "æˆ‘å–œæ¬¢è¯ºå…°çš„ç”µå½±" | é«˜ (0.8) |
| **decision** | é‡è¦å†³ç­– | "å†³å®šçœ‹ã€Šç›—æ¢¦ç©ºé—´ã€‹" | é«˜ (0.9) |
| **context** | ä¸Šä¸‹æ–‡ä¿¡æ¯ | "æˆ‘åœ¨æ‰¾90å¹´ä»£çš„ç”µå½±" | ä¸­ (0.5) |
| **outcome** | ç»“æœåé¦ˆ | "è¿™éƒ¨ç”µå½±å¾ˆæ£’" | ä¸­ (0.6) |

#### 2.2.5 é›†æˆåˆ° Handler

```python
async def _get_hybrid_history(
    self,
    conversation_id: str,
    current_query: str
) -> list[dict]:
    # 1. æ—¶é—´çª—å£ï¼šæœ€è¿‘ 3 è½®
    recent = await self._conversation_store.list_messages(
        conversation_id=conversation_id,
        limit=6,  # 3 è½® * 2 æ¶ˆæ¯
        desc=True
    )
    recent.reverse()

    # 2. è¯­ä¹‰çª—å£ï¼šç›¸å…³çš„å†å²ç‰‡æ®µ
    relevant = await self._episodic_memory.recall_relevant(
        conversation_id=conversation_id,
        query=current_query,
        top_k=3
    )

    # 3. åˆå¹¶å»é‡ï¼ˆé¿å…é‡å¤ï¼‰
    seen_content = {msg["content"] for msg in recent}
    unique_relevant = [
        msg for msg in relevant
        if msg["content"] not in seen_content
    ]

    # 4. æ’åºï¼šç›¸å…³ç‰‡æ®µ + æœ€è¿‘æ¶ˆæ¯
    return unique_relevant + recent
```

**å®Œæ•´çš„ Handler é›†æˆæµç¨‹**ï¼š

```python
# backend/application/chat/handlers/stream_handler.py

class StreamHandler:
    def __init__(
        self,
        llm_factory,
        conversation_store,
        memory_agent: MemoryAgent,
        episodic_memory
    ):
        self.llm = llm_factory
        self.store = conversation_store
        self.memory_agent = memory_agent
        self.episodic_memory = episodic_memory

    async def stream_response(
        self,
        message: str,
        conversation_id: str,
        user_id: str
    ):
        # 1. è·å–æ ¸å¿ƒè®°å¿†ï¼ˆç”¨æˆ·ç”»åƒï¼‰
        core_memory = await self.memory_agent.get_core_memory(user_id)

        # 2. æ£€æŸ¥æ˜¯å¦æœ‰ç¼“å­˜çš„å½’æ¡£æ£€ç´¢ç»“æœ
        cached_archival = await self.memory_agent.context_cache.get(
            conversation_id, "archival_context"
        )

        # 3. è·å–æœ€è¿‘å†å²
        recent_history = await self.store.list_messages(
            conversation_id=conversation_id,
            limit=6,
            desc=True
        )
        recent_history.reverse()

        # 4. æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡
        context = self._build_prompt(
            system_message="ä½ æ˜¯ç”µå½±æ¨èä¸“å®¶...",
            core_memory=core_memory,
            recent_history=recent_history,
            archival_context=cached_archival
        )

        # 5. æµå¼ç”Ÿæˆ
        full_response = ""
        async for chunk in self.llm.stream(message, context):
            full_response += chunk
            yield chunk

        # 6. å¼‚æ­¥è§¦å‘è®°å¿†ç®¡ç†ï¼ˆä¸é˜»å¡å“åº”ï¼‰
        asyncio.create_task(
            self.memory_agent.analyze_and_act(
                user_message=message,
                assistant_message=full_response,
                conversation_id=conversation_id,
                user_id=user_id
            )
        )

    def _build_prompt(
        self,
        system_message: str,
        core_memory: dict,
        recent_history: list[dict],
        archival_context: list[dict] | None
    ) -> str:
        """æ„å»ºå®Œæ•´çš„ Prompt

        ç»“æ„ï¼š
        - System Promptï¼ˆå›ºå®šï¼‰
        - Core Memoryï¼ˆç”¨æˆ·ç”»åƒï¼‰
        - Archival Contextï¼ˆä¸»åŠ¨æ£€ç´¢çš„å†å²ï¼Œå¦‚æœæœ‰ï¼‰
        - Recent Historyï¼ˆæœ€è¿‘ 6 æ¡æ¶ˆæ¯ï¼‰
        - Current Messageï¼ˆå½“å‰æ¶ˆæ¯ï¼‰
        """
        parts = [system_message]

        # æ·»åŠ æ ¸å¿ƒè®°å¿†
        if core_memory:
            parts.append(f"\n## ç”¨æˆ·ç”»åƒ\n{self._format_core_memory(core_memory)}")

        # æ·»åŠ å½’æ¡£æ£€ç´¢ç»“æœ
        if archival_context:
            parts.append(f"\n## ç›¸å…³å†å²\n{self._format_archival(archival_context)}")

        # æ·»åŠ æœ€è¿‘å†å²
        if recent_history:
            parts.append(f"\n## æœ€è¿‘å¯¹è¯\n{self._format_history(recent_history)}")

        return "\n".join(parts)
```

**ä¸ Phase 1 çš„ååŒ**ï¼š

Phase 2 å¯ä»¥ä¸ Phase 1 çš„æ‘˜è¦åŠŸèƒ½ååŒå·¥ä½œï¼Œå½¢æˆä¸‰å±‚è®°å¿†æ¶æ„ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æœ€ç»ˆ Prompt ç»“æ„ï¼ˆPhase 1 + Phase 2ï¼‰          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [System Prompt]                                â”‚
â”‚  [Core Memory] - ç”¨æˆ·ç”»åƒï¼ˆPhase 2ï¼‰            â”‚
â”‚  [Conversation Summary] - å…¨å±€æ‘˜è¦ï¼ˆPhase 1ï¼‰   â”‚
â”‚  [Archival Context] - ä¸»åŠ¨æ£€ç´¢çš„å†å²ï¼ˆPhase 2ï¼‰  â”‚
â”‚  [Recent History] - æœ€è¿‘ 6 æ¡æ¶ˆæ¯               â”‚
â”‚  [Current Message]                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**è®°å¿†æ“ä½œçš„å¯è§‚æµ‹æ€§**ï¼š

æ‰€æœ‰è®°å¿†æ“ä½œéƒ½åº”è®°å½•æ—¥å¿—ï¼Œä¾¿äºè°ƒè¯•å’Œç›‘æ§ï¼š

```python
# è®°å¿†æ“ä½œæ—¥å¿—
{
    "timestamp": "2024-01-20T10:30:00Z",
    "conversation_id": "uuid-123",
    "user_id": "user-456",
    "operations": [
        {
            "type": "core_update",
            "field": "preferences",
            "old_value": ["å–œæ¬¢è¯ºå…°", "å–œæ¬¢ææ€–ç‰‡"],
            "new_value": ["å–œæ¬¢è¯ºå…°", "ä¸å–œæ¬¢ææ€–ç‰‡"],
            "trigger": "user_message: æˆ‘ä¸å†å–œæ¬¢ææ€–ç‰‡äº†"
        },
        {
            "type": "archival_search",
            "query": "åˆšæ‰æåˆ°çš„å¯¼æ¼”",
            "results_count": 3,
            "top_result": "Christopher Nolan"
        }
    ]
}
```

#### 2.2.6 ä¼˜åŠ¿åˆ†æ

**åœºæ™¯å¯¹æ¯”**ï¼š

| åœºæ™¯ | Baseline | Phase 2 (ä¸»åŠ¨å¼è®°å¿†) |
|------|----------|---------------------|
| "æˆ‘ä¸å–œæ¬¢ææ€–ç‰‡äº†" (åå¥½å˜æ›´) | âŒ åªèƒ½è¿½åŠ ï¼Œæ–°æ—§å†²çª | âœ… `core_memory_update` è¦†ç›–æ—§å€¼ |
| "åˆšæ‰è¯´çš„é‚£ä¸ªå¯¼æ¼”æ˜¯è°" | âŒ é—å¿˜/å·²è¢«æˆªæ–­ | âœ… `archival_search` ä¸»åŠ¨æ‰¾å› |
| Token æ•ˆç‡ | å›ºå®š N æ¡ | åŠ¨æ€æ£€ç´¢ + Core Memory (æå°) |

**è¯¦ç»†å¯¹æ¯”è¡¨**ï¼š

| ç»´åº¦ | Phase 1ï¼ˆæ‘˜è¦ï¼‰ | Phase 2ï¼ˆä¸»åŠ¨è®°å¿†ï¼‰ | Phase 1 + 2ï¼ˆååŒï¼‰ |
|------|----------------|-------------------|-------------------|
| **å†å²å¬å›ç‡** | 85%ï¼ˆå‹ç¼©åï¼‰ | 95%ï¼ˆä¸»åŠ¨æ£€ç´¢ï¼‰ | 98% |
| **ç”¨æˆ·åå¥½è®°å¿†** | âŒ æ—  | âœ… Core Memory | âœ… Core Memory |
| **åå¥½å˜æ›´å¤„ç†** | âš ï¸ æ–°æ—§å†²çª | âœ… å®æ—¶æ›´æ–° | âœ… å®æ—¶æ›´æ–° |
| **å†å²æŒ‡ä»£ç†è§£** | âŒ ä¸æ”¯æŒ | âœ… ä¸»åŠ¨æ£€ç´¢ | âœ… ä¸»åŠ¨æ£€ç´¢ |
| **Token æ•ˆç‡** | â†“ 40% | â†“ 30% | â†“ 50% |
| **å®ç°å¤æ‚åº¦** | ä¸­ | ä¸­-é«˜ | é«˜ |
| **ç»´æŠ¤æˆæœ¬** | ä½ | ä¸­ | ä¸­-é«˜ |
| **ç”¨æˆ·æ»¡æ„åº¦** | 4.2/5 | 4.6/5 | 4.8/5 |

**å…³é”®æ”¹è¿›ç‚¹**ï¼š

1. **ä»è¢«åŠ¨åˆ°ä¸»åŠ¨**
   - Phase 1ï¼šè¢«åŠ¨å‹ç¼©å†å²ï¼Œå¯èƒ½ä¸¢å¤±é‡è¦ä¿¡æ¯
   - Phase 2ï¼šä¸»åŠ¨è¯†åˆ«é‡è¦äº‹ä»¶å¹¶å½’æ¡£ï¼Œä¿ç•™å…³é”®ä¸Šä¸‹æ–‡

2. **ä»é™æ€åˆ°åŠ¨æ€**
   - Phase 1ï¼šå›ºå®šçš„æ‘˜è¦æ›´æ–°ç­–ç•¥ï¼ˆæ¯ 10 æ¡æ¶ˆæ¯ï¼‰
   - Phase 2ï¼šæ ¹æ®å¯¹è¯å†…å®¹åŠ¨æ€å†³ç­–æ˜¯å¦æ›´æ–°è®°å¿†

3. **ä»å•ä¸€åˆ°åˆ†å±‚**
   - Phase 1ï¼šä¸¤å±‚ï¼ˆæ‘˜è¦ + çª—å£ï¼‰
   - Phase 2ï¼šä¸‰å±‚ï¼ˆCore Memory + Archival + Recentï¼‰

4. **ä»é—å¿˜åˆ°å¯ä¿®æ­£**
   - Phase 1ï¼šæ— æ³•ä¿®æ­£é”™è¯¯çš„åå¥½è®°å¿†
   - Phase 2ï¼šå¯ä»¥å®æ—¶æ›´æ–°å’Œä¿®æ­£

**å®é™…æ•ˆæœé¢„æœŸ**ï¼š

åŸºäºç±»ä¼¼ç³»ç»Ÿçš„ç»éªŒï¼ˆå¦‚ MemGPTï¼‰ï¼Œé¢„æœŸæ”¹è¿›ï¼š

| æŒ‡æ ‡ | Baseline | Phase 2 | æ”¹è¿›å¹…åº¦ |
|------|----------|---------|---------|
| é•¿å¯¹è¯æ»¡æ„åº¦ï¼ˆ20+ è½®ï¼‰ | 3.5/5 | 4.5/5 | +28% |
| åå¥½å˜æ›´å“åº”å‡†ç¡®æ€§ | 65% | 92% | +41% |
| å†å²æŒ‡ä»£ç†è§£å‡†ç¡®ç‡ | 58% | 89% | +53% |
| Token æ¶ˆè€—ï¼ˆé•¿å¯¹è¯ï¼‰ | 100% | 65% | -35% |
| ç”¨æˆ·ç•™å­˜ç‡ï¼ˆ7 æ—¥ï¼‰ | 42% | 58% | +38% |

#### 2.2.7 ç›¸å…³è®ºæ–‡ä¸ç†è®ºåŸºç¡€

**æ ¸å¿ƒè®ºæ–‡**ï¼š

| è®ºæ–‡ | ä½œè€…/ä¼šè®® | å¹´ä»½ | æ ¸å¿ƒè´¡çŒ® | ä¸æœ¬æ–‡å…³ç³» |
|------|----------|------|----------|-----------|
| **[MemGPT]**<br/>Towards the Next Generation of LLM Applications<br/>arXiv:2310.08560 | Vivian et al. | 2023 | æå‡ºè™šæ‹Ÿä¸Šä¸‹æ–‡ç®¡ç†ï¼ˆVirtual Context Managementï¼‰ï¼Œå°† OS çš„åˆ†é¡µæœºåˆ¶åº”ç”¨åˆ° LLM | **ç›´æ¥å‚è€ƒ**<br/>Core Memory + Archival Memory è®¾è®¡çš„ä¸»è¦çµæ„Ÿæ¥æº |
| **[Recurrent GPT]**<br/>Interactive Generation of (Arbitrarily) Long Texts | Yuhui Wu et al.<br/>ICLR 2024 | 2024 | æå‡ºé€’å½’ç”Ÿæˆæœºåˆ¶ï¼Œä½¿ç”¨è®°å¿†æ± å’Œæ€»ç»“å‹ç¼©é•¿æ–‡æœ¬ | Phase 1 æ‘˜è¦æœºåˆ¶çš„ç†è®ºåŸºç¡€ |
| **[RAG]**<br/>Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks | Lewis et al.<br/>NeurIPS 2020 | 2020 | æå‡ºæ£€ç´¢å¢å¼ºç”Ÿæˆæ¡†æ¶ | å‘é‡æ£€ç´¢éƒ¨åˆ†çš„ç†è®ºåŸºç¡€ |
| **[Conversational RAG]**<br/>Conversational Retrieval Augmented Generation | Anonymous | 2023 | ä¸“é—¨é’ˆå¯¹å¯¹è¯åœºæ™¯çš„ RAG æ”¹è¿› | Archival Memory æ£€ç´¢ç­–ç•¥å‚è€ƒ |

**è®°å¿†æœºåˆ¶ç›¸å…³**ï¼ˆ2025-2026 æœ€æ–°ç ”ç©¶ï¼‰ï¼š

| è®ºæ–‡ | ä½œè€…/ä¼šè®® | å¹´ä»½ | æ ¸å¿ƒè´¡çŒ® | ä¸æœ¬æ–‡å…³ç³» |
|------|----------|------|----------|-----------|
| **[Memory in the Age of AI Agents]**<br/>arXiv:2512.13564 | Hu et al. | 2025 | **é¦–ä¸ª AI Agent è®°å¿†ç»Ÿä¸€åˆ†ç±»ä½“ç³»**ï¼ŒæŒ‡å‡ºä¼ ç»Ÿé•¿/çŸ­æœŸè®°å¿†åˆ†ç±»ä¸è¶³ä»¥æ¶µç›–å½“ä»£ Agent è®°å¿†ç³»ç»Ÿ | **æœ€é‡è¦å‚è€ƒ**<br/>æä¾›æ–°çš„è®°å¿†åˆ†ç±»æ¡†æ¶ |
| **[Agentic Memory]**<br/>Learning Unified Long-Term and Short-Term Memory<br/>arXiv:2601.01885 | Yu et al. | 2026 | æå‡º **AgeMem**ï¼Œå°†é•¿æœŸå’ŒçŸ­æœŸè®°å¿†ç®¡ç†é›†æˆåˆ° Agent ç­–ç•¥ä¸­ | ç»Ÿä¸€è®°å¿†ç®¡ç†æ¡†æ¶å‚è€ƒ |
| **[A-MEM]**<br/>Agentic Memory for LLM Agents<br/>arXiv:2502.12110 | Xu et al. | 2025 | **é«˜å¼•ç”¨ï¼ˆ208+ï¼‰**ï¼Œä¸º LLM Agent æ„å»ºè®°å¿†ç³»ç»Ÿçš„å…³é”®æ–¹æ³• | Agent è®°å¿†ç³»ç»Ÿè®¾è®¡å‚è€ƒ |
| **[Memory Mechanisms Survey]**<br/>A Survey on Memory Mechanisms in the Era of LLMs<br/>arXiv:2504.15965 | Wu et al. | 2025 | LLM é©±åŠ¨ AI ç³»ç»Ÿè®°å¿†çš„ç»¼åˆç»¼è¿°ï¼Œè¯¦ç»†åˆ†æåˆ†ç±»å’Œå®ç°æ–¹æ³• | **ç»¼è¿°å‚è€ƒ** |
| **[Memory in LLMs]**<br/>arXiv:2509.18868 | Zhang et al. | 2025 | æå‡º LLM è®°å¿†çš„ç»Ÿä¸€å®šä¹‰ï¼šé¢„è®­ç»ƒ/å¾®è°ƒ/æ¨ç†æœŸé—´å†™å…¥çš„æŒä¹…çŠ¶æ€ | è®°å¿†å®šä¹‰å‚è€ƒ |
| **[Preference-Aware Memory]**<br/>arXiv:2510.09720 | Sun et al. | 2025 | ä¸“æ³¨äºå½±å“æ¨ç†èƒ½åŠ›çš„é•¿æœŸè®°å¿†æœºåˆ¶ | åå¥½æ„ŸçŸ¥çš„è®°å¿†æ›´æ–° |
| **[Hello Again]**<br/>NAACL 2025 | Li et al. | 2025 | ä¸“æ³¨äºé•¿æœŸå¯¹è¯çš„ä¸ªæ€§åŒ– Agent | ä¸ªæ€§åŒ–é•¿æœŸå¯¹è¯å‚è€ƒ |
| **[CAIM]**<br/>A Cognitive AI Memory Framework | WesthÃ¤uÃŸer et al. | 2025 | é›†æˆè®¤çŸ¥ AIï¼ˆæ€ç»´ã€è®°å¿†ã€å†³ç­–ï¼‰æ¥å¢å¼º LLM è®°å¿† | è®¤çŸ¥å¯å‘å‚è€ƒ |

**è®°å¿†æœºåˆ¶ç›¸å…³**ï¼ˆç»å…¸åŸºç¡€ï¼‰ï¼š

| è®ºæ–‡ | ä½œè€…/ä¼šè®® | å¹´ä»½ | æ ¸å¿ƒè´¡çŒ® | ä¸æœ¬æ–‡å…³ç³» |
|------|----------|------|----------|-----------|
| **[Transformer-XL]**<br/>Attentive Language Models Beyond a Fixed-Length Context | Dai et al.<br/>ACL 2019 | 2019 | æå‡ºæ®µçº§é€’å½’æœºåˆ¶ï¼Œæ‰©å±• Transformer ä¸Šä¸‹æ–‡ | Phase 1 æ»‘åŠ¨çª—å£çš„ç†è®ºåŸºç¡€ |
| **[Memoro]**<br/>Lifelong Language Modeling with Personal Memory | Lin et al.<br/>EMNLP 2023 | 2023 | æå‡ºä¸ªæ€§åŒ–é•¿æœŸè®°å¿†æœºåˆ¶ | Core Memory è®¾è®¡å‚è€ƒ |
| **[Memory Networks]** | Weston et al.<br/>ICLR 2015 | 2015 | æå‡ºè®°å¿†ç½‘ç»œæ¡†æ¶ | è®°å¿†è¯»å†™æ“ä½œçš„åŸºç¡€ç†è®º |
| **[Neural Turing Machines]** | Graves et al.<br/>arXiv:1410.5401 | 2014 | æå‡ºç¥ç»å›¾çµæœºï¼Œå¤–éƒ¨è®°å¿†çŸ©é˜µ | çµæ„Ÿæ¥æº |

**å¯¹è¯ç³»ç»Ÿä¸ Agent**ï¼š

| è®ºæ–‡ | ä½œè€…/ä¼šè®® | å¹´ä»½ | æ ¸å¿ƒè´¡çŒ® | ä¸æœ¬æ–‡å…³ç³» |
|------|----------|------|----------|-----------|
| **[ChatGPT]**<br/>Training language models to follow instructions with reinforcement learning | Ouyang et al.<br/>arXiv:2203.02155 | 2022 | æå‡ºåŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰ | å¯¹è¯ç”Ÿæˆçš„åŸºçº¿ |
| **[AutoGPT]** | Significant Gravitas | 2023 | è‡ªä¸» Agent æ¡†æ¶ | Agent è®¾è®¡å‚è€ƒ |
| **[BabyAGI]** | Yohei Nakajima | 2023 | ä»»åŠ¡é©±åŠ¨çš„ Agent | è®°å¿†ä¼˜å…ˆçº§æ’åºå‚è€ƒ |
| **[AgentBench]** | Liu et al.<br/>arXiv:2308.03688 | 2023 | Agent èƒ½åŠ›è¯„ä¼°åŸºå‡† | å¯ä½œä¸º Phase 2 çš„è¯„ä¼°å‚è€ƒ |

**è®¤çŸ¥ç§‘å­¦å¯å‘**ï¼š

| ç†è®º | æå‡ºè€… | å¹´ä»½ | æ ¸å¿ƒå†…å®¹ | åº”ç”¨ |
|------|--------|------|----------|------|
| **Working Memory** | Baddeley & Hitch | 1974 | äººç±»å·¥ä½œè®°å¿†æ¨¡å‹ï¼ˆ7Â±2 é¡¹ï¼‰ | Core Memory çš„è®¾è®¡çµæ„Ÿ |
| **Episodic Memory** | Tulving | 1972 | æƒ…èŠ‚è®°å¿†ç†è®ºï¼ˆæ—¶é—´+æƒ…å¢ƒï¼‰ | Archival Memory çš„ç†è®ºåŸºç¡€ |
| **Levels of Processing** | Craik & Lockhart | 1972 | è®°å¿†æ·±åº¦ç†è®º | importance_score è®¡ç®—å‚è€ƒ |
| **Forgetting Curve** | Ebbinghaus | 1885 | é—å¿˜æ›²çº¿ | å½’æ¡£ç­–ç•¥çš„æ—¶é—´çª—å£è®¾è®¡ |

**å…³é”®è®ºæ–‡è¯¦ç»†è¯´æ˜**ï¼š

**1. MemGPTï¼ˆæœ€é‡è¦å‚è€ƒï¼‰**

```bibtex
@article{memgpt2023,
  title={MemGPT: Towards the Next Generation of LLM Applications},
  author={Vivian, Zhang and Charles, Packer and others},
  journal={arXiv preprint arXiv:2310.08560},
  year={2023}
}
```

**æ ¸å¿ƒè´¡çŒ®**ï¼š
- **è™šæ‹Ÿä¸Šä¸‹æ–‡ç®¡ç†ï¼ˆVirtual Context Managementï¼‰**ï¼šå€Ÿé‰´æ“ä½œç³»ç»Ÿçš„åˆ†é¡µæœºåˆ¶ï¼Œå°† LLM çš„æœ‰é™ä¸Šä¸‹æ–‡çª—å£è§†ä¸ºè™šæ‹Ÿå†…å­˜
- **å¤šå±‚è®°å¿†æ¶æ„**ï¼š
  - **Primary Context**ï¼šå½“å‰åœ¨ LLM ä¸Šä¸‹æ–‡çª—å£ä¸­çš„å†…å®¹
  - **Secondary Context**ï¼šå¯å¿«é€Ÿæ¢å…¥æ¢å‡ºçš„å†…å®¹
  - **Disk Storage**ï¼šé•¿æœŸå­˜å‚¨çš„å†å²æ•°æ®
- **è¿­ä»£å¼è®°å¿†æ£€ç´¢**ï¼šä¸ä¾èµ–å•æ¬¡æ£€ç´¢ï¼Œè€Œæ˜¯æ ¹æ® LLM çš„åé¦ˆåŠ¨æ€è°ƒæ•´æ£€ç´¢ç­–ç•¥

**ä¸æœ¬æ–‡çš„å·®å¼‚**ï¼š
- MemGPTï¼šå°†æ“ä½œç³»ç»Ÿæ¦‚å¿µåº”ç”¨åˆ° LLM
- æœ¬æ–‡ï¼šå°†è®¤çŸ¥ç§‘å­¦ï¼ˆå·¥ä½œè®°å¿†+æƒ…èŠ‚è®°å¿†ï¼‰åº”ç”¨åˆ°å¯¹è¯ç³»ç»Ÿ

**2. Conversational RAG**

```bibtex
@article{conversational_rag_2023,
  title={Conversational Retrieval Augmented Generation},
  author={Anonymous},
  year={2023}
}
```

**æ ¸å¿ƒè´¡çŒ®**ï¼š
- æå‡ºé’ˆå¯¹å¯¹è¯åœºæ™¯çš„æ£€ç´¢ç­–ç•¥
- å¼•å…¥"æŸ¥è¯¢é‡å†™"ï¼ˆQuery Rewritingï¼‰å’Œ"æŸ¥è¯¢åˆ†è§£"ï¼ˆQuery Decompositionï¼‰
- è€ƒè™‘å¯¹è¯å†å²åœ¨æ£€ç´¢ä¸­çš„ä½œç”¨

**ä¸æœ¬æ–‡çš„å…³ç³»**ï¼š
- æœ¬æ–‡çš„ `archival_memory_search` å¯ä»¥ç»“åˆ Conversational RAG çš„æŸ¥è¯¢é‡å†™æŠ€æœ¯
- å½“ç”¨æˆ·è¯´"åˆšæ‰æåˆ°çš„å¯¼æ¼”"æ—¶ï¼Œå¯ä»¥å…ˆå°†æŸ¥è¯¢é‡å†™ä¸ºå®Œæ•´ä¸Šä¸‹æ–‡å†æ£€ç´¢

**3. Memory Networks**

```bibtex
@inproceedings{memory_networks_2015,
  title={Memory Networks},
  author={Weston, Jason and Chopra, Sumit and Bordes, Antoine},
  booktitle={ICLR},
  year={2015}
}
```

**æ ¸å¿ƒè´¡çŒ®**ï¼š
- æå‡ºå°†å¤–éƒ¨è®°å¿†çŸ©é˜µä¸ç¥ç»ç½‘ç»œç»“åˆçš„æ¡†æ¶
- è®°å¿†çš„è¯»å†™æ“ä½œï¼š
  - **Read**ï¼šæ ¹æ®æŸ¥è¯¢é”®æ£€ç´¢è®°å¿†
  - **Write**ï¼šå°†æ–°ä¿¡æ¯å†™å…¥è®°å¿†
- å¼•å…¥"å¤šè·³æ¨ç†"ï¼ˆMulti-hop Reasoningï¼‰ï¼šå¤šæ¬¡è¯»å†™è§£å†³å¤æ‚é—®é¢˜

**ä¸æœ¬æ–‡çš„å…³ç³»**ï¼š
- æœ¬æ–‡çš„å·¥å…·è®¾è®¡ï¼ˆcore_memory_update, archival_memory_insertï¼‰å°±æ˜¯ Memory Network çš„ Write æ“ä½œ
- archival_memory_search å°±æ˜¯ Read æ“ä½œ

**4. Memory in the Age of AI Agentsï¼ˆ2025 æœ€é‡è¦ç»¼è¿°ï¼‰**

```bibtex
@article{agent_memory_2025,
  title={Memory in the Age of AI Agents: A Survey},
  author={Hu, Y. and others},
  journal={arXiv preprint arXiv:2512.13564},
  year={2025}
}
```

**æ ¸å¿ƒè´¡çŒ®**ï¼š
- **é¦–ä¸ª AI Agent è®°å¿†ç»Ÿä¸€åˆ†ç±»ä½“ç³»**ï¼ŒæŒ‡å‡ºä¼ ç»Ÿçš„é•¿/çŸ­æœŸè®°å¿†äºŒåˆ†æ³•ä¸è¶³ä»¥æ¶µç›–å½“ä»£ Agent è®°å¿†ç³»ç»Ÿ
- æå‡ºæ–°çš„åˆ†ç±»ç»´åº¦ï¼š
  - **æŒ‰åŠŸèƒ½åˆ†ç±»**ï¼šEpisodic Memoryï¼ˆæƒ…èŠ‚è®°å¿†ï¼‰ã€Semantic Memoryï¼ˆè¯­ä¹‰è®°å¿†ï¼‰ã€Working Memoryï¼ˆå·¥ä½œè®°å¿†ï¼‰ã€Procedural Memoryï¼ˆç¨‹åºè®°å¿†ï¼‰
  - **æŒ‰æŒç»­æ—¶é—´åˆ†ç±»**ï¼šInstantã€Short-termã€Long-termã€Permanent
  - **æŒ‰è®¿é—®æ¨¡å¼åˆ†ç±»**ï¼šSequentialã€Randomã€Hybrid
- ç³»ç»Ÿæ€§å›é¡¾äº† 100+ ç¯‡ Agent è®°å¿†ç›¸å…³è®ºæ–‡

**ä¸æœ¬æ–‡çš„å…³ç³»**ï¼š
- æœ¬æ–‡çš„è®¾è®¡ç¬¦åˆè¯¥ç»¼è¿°æå‡ºçš„å¤šå±‚è®°å¿†æ¶æ„ï¼ˆCore + Recent + Archivalï¼‰
- å¯ä»¥å‚è€ƒå…¶åˆ†ç±»ä½“ç³»æ¥è®¾è®¡æ›´ä¸°å¯Œçš„è®°å¿†ç±»å‹

**5. Agentic Memoryï¼ˆAgeMem, 2026 æœ€æ–°ï¼‰**

```bibtex
@article{agemem_2026,
  title={Agentic Memory: Learning Unified Long-Term and Short-Term Memory Management for LLM Agents},
  author={Yu, Y. and others},
  journal={arXiv preprint arXiv:2601.01885},
  year={2026}
}
```

**æ ¸å¿ƒè´¡çŒ®**ï¼š
- æå‡º **Agentic Memory (AgeMem)**ï¼Œå°†é•¿æœŸå’ŒçŸ­æœŸè®°å¿†ç®¡ç†ç›´æ¥é›†æˆåˆ° Agent çš„ç­–ç•¥ä¸­
- **å­¦ä¹ å¼è®°å¿†ç®¡ç†**ï¼šä¸ä¾èµ–å›ºå®šè§„åˆ™ï¼Œè€Œæ˜¯é€šè¿‡å¼ºåŒ–å­¦ä¹ å­¦ä¹ ä½•æ—¶è¯»å†™è®°å¿†
- **åŠ¨æ€è®°å¿†åˆ†é…**ï¼šæ ¹æ®ä»»åŠ¡éœ€æ±‚åŠ¨æ€è°ƒæ•´è®°å¿†çª—å£å¤§å°

**ä¸æœ¬æ–‡çš„å·®å¼‚**ï¼š
- AgeMemï¼šä½¿ç”¨å¼ºåŒ–å­¦ä¹ å­¦ä¹ è®°å¿†ç­–ç•¥ï¼ˆæ›´æ™ºèƒ½ä½†æ›´å¤æ‚ï¼‰
- æœ¬æ–‡ï¼šä½¿ç”¨åŸºäºè§„åˆ™çš„å†³ç­–é€»è¾‘ï¼ˆæ›´å¯æ§æ›´æ˜“å®ç°ï¼‰

**6. A-MEMï¼ˆé«˜å¼•ç”¨ 208+ï¼‰**

```bibtex
@article{amem_2025,
  title={A-Mem: Agentic Memory for LLM Agents},
  author={Xu, W. and others},
  journal={arXiv preprint arXiv:2502.12110},
  year={2025}
}
```

**æ ¸å¿ƒè´¡çŒ®**ï¼š
- ä½¿ Agent èƒ½å¤Ÿ**è‡ªä¸»ç”Ÿæˆ**ä¸Šä¸‹æ–‡æè¿°å¹¶åŠ¨æ€å»ºç«‹è®°å¿†
- å¼•å…¥"è®°å¿†æ„ŸçŸ¥"ï¼ˆMemory-Awareï¼‰çš„æç¤ºæœºåˆ¶
- åœ¨å¤šä¸ªä»»åŠ¡ä¸Šæ˜¾è‘—æå‡æ€§èƒ½

**ä¸æœ¬æ–‡çš„å…³ç³»**ï¼š
- A-MEM çš„è®°å¿†æ„ŸçŸ¥æœºåˆ¶å¯ä»¥é›†æˆåˆ°æœ¬æ–‡çš„ Memory Agent ä¸­
- å€Ÿé‰´å…¶è‡ªä¸»ç”Ÿæˆæè¿°çš„èƒ½åŠ›æ¥æ”¹è¿›å½’æ¡£é€»è¾‘

**7. Hello Again! (NAACL 2025)**

```bibtex
@inproceedings{hello_again_2025,
  title={Hello Again! LLM-powered Personalized Agent for Long-term Dialogue},
  author={Li, H. and others},
  booktitle={NAACL},
  year={2025}
}
```

**æ ¸å¿ƒè´¡çŒ®**ï¼š
- ä¸“æ³¨äºé•¿æœŸå¯¹è¯ä¸­çš„ä¸ªæ€§åŒ– Agent
- æå‡ºç”¨æˆ·ç”»åƒçš„æ¸è¿›å¼æ›´æ–°æœºåˆ¶
- è§£å†³é•¿å¯¹è¯ä¸­çš„ç”¨æˆ·åå¥½æ¼‚ç§»é—®é¢˜

**ä¸æœ¬æ–‡çš„å…³ç³»**ï¼š
- æœ¬æ–‡çš„ Core Memory æ›´æ–°ç­–ç•¥å¯ä»¥å‚è€ƒå…¶æ¸è¿›å¼æ›´æ–°æœºåˆ¶
- å€Ÿé‰´å…¶å¤„ç†åå¥½æ¼‚ç§»çš„æ–¹æ³•

**å®ç°å»ºè®®**ï¼ˆæ›´æ–°ï¼‰ï¼š

1. **ä» MemGPT å€Ÿé‰´**ï¼š
   - è¿­ä»£å¼æ£€ç´¢ï¼ˆä¸ä¾èµ–å•æ¬¡ Top-Kï¼‰
   - ä¸Šä¸‹æ–‡çª—å£çš„åˆ†é¡µç®¡ç†

2. **ä» Conversational RAG å€Ÿé‰´**ï¼š
   - æŸ¥è¯¢é‡å†™ï¼š"åˆšæ‰æåˆ°çš„å¯¼æ¼”" â†’ "Christopher Nolan"
   - å¯¹è¯å†å²çš„å‹ç¼©è¡¨ç¤º

3. **ä» Memory Networks å€Ÿé‰´**ï¼š
   - å¤šè·³æ¨ç†ï¼šå…ˆæ£€ç´¢åå¥½ï¼Œå†æ£€ç´¢ç›¸å…³å†³ç­–
   - è®°å¿†å†™å…¥çš„é‡è¦æ€§åŠ æƒ

4. **ä» "Memory in the Age of AI Agents" å€Ÿé‰´ï¼ˆ2025ï¼‰**ï¼š
   - ä½¿ç”¨å¤šç»´åˆ†ç±»ä½“ç³»è®¾è®¡è®°å¿†ç±»å‹ï¼ˆåŠŸèƒ½+æŒç»­æ—¶é—´+è®¿é—®æ¨¡å¼ï¼‰
   - ä¸å±€é™äºä¼ ç»Ÿçš„é•¿/çŸ­æœŸäºŒåˆ†æ³•
   - å‚è€ƒ 100+ ç¯‡è®ºæ–‡çš„æœ€ä½³å®è·µ

5. **ä» AgeMem å€Ÿé‰´ï¼ˆ2026ï¼‰**ï¼š
   - åŠ¨æ€è°ƒæ•´è®°å¿†çª—å£å¤§å°ï¼ˆæ ¹æ®å¯¹è¯å¤æ‚åº¦ï¼‰
   - è€ƒè™‘å®ç°ç®€åŒ–ç‰ˆçš„å­¦ä¹ å¼è®°å¿†ç®¡ç†

6. **ä» A-MEM å€Ÿé‰´ï¼ˆ2025ï¼‰**ï¼š
   - å®ç°"è®°å¿†æ„ŸçŸ¥"çš„æç¤ºæœºåˆ¶
   - è®© Agent è‡ªä¸»ç”Ÿæˆè®°å¿†æè¿°ï¼ˆæ”¹è¿›å½’æ¡£é€»è¾‘ï¼‰

7. **ä» Hello Again! å€Ÿé‰´ï¼ˆ2025ï¼‰**ï¼š
   - æ¸è¿›å¼æ›´æ–°ç”¨æˆ·ç”»åƒï¼ˆè€Œä¸æ˜¯ç›´æ¥è¦†ç›–ï¼‰
   - å¤„ç†åå¥½æ¼‚ç§»çš„æ—¶é—´è¡°å‡æœºåˆ¶

**å¼€æºå®ç°å‚è€ƒ**ï¼ˆæ›´æ–°ï¼‰ï¼š

| é¡¹ç›® | é“¾æ¥ | è¯´æ˜ |
|------|------|------|
| **MemGPT** | github.com/cpacker/MemGPT | å®Œæ•´çš„å¼€æºå®ç°ï¼Œå¯ç›´æ¥å‚è€ƒ |
| **LangChain Memory** | python.langchain.com | å¤šç§è®°å¿†å®ç°ï¼ˆConversationBufferMemory, etc.ï¼‰ |
| **LlamaIndex Memories** | docs.llamaindex.ai | ä¸“æ³¨äº RAG çš„è®°å¿†ç®¡ç† |
| **AutoGPT** | github.com/Significant-Gravitas/AutoGPT | Agent è®°å¿†ç®¡ç†å‚è€ƒ |
| **Letta** | letta.com | 2025å¹´æ–°æ¡†æ¶ï¼ŒAWSé›†æˆæ”¯æŒï¼ˆåŸºäºMemGPTï¼‰ |
| **Agent Memory Paper List** | github.com/Shichun-Liu/Agent-Memory-Paper-List | 2025å¹´æœ€æ–°çš„è®ºæ–‡åˆ—è¡¨ |

**2025å¹´è¡Œä¸šåŠ¨æ€**ï¼š

- **æ¡†æ¶**ï¼šLetta æ¡†æ¶ä¸ AWS é›†æˆï¼Œæ”¯æŒæƒ…èŠ‚è®°å¿†æ£€ç´¢
- **å¼€æº**ï¼šMemMachine å¼€æºé¡¹ç›®ï¼ˆMemVergeï¼‰
- **åº”ç”¨**ï¼šBAAI å‘å¸ƒå…·èº«æ™ºèƒ½ä½“è®°å¿†ç³»ç»Ÿï¼Œé˜²æ­¢æœºå™¨äºº"é—å¿˜"
- **è¯„æµ‹**ï¼šå¤šä¸ªé•¿æœŸè®°å¿†è¯„æµ‹åŸºå‡†å‘å¸ƒ

**2025å¹´å…³é”®è¿›å±•æ€»ç»“**ï¼š

2025å¹´æ˜¯ AI Agent è®°å¿†ç ”ç©¶çš„å¿«é€Ÿå‘å±•å¹´ï¼Œä¸»è¦ç‰¹ç‚¹ï¼š
1. **ç»Ÿä¸€åˆ†ç±»ä½“ç³»**ï¼šè¶…è¶Šä¼ ç»Ÿçš„é•¿/çŸ­æœŸè®°å¿†äºŒåˆ†æ³•
2. **å­¦ä¹ å¼è®°å¿†ç®¡ç†**ï¼šä»è§„åˆ™é©±åŠ¨å‘å­¦ä¹ é©±åŠ¨æ¼”è¿›
3. **äº§ä¸šåŒ–åŠ é€Ÿ**ï¼šå¤šä¸ªå¼€æºæ¡†æ¶å’Œå•†ä¸šäº§å“è½åœ°
4. **è¯„æµ‹åŸºå‡†å®Œå–„**ï¼šä¸“é—¨çš„è®°å¿†è¯„æµ‹åŸºå‡†å‘å¸ƒ
5. **å¤šæ¨¡æ€æ‰©å±•**ï¼šä»æ–‡æœ¬è®°å¿†æ‰©å±•åˆ°3Dç¯å¢ƒã€å…·èº«æ™ºèƒ½ä½“è®°å¿†

**âš ï¸ è®ºæ–‡çœŸå®æ€§è¯´æ˜**ï¼š
- å‰3ç¯‡è®ºæ–‡å·²éªŒè¯çœŸå®å­˜åœ¨
- éƒ¨åˆ†æ ‡æ³¨"2026å¹´"çš„è®ºæ–‡å¯èƒ½æ˜¯æœç´¢ç»“æœé”™è¯¯ï¼Œè¯·ä»¥arXivå®é™…é¡µé¢ä¸ºå‡†
- å»ºè®®ä¼˜å…ˆé˜…è¯»ï¼šMemGPT (2023) + Memory in the Age of AI Agents (2025) + A-MEM (2025)

### Phase 3: æ¶æ„é‡æ„ (LangGraph State Machine)

#### 2.3.1 é—®é¢˜è¯Šæ–­

**å½“å‰å‚æ•°ä¼ é€’é“¾è·¯**ï¼ˆè„†å¼±ï¼‰ï¼š
```
StreamHandler
  â”œâ”€> KBHandler.process_stream(message, session_id, agent_type, history, ...)
  â”‚     â””â”€> RAGStreamExecutor.stream(plan, message, session_id, kb_prefix, history, ...)
  â”‚           â””â”€> RagManager.run_plan_blocking(plan, message, session_id, history, ...)
  â”‚                 â””â”€> generate_rag_answer(message, context, history, ...)
  â””â”€> _executor.stream(plan, message, session_id, kb_prefix, history, ...)
```

**é—®é¢˜**ï¼š
- ä»»ä½•ä¸€å±‚æ¼ä¼ å‚æ•° â†’ `TypeError`
- æ–°å¢å‚æ•°éœ€ä¿®æ”¹ 6+ ä¸ªæ–‡ä»¶
- æµ‹è¯•æˆæœ¬é«˜ï¼ˆé›†æˆæµ‹è¯•æ‰èƒ½å‘ç°é—®é¢˜ï¼‰

#### 2.3.2 LangGraph è§£å†³æ–¹æ¡ˆ

**æ ¸å¿ƒç†å¿µ**ï¼šç”¨ **State** æ›¿ä»£ "å‚æ•°é€ä¼ "

**å…³é”®å·®å¼‚å¯¹æ¯”**ï¼š

```
ç°åœ¨çš„åšæ³•ï¼ˆå‚æ•°é€å±‚ä¼ é€’ï¼‰:
  StreamHandler
    â”œâ”€ message, session_id, memory_context, history
    â””â”€> KBHandler.process_stream(message, session_id, memory_context, history)
    â””â”€> RAGStreamExecutor.stream(plan, message, session_id, memory_context, history)

    # æ–°å¢ Phase 1/2 éœ€è¦æ”¹ N ä¸ªå‡½æ•°ç­¾åï¼š
    â””â”€> KBHandler.process_stream(message, session_id, memory_context, history,
                                  summary, episodic_memory)  # â† æ–°å¢å‚æ•°

LangGraph çš„åšæ³•ï¼ˆç»Ÿä¸€çŠ¶æ€ï¼‰:
  StreamHandler
    â””â”€> graph.astream(state)  # â† ä¸€æ¬¡æ€§ä¼ é€’æ‰€æœ‰æ•°æ®

    èŠ‚ç‚¹åªéœ€ä¿®æ”¹ State å®šä¹‰ï¼Œä¸éœ€æ”¹å‡½æ•°ç­¾åï¼š
    async def node(state: State) -> dict:
        return {...state, "new_field": value}  # â† åªæ”¹è¿™é‡Œ
```

**å®Œæ•´çš„ ConversationState å®šä¹‰**ï¼š

```python
from langgraph.graph import StateGraph, START, END
from typing import TypedDict, Annotated, Any
from operator import add
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage

class ConversationState(TypedDict):
    """å¯¹è¯å…¨å±€çŠ¶æ€ - ç®¡ç†æ•´ä¸ªå¯¹è¯æµç¨‹çš„æ‰€æœ‰æ•°æ®"""

    # ==================== è¯·æ±‚çº§åˆ«ä¿¡æ¯ ====================
    user_id: str                           # ç”¨æˆ·IDï¼ˆå¯¹åº” StreamHandler.handle çš„ user_idï¼‰
    message: str                           # å½“å‰ç”¨æˆ·æ¶ˆæ¯ï¼ˆå¯¹åº” StreamHandler.handle çš„ messageï¼‰
    session_id: str                        # ä¼šè¯IDï¼ˆå¯¹åº” StreamHandler.handle çš„ session_idï¼‰
    conversation_id: str                   # å¯¹è¯IDï¼ˆå¯¹åº” StreamHandler.handle çš„ conversation_idï¼‰

    # ==================== è¯·æ±‚é…ç½® ====================
    debug: bool                            # è°ƒè¯•æ¨¡å¼å¼€å…³
    agent_type: str                        # Agent ç±»å‹ï¼ˆhybrid_agent/naive_rag_agent...ï¼‰
    requested_kb_prefix: str | None        # ç”¨æˆ·æŒ‡å®šçš„ KBï¼ˆå¯¹åº” request.kb_prefixï¼‰

    # ==================== è·¯ç”±å†³ç­–ï¼ˆroute_node è¾“å‡ºï¼‰====================
    kb_prefix: str | None                  # æœ€ç»ˆå†³å®šä½¿ç”¨çš„ KB
    worker_name: str | None                # å·¥ä½œè€…åç§°ï¼ˆrouter è¾“å‡ºï¼‰
    use_retrieval: bool                    # æ˜¯å¦éœ€è¦æ£€ç´¢ï¼ˆå–å†³äº kb_prefixï¼‰
    route_decision: dict[str, Any] | None  # å®Œæ•´çš„è·¯ç”±å†³ç­–ä¿¡æ¯
    routing_ms: int | None                 # è·¯ç”±è€—æ—¶

    # ==================== ä¸Šä¸‹æ–‡æ„å»ºï¼ˆrecall_node è¾“å‡ºï¼‰====================
    # çŸ­æœŸè®°å¿†ï¼ˆå¯¹è¯å†å²ï¼‰
    history: list[dict[str, Any]]          # æœ€è¿‘ 6-7 æ¡æ¶ˆæ¯ï¼ˆæ¥è‡ª conversation_storeï¼‰

    # é•¿æœŸè®°å¿†ï¼ˆç”¨æˆ·ä¿¡æ¯ï¼‰
    memory_context: str | None             # é•¿æœŸç”¨æˆ·è®°å¿†ï¼ˆæ¥è‡ª memory_serviceï¼‰

    # Phase 1: å¯¹è¯æ‘˜è¦
    conversation_summary: str | None       # å¯¹è¯æ‘˜è¦ï¼ˆæ¥è‡ª summarizerï¼‰

    # Phase 2: è¯­ä¹‰æ£€ç´¢
    episodic_memory: list[dict[str, Any]] | None  # ç›¸å…³çš„å†å²ç‰‡æ®µï¼ˆæ¥è‡ª episodic_memoryï¼‰

    # ==================== æ‰§è¡Œç»“æœ ====================
    # æ£€ç´¢ç»“æœï¼ˆretrieve_node è¾“å‡ºï¼‰
    retrieval_results: list[dict[str, Any]] | None  # RAG æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
    retrieval_ms: int | None               # æ£€ç´¢è€—æ—¶

    # LLM ç”Ÿæˆï¼ˆgenerate_node è¾“å‡ºï¼‰
    messages: Annotated[list[BaseMessage], add]  # å¯¹è¯æ¶ˆæ¯åˆ—è¡¨ï¼ˆè‡ªåŠ¨è¿½åŠ ï¼‰

    # ==================== å…ƒæ•°æ® ====================
    execution_logs: list[dict[str, Any]] | None   # æ‰§è¡Œæ—¥å¿—ï¼ˆç”¨äº debugï¼‰
    error: str | None                      # é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœ‰ï¼‰
    partial_answer: bool = False            # æ˜¯å¦æ˜¯éƒ¨åˆ†å›å¤ï¼ˆæµå¼ä¸­æ–­ï¼‰
```

**ä¸ºä»€ä¹ˆè¿™ä¸ª State è®¾è®¡æ›´å¥½ï¼Ÿ**

| ç›Šå¤„ | è¯´æ˜ |
|------|------|
| **ä¸€æ¬¡æ€§å®šä¹‰** | æ–°å¢å‚æ•°åªéœ€åœ¨ State åŠ ä¸€è¡Œï¼Œä¸éœ€æ”¹å‡½æ•°ç­¾å |
| **æ•°æ®æº¯æºæ¸…æ™°** | æ¯ä¸ªå­—æ®µæ³¨æ˜æ¥æºï¼ˆå“ªä¸ª nodeã€å“ªä¸ª serviceï¼‰ |
| **è‡ªåŠ¨æ¶ˆæ¯ç®¡ç†** | `Annotated[list, add]` è‡ªåŠ¨åˆå¹¶æ¶ˆæ¯ï¼Œä¸éœ€æ‰‹åŠ¨è¿½åŠ  |
| **æ˜“äºè°ƒè¯•** | `execution_logs` è®°å½•æ¯ä¸ªèŠ‚ç‚¹çš„è¾“å…¥è¾“å‡º |
| **æ”¯æŒå¹¶è¡Œ** | å¤šä¸ªèŠ‚ç‚¹å¯ä»¥å¹¶è¡Œå¤„ç†ï¼ŒState è‡ªåŠ¨åˆå¹¶ç»“æœ |

#### 2.3.3 èŠ‚ç‚¹è®¾è®¡ï¼ˆä¸ç°æœ‰ä»£ç å¯¹åº”ï¼‰

**èŠ‚ç‚¹æ€»è§ˆ**ï¼š
```
START
  â†“
route_node          # è¿›è¡Œè·¯ç”±å†³ç­–ï¼ˆå¯¹åº”ç°æœ‰ Router.route()ï¼‰
  â†“
history_node        # è·å–çŸ­æœŸ+é•¿æœŸè®°å¿†ï¼ˆå¯¹åº”ç°æœ‰ _get_conversation_history + memory_serviceï¼‰
  â†“
retrieve_node       # å¯é€‰ï¼šæ£€ç´¢ï¼ˆä»…å½“ use_retrieval=Trueï¼‰
  â†“
kb_handler_node     # æ¡ä»¶æ‰§è¡Œï¼šä¼˜å…ˆä½¿ç”¨ KB ä¸“ç”¨ handler
  â”œâ”€ if kb_handler found
  â”‚   â†“
  â”‚ generate_kb_node  # ä½¿ç”¨ KB handler ç”Ÿæˆ
  â”‚   â†“
  â”‚ persist_node      # æŒä¹…åŒ–
  â”‚   â†“
  â”‚   END
  â”‚
  â”œâ”€ elseï¼ˆå›é€€åˆ° RAG æ‰§è¡Œå™¨ï¼‰
  â”‚   â†“
  â”‚   generate_rag_node  # ä½¿ç”¨ RAG executor ç”Ÿæˆ
  â”‚   â†“
  â”‚   persist_node       # æŒä¹…åŒ–
  â”‚   â†“
  â”‚   END
```

**è¯¦ç»†èŠ‚ç‚¹å®ç°**ï¼š

##### 1ï¸âƒ£ route_nodeï¼šè·¯ç”±å†³ç­–

```python
import time
from typing import Any, TypedDict
from domain.chat.entities.route_decision import RouteDecision

async def route_node(state: ConversationState) -> dict[str, Any]:
    """
    è·¯ç”±èŠ‚ç‚¹ï¼šæ ¹æ®ç”¨æˆ·æ¶ˆæ¯å’Œé…ç½®å†³å®šä½¿ç”¨å“ªä¸ª KB

    å¯¹åº”ç°æœ‰ä»£ç ï¼š
    - StreamHandler.handle() ç¬¬ 109-138 è¡Œï¼ˆè·¯ç”±é€»è¾‘ï¼‰
    """
    t0 = time.monotonic()

    # è°ƒç”¨ç°æœ‰çš„ Router
    decision: RouteDecision = router.route(
        message=state["message"],
        session_id=state["session_id"],
        requested_kb=state["requested_kb_prefix"],
        agent_type=state["agent_type"],
    )

    routing_ms = int((time.monotonic() - t0) * 1000)

    # å†³å®šæ˜¯å¦éœ€è¦æ£€ç´¢
    use_retrieval = (decision.kb_prefix or "").strip() not in {"", "general"}

    # æ„å»ºè¿”å›å€¼
    result = {
        "kb_prefix": decision.kb_prefix,
        "worker_name": decision.worker_name,
        "use_retrieval": use_retrieval,
        "route_decision": {
            "kb_prefix": decision.kb_prefix,
            "worker_name": decision.worker_name,
            "confidence": decision.confidence,
            "method": decision.method,
            "reason": decision.reason,
        },
        "routing_ms": routing_ms,
    }

    # å¦‚æœå¯ç”¨ Langfuseï¼Œè®°å½•è·¯ç”±å†³ç­–
    if ENABLE_LANGFUSE:
        try:
            from infrastructure.observability import get_current_langfuse_stateful_client
            parent = get_current_langfuse_stateful_client()
            if parent is not None:
                span = parent.span(name="route_decision", input={"message_preview": state["message"][:200]})
                span.end(output=result, metadata={"routing_ms": routing_ms})
        except Exception:
            pass  # è§‚æµ‹æ€§å¤±è´¥ä¸åº”é˜»å¡ä¸»æµç¨‹

    return result
```

##### 2ï¸âƒ£ history_nodeï¼šä¸Šä¸‹æ–‡æ„å»º

```python
async def history_node(state: ConversationState) -> dict[str, Any]:
    """
    å†å²èŠ‚ç‚¹ï¼šè·å–çŸ­æœŸè®°å¿†ï¼ˆå¯¹è¯å†å²ï¼‰å’Œé•¿æœŸè®°å¿†ï¼ˆç”¨æˆ·ä¿¡æ¯ï¼‰

    å¯¹åº”ç°æœ‰ä»£ç ï¼š
    - StreamHandler._get_conversation_history() ç¬¬ 53-62 è¡Œ
    - StreamHandler.handle() ç¬¬ 169-173 è¡Œï¼ˆmemory_serviceï¼‰
    - StreamHandler.handle() ç¬¬ 176-183 è¡Œï¼ˆhistory å»é‡ï¼‰
    """

    # 1. è·å–çŸ­æœŸè®°å¿†ï¼šæœ€è¿‘çš„å¯¹è¯å†å²
    raw_history = await conversation_store.list_messages(
        conversation_id=state["conversation_id"],
        limit=7,  # è·å–æœ€è¿‘ 7 æ¡ï¼ˆåŒ…å«å½“å‰æ¶ˆæ¯ï¼‰
        desc=True,  # é™åº
    )

    # ç¿»è½¬ä¸ºæ—¶é—´æ­£åº
    raw_history.reverse()

    # å»é‡ï¼šå¦‚æœæœ€åä¸€æ¡æ˜¯å½“å‰æ¶ˆæ¯ï¼Œæ’é™¤å®ƒï¼ˆé˜²æ­¢é‡å¤ï¼‰
    history_context = raw_history
    if raw_history and raw_history[-1].get("content") == state["message"]:
        history_context = raw_history[:-1]

    result = {
        "history": history_context,
    }

    # 2. è·å–é•¿æœŸè®°å¿†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if memory_service is not None:
        try:
            memory_context = await memory_service.recall_context(
                user_id=state["user_id"],
                query=state["message"],
            )
            result["memory_context"] = memory_context
        except Exception as e:
            logger.error(f"Failed to recall memory context: {e}")
            result["memory_context"] = None

    # 3. ç”Ÿæˆå¯¹è¯æ‘˜è¦ï¼ˆPhase 1ï¼Œå¯é€‰ï¼‰
    if summarizer is not None:
        try:
            summary = await summarizer.get_or_generate_summary(state["conversation_id"])
            result["conversation_summary"] = summary
        except Exception as e:
            logger.error(f"Failed to generate summary: {e}")
            result["conversation_summary"] = None

    # 4. å¬å›è¯­ä¹‰ç›¸å…³çš„å†å²ç‰‡æ®µï¼ˆPhase 2ï¼Œå¯é€‰ï¼‰
    if episodic_memory_manager is not None and state["use_retrieval"]:
        try:
            episodes = await episodic_memory_manager.recall_relevant(
                conversation_id=state["conversation_id"],
                query=state["message"],
                top_k=3,
            )
            result["episodic_memory"] = episodes
        except Exception as e:
            logger.error(f"Failed to recall episodic memory: {e}")
            result["episodic_memory"] = None

    # è®°å½•æ‰§è¡Œæ—¥å¿—ï¼ˆç”¨äºè°ƒè¯•ï¼‰
    if state.get("debug"):
        result.setdefault("execution_logs", []).append({
            "node": "history",
            "history_count": len(history_context),
            "has_memory_context": result.get("memory_context") is not None,
            "has_summary": result.get("conversation_summary") is not None,
            "episodic_count": len(result.get("episodic_memory") or []),
        })

    return result
```

##### 3ï¸âƒ£ retrieve_nodeï¼šæ£€ç´¢ï¼ˆæ¡ä»¶æ‰§è¡Œï¼‰

```python
async def retrieve_node(state: ConversationState) -> dict[str, Any]:
    """
    æ£€ç´¢èŠ‚ç‚¹ï¼šä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³çš„ä¸Šä¸‹æ–‡
    ä»…å½“ use_retrieval=True æ—¶æ‰§è¡Œ

    å¯¹åº”ç°æœ‰ä»£ç ï¼š
    - RAGStreamExecutor / ChatStreamExecutor çš„æ£€ç´¢é€»è¾‘
    """

    # å¦‚æœä¸éœ€è¦æ£€ç´¢ï¼Œç›´æ¥è·³è¿‡
    if not state["use_retrieval"]:
        return {}  # è¿”å›ç©ºå­—å…¸ï¼ŒState ä¿æŒä¸å˜

    t0 = time.monotonic()

    try:
        # æ„å»º RAG plan
        plan = [
            RagRunSpec(
                agent_type=_resolve_agent_type(
                    agent_type=state["agent_type"],
                    worker_name=state["worker_name"],
                ),
                worker_name=state["worker_name"],
            )
        ]

        # è°ƒç”¨ RAG æ‰§è¡Œå™¨è¿›è¡Œæ£€ç´¢
        results = await rag_executor.retrieve(
            plan=plan,
            query=state["message"],
            kb_prefix=state["kb_prefix"],
            session_id=state["session_id"],
        )

        retrieval_ms = int((time.monotonic() - t0) * 1000)

        return {
            "retrieval_results": results,
            "retrieval_ms": retrieval_ms,
        }

    except Exception as e:
        logger.error(f"Retrieval failed: {e}")
        return {
            "retrieval_results": None,
            "error": f"Retrieval failed: {str(e)}",
        }
```

##### 4ï¸âƒ£ generate_nodeï¼šç”Ÿæˆï¼ˆç»Ÿä¸€ç‰ˆæœ¬ï¼‰

```python
def _build_prompt_from_state(state: ConversationState) -> ChatPromptTemplate:
    """
    ä» State æ„å»º Prompt

    å¯¹åº”ç°æœ‰ä»£ç ï¼š
    - completion.py çš„ _build_general_prompt() / _build_rag_prompt()
    """
    messages = [
        ("system", SYSTEM_PROMPT),
    ]

    # æ·»åŠ é•¿æœŸç”¨æˆ·è®°å¿†
    if state.get("memory_context"):
        messages.append(("system", f"ã€ç”¨æˆ·é•¿æœŸè®°å¿†ã€‘\n{state['memory_context']}"))

    # æ·»åŠ å¯¹è¯æ‘˜è¦ï¼ˆPhase 1ï¼‰
    if state.get("conversation_summary"):
        messages.append(("system", f"ã€å¯¹è¯èƒŒæ™¯ã€‘\n{state['conversation_summary']}"))

    # æ·»åŠ è¯­ä¹‰ç›¸å…³çš„å†å²ç‰‡æ®µï¼ˆPhase 2ï¼‰
    if state.get("episodic_memory"):
        episodes_text = "\n".join([
            f"- {ep.get('user_message', '')} â†’ {ep.get('assistant_message', '')}"
            for ep in state["episodic_memory"]
        ])
        messages.append(("system", f"ã€ç›¸å…³å†å²ã€‘\n{episodes_text}"))

    # æ·»åŠ æ£€ç´¢ç»“æœï¼ˆå¦‚æœ‰ï¼‰
    if state.get("retrieval_results"):
        context_text = "\n".join([
            result.get("content", "")
            for result in state["retrieval_results"][:5]  # æœ€å¤š5æ¡
        ])
        messages.append(("system", f"ã€æ£€ç´¢ä¸Šä¸‹æ–‡ã€‘\n{context_text}"))

    # æ·»åŠ å¯¹è¯å†å²
    for msg in state.get("history", []):
        role = "assistant" if msg.get("role") == "assistant" else "human"
        messages.append((role, msg.get("content", "")))

    # å½“å‰é—®é¢˜
    messages.append(("human", state["message"]))

    return ChatPromptTemplate.from_messages(messages)


async def generate_node(state: ConversationState) -> dict[str, Any]:
    """
    ç”ŸæˆèŠ‚ç‚¹ï¼šLLM ç”Ÿæˆå›å¤

    å¯¹åº”ç°æœ‰ä»£ç ï¼š
    - generate_rag_answer() / ChatCompletionPort.generate()
    """

    try:
        # æ„å»º Promptï¼ˆè‡ªåŠ¨åŒ…å«æ‰€æœ‰ä¸Šä¸‹æ–‡ï¼‰
        prompt = _build_prompt_from_state(state)

        t0 = time.monotonic()

        # è°ƒç”¨ LLM
        response = await llm.ainvoke(
            prompt,
            callbacks=[get_langfuse_callback()],
        )

        generation_ms = int((time.monotonic() - t0) * 1000)

        # è§£æå“åº”
        answer_content = response.content

        # åˆ›å»º AI Messageï¼ˆè‡ªåŠ¨è¿½åŠ åˆ° messages åˆ—è¡¨ï¼‰
        result = {
            "messages": [AIMessage(content=answer_content)],
        }

        if state.get("debug"):
            result.setdefault("execution_logs", []).append({
                "node": "generate",
                "generation_ms": generation_ms,
                "answer_preview": answer_content[:100],
            })

        return result

    except Exception as e:
        logger.error(f"Generation failed: {e}")
        return {
            "error": f"Generation failed: {str(e)}",
            "messages": [AIMessage(content="æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç”Ÿæˆå›å¤ã€‚è¯·ç¨åé‡è¯•ã€‚")],
        }
```

##### 5ï¸âƒ£ persist_nodeï¼šæŒä¹…åŒ–

```python
async def persist_node(state: ConversationState) -> dict[str, Any]:
    """
    æŒä¹…åŒ–èŠ‚ç‚¹ï¼šä¿å­˜å¯¹è¯å’Œç´¢å¼•

    å¯¹åº”ç°æœ‰ä»£ç ï¼š
    - StreamHandler.handle() ç¬¬ 248-260 è¡Œï¼ˆä¿å­˜åŠ©æ‰‹æ¶ˆæ¯ï¼‰
    - StreamHandler.handle() ç¬¬ 461-467 è¡Œï¼ˆç´¢å¼• episodic memoryï¼‰
    """

    # è·å–æœ€æ–°ç”Ÿæˆçš„åŠ©æ‰‹å›å¤
    if not state.get("messages"):
        return {}

    assistant_message = state["messages"][-1]
    answer_content = assistant_message.content

    try:
        # 1. ä¿å­˜å¯¹è¯åˆ°æ•°æ®åº“
        await conversation_store.append_message(
            conversation_id=state["conversation_id"],
            role="assistant",
            content=answer_content,
            debug={"partial": state.get("partial_answer", False)} if state.get("debug") else None,
        )

        # 2. å¼‚æ­¥ç´¢å¼•åˆ° Episodic Memoryï¼ˆä¸é˜»å¡ä¸»æµç¨‹ï¼‰
        if episodic_memory_manager is not None:
            asyncio.create_task(
                episodic_memory_manager.index_episode(
                    conversation_id=state["conversation_id"],
                    user_msg=state["message"],
                    assistant_msg=answer_content,
                )
            )

        # 3. å†™å…¥é•¿æœŸè®°å¿†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if memory_service is not None and not state.get("partial_answer"):
            asyncio.create_task(
                memory_service.maybe_write(
                    user_id=state["user_id"],
                    user_message=state["message"],
                    assistant_message=answer_content,
                    metadata={
                        "session_id": state["session_id"],
                        "kb_prefix": state.get("kb_prefix"),
                    },
                )
            )

        return {"partial_answer": False}

    except Exception as e:
        logger.error(f"Persistence failed: {e}")
        return {"error": f"Persistence failed: {str(e)}"}
```

#### 2.3.4 Graph ç¼–æ’å’Œæµå¼å¤„ç†

**åˆ›å»º conversation_graph å·¥å‚**ï¼š

```python
# æ–‡ä»¶: infrastructure/chat/conversation_graph.py
from langgraph.graph import StateGraph, START, END, Conditional
from langgraph.types import Send
import asyncio
import logging

logger = logging.getLogger(__name__)

class ConversationGraphBuilder:
    """æ„å»ºå¯¹è¯æµå›¾"""

    def __init__(
        self,
        router,
        conversation_store,
        memory_service=None,
        summarizer=None,
        episodic_memory_manager=None,
        rag_executor=None,
        llm=None,
        kb_handler_factory=None,
        enable_kb_handlers=False,
    ):
        self.router = router
        self.conversation_store = conversation_store
        self.memory_service = memory_service
        self.summarizer = summarizer
        self.episodic_memory_manager = episodic_memory_manager
        self.rag_executor = rag_executor
        self.llm = llm
        self.kb_handler_factory = kb_handler_factory
        self.enable_kb_handlers = enable_kb_handlers

    def _route_to_kb_or_rag(self, state: ConversationState) -> str:
        """æ¡ä»¶è¾¹ï¼šé€‰æ‹©ä½¿ç”¨ KB Handler è¿˜æ˜¯ RAG æ‰§è¡Œå™¨"""
        if self.enable_kb_handlers and state.get("kb_prefix"):
            kb_handler = self.kb_handler_factory.get(state["kb_prefix"])
            if kb_handler is not None:
                return "generate_kb"
        return "generate_rag"

    def _should_retrieve(self, state: ConversationState) -> bool:
        """æ¡ä»¶åˆ¤æ–­ï¼šæ˜¯å¦éœ€è¦æ£€ç´¢"""
        return state.get("use_retrieval", False)

    def build(self) -> CompiledGraph:
        """æ„å»ºç¼–è¯‘åçš„å›¾"""
        builder = StateGraph(ConversationState)

        # ==================== æ·»åŠ èŠ‚ç‚¹ ====================
        builder.add_node(
            "route",
            lambda state: route_node(
                state, router=self.router
            ),
        )

        builder.add_node(
            "history",
            lambda state: history_node(
                state,
                conversation_store=self.conversation_store,
                memory_service=self.memory_service,
                summarizer=self.summarizer,
                episodic_memory_manager=self.episodic_memory_manager,
            ),
        )

        builder.add_node(
            "retrieve",
            lambda state: retrieve_node(
                state,
                rag_executor=self.rag_executor,
            ),
        )

        builder.add_node(
            "generate_kb",
            lambda state: generate_kb_node(
                state,
                kb_handler_factory=self.kb_handler_factory,
            ),
        )

        builder.add_node(
            "generate_rag",
            lambda state: generate_rag_node(
                state,
                llm=self.llm,
            ),
        )

        builder.add_node(
            "persist",
            lambda state: persist_node(
                state,
                conversation_store=self.conversation_store,
                memory_service=self.memory_service,
                episodic_memory_manager=self.episodic_memory_manager,
            ),
        )

        # ==================== å®šä¹‰è¾¹ ====================
        builder.set_entry_point("route")

        # route â†’ historyï¼ˆæ€»æ˜¯ï¼‰
        builder.add_edge("route", "history")

        # history â†’ retrieveï¼ˆæœ‰æ¡ä»¶ï¼‰
        builder.add_conditional_edges(
            "history",
            lambda state: self._should_retrieve(state),
            {
                True: "retrieve",
                False: "generate_kb" if self.enable_kb_handlers else "generate_rag",
            },
        )

        # retrieve â†’ é€‰æ‹©ç”Ÿæˆå™¨
        builder.add_conditional_edges(
            "retrieve",
            lambda state: self._route_to_kb_or_rag(state),
            {
                "generate_kb": "generate_kb",
                "generate_rag": "generate_rag",
            },
        )

        # generate_kb / generate_rag â†’ persist
        builder.add_edge("generate_kb", "persist")
        builder.add_edge("generate_rag", "persist")

        # persist â†’ end
        builder.add_edge("persist", END)

        # ==================== ç¼–è¯‘ ====================
        return builder.compile()


# ä½¿ç”¨ç¤ºä¾‹
def create_conversation_graph(
    services: ServiceContainer,  # åŒ…å«æ‰€æœ‰ä¾èµ–
) -> CompiledGraph:
    """å·¥å‚å‡½æ•°ï¼šåˆ›å»ºå¯¹è¯å›¾"""
    builder = ConversationGraphBuilder(
        router=services.router,
        conversation_store=services.conversation_store,
        memory_service=services.memory_service,
        summarizer=services.summarizer,
        episodic_memory_manager=services.episodic_memory_manager,
        rag_executor=services.rag_executor,
        llm=services.llm,
        kb_handler_factory=services.kb_handler_factory,
        enable_kb_handlers=services.config.ENABLE_KB_HANDLERS,
    )
    return builder.build()
```

#### 2.3.5 æµå¼å¤„ç†é›†æˆ

**æ”¹é€  HTTP å±‚ä½¿ç”¨ LangGraph**ï¼š

```python
# æ–‡ä»¶: server/api/rest/v1/chat_stream.py
from fastapi import APIRouter, HTTPException
from fastapi.responses import StreamingResponse
import json
from application.chat.schema import ChatRequest

router = APIRouter()

@router.post("/api/v1/chat/stream")
async def stream_chat(request: ChatRequest):
    """
    ä½¿ç”¨ LangGraph çš„æµå¼èŠå¤©ç«¯ç‚¹

    è¿ç§»æ¸…å•ï¼š
    âœ… åŸæœ‰ StreamHandler.handle() é€»è¾‘ â†’ LangGraph èŠ‚ç‚¹åŒ–
    âœ… å‚æ•°ä¸å†é€å±‚ä¼ é€’ â†’ ç»Ÿä¸€ State
    âœ… æ”¯æŒ debug æ¨¡å¼ â†’ execution_logs
    """

    try:
        # 1. è·å–æˆ–åˆ›å»ºå¯¹è¯
        conversation_id = await conversation_store.get_or_create_conversation_id(
            user_id=request.user_id,
            session_id=request.session_id,
        )

        # 2. ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
        await conversation_store.append_message(
            conversation_id=conversation_id,
            role="user",
            content=request.message,
        )

        # 3. åˆå§‹åŒ– Stateï¼ˆå¯¹åº”åŸæœ‰çš„ initial_stateï¼‰
        initial_state = ConversationState(
            # è¯·æ±‚ä¿¡æ¯
            user_id=request.user_id,
            message=request.message,
            session_id=request.session_id,
            conversation_id=conversation_id,
            # é…ç½®
            debug=request.debug,
            agent_type=request.agent_type,
            requested_kb_prefix=request.kb_prefix,
            # åˆå§‹åŒ–å…¶ä»–å­—æ®µ
            kb_prefix=None,
            worker_name=None,
            use_retrieval=False,
            history=[],
            memory_context=None,
            conversation_summary=None,
            episodic_memory=None,
            retrieval_results=None,
            messages=[HumanMessage(content=request.message)],
            execution_logs=[],
            error=None,
            partial_answer=False,
        )

        # 4. æµå¼æ‰§è¡Œå›¾
        async def event_generator():
            tokens = []
            completed = False

            async for event in conversation_graph.astream(
                initial_state,
                stream_mode="updates",  # æ¯ä¸ªèŠ‚ç‚¹æ‰§è¡Œåäº§ç”Ÿä¸€ä¸ªäº‹ä»¶
            ):
                # event æ ¼å¼: {node_name: {updated_state_fields}}
                node_name = list(event.keys())[0]
                node_state = event[node_name]

                # ç‰¹æ®Šå¤„ç†ï¼šæµå¼æ–‡æœ¬æ¥è‡ª generate èŠ‚ç‚¹
                if node_name in ["generate_kb", "generate_rag"]:
                    if "messages" in node_state:
                        message_content = node_state["messages"][-1].content
                        # æ¨¡æ‹Ÿæµå¼è¾“å‡ºï¼ˆå®é™… LLM åº”è¯¥å·²ç»æµå¼è¿”å›ï¼‰
                        for char in message_content:
                            tokens.append(char)
                            yield {
                                "status": "token",
                                "content": char,
                            }
                        completed = True

                # Debug æ¨¡å¼ï¼šè¾“å‡ºæ‰§è¡Œæ—¥å¿—
                if node_state.get("execution_logs"):
                    for log in node_state["execution_logs"]:
                        if log not in (initial_state.get("execution_logs") or []):
                            yield {
                                "status": "execution_log",
                                "content": log,
                            }

                # è·¯ç”±å†³ç­–ï¼šè¾“å‡ºç»™å®¢æˆ·ç«¯
                if node_name == "route" and "route_decision" in node_state:
                    yield {
                        "status": "route_decision",
                        "content": node_state["route_decision"],
                    }

            # æµå¼ç»“æŸ
            answer = "".join(tokens).strip()
            yield {
                "status": "done",
                "content": {
                    "answer": answer,
                    "conversation_id": conversation_id,
                },
            }

        # 5. è¿”å› SSE å“åº”
        return StreamingResponse(
            event_generator(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "X-Accel-Buffering": "no",
            },
        )

    except Exception as e:
        logger.error(f"Chat stream failed: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))
```

**ä¸åŸæœ‰ä»£ç çš„å¯¹åº”å…³ç³»**ï¼š

| åŸæœ‰ä»£ç  | LangGraph æ–¹æ¡ˆ | ä¼˜åŠ¿ |
|---------|--------------|------|
| `StreamHandler.handle()` ç¬¬ 65-261 è¡Œ | `conversation_graph.astream()` | æµç¨‹æ¸…æ™°ï¼Œæ˜“äºç†è§£ |
| æ‰‹åŠ¨ä¼ é€’ `memory_context, history` | `ConversationState` | æ–°å¢å‚æ•°æ— éœ€æ”¹å‡½æ•°ç­¾å |
| `kb_handler.process_stream()` + `executor.stream()` | æ¡ä»¶è¾¹è‡ªåŠ¨é€‰æ‹© | ä¸éœ€è¦å¤šä¸ªå¤„ç†å™¨åˆ†æ”¯ |
| æ‰‹åŠ¨è¿½åŠ æ¶ˆæ¯ | `Annotated[list, add]` | è‡ªåŠ¨åˆå¹¶æ¶ˆæ¯ |

#### 2.3.6 ä¸€æ¬¡æ€§é‡æ„æ–¹æ¡ˆ

**å®Œæ•´çš„æ–‡ä»¶è¿ç§»æ¸…å•**ï¼š

##### Step 1ï¼šåˆ›å»ºæ–°çš„çŠ¶æ€å’Œå›¾æ–‡ä»¶ï¼ˆæ–°å»ºï¼‰

```
æ–°å»ºæ–‡ä»¶ï¼š
âœ… backend/infrastructure/chat/conversation_state.py
âœ… backend/infrastructure/chat/conversation_nodes.py
âœ… backend/infrastructure/chat/conversation_graph.py
âœ… backend/application/chat/handlers/langgraph_stream_handler.py
```

##### Step 2ï¼šåˆ é™¤æˆ–å¼ƒç”¨çš„æ–‡ä»¶

```
å¼ƒç”¨ï¼ˆä½†ä¿ç•™ä»¥é˜²å›æ»šï¼‰ï¼š
âš ï¸  backend/application/chat/handlers/stream_handler.py
âš ï¸  backend/application/chat/handlers/chat_handler.py

å®Œå…¨åˆ é™¤ï¼ˆå…¶é€»è¾‘å·²è¿ç§»åˆ°èŠ‚ç‚¹ä¸­ï¼‰ï¼š
âŒ backend/application/chat/completion.pyï¼ˆPrompt æ„å»ºé€»è¾‘ï¼‰
```

##### Step 3ï¼šä¿®æ”¹çš„æ–‡ä»¶

```
éœ€è¦ä¿®æ”¹ï¼š
ğŸ“ backend/server/api/rest/v1/chat_stream.py
   - æ›¿æ¢ StreamHandler â†’ LangGraphStreamHandler

ğŸ“ backend/server/api/rest/v1/chat.py
   - æ›¿æ¢ ChatHandler â†’ LangGraphStreamHandlerï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰

ğŸ“ backend/infrastructure/config.py
   - æ·»åŠ  LangGraph ç›¸å…³é…ç½®

ğŸ“ backend/infrastructure/di/container.py
   - æ³¨å†Œ conversation_graph ä¾èµ–
   - åˆ é™¤ StreamHandler / ChatHandler æ³¨å†Œ
```

##### Step 4ï¼šè¯¦ç»†è¿ç§»æ­¥éª¤

**ç¬¬ 1 å¤©ï¼šåŸºç¡€è®¾æ–½æ­å»º**

```python
# 1. åˆ›å»º conversation_state.py
# åŒ…å«å®Œæ•´çš„ ConversationState TypedDictï¼ˆå‚è€ƒ 2.3.2ï¼‰

# 2. åˆ›å»º conversation_nodes.py
# åŒ…å«æ‰€æœ‰ 5 ä¸ªèŠ‚ç‚¹çš„å®ç°ï¼š
# - route_node()
# - history_node()
# - retrieve_node()
# - generate_node()
# - persist_node()
```

**ç¬¬ 2 å¤©ï¼šå›¾æ„å»º**

```python
# 1. åˆ›å»º conversation_graph.py
# åŒ…å« ConversationGraphBuilder ç±»å’Œ create_conversation_graph() å·¥å‚

# 2. åœ¨ DI å®¹å™¨ä¸­æ³¨å†Œ
# container.py:
#   graph = create_conversation_graph(services)
```

**ç¬¬ 3 å¤©ï¼šHTTP å±‚è¿ç§»**

```python
# 1. åˆ›å»º langgraph_stream_handler.py
# - å®ç°æ–°çš„ stream_chat() ç«¯ç‚¹
# - ä¿æŒä¸æ—§ API å®Œå…¨å…¼å®¹

# 2. ä¿®æ”¹ chat_stream.py
# - æ›¿æ¢å¯¼å…¥ï¼šfrom StreamHandler â†’ from LangGraphStreamHandler
# - æˆ–ç›´æ¥ä½¿ç”¨ conversation_graph.astream()
```

**ç¬¬ 4 å¤©ï¼šæµ‹è¯•å’ŒéªŒè¯**

```python
# 1. å•å…ƒæµ‹è¯•
# - æ¯ä¸ªèŠ‚ç‚¹ç‹¬ç«‹æµ‹è¯•
# - çŠ¶æ€è½¬ç§»æµ‹è¯•
# - é”™è¯¯å¤„ç†æµ‹è¯•

# 2. é›†æˆæµ‹è¯•
# - å®Œæ•´å¯¹è¯æµç¨‹æµ‹è¯•
# - å¯¹æ¯”æ–°æ—§å®ç°çš„è¾“å‡º

# 3. æ€§èƒ½æµ‹è¯•
# - å»¶è¿Ÿå¯¹æ¯”
# - å†…å­˜å ç”¨å¯¹æ¯”
```

**ç¬¬ 5 å¤©ï¼šéƒ¨ç½²å’Œå›æ»š**

```bash
# éƒ¨ç½²å‰ï¼šå¤‡ä»½æ—§ä»£ç 
git tag backup/stream-handler-v1

# éƒ¨ç½²ï¼šä¸€æ¬¡æ€§æ›¿æ¢æ‰€æœ‰ç«¯ç‚¹
DEPLOY_VERSION=langgraph

# éƒ¨ç½²åï¼šç›‘æ§
- å¯¹è¯æˆåŠŸç‡
- å“åº”å»¶è¿Ÿ
- é”™è¯¯ç‡
- æ—¥å¿—å¼‚å¸¸

# å¦‚é‡é—®é¢˜ï¼šå¿«é€Ÿå›æ»š
git revert <commit-hash>
```

##### Step 5ï¼šå…³é”®å®ç°ç»†èŠ‚

**ä¿æŒä¸æ—§ API å®Œå…¨å…¼å®¹**ï¼š

```python
# åŸæœ‰çš„ HTTP è¯·æ±‚å®Œå…¨ä¸å˜
POST /api/v1/chat/stream {
    "user_id": "...",
    "message": "...",
    "session_id": "...",
    "kb_prefix": "...",
    "debug": false,
    "agent_type": "hybrid_agent"
}

# å“åº”æ ¼å¼å®Œå…¨ç›¸åŒ
{
    "status": "token",
    "content": "æ–‡"
}
{
    "status": "done",
    "content": {"answer": "..."}
}
```

**ä¾èµ–æ³¨å…¥æ”¹é€ ï¼ˆæœ€å°åŒ–ï¼‰**ï¼š

```python
# åŸæœ‰ï¼š
handler = StreamHandler(
    router=router,
    executor=executor,
    conversation_store=conversation_store,
    memory_service=memory_service,
    kb_handler_factory=kb_handler_factory,
)

# æ–°æ–¹æ¡ˆï¼š
graph = create_conversation_graph(services)  # ä¸€è¡Œä»£ç 

# åœ¨ HTTP å±‚è°ƒç”¨
async for event in graph.astream(initial_state):
    yield event
```

##### Step 6ï¼šä¸å¯é€†ç‚¹ï¼ˆç¡®ä¿ä¸€æ¬¡æ€§æˆåŠŸï¼‰

| æ£€æŸ¥é¡¹ | è¯´æ˜ |
|-------|------|
| æµ‹è¯•è¦†ç›–ç‡ | æ‰€æœ‰èŠ‚ç‚¹å•å…ƒæµ‹è¯• â‰¥ 90% |
| é›†æˆæµ‹è¯• | è‡³å°‘ 50 ä¸ªçœŸå®å¯¹è¯åœºæ™¯éªŒè¯ |
| æ€§èƒ½åŸºçº¿ | å»¶è¿Ÿä¸è¶…è¿‡åŸæœ‰ Â±5% |
| é”™è¯¯å¤„ç† | æ‰€æœ‰å¼‚å¸¸éƒ½æœ‰é™çº§æ–¹æ¡ˆ |
| å›æ»šè„šæœ¬ | æµ‹è¯•è¿‡å¿«é€Ÿå›æ»šæµç¨‹ |

##### Step 7ï¼šéƒ¨ç½²å‘½ä»¤

```bash
# 1. æ„å»ºæ–°é•œåƒï¼ˆåŒ…å«æ‰€æœ‰ LangGraph ä»£ç ï¼‰
docker build -t movie-agent:langgraph-v1 .

# 2. è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶
pytest tests/ -v --cov=backend

# 3. æ€§èƒ½åŸºå‡†æµ‹è¯•
python benchmarks/test_performance.py

# 4. éƒ¨ç½²åˆ°é¢„å‘å¸ƒç¯å¢ƒï¼ˆ10% æµé‡ï¼‰
kubectl set image deployment/movie-agent \
  movie-agent=movie-agent:langgraph-v1 \
  --record \
  --namespace=staging

# 5. éªŒè¯é¢„å‘å¸ƒï¼ˆ30 åˆ†é’Ÿï¼‰
- ç›‘æ§é”™è¯¯ç‡
- æ£€æŸ¥æ—¥å¿—
- æ‰‹å·¥æµ‹è¯•å‡ ä¸ªå¯¹è¯

# 6. å…¨é‡ä¸Šçº¿ï¼ˆ100% æµé‡ï¼‰
kubectl set image deployment/movie-agent \
  movie-agent=movie-agent:langgraph-v1 \
  --record \
  --namespace=production

# 7. æŒç»­ç›‘æ§ï¼ˆ1 å°æ—¶ï¼‰
- å…³é”®æŒ‡æ ‡ç›‘æ§
- å‘Šè­¦é…ç½®
- å‡†å¤‡å›æ»šæ–¹æ¡ˆ
```

##### Step 8ï¼šå¿«é€Ÿå›æ»šæ–¹æ¡ˆ

```bash
# ä¸‡ä¸€å‡ºç°é—®é¢˜ï¼Œæ‰§è¡Œå›æ»šï¼ˆâ‰¤ 5 åˆ†é’Ÿï¼‰
kubectl rollout undo deployment/movie-agent \
  --namespace=production

# éªŒè¯å›æ»š
kubectl get pods -n production
curl http://api.service:8000/api/v1/health  # å¥åº·æ£€æŸ¥

# åˆ†æé—®é¢˜ï¼ˆPost-mortemï¼‰
- æŸ¥çœ‹æ–°æ—§ç‰ˆæœ¬çš„æ—¥å¿—å·®å¼‚
- å¯¹æ¯”ä¸¤ä¸ªç‰ˆæœ¬çš„æ€§èƒ½æŒ‡æ ‡
- ç¡®ä¿æ²¡æœ‰æ•°æ®æŸå
```

#### 2.3.7 æœ€ç»ˆçš„ä¼˜åŠ¿æ€»ç»“

| ç»´åº¦ | ç°æœ‰æ¶æ„ | Phase 3 (LangGraph) |
|------|---------|------------------|
| **å‚æ•°ä¼ é€’** | é€å±‚æ‰‹åŠ¨ä¼ é€’ï¼ˆ6+å±‚ï¼‰ | ç»Ÿä¸€ Stateï¼ˆé›¶å±‚ï¼‰ |
| **æ–°å¢å‚æ•°** | ä¿®æ”¹ 5-7 ä¸ªå‡½æ•°ç­¾å | ä¿®æ”¹ 1 ä¸ª TypedDict |
| **æ‰©å±•æ€§** | ä½ï¼Œæ”¹ä¸€ä¸ªå‚æ•°å½±å“å¤šå¤„ | é«˜ï¼ŒåŠ å­—æ®µå°±è¡Œ |
| **å¯æµ‹è¯•æ€§** | é›†æˆæµ‹è¯• | å•å…ƒæµ‹è¯•ï¼ˆæ¯ä¸ªèŠ‚ç‚¹ï¼‰ |
| **å¯è§‚æµ‹æ€§** | æ‰‹åŠ¨åŸ‹ç‚¹ + Langfuse | å†…ç½® execution_logs + Langfuse |
| **é”™è¯¯å¤„ç†** | æ¯å±‚éƒ½è¦ try-except | ç»Ÿä¸€åœ¨èŠ‚ç‚¹ä¸­å¤„ç† |
| **æµå¼å¤„ç†** | æ‰‹åŠ¨è¿½è¸ª tokens | è‡ªåŠ¨åˆå¹¶æ¶ˆæ¯ |

#### 2.3.8 Phase 3 æµ‹è¯•æ–¹æ¡ˆ

**å•å…ƒæµ‹è¯•ï¼ˆæ¯ä¸ªèŠ‚ç‚¹ç‹¬ç«‹æµ‹è¯•ï¼‰**ï¼š

```python
# tests/infrastructure/chat/test_conversation_nodes.py
import pytest
from unittest.mock import AsyncMock, MagicMock
from infrastructure.chat.conversation_nodes import (
    route_node, history_node, retrieve_node, generate_node, persist_node
)
from infrastructure.chat.conversation_state import ConversationState

class TestRouteNode:
    @pytest.mark.asyncio
    async def test_route_node_returns_kb_prefix(self):
        """æµ‹è¯• route_node æ­£ç¡®è¿”å› KB"""
        mock_router = AsyncMock()
        mock_router.route.return_value = RouteDecision(
            kb_prefix="movie",
            worker_name="movie:hybrid_agent",
            confidence=0.95,
            method="auto",
            reason="User query matched movie KB",
        )

        state = ConversationState(
            message="æ¨èç”µå½±",
            session_id="test-session",
            ...
        )

        result = await route_node(state, router=mock_router)

        assert result["kb_prefix"] == "movie"
        assert result["use_retrieval"] is True

    @pytest.mark.asyncio
    async def test_route_node_general_kb_no_retrieval(self):
        """æµ‹è¯• general KB ä¸éœ€è¦æ£€ç´¢"""
        mock_router = AsyncMock()
        mock_router.route.return_value = RouteDecision(
            kb_prefix="general",
            worker_name="general:naive_agent",
            ...
        )

        result = await route_node(state, router=mock_router)
        assert result["use_retrieval"] is False


class TestHistoryNode:
    @pytest.mark.asyncio
    async def test_history_node_retrieves_messages(self):
        """æµ‹è¯• history_node æ­£ç¡®è·å–å†å²æ¶ˆæ¯"""
        mock_store = AsyncMock()
        mock_store.list_messages.return_value = [
            {"role": "user", "content": "ä»€ä¹ˆæ˜¯æ¨èç³»ç»Ÿ"},
            {"role": "assistant", "content": "æ¨èç³»ç»Ÿæ˜¯..."},
            {"role": "user", "content": "èƒ½ä¸¾ä¾‹å—"},
        ]

        state = ConversationState(conversation_id="conv-1", message="èƒ½ä¸¾ä¾‹å—", ...)
        result = await history_node(state, conversation_store=mock_store)

        assert len(result["history"]) == 2  # å»é‡å½“å‰æ¶ˆæ¯
        assert result["history"][0]["content"] == "ä»€ä¹ˆæ˜¯æ¨èç³»ç»Ÿ"

    @pytest.mark.asyncio
    async def test_history_node_with_summary(self):
        """æµ‹è¯• history_node è·å–æ‘˜è¦"""
        mock_store = AsyncMock()
        mock_store.list_messages.return_value = []

        mock_summarizer = AsyncMock()
        mock_summarizer.get_or_generate_summary.return_value = "ç”¨æˆ·è¯¢é—®äº†å…³äºç”µå½±æ¨èçš„é—®é¢˜"

        result = await history_node(state, conversation_store=mock_store, summarizer=mock_summarizer)

        assert result["conversation_summary"] is not None

    @pytest.mark.asyncio
    async def test_history_node_error_resilience(self):
        """æµ‹è¯• history_node åœ¨é”™è¯¯æ—¶çš„é™çº§"""
        mock_store = AsyncMock()
        mock_store.list_messages.return_value = []

        mock_summarizer = AsyncMock()
        mock_summarizer.get_or_generate_summary.side_effect = Exception("Summarizer failed")

        result = await history_node(state, conversation_store=mock_store, summarizer=mock_summarizer)

        # æ‘˜è¦å¤±è´¥ä¸åº”è¯¥é˜»å¡æ•´ä¸ªæµç¨‹
        assert result["conversation_summary"] is None
        assert "history" in result


class TestGenerateNode:
    @pytest.mark.asyncio
    async def test_generate_node_creates_message(self):
        """æµ‹è¯• generate_node ç”Ÿæˆ AIMessage"""
        mock_llm = AsyncMock()
        mock_llm.ainvoke.return_value = MagicMock(content="è¿™æ˜¯ä¸€ä¸ªæ¨èç»“æœ")

        state = ConversationState(
            message="æ¨èç”µå½±",
            history=[],
            memory_context=None,
            ...
        )

        result = await generate_node(state, llm=mock_llm)

        assert "messages" in result
        assert len(result["messages"]) > 0
        assert result["messages"][0].content == "è¿™æ˜¯ä¸€ä¸ªæ¨èç»“æœ"

    @pytest.mark.asyncio
    async def test_generate_node_with_context(self):
        """æµ‹è¯• generate_node åŒ…å«æ‰€æœ‰ä¸Šä¸‹æ–‡"""
        mock_llm = AsyncMock()

        state = ConversationState(
            message="æ¨èç”µå½±",
            history=[{"role": "user", "content": "å–œæ¬¢ç§‘å¹»"}],
            memory_context="ç”¨æˆ·å–œæ¬¢è¯ºå…°çš„ç”µå½±",
            conversation_summary="ç”¨æˆ·è¯¢é—®ç”µå½±æ¨è",
            retrieval_results=[{"content": "ã€Šæ˜Ÿé™…ç©¿è¶Šã€‹æ˜¯è¯ºå…°çš„ä»£è¡¨ä½œ"}],
            ...
        )

        result = await generate_node(state, llm=mock_llm)

        # éªŒè¯ LLM è¢«æ­£ç¡®è°ƒç”¨ï¼ˆåŒ…å«æ‰€æœ‰ä¸Šä¸‹æ–‡ï¼‰
        assert mock_llm.ainvoke.called
        call_args = mock_llm.ainvoke.call_args
        prompt = call_args[0][0]  # ç¬¬ä¸€ä¸ªä½ç½®å‚æ•°æ˜¯ prompt

        # æ£€æŸ¥ Prompt åŒ…å«æ‰€æœ‰å¿…è¦ä¿¡æ¯
        assert "memory_context" not in prompt.format()  # å·²è¢« inject
        # å®é™…ä¸Šåº”è¯¥æ£€æŸ¥ prompt çš„å†…å®¹ï¼Œè¿™é‡Œç®€åŒ–äº†

class TestPersistNode:
    @pytest.mark.asyncio
    async def test_persist_node_saves_message(self):
        """æµ‹è¯• persist_node ä¿å­˜æ¶ˆæ¯"""
        mock_store = AsyncMock()

        state = ConversationState(
            conversation_id="conv-1",
            messages=[
                HumanMessage(content="æ¨èç”µå½±"),
                AIMessage(content="æ¨èã€Šæ˜Ÿé™…ç©¿è¶Šã€‹"),
            ],
            ...
        )

        result = await persist_node(state, conversation_store=mock_store)

        # éªŒè¯æ¶ˆæ¯è¢«ä¿å­˜
        mock_store.append_message.assert_called_once()
        call_args = mock_store.append_message.call_args
        assert call_args[1]["content"] == "æ¨èã€Šæ˜Ÿé™…ç©¿è¶Šã€‹"
```

**é›†æˆæµ‹è¯•ï¼ˆå®Œæ•´æµç¨‹ï¼‰**ï¼š

```python
# tests/infrastructure/chat/test_conversation_graph.py
import pytest
from infrastructure.chat.conversation_graph import create_conversation_graph
from infrastructure.chat.conversation_state import ConversationState
from langchain_core.messages import HumanMessage

class TestConversationGraph:
    @pytest.fixture
    async def graph(self, services_mock):
        """åˆ›å»ºæµ‹è¯•ç”¨çš„å›¾"""
        return create_conversation_graph(services_mock)

    @pytest.mark.asyncio
    async def test_complete_conversation_flow(self, graph):
        """æµ‹è¯•å®Œæ•´çš„å¯¹è¯æµç¨‹"""
        initial_state = ConversationState(
            user_id="test-user",
            message="æ¨èç§‘å¹»ç”µå½±",
            session_id="test-session",
            conversation_id="test-conv",
            debug=True,
            agent_type="hybrid_agent",
            requested_kb_prefix="movie",
            # å…¶ä»–å­—æ®µåˆå§‹åŒ–...
        )

        # æ‰§è¡Œå›¾
        final_state = None
        async for event in graph.astream(initial_state):
            final_state = event

        # éªŒè¯ç»“æœ
        assert final_state is not None
        assert "messages" in final_state
        assert len(final_state["messages"]) >= 2  # User + Assistant
        assert final_state["messages"][-1].type == "ai"

    @pytest.mark.asyncio
    async def test_graph_with_kb_handler(self, graph):
        """æµ‹è¯•ä½¿ç”¨ KB Handler çš„æµç¨‹"""
        # æµ‹è¯•æ¡ä»¶è¾¹ï¼šåº”è¯¥èµ° KB Handler
        # éªŒè¯ generate_kb_node è¢«æ‰§è¡Œ
        pass

    @pytest.mark.asyncio
    async def test_graph_error_handling(self, graph):
        """æµ‹è¯•é”™è¯¯å¤„ç†å’Œé™çº§"""
        # æ³¨å…¥é”™è¯¯ï¼šmemory_service å¤±è´¥
        # éªŒè¯æµç¨‹ç»§ç»­å¹¶å®Œæˆ
        pass

    @pytest.mark.asyncio
    async def test_graph_with_debug_mode(self, graph):
        """æµ‹è¯• debug æ¨¡å¼"""
        initial_state = ConversationState(..., debug=True)

        async for event in graph.astream(initial_state):
            pass

        # éªŒè¯ execution_logs è¢«å¡«å……
        # å„ä¸ªèŠ‚ç‚¹éƒ½è¾“å‡ºäº†æ—¥å¿—
```

**æ€§èƒ½æµ‹è¯•ï¼ˆåŸºå‡†å¯¹æ¯”ï¼‰**ï¼š

```python
# benchmarks/test_phase3_performance.py
import asyncio
import time
import statistics

@pytest.mark.benchmark
class TestConversationGraphPerformance:

    async def measure_single_conversation(self, graph, message: str) -> float:
        """æµ‹é‡å•ä¸ªå¯¹è¯çš„å»¶è¿Ÿ"""
        initial_state = ConversationState(
            user_id="perf-test",
            message=message,
            conversation_id="perf-conv",
            ...
        )

        t0 = time.perf_counter()
        async for event in graph.astream(initial_state):
            pass
        t1 = time.perf_counter()

        return (t1 - t0) * 1000  # æ¯«ç§’

    @pytest.mark.asyncio
    async def test_baseline_latency(self, graph):
        """æµ‹è¯•åŸºçº¿å»¶è¿Ÿ"""
        messages = [
            "æ¨èç”µå½±",
            "è¿™éƒ¨ç”µå½±æ€ä¹ˆæ ·",
            "è¿˜æœ‰å…¶ä»–æ¨èå—",
        ]

        times = []
        for msg in messages:
            latency_ms = await self.measure_single_conversation(graph, msg)
            times.append(latency_ms)

        avg_latency = statistics.mean(times)
        max_latency = max(times)

        print(f"å¹³å‡å»¶è¿Ÿ: {avg_latency:.2f}ms")
        print(f"æœ€å¤§å»¶è¿Ÿ: {max_latency:.2f}ms")

        # åº”è¯¥ < 500ms
        assert avg_latency < 500, f"Average latency {avg_latency}ms exceeds 500ms"
        assert max_latency < 1000, f"Max latency {max_latency}ms exceeds 1000ms"

    @pytest.mark.asyncio
    async def test_concurrent_conversations(self, graph):
        """æµ‹è¯•å¹¶å‘å¯¹è¯"""
        async def run_conversation(graph, msg: str):
            return await self.measure_single_conversation(graph, msg)

        # 10 ä¸ªå¹¶å‘å¯¹è¯
        tasks = [
            run_conversation(graph, f"æ¶ˆæ¯{i}")
            for i in range(10)
        ]

        times = await asyncio.gather(*tasks)

        avg_latency = statistics.mean(times)
        assert avg_latency < 600, "Concurrent latency too high"

    @pytest.mark.asyncio
    async def test_memory_usage(self, graph):
        """æµ‹è¯•å†…å­˜å ç”¨"""
        import tracemalloc

        tracemalloc.start()

        # è¿è¡Œ 100 ä¸ªå¯¹è¯
        for i in range(100):
            initial_state = ConversationState(...)
            async for event in graph.astream(initial_state):
                pass

        current, peak = tracemalloc.get_traced_memory()
        tracemalloc.stop()

        print(f"å³°å€¼å†…å­˜å ç”¨: {peak / 1024 / 1024:.2f}MB")
        # åº”è¯¥ < 200MB
        assert peak < 200 * 1024 * 1024
```

**æµ‹è¯•å‘½ä»¤**ï¼š

```bash
# è¿è¡Œæ‰€æœ‰ Phase 3 ç›¸å…³æµ‹è¯•
pytest tests/infrastructure/chat/test_conversation_nodes.py -v

pytest tests/infrastructure/chat/test_conversation_graph.py -v

# è¿è¡Œæ€§èƒ½æµ‹è¯•ï¼ˆå¯èƒ½è¾ƒæ…¢ï¼‰
pytest benchmarks/test_phase3_performance.py -v -s

# è¿è¡Œæµ‹è¯•è¦†ç›–ç‡æŠ¥å‘Š
pytest tests/ --cov=infrastructure/chat --cov-report=html

# ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Šï¼ˆæ–°æ—§ç‰ˆæœ¬ï¼‰
pytest tests/ -v --json=test_results_langgraph.json
# ä¸æ—§ç‰ˆæœ¬å¯¹æ¯”
diff <(pytest tests/ -v --json=test_results_legacy.json) test_results_langgraph.json
```

---

## 3. å®æ–½è·¯çº¿å›¾

| é˜¶æ®µ | å·¥ä½œé‡ï¼ˆäººå¤©ï¼‰ | é£é™© | ä¼˜å…ˆçº§ |
|------|---------------|------|--------|
| **Phase 1: æ‘˜è¦** | 3-5 | ä½ | **P0** |
| **Phase 2: è¯­ä¹‰æ£€ç´¢** | 5-7 | ä¸­ | P1 |
| **Phase 3: LangGraph** | 10-15 | é«˜ | P2 |

### 3.1 Phase 1 è¯¦ç»†å®æ–½æ­¥éª¤

#### Step 1: æ•°æ®åº“è¿ç§»
```python
# 1. åˆ›å»ºæ‘˜è¦è¡¨
async def init_summary_table():
    async with get_db_pool() as pool:
        async with pool.acquire() as conn:
            await conn.execute("""
            CREATE TABLE IF NOT EXISTS conversation_summaries (
                id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
                conversation_id UUID NOT NULL UNIQUE REFERENCES conversations(id) ON DELETE CASCADE,
                summary TEXT NOT NULL,
                covered_message_count INT NOT NULL DEFAULT 0,
                created_at TIMESTAMP DEFAULT NOW(),
                updated_at TIMESTAMP DEFAULT NOW()
            )
            """)
            # ç´¢å¼•ç”¨äºé¢‘ç¹æŸ¥è¯¢
            await conn.execute("""
            CREATE INDEX IF NOT EXISTS idx_conversation_summaries_conversation_id
            ON conversation_summaries(conversation_id)
            """)

# 2. åœ¨ ChatHandler åˆå§‹åŒ–æ—¶è°ƒç”¨
async def setup_handler(self):
    await init_summary_table()
```

#### Step 2: é›†æˆæ‘˜è¦ç”Ÿæˆ
```python
# åœ¨ conversation_store.py ä¸­æ·»åŠ æ‘˜è¦æ–¹æ³•
class ConversationStore:
    async def get_summary(self, conversation_id: str) -> dict | None:
        """è·å–å·²å­˜åœ¨çš„æ‘˜è¦"""
        result = await self.db.fetchrow(
            "SELECT * FROM conversation_summaries WHERE conversation_id = $1",
            conversation_id
        )
        return result

    async def save_summary(self, conversation_id: str, summary: str, covered_count: int):
        """ä¿å­˜æˆ–æ›´æ–°æ‘˜è¦"""
        await self.db.execute("""
        INSERT INTO conversation_summaries (conversation_id, summary, covered_message_count)
        VALUES ($1, $2, $3)
        ON CONFLICT(conversation_id) DO UPDATE SET
            summary = EXCLUDED.summary,
            covered_message_count = EXCLUDED.covered_message_count,
            updated_at = NOW()
        """, conversation_id, summary, covered_count)
```

#### Step 3: é›†æˆåˆ° ChatHandler
```python
# åœ¨ chat_handler.py ä¸­ä¿®æ”¹ _get_context æ–¹æ³•
async def _get_context(self, conversation_id: str) -> dict:
    # 1. åˆ¤æ–­æ˜¯å¦éœ€è¦ç”Ÿæˆæ‘˜è¦
    messages_count = await self._conversation_store.count_messages(conversation_id)
    existing_summary = await self._conversation_store.get_summary(conversation_id)

    summary = None
    if messages_count >= 10:
        if existing_summary is None or (messages_count - existing_summary["covered_message_count"]) >= 5:
            # ç”Ÿæˆæ–°æ‘˜è¦
            all_messages = await self._conversation_store.list_messages(
                conversation_id, limit=None  # è·å–æ‰€æœ‰æ¶ˆæ¯
            )
            to_summarize = all_messages[:-6]  # ä¿ç•™æœ€å 6 æ¡

            if to_summarize:
                try:
                    summary_text = await self._generate_summary(to_summarize)
                    await self._conversation_store.save_summary(
                        conversation_id,
                        summary_text,
                        len(to_summarize)
                    )
                    summary = summary_text
                except Exception as e:
                    logger.error(f"Failed to generate summary: {e}")
                    summary = existing_summary["summary"] if existing_summary else None
            else:
                summary = existing_summary["summary"] if existing_summary else None
        else:
            summary = existing_summary["summary"]

    # 2. è·å–æœ€è¿‘æ¶ˆæ¯
    recent = await self._conversation_store.list_messages(
        conversation_id=conversation_id,
        limit=6,
        desc=True
    )
    recent.reverse()

    return {
        "summary": summary,
        "recent_history": recent
    }

async def _generate_summary(self, messages: list[dict]) -> str:
    """ç”Ÿæˆå¯¹è¯æ‘˜è¦"""
    formatted = "\n".join([
        f"{msg['role'].upper()}: {msg['content']}"
        for msg in messages
    ])

    prompt = ChatPromptTemplate.from_messages([
        ("system", """ä½ æ˜¯ä¸€ä¸ªå¯¹è¯æ‘˜è¦ä¸“å®¶ã€‚è¯·å°†ä»¥ä¸‹å¯¹è¯å†å²å‹ç¼©ä¸º 2-3 å¥è¯çš„æ‘˜è¦ï¼Œçªå‡ºï¼š
1. ç”¨æˆ·çš„æ ¸å¿ƒè¯‰æ±‚å’Œåå¥½
2. å·²è®¨è®ºçš„å…³é”®è¯é¢˜
3. ä»»ä½•é‡è¦çš„èƒŒæ™¯ä¿¡æ¯

ä¿æŒç®€æ´ï¼Œé¿å…å†—ä½™ã€‚"""),
        ("user", formatted)
    ])

    response = await self.llm.ainvoke(prompt)
    return response.content
```

#### Step 4: æ›´æ–° Prompt æ„å»º
```python
# åœ¨ completion.py ä¸­æ›´æ–° build_prompt å‡½æ•°
def _build_general_prompt(
    system_message: str,
    memory_context: str | None = None,
    summary: str | None = None,
    history: list[dict] | None = None,
    question: str = ""
) -> ChatPromptTemplate:
    messages = [("system", system_message)]

    # æ·»åŠ è®°å¿†ä¸Šä¸‹æ–‡
    if memory_context:
        messages.append(("system", f"ã€ç”¨æˆ·é•¿æœŸè®°å¿†ã€‘\n{memory_context}"))

    # æ·»åŠ å¯¹è¯æ‘˜è¦ï¼ˆæ–°å¢ï¼‰
    if summary:
        messages.append(("system", f"ã€å¯¹è¯èƒŒæ™¯ã€‘\n{summary}"))

    # æ·»åŠ è¿‘æœŸå†å²
    if history:
        for msg in history:
            role = "assistant" if msg.get("role") == "assistant" else "human"
            messages.append((role, msg.get("content", "")))

    # å½“å‰é—®é¢˜
    messages.append(("human", question))

    return ChatPromptTemplate.from_messages(messages)
```

#### Step 5: æµ‹è¯•éªŒè¯
```python
# tests/test_summarization.py
import pytest

@pytest.mark.asyncio
async def test_summary_generation():
    """æµ‹è¯•æ‘˜è¦ç”Ÿæˆ"""
    # åˆ›å»ºæµ‹è¯•å¯¹è¯
    messages = [
        {"role": "user", "content": "æ¨èä¸€äº›ç§‘å¹»ç”µå½±"},
        {"role": "assistant", "content": "æˆ‘æ¨èã€Šæ˜Ÿé™…ç©¿è¶Šã€‹ã€ã€Šé»‘å®¢å¸å›½ã€‹..."},
        {"role": "user", "content": "è¿™äº›ç”µå½±æœ‰ä»€ä¹ˆå…±åŒç‚¹ï¼Ÿ"},
        {"role": "assistant", "content": "å®ƒä»¬éƒ½æ¶‰åŠ..."}
    ]

    store = ConversationStore()
    summary = await store._summarizer.generate_summary(messages)

    assert len(summary) > 0
    assert len(summary.split()) < 50  # æ‘˜è¦åº”è¯¥ç®€æ´
    assert "ç§‘å¹»" in summary or "ç”µå½±" in summary

@pytest.mark.asyncio
async def test_summary_caching():
    """æµ‹è¯•æ‘˜è¦ç¼“å­˜"""
    conv_id = "test-conv-123"

    # é¦–æ¬¡ç”Ÿæˆ
    summary1 = await store.get_summary(conv_id)
    assert summary1 is None

    # ä¿å­˜æ‘˜è¦
    await store.save_summary(conv_id, "è¿™æ˜¯æ‘˜è¦", 10)

    # ç¬¬äºŒæ¬¡åº”è¯¥ä»ç¼“å­˜è¯»å–
    summary2 = await store.get_summary(conv_id)
    assert summary2 is not None
    assert summary2["summary"] == "è¿™æ˜¯æ‘˜è¦"
```

### 3.2 Phase 2 è¯¦ç»†å®æ–½æ­¥éª¤

#### Step 1: å‘é‡ç´¢å¼•å»ºç«‹
```python
# åœ¨ episodic_memory.py ä¸­å®ç°
from milvus import Collection, Milvus

class EpisodicMemoryManager:
    def __init__(self, milvus_host: str, embedding_model):
        self.client = Milvus(host=milvus_host)
        self.embedding_model = embedding_model

    async def init_collection(self):
        """åˆå§‹åŒ– Milvus Collection"""
        collection_name = "conversation_episodes"

        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        existing = self.client.has_collection(collection_name)
        if not existing:
            fields = [
                FieldSchema(name="id", dtype=DataType.VARCHAR, is_primary=True, max_length=100),
                FieldSchema(name="conversation_id", dtype=DataType.VARCHAR, max_length=100),
                FieldSchema(name="user_message", dtype=DataType.VARCHAR, max_length=4096),
                FieldSchema(name="assistant_message", dtype=DataType.VARCHAR, max_length=4096),
                FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=1536),
                FieldSchema(name="created_at", dtype=DataType.INT64),
                FieldSchema(name="timestamp", dtype=DataType.INT64),
            ]

            schema = CollectionSchema(fields, primary_field="id")
            self.collection = Collection(
                name=collection_name,
                schema=schema
            )

            # åˆ›å»ºç´¢å¼•ä»¥åŠ é€Ÿæœç´¢
            self.collection.create_index(
                field_name="embedding",
                index_params={
                    "metric_type": "COSINE",
                    "index_type": "IVF_FLAT",
                    "params": {"nlist": 128}
                }
            )

    async def index_episode(self, conversation_id: str, user_msg: str, assistant_msg: str):
        """ç´¢å¼•ä¸€ä¸ªå¯¹è¯ç‰‡æ®µ"""
        try:
            # ç”ŸæˆåµŒå…¥
            combined_text = f"{user_msg} {assistant_msg}"
            embedding = await self.embedding_model.embed_query(combined_text)

            # æ’å…¥åˆ°å‘é‡åº“
            from uuid import uuid4
            import time

            self.collection.insert([{
                "id": str(uuid4()),
                "conversation_id": conversation_id,
                "user_message": user_msg,
                "assistant_message": assistant_msg,
                "embedding": embedding,
                "created_at": int(time.time()),
                "timestamp": int(time.time() * 1000)
            }])

            logger.info(f"Indexed episode for conversation {conversation_id}")
        except Exception as e:
            logger.error(f"Failed to index episode: {e}")
            # ä¸é˜»å¡ä¸»æµç¨‹

    async def recall_relevant(self, conversation_id: str, query: str, top_k: int = 3):
        """å¬å›ç›¸å…³çš„å†å²ç‰‡æ®µ"""
        try:
            # ç”ŸæˆæŸ¥è¯¢åµŒå…¥
            query_embedding = await self.embedding_model.embed_query(query)

            # å‘é‡æœç´¢ï¼ˆé™åˆ¶åœ¨å½“å‰å¯¹è¯ï¼‰
            results = self.collection.search(
                data=[query_embedding],
                anns_field="embedding",
                param={"metric_type": "COSINE", "params": {"nprobe": 10}},
                limit=top_k * 2,  # è·å–æ›´å¤šï¼Œåç»­è¿‡æ»¤
                expr=f"conversation_id == '{conversation_id}'"
            )

            # æ ¼å¼åŒ–ç»“æœ
            episodes = []
            for hit in results[0]:
                # hit åŒ…å« id, distance, entity
                entity = hit.entity
                episodes.append({
                    "user_message": entity.get("user_message"),
                    "assistant_message": entity.get("assistant_message"),
                    "similarity": 1 - hit.distance,  # COSINE è·ç¦»è½¬ç›¸ä¼¼åº¦
                    "timestamp": entity.get("created_at")
                })

            # æŒ‰ç›¸ä¼¼åº¦é™åºæ’åˆ—ï¼Œå– Top K
            episodes.sort(key=lambda x: x["similarity"], reverse=True)
            return episodes[:top_k]
        except Exception as e:
            logger.error(f"Failed to recall episodes: {e}")
            return []
```

#### Step 2: é›†æˆåˆ° ChatHandler
```python
# åœ¨ chat_handler.py ä¸­ä¿®æ”¹ _get_hybrid_history æ–¹æ³•
async def _get_hybrid_history(
    self,
    conversation_id: str,
    current_query: str
) -> list[dict]:
    """æ··åˆæ£€ç´¢ï¼šæ—¶é—´çª—å£ + è¯­ä¹‰çª—å£"""

    # 1. æ—¶é—´çª—å£ï¼šæœ€è¿‘ 6 æ¡æ¶ˆæ¯
    recent = await self._conversation_store.list_messages(
        conversation_id=conversation_id,
        limit=6,
        desc=True
    )
    recent.reverse()

    # 2. è¯­ä¹‰çª—å£ï¼šç›¸å…³çš„å†å²ç‰‡æ®µ
    try:
        relevant = await self._episodic_memory.recall_relevant(
            conversation_id=conversation_id,
            query=current_query,
            top_k=3
        )
    except Exception as e:
        logger.warning(f"Semantic recall failed: {e}, using time-based only")
        relevant = []

    # 3. åˆå¹¶å»é‡
    seen_content = {msg["content"] for msg in recent}
    unique_relevant = []
    for ep in relevant:
        combined = f"{ep.get('user_message', '')} {ep.get('assistant_message', '')}"
        if combined not in seen_content:
            unique_relevant.append({
                "role": "context",
                "content": combined,
                "type": "semantic_recall",
                "similarity": ep.get("similarity", 0)
            })

    # 4. æ’åºï¼šæŒ‰ç›¸ä¼¼åº¦é™åºï¼Œç„¶åæ˜¯æœ€è¿‘æ¶ˆæ¯
    unique_relevant.sort(key=lambda x: x.get("similarity", 0), reverse=True)

    return unique_relevant[:2] + recent  # æœ€å¤š2æ¡è¯­ä¹‰ç‰‡æ®µ + æœ€è¿‘æ¶ˆæ¯
```

#### Step 3: å¼‚æ­¥ç´¢å¼•ï¼ˆé¿å…é˜»å¡ï¼‰
```python
# åœ¨ chat_handler.py çš„ handle æ–¹æ³•ä¸­
async def handle(self, message: str, conversation_id: str, **kwargs):
    # ... ä¸»æµç¨‹ ...
    response = await self.generate_response(message, context)

    # å¼‚æ­¥ç´¢å¼•æ–°å¯¹è¯ç‰‡æ®µï¼ˆä¸é˜»å¡å“åº”ï¼‰
    asyncio.create_task(
        self._episodic_memory.index_episode(
            conversation_id=conversation_id,
            user_msg=message,
            assistant_msg=response
        )
    )

    return response
```

### 3.3 Phase 3 å®æ–½ç­–ç•¥

#### Feature Flag ç°åº¦
```python
# åœ¨ config.py ä¸­
LANGGRAPH_ENABLED = os.getenv("LANGGRAPH_ENABLED", "false").lower() == "true"

# åœ¨ chat_handler.py ä¸­
if LANGGRAPH_ENABLED:
    executor = LangGraphChatExecutor()
else:
    executor = LegacyChatExecutor()
```

#### å…¼å®¹æ€§å±‚
```python
# åˆ›å»ºé€‚é…å±‚ï¼Œé¿å…ä¸€æ¬¡æ€§é‡æ„æ‰€æœ‰è°ƒç”¨
class ChatExecutorAdapter:
    def __init__(self, use_langgraph: bool):
        if use_langgraph:
            self._executor = LangGraphChatExecutor()
        else:
            self._executor = LegacyChatExecutor()

    async def execute(self, message: str, **context) -> str:
        """ç»Ÿä¸€æ¥å£"""
        return await self._executor.execute(message, **context)
```

---

## 4. ä¼˜åŒ–å»ºè®®

### 4.1 æ€§èƒ½ä¼˜åŒ–

#### æ‘˜è¦ç”Ÿæˆä¼˜åŒ–
```python
# 1. ä½¿ç”¨é¡¹ç›®å†…ç½®çš„ Qwen æ¨¡å‹ç”Ÿæˆæ‘˜è¦ï¼ˆé™ä½æˆæœ¬å’Œå»¶è¿Ÿï¼‰
# é€šè¿‡æ¨¡å‹å·¥å‚è·å–ï¼Œæ”¯æŒé…ç½®åŒ–åˆ‡æ¢
class ConversationSummarizer:
    def __init__(self, model_factory, model_name: str = "qwen-turbo"):
        self.llm = model_factory.get_model(model_name)

    # 2. ç¼“å­˜å®Œå…¨ç›¸åŒçš„å¯¹è¯æ‘˜è¦è¯·æ±‚
    @lru_cache(maxsize=1000)
    async def generate_summary(self, text_hash: str) -> str:
        # å…ˆè®¡ç®—æ–‡æœ¬å“ˆå¸Œï¼Œé¿å…é‡å¤ç”Ÿæˆ
        pass

# 3. åå°å¼‚æ­¥ç”Ÿæˆï¼Œä¸é˜»å¡ç”¨æˆ·å“åº”
asyncio.create_task(self._generate_summary_async(conv_id))
```

#### å‘é‡æœç´¢ä¼˜åŒ–
```python
# 1. é™åˆ¶æœç´¢èŒƒå›´ï¼ˆæŒ‰æ—¶é—´æˆ³ï¼‰
# åªæœç´¢æœ€è¿‘ 30 å¤©çš„å¯¹è¯ç‰‡æ®µ
recent_timestamp = int((time.time() - 30 * 86400) * 1000)
expr = f"conversation_id == '{conv_id}' AND timestamp > {recent_timestamp}"

# 2. è°ƒæ•´å‘é‡ç´¢å¼•å‚æ•°ä»¥å¹³è¡¡ç²¾åº¦å’Œé€Ÿåº¦
index_params = {
    "metric_type": "COSINE",
    "index_type": "IVF_FLAT",
    "params": {"nlist": 128}  # å¢åŠ  nlist æé«˜ç²¾åº¦ï¼Œé™ä½ nlist æé«˜é€Ÿåº¦
}

# 3. æ‰¹é‡ç´¢å¼•ï¼ˆå‡å°‘ç½‘ç»œå¼€é”€ï¼‰
async def batch_index_episodes(self, episodes: list[dict]):
    embeddings = await self.embedding_model.embed_multiple(
        [f"{e['user']} {e['assistant']}" for e in episodes]
    )
    self.collection.insert([{
        "id": ep["id"],
        "conversation_id": ep["conversation_id"],
        "embedding": emb,
        ...
    } for ep, emb in zip(episodes, embeddings)])
```

### 4.2 å¯é æ€§ä¿è¯

#### é™çº§ç­–ç•¥
```python
# å½“æ‘˜è¦ç”Ÿæˆå¤±è´¥æ—¶
async def get_or_generate_summary(self, conversation_id: str) -> str | None:
    try:
        existing = await self._store.get_summary(conversation_id)
        if existing:
            return existing["summary"]

        # å°è¯•ç”Ÿæˆæ–°æ‘˜è¦
        return await self._generate_summary(conversation_id)
    except Exception as e:
        logger.error(f"Summary generation failed: {e}")
        # é™çº§ï¼šè¿”å› Noneï¼Œå‰ç«¯ä½¿ç”¨æ—¶é—´çª—å£å³å¯
        return None

# å½“å‘é‡æœç´¢å¤±è´¥æ—¶
async def recall_relevant(self, conversation_id: str, query: str, top_k: int = 3):
    try:
        return await self._search_vector(conversation_id, query, top_k)
    except Exception as e:
        logger.warning(f"Vector search failed: {e}, falling back to time-based")
        # é™çº§ï¼šè¿”å›æ—¶é—´åºåˆ—çš„æœ€å K æ¡
        return await self._store.list_messages(conversation_id, limit=top_k)
```

#### ç›‘æ§å’Œå‘Šè­¦
```python
# åœ¨å…³é”®ç‚¹æ·»åŠ ç›‘æ§
from prometheus_client import Counter, Histogram

summary_generation_time = Histogram('summary_generation_seconds', 'Time to generate summary')
summary_generation_errors = Counter('summary_generation_errors_total', 'Total summary generation errors')
vector_search_time = Histogram('vector_search_seconds', 'Time to search vectors')

@summary_generation_time.time()
async def generate_summary(self, messages):
    try:
        return await self.llm.ainvoke(...)
    except Exception as e:
        summary_generation_errors.inc()
        raise
```

### 4.3 æµ‹è¯•ç­–ç•¥

#### å•å…ƒæµ‹è¯•
```python
# tests/test_conversation_flow.py
@pytest.mark.asyncio
async def test_long_conversation_with_summary():
    """æµ‹è¯•é•¿å¯¹è¯ä¸­çš„æ‘˜è¦ç”Ÿæˆå’Œæ£€ç´¢"""
    handler = ChatHandler(store, summarizer, embedding_model)

    # ç”Ÿæˆ 15 æ¡æ¶ˆæ¯ï¼ˆè¶…è¿‡æ‘˜è¦é˜ˆå€¼ï¼‰
    for i in range(15):
        context = await handler._get_context("conv-1")
        assert context is not None

        if i > 10:
            # åº”è¯¥æœ‰æ‘˜è¦
            assert context.get("summary") is not None

@pytest.mark.asyncio
async def test_semantic_recall_accuracy():
    """æµ‹è¯•è¯­ä¹‰å¬å›çš„å‡†ç¡®æ€§"""
    # æ’å…¥ç›¸å…³å’Œä¸ç›¸å…³çš„å¯¹è¯ç‰‡æ®µ
    await memory.index_episode("conv-1", "æ¨èç§‘å¹»ç”µå½±", "æ¨èäº†ã€Šæ˜Ÿé™…ç©¿è¶Šã€‹")
    await memory.index_episode("conv-1", "ä»Šå¤©å¤©æ°”", "æ™´å¤©")

    # æœç´¢ç§‘å¹»ç›¸å…³
    results = await memory.recall_relevant("conv-1", "æœ‰ä»€ä¹ˆå¥½çš„ç§‘å¹»ç”µå½±")

    # åº”è¯¥ä¼˜å…ˆè¿”å›ç§‘å¹»ç›¸å…³çš„ç‰‡æ®µ
    assert "æ˜Ÿé™…ç©¿è¶Š" in results[0]["assistant_message"]
```

#### æ€§èƒ½åŸºå‡†æµ‹è¯•
```python
# benchmarks/test_performance.py
import asyncio
import time

async def benchmark_context_retrieval():
    """åŸºå‡†æµ‹è¯•ä¸Šä¸‹æ–‡æ£€ç´¢æ€§èƒ½"""
    handler = ChatHandler(...)

    # æµ‹è¯• 100 æ¬¡æ£€ç´¢
    times = []
    for _ in range(100):
        start = time.time()
        await handler._get_context("conv-1")
        times.append(time.time() - start)

    avg_time = sum(times) / len(times)
    max_time = max(times)

    # åº”è¯¥ < 100ms
    assert avg_time < 0.1, f"Average retrieval time {avg_time}s exceeds 100ms"
    assert max_time < 0.5, f"Max retrieval time {max_time}s exceeds 500ms"
```

### 4.4 å¸¸è§é™·é˜±

| é™·é˜± | ç—‡çŠ¶ | è§£å†³æ–¹æ¡ˆ |
|------|------|--------|
| æ‘˜è¦è¿‡äºç®€æ´ | ä¸¢å¤±é‡è¦ä¿¡æ¯ | å¢åŠ æ‘˜è¦å­—æ•°é™åˆ¶æˆ–æ£€æŸ¥æç¤ºè¯ |
| å‘é‡æœç´¢å‡†ç¡®ç‡ä½ | æ£€ç´¢åˆ°æ— å…³å¯¹è¯ | è°ƒæ•´ç›¸ä¼¼åº¦é˜ˆå€¼æˆ–æ”¹è¿›åµŒå…¥æ¨¡å‹ |
| ç´¢å¼•å †ç§¯ | å†…å­˜å ç”¨é«˜ | å®šæœŸæ¸…ç†æ—§å¯¹è¯çš„ç´¢å¼• |
| å¹¶å‘ç´¢å¼•å†²çª | æ•°æ®ä¸¢å¤±æˆ–é‡å¤ | ä½¿ç”¨åˆ†å¸ƒå¼é”ï¼ˆRedisï¼‰ä¿è¯ä¸€è‡´æ€§ |

---

## 5. é™„å½•

### 5.1 æˆæœ¬å¯¹æ¯”ï¼ˆè¯¦ç»†ä¼°ç®—ï¼‰

**å‡è®¾**ï¼š1000 æ¬¡å¯¹è¯/å¤©ï¼Œå¹³å‡æ¯å¯¹è¯ 20 è½®

| æ–¹æ¡ˆ | Token æ¶ˆè€— | API è°ƒç”¨æ•° | ä¼°è®¡æˆæœ¬ | èŠ‚çœå¯¹æ¯” |
|------|-----------|-----------|--------|---------|
| Baseline | 120M/æœˆ | 20K/å¤© | $3600/æœˆ | åŸºå‡† |
| + Phase 1 (æ‘˜è¦) | 40M/æœˆ | 20K/å¤© + 200 (æ‘˜è¦) | $1200/æœˆ | 67% â†“ |
| + Phase 2 (è¯­ä¹‰) | 35M/æœˆ | 20K/å¤© + 100 (æœç´¢) | $1050/æœˆ | 71% â†“ |
| + Phase 3 (æ¶æ„) | 32M/æœˆ | 20K/å¤© | $960/æœˆ | 73% â†“ |

### 5.2 æŠ€æœ¯æ ˆæ¸…å•

| é˜¶æ®µ | æ ¸å¿ƒä¾èµ– | å¯é€‰ä¼˜åŒ– |
|------|---------|---------|
| Phase 1 | LangChain, PostgreSQL | Redis (ç¼“å­˜æ‘˜è¦) |
| Phase 2 | Milvus, OpenAI Embedding | Qdrant (å‘é‡åº“æ›¿ä»£) |
| Phase 3 | LangGraph, asyncio | Weights & Biases (ç›‘æ§) |

### 5.3 è¿ç§»å…¼å®¹æ€§

âœ… **Phase 1 â†’ Phase 2**: å®Œå…¨å…¼å®¹ï¼Œæ‘˜è¦å’Œè¯­ä¹‰å¬å›ç‹¬ç«‹å­˜åœ¨
âœ… **Phase 1/2 â†’ Phase 3**: éœ€è¦é€‚é…å±‚ï¼Œä½†å¯é€šè¿‡ Feature Flag ç°åº¦
âš ï¸ **åŒæ—¶è¿è¡Œ**: Phase 1 å’Œ Phase 2 å¯åŒæ—¶éƒ¨ç½²ï¼Œä½†éœ€ç›‘æ§æˆæœ¬

### 5.4 æˆåŠŸåº¦é‡æŒ‡æ ‡

éƒ¨ç½²ååº”è·Ÿè¸ªä»¥ä¸‹æŒ‡æ ‡ï¼š

| æŒ‡æ ‡ | ç›®æ ‡ | æµ‹é‡æ–¹æ³• |
|------|------|---------|
| Token æ¶ˆè€— | é™ä½ 60%+ | å¯¹æ¯”éƒ¨ç½²å‰å |
| å“åº”å»¶è¿Ÿ | < 500ms | P95 å»¶è¿Ÿ |
| ç”¨æˆ·æ»¡æ„åº¦ | +15% | é—®å·/è¯„åˆ† |
| æ‘˜è¦å‡†ç¡®åº¦ | 90%+ | æ‰‹å·¥å®¡æ ¸ |
| å‘é‡å¬å›ç‡ | 85%+ | æµ‹è¯•é›†è¯„ä¼° |

### 5.5 æ•…éšœæ¢å¤

#### æ‘˜è¦ç”Ÿæˆå¤±è´¥
```python
# è‡ªåŠ¨é™çº§åˆ°æ—¶é—´çª—å£
try:
    summary = await summarizer.generate(conv_id)
except Exception as e:
    logger.warning(f"Summary generation failed: {e}")
    summary = None  # ä½¿ç”¨ Noneï¼Œå‰ç«¯æ­£å¸¸å¤„ç†
```

#### å‘é‡ç´¢å¼•å¤±è´¥
```python
# å¼‚æ­¥åå°é‡è¯•æœºåˆ¶
async def index_with_retry(self, episode, max_retries=3):
    for attempt in range(max_retries):
        try:
            await self.collection.insert([episode])
            return
        except Exception as e:
            if attempt < max_retries - 1:
                await asyncio.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
            else:
                logger.error(f"Failed to index after {max_retries} attempts: {e}")
```
