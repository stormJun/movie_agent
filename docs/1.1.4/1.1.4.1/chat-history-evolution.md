# å¯¹è¯å†å²ç®¡ç†æ¼”è¿›æ–¹æ¡ˆè®¾è®¡

**ç‰ˆæœ¬**: 1.1.4.1
**çŠ¶æ€**: âœ… **å·²å®ç°** (Phase 1-3 å…¨éƒ¨å®Œæˆ)
**ä½œè€…**: AI Assistant
**æ—¥æœŸ**: 2026-01-23
**æœ€åæ›´æ–°**: 2026-01-25 (æ ¹æ®ä»£ç å®ç°åŒæ­¥)

---

## å®ç°çŠ¶æ€æ€»è§ˆ

| é˜¶æ®µ | åŠŸèƒ½ | çŠ¶æ€ | æ ¸å¿ƒæ–‡ä»¶ |
|------|------|------|---------|
| **Phase 1** | å¯¹è¯æ‘˜è¦ä¸å‹ç¼© | âœ… å·²å®ç° | `backend/infrastructure/chat_history/summarizer.py`<br/>`backend/infrastructure/persistence/postgres/conversation_summary_store.py` |
| **Phase 2** | è¯­ä¹‰æƒ…èŠ‚è®°å¿† | âœ… å·²å®ç° | `backend/infrastructure/chat_history/episodic_memory.py`<br/>`backend/infrastructure/persistence/postgres/conversation_episode_store.py` |
| **Phase 3** | LangGraph çŠ¶æ€æœº | âœ… å·²å®ç° | `backend/application/chat/conversation_graph.py`<br/>`backend/server/api/rest/v1/chat_stream.py` |

**å…³é”®å®ç°ç‰¹æ€§**ï¼š
- âœ… **å¤åˆæ¸¸æ ‡åˆ†é¡µ**ï¼šä½¿ç”¨ `(created_at, message_id)` ç¡®ä¿å¹‚ç­‰åˆ‡ç‰‡
- âœ… **Completed å­—æ®µ**ï¼šè¿‡æ»¤æµå¼ä¸­æ–­çš„æœªå®Œæˆæ¶ˆæ¯
- âœ… **åå°ä»»åŠ¡ç®¡ç†**ï¼š`SummaryTaskManager` / `EpisodicTaskManager` å¼‚æ­¥å¤„ç†
- âœ… **LangGraph é›†æˆ**ï¼š`ConversationGraphRunner` ä¸‰èŠ‚ç‚¹æ¶æ„ (route â†’ recall â†’ execute)
- âœ… **Debug å¯è§‚æµ‹æ€§**ï¼šæ‰§è¡Œæ—¥å¿— + StreamWriter æ”¯æŒ

---

## 1. èƒŒæ™¯ä¸åŠ¨æœº

### 1.1 å½“å‰å®ç°ï¼ˆBaselineï¼‰

åœ¨ v1.1.4 ä¸­ï¼Œæˆ‘ä»¬å®ç°äº†åŸºç¡€çš„å¯¹è¯å†å²æ³¨å…¥æœºåˆ¶ï¼š

```python
# å½“å‰æµç¨‹
history = await conversation_store.list_messages(limit=6, desc=True)
history.reverse()  # æ—¶é—´æ­£åº
prompt = build_prompt(system + history + current_message)
```

**ä¼˜ç‚¹**ï¼š
- âœ… ç®€å•ç›´æ¥ï¼Œæ˜“äºç†è§£å’Œç»´æŠ¤
- âœ… è§£å†³äº†åŸºæœ¬çš„ä¸Šä¸‹æ–‡ä¸¢å¤±é—®é¢˜
- âœ… å¯¹çŸ­ä¼šè¯ï¼ˆ< 10 è½®ï¼‰æ•ˆæœè‰¯å¥½

**å±€é™æ€§**ï¼š
- âŒ **å›ºå®šçª—å£ç›²åŒº**ï¼šè¶…å‡º N æ¡çš„å†å²è¢«é—å¿˜ï¼ˆå¦‚ç”¨æˆ·åœ¨ç¬¬ 1 è½®æåˆ°çš„é‡è¦ä¿¡æ¯ï¼‰
- âŒ **Token æµªè´¹**ï¼šæ¯æ¬¡éƒ½ä¼ é€’å®Œæ•´çš„å†å²æ¶ˆæ¯ï¼Œå³ä½¿å†…å®¹é‡å¤æˆ–æ— å…³
- âŒ **æ—¶é—´åè§**ï¼šåªæŒ‰æ—¶é—´åˆ‡ç‰‡ï¼Œä¸è€ƒè™‘è¯­ä¹‰ç›¸å…³æ€§ï¼ˆç”¨æˆ·å¯èƒ½è·³å›ä¹‹å‰çš„è¯é¢˜ï¼‰
- âŒ **æ‰©å±•æ€§å·®**ï¼šéšç€å¯¹è¯å˜é•¿ï¼Œæˆæœ¬çº¿æ€§å¢é•¿

### 1.2 æ¼”è¿›ç›®æ ‡

æ„å»ºä¸€ä¸ª**å¯æ‰©å±•ã€é«˜æ•ˆã€æ™ºèƒ½**çš„å¯¹è¯è®°å¿†ç³»ç»Ÿï¼Œæ”¯æŒï¼š
1. **é•¿æœŸä¸Šä¸‹æ–‡ä¿ç•™**ï¼šå³ä½¿å¯¹è¯è¶…è¿‡ 100 è½®ï¼Œå…³é”®ä¿¡æ¯ä¸ä¸¢å¤±
2. **æˆæœ¬ä¼˜åŒ–**ï¼šé™ä½ Token æ¶ˆè€—ï¼Œæå‡å“åº”é€Ÿåº¦
3. **è¯­ä¹‰æ„ŸçŸ¥**ï¼šæ ¹æ®ç›¸å…³æ€§è€Œéæ—¶é—´æ£€ç´¢å†å²
4. **æ¶æ„å¥å£®æ€§**ï¼šå‡å°‘æ‰‹åŠ¨å‚æ•°ä¼ é€’ï¼Œé™ä½ç»´æŠ¤æˆæœ¬

---

## 2. ä¸‰é˜¶æ®µæ¼”è¿›æ–¹æ¡ˆ

> **ğŸ“Œ å®ç°è¯´æ˜**ï¼šä»¥ä¸‹ä¸‰ä¸ªé˜¶æ®µå‡å·²å®ç°ã€‚è®¾è®¡æ–‡æ¡£ä¿ç•™äº†å®Œæ•´çš„è®¾è®¡æ€è·¯å’Œå†³ç­–è¿‡ç¨‹ï¼Œä½†å®é™…ä»£ç å®ç°å¯èƒ½åœ¨ç»†èŠ‚ä¸Šæœ‰æ‰€ä¼˜åŒ–è°ƒæ•´ã€‚
> æ¯ä¸ªé˜¶æ®µçš„å®ç°è¦ç‚¹ä¸è®¾è®¡æ–‡æ¡£çš„å·®å¼‚è¯¦è§å„é˜¶æ®µçš„"å®ç°å·®å¼‚"å°èŠ‚ã€‚

---

### Phase 1: è®°å¿†å‹ç¼©ä¸æ‘˜è¦ (Memory Summarization) âœ… å·²å®ç°

#### 2.1.1 æ ¸å¿ƒè®¾è®¡ç†å¿µ

é‡‡ç”¨ **æ»‘åŠ¨çª—å£ + å†å²æ‘˜è¦** ç­–ç•¥ï¼Œé€šè¿‡å¯¹è¯å†å²çš„åˆ†å±‚å‹ç¼©æ¥è§£å†³é•¿å¯¹è¯çš„ Token æµªè´¹å’Œä¸Šä¸‹æ–‡ä¸¢å¤±é—®é¢˜ã€‚

**æ ¸å¿ƒæ€æƒ³ï¼š**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æœ€ç»ˆ Prompt ç»“æ„                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [System Prompt]                         â”‚
â”‚  [å¯¹è¯èƒŒæ™¯æ‘˜è¦]: å‹ç¼©çš„å…¨å±€ä¸Šä¸‹æ–‡         â”‚
â”‚  [æœ€è¿‘çª—å£]: æœ€è¿‘ 6 æ¡åŸå§‹å¯¹è¯ï¼ˆä¿æŒç»†èŠ‚ï¼‰ â”‚
â”‚  [å½“å‰æ¶ˆæ¯]                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ä¿¡æ¯å±‚çº§ï¼š**
- **æ‘˜è¦å±‚ï¼ˆé•¿æœŸè®°å¿†ï¼‰**ï¼šä¿ç•™å…¨å±€èƒŒæ™¯ã€ç”¨æˆ·åå¥½ã€å…³é”®å†³ç­–
  - ç¤ºä¾‹ï¼š"ç”¨æˆ·è®¨è®ºäº†90å¹´ä»£ç§‘å¹»ç”µå½±ï¼Œç‰¹åˆ«å…³æ³¨è¯ºå…°å¯¼æ¼”ä½œå“ï¼Œä¸å–œæ¬¢ææ€–ç‰‡"
- **çª—å£å±‚ï¼ˆçŸ­æœŸè®°å¿†ï¼‰**ï¼šä¿ç•™æœ€è¿‘å¯¹è¯çš„å®Œæ•´ç»†èŠ‚
  - åŒ…å«æœ€è¿‘ 3 è½®å¯¹è¯ï¼ˆ6 æ¡æ¶ˆæ¯ï¼‰
  - ç¡®ä¿å½“å‰è¯é¢˜çš„ä¸Šä¸‹æ–‡è¿ç»­æ€§

**æŠ€æœ¯æŒ‘æˆ˜ä¸è®¾è®¡è€ƒé‡**

åœ¨å®ç°åˆ†å±‚è®°å¿†æ¶æ„æ—¶ï¼Œéœ€è¦è§£å†³å››ä¸ªæ ¸å¿ƒæŠ€æœ¯æŒ‘æˆ˜ï¼Œä»¥ç¡®ä¿ç³»ç»Ÿçš„å¯é æ€§å’Œæ€§èƒ½ï¼š

1. **UUID æ¸¸æ ‡åˆ†é¡µ**ï¼šç”±äºä½¿ç”¨ UUID v4 ä½œä¸ºæ¶ˆæ¯ä¸»é”®ï¼Œä¸èƒ½ç®€å•åœ°ä½¿ç”¨ `WHERE id > last_id` è¿›è¡Œåˆ†é¡µï¼ˆä¼šæ¼æ¶ˆæ¯ã€ä¹±åºã€ä¸å¹‚ç­‰ï¼‰ã€‚è§£å†³æ–¹æ¡ˆæ˜¯é‡‡ç”¨å¤åˆæ¸¸æ ‡ `(created_at, id)`ï¼Œé€šè¿‡æ—¶é—´æˆ³ä½œä¸ºä¸»åºã€UUID ä½œä¸º tie-breakï¼Œå®ç°ç²¾å‡†ä¸”å¹‚ç­‰çš„åˆ‡ç‰‡ã€‚

2. **æ¶ˆæ¯å»é‡ç­–ç•¥**ï¼šä¸ºäº†é¿å…å½“å‰æ¶ˆæ¯è¢«é‡å¤å¤„ç†ï¼Œéœ€è¦æ˜ç¡®è¯†åˆ«å¹¶æ’é™¤ã€‚æ¨èåšæ³•æ˜¯åœ¨ Handler å±‚æ¥ä½ `append_message()` è¿”å›çš„ UUIDï¼Œåœ¨åç»­æµç¨‹ä¸­ä½¿ç”¨ ID è€Œéå†…å®¹è¿›è¡Œè¿‡æ»¤ï¼Œé¿å…é‡å¤å†…å®¹å¯¼è‡´çš„è¯¯åˆ¤ã€‚

3. **æµå¼ä¸­æ–­å¤„ç†**ï¼šåœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œæµå¼å“åº”å¯èƒ½å› ç½‘ç»œè¶…æ—¶æˆ–å¼‚å¸¸è€Œä¸­æ–­ï¼Œå¯¼è‡´ä¸å®Œæ•´çš„ assistant æ¶ˆæ¯è½å…¥æ•°æ®åº“ã€‚ä¸ºé¿å…æ±¡æŸ“æ‘˜è¦å’Œå‘é‡ç´¢å¼•ï¼Œéœ€è¦å¼•å…¥ä¸ debug æ— å…³çš„ `completed` å­—æ®µï¼Œæ˜ç¡®æ ‡è®°æ¶ˆæ¯æ˜¯å¦å®Œæˆã€‚

4. **åå°ä»»åŠ¡æŒä¹…åŒ–**ï¼šæ‘˜è¦ç”Ÿæˆå’Œå‘é‡ç´¢å¼•æ˜¯è€—æ—¶æ“ä½œï¼Œä¸åº”é˜»å¡ç”¨æˆ·å“åº”ã€‚ç®€å•çš„ `background_tasks.add_task()` åœ¨æµå¼åœºæ™¯ä¸å¯é ï¼ˆè¯·æ±‚ç»“æŸä¼šä¸¢å¤±ä»»åŠ¡ï¼‰ï¼Œéœ€è¦å®ç°ç‹¬ç«‹çš„åå°ä»»åŠ¡ç®¡ç†å™¨ï¼Œä½¿ç”¨è¿›ç¨‹å†…é˜Ÿåˆ—æˆ–æ•°æ®åº“ job è¡¨ï¼Œç¡®ä¿ä»»åŠ¡ä¸ä¸¢å¤±ã€‚

è¿™äº›æŠ€æœ¯æŒ‘æˆ˜çš„è§£å†³æ–¹æ¡ˆå·²ç»åœ¨å®é™…ä»£ç ä¸­å®ç°ï¼Œè¯¦è§åç»­çš„"å®ç°å·®å¼‚"ç« èŠ‚ã€‚

#### 2.1.2 æ¶æ„ä¸æµç¨‹å¯è§†åŒ–

##### æ•°æ®æµæ¶æ„å›¾

**Phase 1 çš„æ•°æ®æµåŠ¨ä¸å­˜å‚¨ç»“æ„ï¼š**

```mermaid
flowchart TB
    subgraph Main["ä¸»æµç¨‹ï¼ˆåŒæ­¥ï¼‰- ç”¨æˆ·è¯·æ±‚å“åº”"]
        direction TB
        User[ç”¨æˆ·å‘é€æ¶ˆæ¯] --> Handler[StreamHandler.handle]
        Handler --> AppendUser[(append_message user<br/>è·å– current_user_message_id)]
        AppendUser --> Graph[ConversationGraph.astream_custom]

        subgraph GraphNodes["LangGraph çŠ¶æ€æœº"]
            Route[route èŠ‚ç‚¹<br/>å†³å®šæ˜¯å¦ä½¿ç”¨æ£€ç´¢]
            Recall[recall èŠ‚ç‚¹<br/>è·å–ä¸Šä¸‹æ–‡]
            Execute[execute èŠ‚ç‚¹<br/>æµå¼ç”Ÿæˆå“åº”]

            Route --> Recall
            Recall --> Execute
        end

        Graph --> StreamTokens[æµå¼è¿”å› tokens]
        StreamTokens --> Finally{finally å—}
        Finally --> AppendAssistant[(append_message assistant<br/>è·å– assistant_message_id)]
        AppendAssistant --> CheckComplete{{completed_normally?}}

        CheckComplete -->|True| Schedule[è§¦å‘åå°ä»»åŠ¡<br/>schedule_update + schedule_index]
        CheckComplete -->|False| End1[ç»“æŸ]
    end

    subgraph Background["åå°æµç¨‹ï¼ˆå¼‚æ­¥ï¼‰- æ‘˜è¦ç”Ÿæˆ"]
        direction TB
        Schedule --> TaskManager[SummaryTaskManager<br/>ä»»åŠ¡å»é‡ä¸è°ƒåº¦]
        TaskManager --> TriggerUpdate[ConversationSummarizer<br/>.try_trigger_update]

        TriggerUpdate --> CheckTotal{total_completed<br/>>= 10?}
        CheckTotal -->|å¦| Skip[è·³è¿‡æ›´æ–°]
        CheckTotal -->|æ˜¯| GetSummary[(è·å–ç°æœ‰æ‘˜è¦<br/>get_summary)]

        GetSummary --> CalcWindow[è®¡ç®—çª—å£èµ·å§‹<br/>list_recent_messages limit=6<br/>å–æœ€æ—§çš„ä¸€æ¡]
        CalcWindow --> FetchEligible[è·å– eligible messages<br/>list_messages_since<br/>covered â†’ window_start]

        FetchEligible --> CheckDelta{eligible<br/>>= 5?}
        CheckDelta -->|å¦| Skip
        CheckDelta -->|æ˜¯| GenLLM[LLM ç”Ÿæˆ/æ›´æ–°æ‘˜è¦<br/>ainvoke/async]

        GenLLM --> SaveSummary[(save_summary_upsert<br/>ä¹è§‚é” version)]
        SaveSummary --> End2[å®Œæˆ]
    end

    subgraph RecallFlow["Recall èŠ‚ç‚¹è¯¦ç»†æµç¨‹"]
        direction TB
        GetSummaryText[get_summary_text<br/>è·å–æ‘˜è¦]
        ListHistory[list_messages limit=8<br/>è·å–æœ€è¿‘æ¶ˆæ¯]
        FilterHistory[è¿‡æ»¤ completed=True<br/>æ’é™¤ current_user_message_id]

        GetSummaryText --> BuildCtx[æ„å»ºä¸Šä¸‹æ–‡]
        ListHistory --> FilterHistory
        FilterHistory --> BuildCtx
        BuildCtx --> Execute
    end

    subgraph Storage["PostgreSQL å­˜å‚¨å±‚"]
        Messages[(messages è¡¨<br/>id + role + content<br/>+ completed + created_at)]
        Summaries[(conversation_summaries è¡¨<br/>conversation_id + summary<br/>+ summary_version<br/>+ covered_through_*)]
    end

    AppendUser -.->|å†™å…¥| Messages
    AppendAssistant -.->|å†™å…¥| Messages
    GetSummaryText -.->|è¯»å–| Summaries
    SaveSummary -.->|æ›´æ–°| Summaries
    FetchEligible -.->|è¯»å–| Messages

    style Schedule fill:#fff4e6
    style TaskManager fill:#ffe6e6
    style GenLLM fill:#e6f3ff
    style SaveSummary fill:#e6ffe6
    style CheckComplete fill:#fffacd
    style CheckTotal fill:#fffacd
    style CheckDelta fill:#fffacd
```

##### ç³»ç»ŸçŠ¶æ€è½¬æ¢å›¾

**å¯¹è¯æ‘˜è¦çš„çŠ¶æ€æœºï¼š**

```mermaid
stateDiagram-v2
    [*] --> NoSummary: å¯¹è¯å¼€å§‹<br/>(total_completed < 10)

    NoSummary --> NoSummary: ç»§ç»­å¯¹è¯<br/>(completed_normally=True<br/>ä½†ä» < 10 æ¡)
    NoSummary --> GeneratingSummary: è§¦å‘æ¡ä»¶æ»¡è¶³<br/>(total_completed â‰¥ 10<br/>ä¸” completed_normally=True)

    GeneratingSummary --> HasSummary: æ‘˜è¦ç”ŸæˆæˆåŠŸ<br/>save_summary_upsert<br/>version=1
    GeneratingSummary --> NoSummary: ç”Ÿæˆå¤±è´¥<br/>(å¼‚å¸¸é™é»˜å¤„ç†)

    HasSummary --> CheckThreshold: completed_normally=True<br/>è§¦å‘ schedule_update

    CheckThreshold --> Cached: eligible < 5<br/>(æœªè¾¾åˆ°æ›´æ–°å¢é‡)
    CheckThreshold --> UpdatingSummary: eligible â‰¥ 5<br/>(è¾¾åˆ°æ›´æ–°å¢é‡)

    Cached --> HasSummary: å¤ç”¨ç°æœ‰æ‘˜è¦<br/>æ— éœ€é‡æ–°ç”Ÿæˆ
    Cached --> CheckThreshold: ä¸‹ä¸€æ¬¡ completed_normally

    UpdatingSummary --> HasSummary: æ›´æ–°æˆåŠŸ<br/>save_summary_upsert<br/>version++
    UpdatingSummary --> HasSummary: æ›´æ–°å¤±è´¥<br/>(ä¿ç•™æ—§æ‘˜è¦<br/>ä¹è§‚é”å†²çª)

    HasSummary --> [*]: å¯¹è¯ç»“æŸ
    NoSummary --> [*]: å¯¹è¯ç»“æŸ

    note right of NoSummary
        çŠ¶æ€ç‰¹å¾:
        - total_completed: 0-9
        - æ‘˜è¦è®°å½•: ä¸å­˜åœ¨
        - ä¸Šä¸‹æ–‡æ„å»º: history_window (æœ€è¿‘ 8 æ¡)
        - è¿‡æ»¤æ¡ä»¶: completed=True, æ’é™¤ current_user_message_id
    end note

    note right of HasSummary
        çŠ¶æ€ç‰¹å¾:
        - total_completed: â‰¥ 10
        - æ‘˜è¦è®°å½•: å­˜åœ¨
        - summary_version: å½“å‰ç‰ˆæœ¬å·
        - covered_through: å¤åˆæ¸¸æ ‡ (created_at, message_id)
        - covered_message_count: å·²æ‘˜è¦æ¶ˆæ¯æ•°
        - ä¸Šä¸‹æ–‡æ„å»º: summary + history_window
        - è¿‡æ»¤æ¡ä»¶: completed=True, æ’é™¤ current_user_message_id
    end note

    note right of UpdatingSummary
        æ›´æ–°é€»è¾‘:
        1. è·å–ç°æœ‰æ‘˜è¦ (expected_version)
        2. è®¡ç®—çª—å£èµ·å§‹ (æœ€è¿‘ 6 æ¡ä¸­æœ€æ—§)
        3. è·å– eligible messages
           (covered â†’ window_start)
        4. LLM åˆå¹¶: old_summary + eligible
        5. ä¹è§‚é”æ›´æ–° (version åŒ¹é…)
    end note
```

##### æ ¸å¿ƒæµç¨‹å›¾

**Phase 1 çš„å®Œæ•´å·¥ä½œæµç¨‹ï¼ˆæŒ‰å®Œæ•´ Turn è§¦å‘ï¼‰ï¼š**

```mermaid
flowchart TD
    subgraph MainFlow["ä¸»æµç¨‹ï¼ˆåŒæ­¥ï¼‰- ç”¨æˆ·è¯·æ±‚å“åº”"]
        Start([ç”¨æˆ·å‘é€æ¶ˆæ¯]) --> Handler[StreamHandler.handle]
        Handler --> AppendUser[(append_message user<br/>è·å– current_user_message_id)]
        AppendUser --> StreamGraph[ConversationGraph.astream_custom]

        StreamGraph --> RecallNode[recall èŠ‚ç‚¹]
        RecallNode --> GetSummary[(get_summary_text<br/>è·å–æ‘˜è¦)]
        RecallNode --> ListHistory[(list_messages limit=8<br/>è·å–æœ€è¿‘æ¶ˆæ¯)]
        ListHistory --> FilterHistory[è¿‡æ»¤ completed=True<br/>æ’é™¤ current_user_message_id]
        GetSummary --> BuildContext[æ„å»ºä¸Šä¸‹æ–‡<br/>summary + history]
        FilterHistory --> BuildContext

        BuildContext --> ExecuteNode[execute èŠ‚ç‚¹<br/>æµå¼ç”Ÿæˆå“åº”]
        ExecuteNode --> StreamTokens[æµå¼è¿”å› tokens ç»™ç”¨æˆ·]

        StreamTokens --> FinallyBlock{finally å—}
        FinallyBlock --> AppendAssistant[(append_message assistant<br/>è·å– assistant_message_id)]
        AppendAssistant --> CheckComplete{{completed_normally?}}

        CheckComplete -->|False| EndNoSum([ç»“æŸ<br/>ä¸è§¦å‘åå°ä»»åŠ¡])
        CheckComplete -->|True| TriggerTasks[è§¦å‘åå°ä»»åŠ¡<br/>schedule_update<br/>schedule_index_episode<br/>maybe_write]
        TriggerTasks --> EndMain([ä¸»æµç¨‹ç»“æŸ])
    end

    subgraph BackgroundFlow["åå°æµç¨‹ï¼ˆå¼‚æ­¥ï¼‰- æ‘˜è¦ç”Ÿæˆ"]
        TriggerTasks -.->|å¼‚æ­¥è°ƒç”¨| TaskManager[SummaryTaskManager<br/>ä»»åŠ¡å»é‡ä¸è°ƒåº¦]
        TaskManager --> TriggerUpdate[try_trigger_update]

        TriggerUpdate --> CheckTotal{count_completed_messages<br/>>>= 10?}
        CheckTotal -->|å¦| SkipUpdate[è·³è¿‡æ›´æ–°]
        CheckTotal -->|æ˜¯| FetchSummary[(get_summary<br/>è·å–ç°æœ‰æ‘˜è¦<br/>expected_version)]

        FetchSummary --> CalcWindow[è®¡ç®—çª—å£èµ·å§‹<br/>list_recent_messages limit=6<br/>å–æœ€æ—§çš„ä¸€æ¡ window_start]
        CalcWindow --> FetchEligible[è·å– eligible messages<br/>list_messages_since<br/>covered â†’ window_start<br/>ç¡¬ä¸Šé™ 200 æ¡]

        FetchEligible --> CheckDelta{eligible >= 5<br/>update_delta?}
        CheckDelta -->|å¦| SkipUpdate
        CheckDelta -->|æ˜¯| HasSummary{existing_summary<br/>ä¸ä¸ºç©º?}

        HasSummary -->|å¦| FirstSummary[é¦–æ¬¡ç”Ÿæˆæç¤ºè¯<br/>conversation â†’ summary]
        HasSummary -->|æ˜¯| IncrementalSummary[å¢é‡æ›´æ–°æç¤ºè¯<br/>old_summary + new_messages â†’ summary]

        FirstSummary --> LLMInvoke[LLM ç”Ÿæˆæ‘˜è¦<br/>ainvoke/async]
        IncrementalSummary --> LLMInvoke

        LLMInvoke --> CheckLength{summary <= 1200<br/>max_summary_chars?}
        CheckLength -->|å¦| Truncate[æˆªæ–­åˆ° 1200 å­—ç¬¦]
        CheckLength -->|æ˜¯| SaveSummary
        Truncate --> SaveSummary

        SaveSummary[(save_summary_upsert<br/>ä¹è§‚é”<br/>expected_version åŒ¹é…)]
        SaveSummary --> CheckSuccess{æ›´æ–°æˆåŠŸ?}
        CheckSuccess -->|æ˜¯| EndBackground([åå°ä»»åŠ¡å®Œæˆ])
        CheckSuccess -->|å¦| Conflict[ä¹è§‚é”å†²çª<br/>ä¿ç•™æ—§æ‘˜è¦]
        Conflict --> EndBackground
        SkipUpdate --> EndBackground
    end

    EndNoSum -.->|ç”¨æˆ·ç»§ç»­å¯¹è¯| Start
    EndMain -.->|ç”¨æˆ·ç»§ç»­å¯¹è¯| Start

    style GetSummary fill:#e6f3ff
    style FilterHistory fill:#e6f3ff
    style BuildContext fill:#e6f3ff
    style CheckComplete fill:#fffacd
    style CheckTotal fill:#fffacd
    style CheckDelta fill:#fffacd
    style CheckSuccess fill:#fffacd
    style LLMInvoke fill:#ffe6e6
    style SaveSummary fill:#e6ffe6
    style TaskManager fill:#fff4e6
```

**æ‘˜è¦ç”Ÿæˆå†³ç­–æ ‘ï¼ˆåå°å¼‚æ­¥æµç¨‹ï¼‰ï¼š**

```mermaid
graph TD
    A[SummaryTaskManager<br/>æ¥æ”¶ schedule_update è¯·æ±‚] --> B[ä»»åŠ¡å»é‡æ£€æŸ¥<br/>åŒä¸€ conversation_id]
    B --> C[è°ƒç”¨ try_trigger_update]

    C --> D{count_completed_messages<br/>>= min_messages 10?}
    D -->|å¦| E[è·³è¿‡æ›´æ–°<br/>è¿”å› False]
    D -->|æ˜¯| F[è·å–ç°æœ‰æ‘˜è¦<br/>get_summary]

    F --> G{æ‘˜è¦è®°å½•å­˜åœ¨?}
    G -->|å¦| H[existing_summary = ''<br/>expected_version = None<br/>covered_at/covered_id = None]
    G -->|æ˜¯| I[æå– summary_version<br/>covered_through_created_at<br/>covered_through_message_id]

    H --> J[è®¡ç®—çª—å£èµ·å§‹<br/>list_recent_messages limit=6<br/>å–æœ€æ—§ä¸€æ¡ window_start]
    I --> J

    J --> K[è·å– eligible messages<br/>list_messages_since<br/>cursor: covered_at/covered_id<br/>stop at: window_start<br/>ç¡¬ä¸Šé™: 200 æ¡]

    K --> L{eligible æ¶ˆæ¯æ•°<br/>>= update_delta 5?}
    L -->|å¦| E
    L -->|æ˜¯| M{existing_summary<br/>ä¸ä¸ºç©º?}

    M -->|å¦| N[é¦–æ¬¡ç”Ÿæˆæç¤ºè¯<br/>system: å¯¹è¯æ‘˜è¦å™¨<br/>human: conversation â†’ summary]
    M -->|æ˜¯| O[å¢é‡æ›´æ–°æç¤ºè¯<br/>system: åˆå¹¶æ‘˜è¦å™¨<br/>human: old_summary + new_messages]

    N --> P[è°ƒç”¨ LLM<br/>ainvoke/async<br/>å…¼å®¹åŒæ­¥æ¨¡å‹]
    O --> P

    P --> Q{ç”ŸæˆæˆåŠŸ?}
    Q -->|å¦| R[è®°å½•è­¦å‘Šæ—¥å¿—<br/>è¿”å›]
    Q -->|æ˜¯| S{summary é•¿åº¦<br/>> max_summary_chars 1200?}

    S -->|æ˜¯| T[æˆªæ–­åˆ° 1200 å­—ç¬¦]
    S -->|å¦| U[save_summary_upsert<br/>UPSERT æ“ä½œ<br/>æœŸæœ›ç‰ˆæœ¬: expected_version]

    T --> U

    U --> V{ä¹è§‚é”æ£€æŸ¥<br/>version åŒ¹é…?}
    V -->|å¦| W[æ›´æ–°å¤±è´¥<br/>ä¿ç•™æ—§æ‘˜è¦<br/>ä»»åŠ¡ç®¡ç†å™¨é‡è¯•]
    V -->|æ˜¯| X[æ›´æ–°æˆåŠŸ<br/>summary_version++<br/>covered_cursor = last_eligible<br/>è¿”å› True]

    style A fill:#fff4e6
    style D fill:#fffacd
    style L fill:#fffacd
    style M fill:#fffacd
    style Q fill:#fffacd
    style V fill:#fffacd
    style P fill:#ffe6e6
    style U fill:#e6ffe6
    style B fill:#e6f3ff
```

##### è¯·æ±‚å¤„ç†åºåˆ—å›¾

**ç”¨æˆ·è¯·æ±‚çš„å®Œæ•´å¤„ç†æµç¨‹ï¼ˆæŒ‰å®Œæ•´ Turn è§¦å‘ï¼‰ï¼š**

```mermaid
sequenceDiagram
    participant User as ç”¨æˆ·
    participant API as chat_stream API
    participant Handler as StreamHandler
    participant Graph as ConversationGraph
    participant Recall as recall èŠ‚ç‚¹
    participant Execute as execute èŠ‚ç‚¹
    participant Store as ConversationStore
    participant Summarizer as ConversationSummarizer
    participant TaskMgr as SummaryTaskManager
    participant LLM as LLM Service

    Note over User,Store: ä¸»æµç¨‹ï¼ˆåŒæ­¥ï¼‰- ç”¨æˆ·è¯·æ±‚å“åº”
    User->>API: POST /chat/stream
    API->>Handler: handle(user_id, message, session_id)

    Handler->>Store: append_message(user)
    Store-->>Handler: current_user_message_id (UUID)

    Handler->>Graph: astream_custom(state)
    activate Graph

    Graph->>Recall: _recall_node(state)
    activate Recall
    Recall->>Summarizer: get_summary_text(conversation_id)
    Summarizer->>Store: get_summary(conversation_id)
    Store-->>Summarizer: summary_row or None
    Summarizer-->>Recall: conversation_summary (str)

    Recall->>Store: list_messages(conversation_id, limit=8, desc=True)
    Store-->>Recall: raw_history (list)

    Note over Recall: è¿‡æ»¤å†å²æ¶ˆæ¯:<br/>1. completed=True<br/>2. æ’é™¤ current_user_message_id
    Recall-->>Graph: history_context (list)
    deactivate Recall

    Graph->>Execute: _execute_node(state)
    activate Execute
    Execute->>LLM: stream(message, summary, history)
    loop æµå¼ç”Ÿæˆ
        LLM-->>Execute: token chunk
        Execute-->>Graph: stream event
        Graph-->>Handler: yield token
        Handler-->>API: SSE token event
        API-->>User: SSE: {"status": "token", "content": "..."}
    end
    deactivate Execute
    deactivate Graph

    Note over Handler,Store: finally å— - æ¸…ç†ä¸è§¦å‘
    Handler->>Store: append_message(assistant, completed=completed_normally)
    Store-->>Handler: assistant_message_id (UUID)

    alt completed_normally = True
        Note over Handler,TaskMgr: è§¦å‘åå°ä»»åŠ¡ï¼ˆå¼‚æ­¥ï¼‰
        Handler->>Summarizer: schedule_update(conversation_id)
        Summarizer->>TaskMgr: schedule(conversation_id, coro)

        par åå°å¼‚æ­¥å¤„ç†ï¼ˆä¸é˜»å¡ï¼‰
            TaskMgr->>TaskMgr: ä»»åŠ¡å»é‡ä¸è°ƒåº¦
            TaskMgr->>Summarizer: try_trigger_update(conversation_id)
            activate Summarizer

            Summarizer->>Store: count_completed_messages(conversation_id)
            Store-->>Summarizer: total_completed (int)

            alt total_completed >= 10
                Summarizer->>Store: get_summary(conversation_id)
                Store-->>Summarizer: summary_row

                Summarizer->>Store: list_recent_messages(limit=6)
                Store-->>Summarizer: recent_messages (6æ¡)

                Note over Summarizer: è®¡ç®—çª—å£èµ·å§‹:<br/>window_start = recent[-1]

                Summarizer->>Store: list_messages_since(cursor=covered, stop=window_start)
                Store-->>Summarizer: eligible_messages

                alt len(eligible) >= 5
                    alt existing_summary ä¸ä¸ºç©º
                        Summarizer->>LLM: ainvoke(å¢é‡æ›´æ–°æç¤ºè¯)
                    else é¦–æ¬¡ç”Ÿæˆ
                        Summarizer->>LLM: ainvoke(é¦–æ¬¡ç”Ÿæˆæç¤ºè¯)
                    end

                    LLM-->>Summarizer: summary_text

                    alt len(summary) > 1200
                        Note over Summarizer: æˆªæ–­åˆ° 1200 å­—ç¬¦
                    end

                    Summarizer->>Store: save_summary_upsert(expected_version)
                    Store-->>Summarizer: success (bool)
                else len(eligible) < 5
                    Note over Summarizer: è·³è¿‡æ›´æ–°<br/>(æœªè¾¾åˆ°å¢é‡é˜ˆå€¼)
                end
            else total_completed < 10
                Note over Summarizer: è·³è¿‡æ›´æ–°<br/>(æœªè¾¾åˆ°è§¦å‘é˜ˆå€¼)
            end

            deactivate Summarizer
        end
    else completed_normally = False
        Note over Handler: ä¸è§¦å‘åå°ä»»åŠ¡<br/>æµå¼ä¸­æ–­
    end

    API-->>User: SSE: {"status": "done"}

    rect rgba(255, 230, 230, 0.3)
        Note over TaskMgr,LLM: åå°å¼‚æ­¥æµç¨‹<br/>ä¸é˜»å¡ç”¨æˆ·å“åº”
    end
```

#### 

#### 2.1.3 è®¾è®¡åŸåˆ™ä¸å…³é”®å†³ç­–

**æ ¸å¿ƒåŸåˆ™ï¼š**

1. **å¼‚æ­¥ä¼˜å…ˆè®¾è®¡**
   æ‰€æœ‰è€—æ—¶æ“ä½œï¼ˆæ‘˜è¦ç”Ÿæˆã€å‘é‡ç´¢å¼•ã€æ•°æ®åº“å†™å…¥ï¼‰å‡é‡‡ç”¨å¼‚æ­¥å¤„ç†ï¼Œç¡®ä¿ç”¨æˆ·å“åº”ä¸å—é˜»å¡ã€‚Handler å±‚åªè´Ÿè´£è§¦å‘ï¼ŒService å±‚åœ¨åå°æ‰§è¡Œï¼Œé€šè¿‡ä»»åŠ¡é˜Ÿåˆ—ä¿è¯å¯é æ€§ã€‚

2. **æ¸è¿›å¼æ¼”è¿›æ¶æ„**
   ç³»ç»Ÿé‡‡ç”¨ä¸‰é˜¶æ®µæ¸è¿›å¼è®¾è®¡ï¼šPhase 1ï¼ˆæ‘˜è¦ï¼‰â†’ Phase 2ï¼ˆå‘é‡è®°å¿†ï¼‰â†’ Phase 3ï¼ˆçŠ¶æ€æœºç¼–æ’ï¼‰ã€‚æ¯ä¸ªé˜¶æ®µç‹¬ç«‹å¯æµ‹è¯•ã€å¯éƒ¨ç½²ï¼Œåç»­é˜¶æ®µå…¼å®¹å‰æœŸåŠŸèƒ½ï¼Œé¿å…å¤§çˆ†ç‚¸å¼é‡æ„ã€‚

3. **å®¹é”™ä¼˜å…ˆç­–ç•¥**
   å…³é”®è·¯å¾„ï¼ˆç”¨æˆ·å“åº”ï¼‰ä¸è¾…åŠ©è·¯å¾„ï¼ˆæ‘˜è¦ã€ç´¢å¼•ï¼‰å®Œå…¨è§£è€¦ã€‚è¾…åŠ©æœåŠ¡å¤±è´¥ä¸åº”å½±å“ä¸»æµç¨‹ï¼Œæ‰€æœ‰åå°æ“ä½œå‡é‡‡ç”¨é™é»˜é™çº§ï¼Œè®°å½•æ—¥å¿—ä½†ä¸ä¸­æ–­ç”¨æˆ·ä½“éªŒã€‚

4. **å…³æ³¨ç‚¹åˆ†ç¦»**
   - Handler å±‚ï¼šä¸šåŠ¡ç¼–æ’ï¼Œå†³å®šä½•æ—¶è§¦å‘ä»€ä¹ˆæœåŠ¡
   - Service å±‚ï¼šæ ¸å¿ƒé€»è¾‘ï¼Œè´Ÿè´£æ‘˜è¦ç”Ÿæˆã€å‘é‡æ£€ç´¢ç­‰
   - Persistence å±‚ï¼šæ•°æ®è®¿é—®ï¼Œæä¾›å¹‚ç­‰çš„å­˜å‚¨æ¥å£
   æ¯å±‚é€šè¿‡æ¸…æ™°çš„ Port/Adapter æ¥å£äº¤äº’ï¼Œä¾¿äºæµ‹è¯•å’Œæ›¿æ¢å®ç°ã€‚

5. **è¯­ä¹‰å®Œæ•´æ€§ä¿éšœ**
   é€šè¿‡ `completed` å­—æ®µåŒºåˆ†æµå¼å®Œæ•´æ¶ˆæ¯ä¸ä¸­æ–­æ®‹ç•™ï¼Œé€šè¿‡ UUID å»é‡é¿å…å½“å‰æ¶ˆæ¯é‡å¤å¤„ç†ï¼Œé€šè¿‡å¤åˆæ¸¸æ ‡ `(created_at, id)` ç¡®ä¿åˆ†é¡µå¹‚ç­‰æ€§ï¼Œç¡®ä¿æ‰€æœ‰æ•°æ®æ“ä½œçš„è¯­ä¹‰æ­£ç¡®æ€§ã€‚

**å…³é”®å†³ç­–ï¼š**

1.  **æ¶æ„æ¨¡å¼ï¼šæ»‘åŠ¨çª—å£ + å†å²æ‘˜è¦**
    - é€‚ç”¨åœºæ™¯ï¼šé€šç”¨åœºæ™¯ï¼Œå¹³è¡¡äº†çŸ­å¯¹è¯çš„å®æ—¶æ€§å’Œé•¿å¯¹è¯çš„ä¸Šä¸‹æ–‡å®Œæ•´æ€§ã€‚
    - **ä¸‰å±‚æ¶æ„**ï¼šHandler å±‚è´Ÿè´£è§¦å‘ã€æœåŠ¡å±‚è´Ÿè´£ç”Ÿæˆã€æŒä¹…å±‚è´Ÿè´£å­˜å‚¨ã€‚

2.  **å‚æ•°é…ç½®**
    - **è§¦å‘é˜ˆå€¼ (min_messages)**: 10 æ¡ï¼ˆ5 è½®å¯¹è¯ï¼‰ã€‚ç¡®ä¿æœ‰è¶³å¤Ÿä¸Šä¸‹æ–‡ç”Ÿæˆæœ‰æ„ä¹‰çš„æ‘˜è¦ã€‚
    - **æ›´æ–°å¢é‡ (update_delta)**: 5 æ¡ã€‚å¹³è¡¡æ‘˜è¦æ–°é²œåº¦å’Œç”Ÿæˆæˆæœ¬ã€‚
    - **çª—å£å¤§å° (window_size)**: 6 æ¡ã€‚ä¿ç•™æœ€è¿‘ 3 è½®å¯¹è¯çš„å®Œæ•´ç»†èŠ‚ã€‚
    - **æ‘˜è¦é•¿åº¦ä¸Šé™ (max_summary_chars)**: 1200 å­—ç¬¦ã€‚é˜²æ­¢æ‘˜è¦è¿‡é•¿å½±å“ Token æ¶ˆè€—ã€‚
    - **ç¡¬ä¸Šé™ä¿æŠ¤ (hard cap)**: å•æ¬¡æ›´æ–°æœ€å¤šå¤„ç† 200 æ¡æ¶ˆæ¯ã€‚é˜²æ­¢æç«¯åœºæ™¯ä¸‹çš„æ€§èƒ½é—®é¢˜ã€‚
    - **è¾¹ç•Œæ§åˆ¶**: ä½¿ç”¨ `(created_at, message_id)` å¤åˆæ¸¸æ ‡ä½œä¸ºæ‘˜è¦è¦†ç›–ç‚¹ã€‚
    - **çª—å£èµ·å§‹è®¡ç®—**: çª—å£èµ·å§‹ç‚¹ = æœ€è¿‘çª—å£æ¶ˆæ¯ä¸­æœ€æ—§çš„ä¸€æ¡ï¼Œè€Œéå›ºå®šåç§»ã€‚
    - **è¿‡æ»¤ç­–ç•¥**: æ‘˜è¦ç”Ÿæˆæ—¶å¿…é¡»è¿‡æ»¤æ‰ `completed=False` çš„æœªå®Œæˆæ¶ˆæ¯ã€‚

3.  **è§¦å‘æ—¶æœºä¸å¼‚æ­¥å¤„ç†**
    - **è§¦å‘æ¡ä»¶**: ä»…åœ¨ `completed_normally=True` æ—¶è§¦å‘ã€‚æµå¼ä¸­æ–­ä¸ä¼šç”Ÿæˆæ‘˜è¦ï¼Œé¿å…æ±¡æŸ“ã€‚
    - **å¼‚æ­¥è°ƒåº¦**: æ‰€æœ‰æ‘˜è¦æ›´æ–°é€šè¿‡ `SummaryTaskManager` å¼‚æ­¥æ‰§è¡Œï¼Œä¸é˜»å¡ç”¨æˆ·å“åº”ã€‚
    - **ä»»åŠ¡å»é‡**: åŒä¸€ conversation_id çš„ä»»åŠ¡è‡ªåŠ¨å»é‡ï¼Œé¿å…é‡å¤ç”Ÿæˆã€‚

4.  **å¹¶å‘æ§åˆ¶ï¼šä¹è§‚é”**
    - **ç‰ˆæœ¬å·æœºåˆ¶**: ä½¿ç”¨ `summary_version` å­—æ®µå®ç°ä¹è§‚é”ï¼Œé˜²æ­¢å¹¶å‘è¦†ç›–ã€‚
    - **æœŸæœ›ç‰ˆæœ¬**: æ›´æ–°æ—¶ä¼ å…¥ `expected_version`ï¼Œç‰ˆæœ¬ä¸åŒ¹é…æ—¶æ”¾å¼ƒæ›´æ–°ã€‚
    - **è‡ªåŠ¨é‡è¯•**: å†²çªæ—¶ä»»åŠ¡ç®¡ç†å™¨è‡ªåŠ¨é‡è¯•ï¼ˆæŒ‡æ•°é€€é¿ï¼‰ã€‚

5.  **å­˜å‚¨æ–¹æ¡ˆï¼šç‹¬ç«‹è¡¨ (conversation_summaries)**
    - æ¸…æ™°åˆ†ç¦»å…³æ³¨ç‚¹ï¼Œé¿å…æ±¡æŸ“æ ¸å¿ƒæ¶ˆæ¯è¡¨ï¼Œä¾¿äºç‹¬ç«‹ä¼˜åŒ–ç´¢å¼•ã€‚
    - **å¤åˆè¦†ç›–ç‚¹**: åŒæ—¶ä¿å­˜ `covered_through_created_at` å’Œ `covered_through_message_id`ã€‚

6.  **æ¨¡å‹é€‰æ‹©ä¸å…¼å®¹æ€§**
    - **å·¥å‚æ¨¡å¼**: ä½¿ç”¨ `get_llm_model()` è·å–æ¨¡å‹ï¼Œæ”¯æŒå¤šç§ LLM å®ç°ã€‚
    - **å¼‚æ­¥å…¼å®¹**: æ£€æŸ¥ `hasattr(llm, "ainvoke")` å…¼å®¹åŒæ­¥/å¼‚æ­¥ LLMã€‚
    - **ä¸­æ–‡æç¤º**: ç³»ç»Ÿæç¤ºè¯ä½¿ç”¨ä¸­æ–‡ï¼Œç¡®ä¿æ‘˜è¦è´¨é‡ã€‚

7.  **é™çº§ç­–ç•¥**
    - **å¤±è´¥é™é»˜å¤„ç†**: æ‘˜è¦ç”Ÿæˆå¤±è´¥æ—¶è®°å½•è­¦å‘Šæ—¥å¿—ï¼Œä¸å½±å“ä¸»æµç¨‹ã€‚
    - **ç‹¬ç«‹ try-except**: æ¯ä¸ªè®°å¿†æºç‹¬ç«‹å¼‚å¸¸å¤„ç†ï¼Œå¤±è´¥ä¸å½±å“å…¶ä»–æºã€‚

8.  **æ›´æ–°ç­–ç•¥ï¼šå¢é‡æ›´æ–°**
    - ä»…å°†"æ—§æ‘˜è¦ + æ–°å¢å¯¹è¯"å‘é€ç»™æ¨¡å‹è¿›è¡Œåˆå¹¶ï¼Œè€Œéæ¯æ¬¡å…¨é‡é‡ç®—ã€‚å¤§å¹…é™ä½ Context å¼€é”€ã€‚
    - **é¦–æ¬¡ç”Ÿæˆ**: æ— æ—§æ‘˜è¦æ—¶ç›´æ¥ç”Ÿæˆï¼Œä½¿ç”¨ä¸“é—¨çš„é¦–æ¬¡ç”Ÿæˆæç¤ºè¯ã€‚

#### 2.1.4 æ ¸å¿ƒå®ç°æ¶æ„

**ç³»ç»Ÿé‡‡ç”¨ä¸‰å±‚æ¶æ„å®ç°å¯¹è¯æ‘˜è¦åŠŸèƒ½**ï¼š

1. **Handler å±‚**ï¼šè´Ÿè´£æ¶ˆæ¯æŒä¹…åŒ–å’Œè§¦å‘æ¡ä»¶åˆ¤æ–­
2. **æœåŠ¡å±‚**ï¼š`ConversationSummarizer` å®ç°æ‘˜è¦ç”Ÿæˆé€»è¾‘
3. **æŒä¹…å±‚**ï¼šPostgreSQL å­˜å‚¨æ‘˜è¦å’Œæ¸¸æ ‡çŠ¶æ€

**æ•°æ®æµ**ï¼š

```
ç”¨æˆ·è¯·æ±‚
  â†“
StreamHandler.handle()
  â”œâ”€ append_message(user)  â†’ ä¿å­˜å¹¶è¿”å› message_id âœ…
  â”œâ”€ ConversationGraph.astream()
  â”‚   â””â”€ recall_node() â†’ get_summary_text()  â†’ è¯»å–æ‘˜è¦
  â””â”€ append_message(assistant) â†’ ä¿å­˜å¹¶è¿”å› message_id âœ…
      â””â”€ completed_normally? â†’ schedule_update()  â†’ å¼‚æ­¥è§¦å‘
```

**æ ¸å¿ƒæµç¨‹è¯´æ˜**ï¼š

##### 1. æ¶ˆæ¯å®Œæˆæ ‡è®°æœºåˆ¶

**é—®é¢˜**ï¼šæµå¼å“åº”å¯èƒ½å› ç½‘ç»œè¶…æ—¶æˆ–å¼‚å¸¸ä¸­æ–­ï¼Œå¯¼è‡´ä¸å®Œæ•´çš„ assistant æ¶ˆæ¯è½å…¥æ•°æ®åº“ã€‚

**è§£å†³æ€è·¯**ï¼šä½¿ç”¨ `completed` å­—æ®µæ˜ç¡®æ ‡è®°æ¶ˆæ¯æ˜¯å¦å®Œæ•´ï¼Œä¸ debug æ¨¡å¼æ— å…³ã€‚

**æµç¨‹**ï¼š
```
ç”¨æˆ·å‘é€æ¶ˆæ¯
  â†“
è¿½åŠ ç”¨æˆ·æ¶ˆæ¯ï¼ˆcompleted=Trueï¼‰  // ç”¨æˆ·æ¶ˆæ¯æ€»æ˜¯å®Œæ•´çš„
  â†“
æµå¼ç”Ÿæˆå“åº”
  â†“
  â”œâ”€ æ­£å¸¸å®Œæˆï¼ˆæ”¶åˆ° done äº‹ä»¶ï¼‰
  â”‚   â†“
  â”‚   completed_normally = True
  â”‚   â†“
  â”‚   è¿½åŠ  assistant æ¶ˆæ¯ï¼ˆcompleted=Trueï¼‰
  â”‚   â†“
  â”‚   è§¦å‘åå°ä»»åŠ¡ï¼ˆæ‘˜è¦ + ç´¢å¼•ï¼‰
  â”‚
  â””â”€ å¼‚å¸¸ä¸­æ–­ï¼ˆè¶…æ—¶ã€æ–­è¿ï¼‰
      â†“
      completed_normally = False
      â†“
      è¿½åŠ  assistant æ¶ˆæ¯ï¼ˆcompleted=Falseï¼‰
      â†“
      ä¸è§¦å‘åå°ä»»åŠ¡
```

**å…³é”®ç‚¹**ï¼š
- ç”¨æˆ·æ¶ˆæ¯å§‹ç»ˆæ ‡è®°ä¸ºå®Œæˆï¼ˆ`completed=True`ï¼‰
- Assistant æ¶ˆæ¯æ ¹æ®æµå¼å®ŒæˆçŠ¶æ€æ ‡è®°ï¼ˆ`completed=completed_normally`ï¼‰
- åªæœ‰ `completed=True` çš„å›åˆæ‰ä¼šç”Ÿæˆæ‘˜è¦å’Œç´¢å¼•
- `recall_node` è¿‡æ»¤ `completed=False` çš„æ¶ˆæ¯ï¼Œé¿å…æ±¡æŸ“ä¸Šä¸‹æ–‡

---

##### 2. å¤åˆæ¸¸æ ‡åˆ†é¡µæœºåˆ¶

**é—®é¢˜**ï¼šUUID v4 ä¸æ”¯æŒæ—¶é—´åºï¼Œä¸èƒ½ç®€å•åœ°ç”¨ `WHERE id > last_id` è¿›è¡Œåˆ†é¡µï¼ˆä¼šæ¼æ¶ˆæ¯ã€ä¹±åºï¼‰ã€‚

**è§£å†³æ€è·¯**ï¼šä½¿ç”¨ `(created_at, id)` å¤åˆæ¸¸æ ‡ï¼Œæ—¶é—´æˆ³ä½œä¸ºä¸»åºã€UUID ä½œä¸º tie-breakã€‚

**æµç¨‹**ï¼š
```
ä¸Šæ¬¡æ‘˜è¦è¦†ç›–ç‚¹ï¼š
  covered_through_created_at = 2024-01-01 10:00:00
  covered_through_message_id = uuid-100

å½“å‰æ¶ˆæ¯ï¼š
  msg1: (2024-01-01 10:00:01, uuid-101)  âœ… æ—¶é—´æˆ³æ›´å¤§ï¼ŒåŒ…å«
  msg2: (2024-01-01 10:00:00, uuid-099)  âŒ æ—¶é—´æˆ³ç›¸ç­‰ï¼ŒID æ›´å°ï¼Œæ’é™¤
  msg3: (2024-01-01 10:00:00, uuid-102)  âœ… æ—¶é—´æˆ³ç›¸ç­‰ï¼ŒID æ›´å¤§ï¼ŒåŒ…å«
  msg4: (2024-01-01 09:59:59, uuid-103)  âŒ æ—¶é—´æˆ³æ›´å°ï¼Œæ’é™¤
```

**SQL æŸ¥è¯¢é€»è¾‘**ï¼š
```sql
WHERE created_at > covered_at           -- ä¸»åºï¼šæ—¶é—´æˆ³ä¹‹åçš„éƒ½åŒ…å«
   OR (created_at = covered_at AND id > covered_id)  -- tie-breakï¼šåŒä¸€æ—¶é—´æˆ³å†…ï¼ŒID æ›´å¤§çš„æ‰åŒ…å«
ORDER BY created_at ASC, id ASC
```

**å…³é”®ç‚¹**ï¼š
- ç¡®ä¿åˆ†é¡µçš„å¹‚ç­‰æ€§ï¼ˆå¤šæ¬¡æŸ¥è¯¢ç»“æœä¸€è‡´ï¼‰
- æ”¯æŒåŒä¸€æ¯«ç§’å†…å¤šæ¡æ¶ˆæ¯çš„æ­£ç¡®æ’åº
- é¿å…æ¶ˆæ¯é—æ¼æˆ–é‡å¤å¤„ç†

---

##### 3. åŒé‡é˜ˆå€¼è§¦å‘æœºåˆ¶

**é—®é¢˜**ï¼šä½•æ—¶ç”Ÿæˆ/æ›´æ–°æ‘˜è¦ï¼Ÿå¤ªé¢‘ç¹æµªè´¹èµ„æºï¼Œå¤ªä¸åŠæ—¶å¤±å»æ•ˆæœã€‚

**è§£å†³æ€è·¯**ï¼šé‡‡ç”¨åŒé‡é˜ˆå€¼æœºåˆ¶ï¼Œå¹³è¡¡æ–°é²œåº¦å’Œæˆæœ¬ã€‚

**æµç¨‹**ï¼š
```
æ¯æ¬¡ completed_normally=True æ—¶
  â†“
æ£€æŸ¥ 1ï¼šæ€»å®Œæˆæ¶ˆæ¯æ•° >= 10ï¼Ÿ
  â”œâ”€ å¦ â†’ è·³è¿‡ï¼ˆæ¶ˆæ¯å¤ªå°‘ï¼Œæ— æ„ä¹‰ï¼‰
  â””â”€ æ˜¯ â†’ ç»§ç»­
      â†“
      æ£€æŸ¥ 2ï¼šè·ç¦»ä¸Šæ¬¡æ‘˜è¦æ–°å¢æ¶ˆæ¯æ•° >= 5ï¼Ÿ
      â”œâ”€ å¦ â†’ è·³è¿‡ï¼ˆå¢é‡ä¸è¶³ï¼Œä¸æ›´æ–°ï¼‰
      â””â”€ æ˜¯ â†’ è§¦å‘æ‘˜è¦ç”Ÿæˆ
          â†“
          è®¡ç®—çª—å£èµ·å§‹ï¼ˆæœ€è¿‘ 6 æ¡ä¸­æœ€æ—§çš„ï¼‰
          â†“
          è·å– eligible messagesï¼ˆcovered æ¸¸æ ‡ â†’ çª—å£èµ·å§‹ï¼‰
          â†“
          è°ƒç”¨ LLM ç”Ÿæˆ/æ›´æ–°æ‘˜è¦
          â†“
          ä¿å­˜æ–°æ‘˜è¦ï¼ˆæ›´æ–° covered æ¸¸æ ‡ + versionï¼‰
```

**é˜ˆå€¼å‚æ•°**ï¼š
- `min_messages=10`ï¼šæ€»æ¶ˆæ¯æ•°é˜ˆå€¼ï¼ˆ5 è½®å¯¹è¯ï¼‰
- `update_delta=5`ï¼šæ–°å¢æ¶ˆæ¯é˜ˆå€¼ï¼ˆè§¦å‘å¢é‡æ›´æ–°ï¼‰
- `window_size=6`ï¼šæ—¶é—´çª—å£å¤§å°ï¼ˆæœ€è¿‘ 3 è½®å¯¹è¯ï¼‰
- `max_summary_chars=1200`ï¼šæ‘˜è¦æœ€å¤§é•¿åº¦

**å…³é”®ç‚¹**ï¼š
- é¦–æ¬¡ç”Ÿæˆï¼šæ‰€æœ‰å†å² - çª—å£ï¼ˆeligible = å…¨éƒ¨ - æœ€è¿‘ 6 æ¡ï¼‰
- å¢é‡æ›´æ–°ï¼šcovered æ¸¸æ ‡ â†’ çª—å£èµ·å§‹ï¼ˆeligible = æ–°å¢ä¸”æ»‘å‡ºçª—å£çš„ï¼‰
- é¿å…"æ‘˜è¦è¿‡æ—§"ï¼šçª—å£å†…çš„æ¶ˆæ¯ä¸çº³å…¥æ‘˜è¦
- é¿å…"é¢‘ç¹æ›´æ–°"ï¼šå¢é‡ < 5 æ—¶ä¸æ›´æ–°

---

##### 4. å•è°ƒé€’å¢è¦†ç›–ç‚¹ + ä¹è§‚é”

**é—®é¢˜**ï¼šå¹¶å‘æ›´æ–°æ‘˜è¦æ—¶å¯èƒ½äº’ç›¸è¦†ç›–ï¼Œä¸¢å¤±æœ€æ–°æ‘˜è¦ã€‚

**è§£å†³æ€è·¯**ï¼šä½¿ç”¨å¤åˆè¦†ç›–ç‚¹ç¡®ä¿å•è°ƒé€’å¢ + ä¹è§‚é”é˜²æ­¢å¹¶å‘å†²çªã€‚

**æµç¨‹**ï¼š
```
æ‘˜è¦ Aï¼ˆæ—¶é—´ T1ï¼Œversion=1ï¼‰ï¼š
  covered_through_created_at = 2024-01-01 10:00:00
  covered_through_message_id = uuid-100
  summary_version = 1

æ‘˜è¦ Bï¼ˆæ—¶é—´ T2 > T1ï¼Œversion=2ï¼‰ï¼š
  covered_through_created_at = 2024-01-01 10:05:00  âœ… æ—¶é—´æˆ³æ›´å¤§ï¼Œå…è®¸æ›´æ–°
  covered_through_message_id = uuid-150
  summary_version = 2

æ‘˜è¦ Cï¼ˆæ—¶é—´ T3 < T1ï¼Œversion=3ï¼‰ï¼š
  covered_through_created_at = 2024-01-01 09:55:00  âŒ æ—¶é—´æˆ³æ›´å°ï¼Œæ‹’ç»æ›´æ–°
  summary_version = 3  ï¼ˆå³ä½¿ç‰ˆæœ¬å·æ›´å¤§ï¼‰
```

**æ•°æ®åº“çº¦æŸ**ï¼š
```sql
-- UPSERT æ—¶æ£€æŸ¥å•è°ƒæ€§
WHERE
    -- å•è°ƒé€’å¢çº¦æŸ
    (
        covered_through_created_at IS NULL
        OR covered_through_created_at < EXCLUDED.covered_through_created_at
        OR (
            covered_through_created_at = EXCLUDED.covered_through_created_at
            AND covered_through_message_id < EXCLUDED.covered_through_message_id
        )
    )
    -- ä¹è§‚é”çº¦æŸ
    AND ($expected_version IS NULL OR summary_version = $expected_version)
```

**å…³é”®ç‚¹**ï¼š
- å¤åˆæ¸¸æ ‡ä¿è¯å•è°ƒé€’å¢ï¼š`(created_at, id)` åªå¢ä¸å‡
- ä¹è§‚é”é˜²æ­¢å¹¶å‘è¦†ç›–ï¼š`summary_version` åŒ¹é…æ‰æ›´æ–°
- å¤±è´¥è‡ªåŠ¨é‡è¯•ï¼šå†²çªæ—¶ä»»åŠ¡ç®¡ç†å™¨è‡ªåŠ¨é‡è¯•
- å…¼å®¹é¦–æ¬¡æ’å…¥ï¼š`expected_version=None` æ—¶é¦–æ¬¡åˆ›å»º

---

##### 5. å¼‚æ­¥ä»»åŠ¡è°ƒåº¦æœºåˆ¶

**é—®é¢˜**ï¼šæ‘˜è¦ç”Ÿæˆæ˜¯è€—æ—¶æ“ä½œï¼ˆLLM è°ƒç”¨ï¼‰ï¼Œå¦‚æœåœ¨ä¸»çº¿ç¨‹åŒæ­¥æ‰§è¡Œä¼šé˜»å¡ç”¨æˆ·å“åº”ã€‚

**è§£å†³æ€è·¯**ï¼šä½¿ç”¨è½»é‡çº§çš„è¿›ç¨‹å†…ä»»åŠ¡ç®¡ç†å™¨ï¼Œå®ç°å¼‚æ­¥è°ƒåº¦ + ä»»åŠ¡å»é‡ + è‡ªåŠ¨æ¸…ç†ã€‚

**æµç¨‹**ï¼š
```
æµå¼å“åº”å®Œæˆï¼ˆcompleted_normally=Trueï¼‰
  â†“
finally å—è§¦å‘åå°ä»»åŠ¡
  â†“
conversation_summarizer.schedule_update(conversation_id)
  â†“
SummaryTaskManager.schedule(conversation_id, coro_factory)
  â†“
  â”œâ”€ æ£€æŸ¥ï¼šè¯¥ conversation_id æ˜¯å¦å·²æœ‰è¿è¡Œä¸­çš„ä»»åŠ¡ï¼Ÿ
  â”‚   â”œâ”€ æ˜¯ â†’ è·³è¿‡ï¼ˆè¿”å› Falseï¼Œå®ç°å»é‡ï¼‰
  â”‚   â””â”€ å¦ â†’ åˆ›å»ºæ–°ä»»åŠ¡
  â”‚       â†“
  â”‚       asyncio.create_task(_run(...))
  â”‚       â†“
  â”‚       ä¿å­˜åˆ° _tasks å­—å…¸
  â”‚       â†“
  â”‚       è¿”å› Trueï¼ˆå·²è°ƒåº¦ï¼‰
  â†“
_run() æ‰§è¡Œï¼š
  â”œâ”€ await coro_factory() â†’ try_trigger_update()
  â”‚   â”œâ”€ æˆåŠŸ â†’ ç»“æŸ
  â”‚   â””â”€ å¤±è´¥ â†’ è®°å½•æ—¥å¿— â†’ ç»“æŸ
  â””â”€ finallyï¼šä» _tasks å­—å…¸ä¸­ç§»é™¤ï¼ˆè‡ªåŠ¨æ¸…ç†ï¼‰
```

**å…³é”®ç‚¹**ï¼š
- **ä»»åŠ¡å»é‡**ï¼šåŒä¸€ conversation_id åŒæ—¶åªè¿è¡Œä¸€ä¸ªä»»åŠ¡
- **å¼‚æ­¥æ‰§è¡Œ**ï¼šä½¿ç”¨ `asyncio.create_task()` ä¸é˜»å¡ä¸»æµç¨‹
- **è‡ªåŠ¨æ¸…ç†**ï¼šä»»åŠ¡å®Œæˆåä»å­—å…¸ä¸­ç§»é™¤ï¼Œé¿å…å†…å­˜æ³„æ¼
- **çº¿ç¨‹å®‰å…¨**ï¼šä½¿ç”¨ `asyncio.Lock` ä¿æŠ¤å…±äº«çŠ¶æ€
- **é™é»˜å¤±è´¥**ï¼šå¼‚å¸¸æ•è· + æ—¥å¿—è®°å½•ï¼Œä¸å½±å“ä¸»æµç¨‹

**ä¸¤ç§ä»»åŠ¡ç®¡ç†å™¨çš„å¯¹æ¯”**ï¼š

| ç‰¹æ€§ | SummaryTaskManager | EpisodicTaskManager |
|------|-------------------|---------------------|
| **å»é‡é”®** | `conversation_id` | `assistant_message_id` |
| **å»é‡ç›®çš„** | åŒä¸€å¯¹è¯åŒæ—¶åªè¿è¡Œä¸€ä¸ªæ‘˜è¦ä»»åŠ¡ | é¿å…é‡å¤ç´¢å¼•åŒä¸€è½®å¯¹è¯ |
| **å¹¶å‘é™åˆ¶** | æ— é™åˆ¶ | `Semaphore(max=4)` |
| **é€‚ç”¨åœºæ™¯** | æ‘˜è¦ç”Ÿæˆï¼ˆè€—æ—¶é•¿ï¼Œé¢‘ç‡ä½ï¼‰ | å‘é‡ç´¢å¼•ï¼ˆè€—æ—¶çŸ­ï¼Œé¢‘ç‡é«˜ï¼‰ |

**ä¸ºä»€ä¹ˆä¸ç”¨é˜Ÿåˆ—/worker æ¨¡å¼**ï¼š
- ç®€åŒ–å®ç°ï¼šä¸éœ€è¦é¢å¤–çš„è¿›ç¨‹ç®¡ç†
- å•è¿›ç¨‹è¶³å¤Ÿï¼šæ‘˜è¦ç”Ÿæˆé¢‘ç‡ä½ï¼ˆæ¯ 5 è½®å¯¹è¯è§¦å‘ä¸€æ¬¡ï¼‰
- æœ€ä½³å®è·µï¼šç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨ DB job table + worker å®ç°æŒä¹…åŒ–

---

**åº”ç”¨åˆå§‹åŒ–**ï¼ˆserver/api/rest/dependencies.py:132-135ï¼‰ï¼š

```python
# dependencies.py
from functools import lru_cache

@lru_cache(maxsize=1)
def _build_summary_task_manager():
    """å•ä¾‹æ¨¡å¼ï¼Œå…¨å±€å…±äº«ä¸€ä¸ªä»»åŠ¡ç®¡ç†å™¨"""
    from infrastructure.chat_history import SummaryTaskManager
    return SummaryTaskManager()

@lru_cache(maxsize=1)
def _build_episodic_task_manager():
    """å•ä¾‹æ¨¡å¼ï¼Œå…¨å±€å…±äº«ä¸€ä¸ªä»»åŠ¡ç®¡ç†å™¨"""
    from infrastructure.chat_history import EpisodicTaskManager
    return EpisodicTaskManager()
```

**è°ƒç”¨é“¾è·¯**ï¼š

```
StreamHandler.handle (finally å—)
  â†“
ConversationSummarizer.schedule_update(conversation_id)
  â†“
SummaryTaskManager.schedule(conversation_id, coro_factory)
  â”œâ”€ æ£€æŸ¥æ˜¯å¦å·²æœ‰è¿è¡Œä¸­çš„ä»»åŠ¡ï¼ˆå»é‡ï¼‰
  â”œâ”€ åˆ›å»º asyncio.create_task(_run(...))
  â””â”€ _run() æ‰§è¡Œ:
      â”œâ”€ await coro_factory() â†’ try_trigger_update()
      â”œâ”€ å¼‚å¸¸æ•è· + æ—¥å¿—è®°å½•
      â””â”€ finally: è‡ªåŠ¨æ¸…ç† _tasks å­—å…¸
```

**è®¾è®¡äº®ç‚¹**ï¼š

1. **ä»»åŠ¡å»é‡**ï¼šåŸºäº conversation_id / assistant_message_idï¼Œé¿å…é‡å¤æ‰§è¡Œ
2. **è½»é‡çº§**ï¼šä¸éœ€è¦é˜Ÿåˆ—/worker æ¨¡å¼ï¼Œç›´æ¥ä½¿ç”¨ asyncio.create_task()
3. **è‡ªåŠ¨æ¸…ç†**ï¼šä»»åŠ¡å®Œæˆåè‡ªåŠ¨ä»å­—å…¸ä¸­ç§»é™¤ï¼Œé¿å…å†…å­˜æ³„æ¼
4. **çº¿ç¨‹å®‰å…¨**ï¼šä½¿ç”¨ asyncio.Lock ä¿æŠ¤å…±äº«çŠ¶æ€
5. **ä¼˜é›…å…³é—­**ï¼šæä¾› shutdown() æ–¹æ³•ï¼Œå–æ¶ˆæ‰€æœ‰è¿è¡Œä¸­çš„ä»»åŠ¡
6. **å¹¶å‘æ§åˆ¶**ï¼ˆEpisodicTaskManagerï¼‰ï¼šä½¿ç”¨ Semaphore é™åˆ¶å¹¶å‘æ•°ï¼Œé¿å…è¿‡è½½
7. **å»¶è¿Ÿåˆ›å»º**ï¼šä½¿ç”¨ coro_factory å»¶è¿Ÿåˆ›å»ºåç¨‹ï¼Œé¿å…åœ¨è°ƒåº¦æ—¶æå‰æ‰§è¡Œ

##### 6. LangGraph é›†æˆ

æ‘˜è¦åŠŸèƒ½é€šè¿‡ LangGraph çš„ `recall_node` é›†æˆåˆ°å¯¹è¯æµç¨‹ï¼š

```python
# conversation_graph.py:215-229
async def _recall_node(self, state: ConversationState, config: RunnableConfig):
    conversation_id = state.get("conversation_id")

    # è·å–å¯¹è¯æ‘˜è¦
    conversation_summary = None
    if self._conversation_summarizer is not None:
        try:
            conversation_summary = await self._conversation_summarizer.get_summary_text(
                conversation_id=conversation_id
            )
        except Exception:
            conversation_summary = None

    # è·å–æœ€è¿‘å†å²ï¼ˆè¿‡æ»¤æœªå®Œæˆæ¶ˆæ¯ï¼‰
    raw_history = await self._conversation_store.list_messages(
        conversation_id=conversation_id,
        limit=8,
        desc=True
    )

    history_context = []
    if isinstance(raw_history, list):
        raw_history.reverse()
        for m in raw_history:
            if not m.get("completed", True):  # âœ… è¿‡æ»¤æœªå®Œæˆæ¶ˆæ¯
                continue
            if current_user_message_id is not None and m.get("id") == current_user_message_id:
                continue  # âœ… æ’é™¤å½“å‰ç”¨æˆ·æ¶ˆæ¯
            history_context.append(m)

    return {
        "conversation_summary": conversation_summary,
        "history": history_context,
    }
```

##### 7. æ ¸å¿ƒä»£ç æ–‡ä»¶

```
backend/
â”œâ”€â”€ infrastructure/chat_history/
â”‚   â”œâ”€â”€ summarizer.py              # ConversationSummarizer æ ¸å¿ƒé€»è¾‘
â”‚   â””â”€â”€ task_manager.py            # SummaryTaskManager å¼‚æ­¥ä»»åŠ¡
â”œâ”€â”€ infrastructure/persistence/postgres/
â”‚   â””â”€â”€ conversation_summary_store.py  # PostgreSQL æŒä¹…åŒ–
â””â”€â”€ application/chat/
    â””â”€â”€ conversation_graph.py       # LangGraph é›†æˆ
```

**å…³é”®ç±»å’Œæ–¹æ³•**ï¼š

- `ConversationSummarizer.try_trigger_update()` - æ‘˜è¦è§¦å‘æ£€æŸ¥
- `ConversationSummarizer.get_summary_text()` - è·å–å½“å‰æ‘˜è¦
- `PostgresConversationSummaryStore.list_messages_since()` - å¤åˆæ¸¸æ ‡åˆ†é¡µ
- `PostgresConversationSummaryStore.save_summary_upsert()` - UPSERT + ä¹è§‚é”
- `StreamHandler.handle()` - æ¶ˆæ¯æŒä¹…åŒ–å’Œè§¦å‘

---

#### 2.1.5 æ•°æ®æ¨¡å‹

**æ–¹æ¡ˆï¼šç‹¬ç«‹æ‘˜è¦è¡¨**

```sql
CREATE TABLE conversation_summaries (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    conversation_id UUID NOT NULL REFERENCES conversations(id) ON DELETE CASCADE,
    summary TEXT NOT NULL,
    summary_version INT DEFAULT 1,  -- ä¹è§‚é”ç‰ˆæœ¬å·
    covered_through_message_id UUID,     -- âœ… æ‘˜è¦è¦†ç›–ç‚¹ï¼šæ¶ˆæ¯ IDï¼ˆtie-breakï¼‰
    covered_through_created_at TIMESTAMP, -- âœ… æ‘˜è¦è¦†ç›–ç‚¹ï¼šæ—¶é—´æˆ³ï¼ˆä¸»åºï¼‰
    covered_message_count INT NOT NULL,   -- ä»…ç”¨äºç»Ÿè®¡/è¾…åŠ©
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    UNIQUE(conversation_id)
);

-- ç´¢å¼•ç”¨äºé¢‘ç¹æŸ¥è¯¢
CREATE INDEX idx_summaries_conversation_id ON conversation_summaries(conversation_id);

-- âš ï¸ é‡è¦ï¼šmessages è¡¨ä¹Ÿéœ€è¦æ·»åŠ  completed å­—æ®µ
ALTER TABLE messages ADD COLUMN completed BOOLEAN DEFAULT true;
CREATE INDEX idx_messages_created_id ON messages(created_at, id);
```

**å­—æ®µè¯´æ˜ï¼š**

| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `id` | UUID | ä¸»é”® |
| `conversation_id` | UUID | å…³è”çš„å¯¹è¯ IDï¼ˆå¤–é”®ï¼‰ |
| `summary` | TEXT | å‹ç¼©åçš„å¯¹è¯æ‘˜è¦ |
| `summary_version` | INT | ä¹è§‚é”ç‰ˆæœ¬å·ï¼Œæ§åˆ¶å¹¶å‘æ›´æ–° |
| `covered_through_message_id` | UUID | âœ… æ‘˜è¦è¦†ç›–ç‚¹ï¼šæ¶ˆæ¯ IDï¼ˆtie-breakï¼Œå¤„ç†åŒä¸€æ¯«ç§’å†…çš„å¤šæ¡æ¶ˆæ¯ï¼‰ |
| `covered_through_created_at` | TIMESTAMP | âœ… æ‘˜è¦è¦†ç›–ç‚¹ï¼šæ—¶é—´æˆ³ï¼ˆä¸»åºï¼Œä¿è¯æ—¶é—´å…ˆåï¼‰ |
| `covered_message_count` | INT | å·²æ‘˜è¦çš„æ¶ˆæ¯æ•°é‡ï¼ˆè¾…åŠ©ç»Ÿè®¡ï¼‰ |
| `created_at` | TIMESTAMP | åˆ›å»ºæ—¶é—´ |
| `updated_at` | TIMESTAMP | æœ€åæ›´æ–°æ—¶é—´ |

**âš ï¸ å…³é”®è®¾è®¡ç‚¹**ï¼š
- **å¤åˆè¦†ç›–ç‚¹**ï¼š`covered_through_created_at + covered_through_message_id` ç¡®ä¿ç²¾å‡†åˆ‡ç‰‡
- **UUID v4 é™åˆ¶**ï¼šä¸èƒ½å•ç‹¬ç”¨ `message_id` è¿›è¡Œ `>` æ¯”è¾ƒï¼ˆä¼šæ¼æ¶ˆæ¯ã€ä¹±åºã€ä¸å¹‚ç­‰ï¼‰
- **SQL æŸ¥è¯¢**ï¼šå¿…é¡»ä½¿ç”¨ `WHERE created_at > $1 OR (created_at = $1 AND id > $2)` å¤åˆæ¡ä»¶
- **completed å­—æ®µ**ï¼šåœ¨ `messages` è¡¨æ·»åŠ ï¼Œç”¨äºæ ‡è®°æ¶ˆæ¯æ˜¯å¦å®Œæˆï¼ˆä¸ debug æ— å…³ï¼‰

**æµå¼ä¸­æ–­ä¸ Partial æ¶ˆæ¯å¤„ç†**ï¼š

| åœºæ™¯ | é—®é¢˜ | è§£å†³æ–¹æ¡ˆ |
|------|------|---------|
| **æµå¼ä¸­æ–­** | ç½‘ç»œè¶…æ—¶æˆ–å¼‚å¸¸å¯¼è‡´ä¸å®Œæ•´çš„ assistant å“åº”è½å…¥æ•°æ®åº“ | ä½¿ç”¨ `completed` å­—æ®µæ ‡è®°æ¶ˆæ¯æ˜¯å¦å®Œæ•´ |
| **æ‘˜è¦æ±¡æŸ“** | ä¸å®Œæ•´çš„å†…å®¹è¿›å…¥é•¿æœŸè®°å¿†ï¼ˆæ‘˜è¦/å‘é‡ç´¢å¼•ï¼‰ | ä»…å¯¹ `completed=True` çš„å›åˆç”Ÿæˆæ‘˜è¦å’Œç´¢å¼• |
| **é‡å¤å¤„ç†** | åŒä¸€è½®å¯¹è¯è¢«å¤šæ¬¡ç´¢å¼• | è§¦å‘æ¡ä»¶ï¼šä»…åœ¨ `completed_normally=True` æ—¶ |

**å®é™…ä»£ç å®ç°**ï¼ˆstream_handler.py:73-136ï¼‰ï¼š

```python
# stream_handler.py
async def handle(
    self,
    *,
    user_id: str,
    message: str,
    session_id: str,
    kb_prefix: Optional[str] = None,
    debug: bool = False,
    agent_type: str = "hybrid_agent",
) -> AsyncGenerator[dict[str, Any], None]:
    conversation_id = await self._conversation_store.get_or_create_conversation_id(
        user_id=user_id,
        session_id=session_id,
    )

    # âœ… ç”¨æˆ·æ¶ˆæ¯å§‹ç»ˆæ ‡è®°ä¸ºå®Œæˆ
    current_user_message_id = await self._conversation_store.append_message(
        conversation_id=conversation_id,
        role="user",
        content=message,
        completed=True,  # âœ… ç”¨æˆ·æ¶ˆæ¯æ€»æ˜¯å®Œæ•´çš„
    )

    tokens: list[str] = []
    completed_normally = False  # âœ… è·Ÿè¸ªæµå¼å“åº”æ˜¯å¦æ­£å¸¸å®Œæˆ

    try:
        # æµå¼æ‰§è¡ŒçŠ¶æ€æœº
        async for event in self._graph.astream_custom(
            {
                "stream": True,
                "user_id": user_id,
                "message": message,
                "session_id": session_id,
                "requested_kb_prefix": kb_prefix,
                "debug": bool(debug),
                "agent_type": agent_type,
                "conversation_id": conversation_id,
                "current_user_message_id": current_user_message_id,
            }
        ):
            if isinstance(event, dict) and event.get("status") == "token":
                tokens.append(str(event.get("content") or ""))
            if isinstance(event, dict) and event.get("status") == "done":
                completed_normally = True  # âœ… æ”¶åˆ° done äº‹ä»¶ï¼Œæ ‡è®°ä¸ºæ­£å¸¸å®Œæˆ
            yield event
    finally:
        # âœ… æ— è®ºæ˜¯å¦å¼‚å¸¸ï¼Œéƒ½ä¼šä¿å­˜ assistant å“åº”
        answer = "".join(tokens).strip()
        if not answer:
            return

        # âœ… ä¿å­˜ assistant æ¶ˆæ¯ï¼Œcompleted å­—æ®µä¸ debug æ— å…³
        assistant_message_id = await self._conversation_store.append_message(
            conversation_id=conversation_id,
            role="assistant",
            content=answer,
            debug={"partial": not completed_normally} if debug else None,  # debug å­—æ®µä»…ç”¨äºè°ƒè¯•
            completed=completed_normally,  # âœ… æ ¸å¿ƒæ ‡è®°ï¼šä¸ debug æ— å…³
        )

        # âœ… åªæœ‰æ­£å¸¸å®Œæˆæ—¶æ‰è§¦å‘åå°ä»»åŠ¡
        if completed_normally and self._conversation_summarizer is not None:
            try:
                await self._conversation_summarizer.schedule_update(conversation_id=conversation_id)
            except Exception:
                pass  # å¤±è´¥ä¸å½±å“ä¸»æµç¨‹

        if completed_normally and self._episodic_memory is not None:
            try:
                await self._episodic_memory.schedule_index_episode(
                    conversation_id=conversation_id,
                    user_message_id=current_user_message_id,
                    assistant_message_id=assistant_message_id,
                    user_message=message,
                    assistant_message=answer,
                )
            except Exception:
                pass

        if completed_normally and self._memory_service is not None:
            try:
                await self._memory_service.maybe_write(
                    user_id=user_id,
                    user_message=message,
                    assistant_message=answer,
                    metadata={"session_id": session_id, "kb_prefix": kb_prefix or ""},
                )
            except Exception:
                pass
```

**å…³é”®è®¾è®¡ç‚¹**ï¼š

1. **`completed` å­—æ®µï¼ˆæ ¸å¿ƒï¼‰**ï¼š
   - ä¸ `debug` æ— å…³ï¼Œå§‹ç»ˆå†™å…¥æ•°æ®åº“
   - `completed=True`ï¼šæµå¼å“åº”æ­£å¸¸å®Œæˆï¼ˆæ”¶åˆ° `{"status": "done"}` äº‹ä»¶ï¼‰
   - `completed=False`ï¼šæµå¼ä¸­æ–­ï¼ˆå¼‚å¸¸ã€è¶…æ—¶ã€å®¢æˆ·ç«¯æ–­è¿ï¼‰

2. **`debug.partial` å­—æ®µï¼ˆè¾…åŠ©ï¼‰**ï¼š
   - ä»…åœ¨ `debug=True` æ—¶å†™å…¥
   - ç”¨äºè°ƒè¯•æ—¶è¯†åˆ«ä¸å®Œæ•´çš„å“åº”
   - ä¸å½±å“æ‘˜è¦å’Œç´¢å¼•çš„ç”Ÿæˆé€»è¾‘

3. **è§¦å‘æ¡ä»¶**ï¼š
   ```python
   if completed_normally:  # âœ… ä»…åœ¨æ­£å¸¸å®Œæˆæ—¶è§¦å‘
       await summarizer.schedule_update(...)
       await episodic_memory.schedule_index_episode(...)
       await memory_service.maybe_write(...)
   ```

4. **recall èŠ‚ç‚¹è¿‡æ»¤**ï¼ˆconversation_graph.py:246ï¼‰ï¼š
   ```python
   # conversation_graph.py:246
   for m in raw_history:
       if not m.get("completed", True):  # âœ… è¿‡æ»¤æœªå®Œæˆæ¶ˆæ¯
           continue
       if current_user_message_id is not None and m.get("id") == current_user_message_id:
           continue  # âœ… æ’é™¤å½“å‰ç”¨æˆ·æ¶ˆæ¯
       history_context.append(m)
   ```

5. **æ•°æ®åº“é»˜è®¤å€¼**ï¼ˆconversation_summary_store.py:181ï¼‰ï¼š
   ```sql
   ALTER TABLE messages
   ADD COLUMN completed boolean NOT NULL DEFAULT true;  -- âœ… é»˜è®¤ä¸º Trueï¼ˆå…¼å®¹è€æ•°æ®ï¼‰
   ```

**æ•°æ®æµå¯¹æ¯”**ï¼š

| åœºæ™¯ | completed å­—æ®µ | debug.partial å­—æ®µ | è§¦å‘åå°ä»»åŠ¡ |
|------|----------------|-------------------|-------------|
| **æ­£å¸¸å®Œæˆ** | `True` | `False`ï¼ˆå¦‚æœ debug=Trueï¼‰ | âœ… æ˜¯ |
| **æµå¼ä¸­æ–­** | `False` | `True`ï¼ˆå¦‚æœ debug=Trueï¼‰ | âŒ å¦ |
| **ç”Ÿäº§ç¯å¢ƒï¼ˆdebug=Falseï¼‰** | `True` / `False` | ä¸å­˜åœ¨ | âœ… / âŒ |


| å¹¶å‘åœºæ™¯ | é—®é¢˜ | è§£å†³æ–¹æ¡ˆ |
|---------|------|---------|
| **å¤šè¯·æ±‚åŒæ—¶æ›´æ–°æ‘˜è¦** | äº’ç›¸è¦†ç›–ï¼Œä¸¢å¤±æ‘˜è¦ | UPSERT + WHERE å•è°ƒé€’å¢çº¦æŸ |
| **ç‰ˆæœ¬å†²çª** | æ—§æ‘˜è¦è¦†ç›–æ–°æ‘˜è¦ | ä¹è§‚é”ï¼ˆsummary_versionï¼‰ |
| **é‡å¤è§¦å‘** | åŒä¸€æ¶ˆæ¯å¤šæ¬¡æ‘˜è¦ | å»é‡æœºåˆ¶ï¼ˆä»… completed_normally è§¦å‘ï¼‰ |
| **é‡è¯•é£æš´** | å¤±è´¥é‡è¯•å¯¼è‡´æ•°æ®åº“å‹åŠ› | æŒ‡æ•°é€€é¿ + Advisory Lock |

**å…³é”®è®¾è®¡çº¦æŸ**ï¼š

1. **å•è°ƒé€’å¢çº¦æŸ**ï¼š
   ```sql
   WHERE (conversation_summaries.covered_through_created_at < EXCLUDED.covered_through_created_at)
      OR (conversation_summaries.covered_through_created_at = EXCLUDED.covered_through_created_at
          AND conversation_summaries.covered_through_message_id IS DISTINCT FROM EXCLUDED.covered_through_message_id)
     AND EXCLUDED.covered_through_message_id IS NOT NULL
   ```
   - åªå…è®¸è¦†ç›–ç‚¹å‰è¿›ï¼ˆå¤åˆæ¡ä»¶ï¼šcreated_at ä¸»åºï¼Œmessage_id tie-breakï¼‰
   - é˜²æ­¢æ—§æ‘˜è¦è¦†ç›–æ–°æ‘˜è¦

2. **ä¹è§‚é”ç‰ˆæœ¬æ£€æŸ¥**ï¼š
   ```sql
   AND ($5 IS NULL OR conversation_summaries.summary_version = $5)
   ```
   - CAS (Compare-And-Swap) è¯­ä¹‰
   - ç‰ˆæœ¬å†²çªæ—¶è¿”å› Falseï¼Œè§¦å‘é‡è¯•

3. **Advisory Lockï¼ˆå¯é€‰ï¼‰**ï¼š
   ```python
   async def try_trigger_update(self, conversation_id: str):
       # è·å–ä¼šè¯çº§åˆ«çš„æ’ä»–é”
       async with self.db.acquire_advisory_lock(f"summary:{conversation_id}"):
           # åŒé‡æ£€æŸ¥ï¼šå†æ¬¡ç¡®è®¤æ˜¯å¦éœ€è¦æ›´æ–°
           if not await self._should_update(conversation_id):
               return
           await self._generate_and_save(conversation_id)
   ```
   - ç¡®ä¿åŒä¸€ä¼šè¯åŒæ—¶åªæœ‰ä¸€ä¸ªæ‘˜è¦ä»»åŠ¡
   - é¿å…é‡å¤ç”Ÿæˆå’Œèµ„æºæµªè´¹

4. **å¹‚ç­‰è§¦å‘æ¡ä»¶**ï¼š
   ```python
   # âœ… ä»…åœ¨æµå¼å“åº”æ­£å¸¸ç»“æŸåè§¦å‘
   if stream_response.completed_normally:
       await summary_task_manager.enqueue(conversation_id)  # âœ… ä½¿ç”¨ä»»åŠ¡é˜Ÿåˆ—
   ```
   - è¿‡æ»¤æ‰ `completed=False` çš„æœªå®Œæˆæ¶ˆæ¯
   - é˜²æ­¢æµå¼ä¸­æ–­å¯¼è‡´çš„é‡å¤æ‘˜è¦
   - ä½¿ç”¨ `SummaryTaskManager` ç¡®ä¿ä»»åŠ¡ä¸ä¸¢å¤±

**å­˜å‚¨æ¥å£è®¾è®¡**

Phase 1 éœ€è¦ä¸“é—¨çš„æ‘˜è¦å­˜å‚¨æ¥å£ï¼Œä¸ç°æœ‰çš„ `ConversationStorePort` èŒè´£åˆ†ç¦»ã€‚

**ç°æœ‰æ¥å£çš„å±€é™**ï¼š

```python
# backend/application/ports/conversation_store_port.py
class ConversationStorePort(ABC):
    """å¯¹è¯æ¶ˆæ¯å­˜å‚¨æ¥å£

    å½“å‰åªå…³æ³¨æ¶ˆæ¯çš„å¢åˆ æŸ¥æ”¹ï¼Œä¸æ”¯æŒæ‘˜è¦åŠŸèƒ½ã€‚
    """

    @abstractmethod
    async def list_messages(
        self,
        conversation_id: str,
        limit: int | None = None,
        desc: bool = False
    ) -> list[dict]:
        """è·å–æ¶ˆæ¯åˆ—è¡¨"""
        ...

    @abstractmethod
    async def append_message(
        self,
        conversation_id: str,
        role: str,
        content: str,
        metadata: dict | None = None
    ):
        """è¿½åŠ æ¶ˆæ¯"""
        ...
```

**è®¾è®¡åŸåˆ™ï¼šæ¥å£åˆ†ç¦»**

ç›´æ¥æ‰©å±•ç°æœ‰ `ConversationStorePort` ä¼šå¯¼è‡´ï¼š
- èŒè´£æ··ä¹±ï¼šä¸€ä¸ªæ¥å£åŒæ—¶è´Ÿè´£æ¶ˆæ¯å­˜å‚¨å’Œæ‘˜è¦ç®¡ç†
- å½±å“é¢å¤§ï¼šæ‰€æœ‰å®ç°ç±»éƒ½éœ€è¦ä¿®æ”¹
- æµ‹è¯•å›°éš¾ï¼šæ‘˜è¦åŠŸèƒ½çš„æµ‹è¯•ä¼šæ±¡æŸ“æ¶ˆæ¯å­˜å‚¨çš„æµ‹è¯•

**è§£å†³æ–¹æ¡ˆï¼šæ–°å¢ `ConversationSummaryStorePort`**

```python
# backend/application/ports/conversation_summary_store_port.py
from abc import ABC, abstractmethod
from datetime import datetime
from typing import Any

class ConversationSummaryStorePort(ABC):
    """å¯¹è¯æ‘˜è¦å­˜å‚¨æ¥å£

    ä¸“é—¨è´Ÿè´£æ‘˜è¦çš„å¢åˆ æŸ¥æ”¹ï¼Œä¸æ¶ˆæ¯å­˜å‚¨è§£è€¦ã€‚
    """

    @abstractmethod
    async def get_summary(self, conversation_id: str) -> dict[str, Any] | None:
        """è·å–å¯¹è¯æ‘˜è¦

        Returns:
            {
                "summary": str,
                "covered_through_created_at": datetime,  # å¤åˆè¦†ç›–ç‚¹ï¼šæ—¶é—´æˆ³
                "covered_through_message_id": str,      # å¤åˆè¦†ç›–ç‚¹ï¼šæ¶ˆæ¯ ID
                "covered_message_count": int,
                "summary_version": int,
                "created_at": datetime,
                "updated_at": datetime
            } or None
        """
        ...

    @abstractmethod
    async def save_summary_upsert(
        self,
        conversation_id: str,
        summary: str,
        covered_through_created_at: datetime,
        covered_through_message_id: str,
        covered_count: int,
        expected_version: int | None = None
    ) -> bool:
        """ä¿å­˜æˆ–æ›´æ–°æ‘˜è¦ï¼ˆUPSERTï¼‰

        å¹¶å‘å®‰å…¨ä¿è¯ï¼š
        - ä½¿ç”¨ ON CONFLICT DO UPDATE
        - WHERE å­å¥ç¡®ä¿åªå…è®¸è¦†ç›–ç‚¹å‰è¿›ï¼ˆå¤åˆè¦†ç›–ç‚¹ï¼‰
        - ä¹è§‚é”ç‰ˆæœ¬æ£€æŸ¥

        Args:
            conversation_id: å¯¹è¯ ID
            summary: æ‘˜è¦æ–‡æœ¬
            covered_through_created_at: è¦†ç›–ç‚¹æ—¶é—´æˆ³ï¼ˆä¸»åºï¼‰
            covered_through_message_id: è¦†ç›–ç‚¹æ¶ˆæ¯ IDï¼ˆtie-breakï¼‰
            covered_count: å·²æ‘˜è¦çš„æ¶ˆæ¯æ•°é‡
            expected_version: æœŸæœ›çš„ç‰ˆæœ¬å·ï¼ˆä¹è§‚é”ï¼ŒNone è¡¨ç¤ºä¸æ£€æŸ¥ï¼‰

        Returns:
            bool: æ˜¯å¦æˆåŠŸæ›´æ–°ï¼ˆFalse è¡¨ç¤ºç‰ˆæœ¬å†²çªï¼Œéœ€è¦é‡è¯•ï¼‰
        """
        ...

    @abstractmethod
    async def count_messages(self, conversation_id: str) -> int:
        """ç»Ÿè®¡å¯¹è¯ä¸­çš„æ¶ˆæ¯æ•°é‡

        ç”¨äºåˆ¤æ–­æ˜¯å¦è¾¾åˆ°æ‘˜è¦é˜ˆå€¼ï¼ˆmin_messages = 10ï¼‰
        æ³¨æ„ï¼šè¿™é‡Œç»Ÿè®¡çš„æ˜¯ messages è¡¨ï¼Œä¸æ˜¯ conversation_summaries è¡¨
        """
        ...

    @abstractmethod
    async def list_messages_since(
        self,
        conversation_id: str,
        since_created_at: datetime | None,
        since_message_id: str | None,
        limit: int | None = 50
    ) -> list[dict[str, Any]]:
        """è·å–æŒ‡å®šè¦†ç›–ç‚¹ä¹‹åçš„æ–°æ¶ˆæ¯ï¼ˆæ¸¸æ ‡åˆ†é¡µï¼‰

        å…³é”®è®¾è®¡ï¼š
        - ä½¿ç”¨ (created_at, id) å¤åˆæ¡ä»¶è¿›è¡Œæ¸¸æ ‡åˆ†é¡µ
        - SQL: WHERE created_at > $1 OR (created_at = $1 AND id > $2)
        - é¿å… UUID v4 çš„éšæœºæ€§é—®é¢˜ï¼ˆæ¼æ¶ˆæ¯ã€ä¹±åºã€ä¸å¹‚ç­‰ï¼‰
        - å®Œå…¨ä¾èµ– message_id å”¯ä¸€æ€§ï¼Œä¸è¿›è¡Œå†…å®¹å»é‡

        Args:
            conversation_id: å¯¹è¯ ID
            since_created_at: è¦†ç›–ç‚¹æ—¶é—´æˆ³ï¼ˆNone è¡¨ç¤ºä»å¤´å¼€å§‹ï¼‰
            since_message_id: è¦†ç›–ç‚¹æ¶ˆæ¯ IDï¼ˆNone è¡¨ç¤ºä»å¤´å¼€å§‹ï¼‰
            limit: æœ€å¤§è¿”å›æ•°é‡ï¼ˆNone è¡¨ç¤ºä¸é™åˆ¶ï¼‰

        Returns:
            æŒ‰ created_at ASC, id ASC æ’åºçš„æ¶ˆæ¯åˆ—è¡¨
        """
        ...
```

**Postgres å®ç°**ï¼š

```python
# backend/infrastructure/persistence/postgres/conversation_summary_store.py
class PostgresConversationSummaryStore(ConversationSummaryStorePort):
    def __init__(self, db_pool):
        self.db = db_pool

    async def get_summary(self, conversation_id: str) -> dict[str, Any] | None:
        result = await self.db.fetchrow(
            "SELECT * FROM conversation_summaries WHERE conversation_id = $1",
            conversation_id
        )
        return dict(result) if result else None

    async def save_summary_upsert(
        self,
        conversation_id: str,
        summary: str,
        covered_through_created_at: datetime,
        covered_through_message_id: str,
        covered_count: int,
        expected_version: int | None = None
    ) -> bool:
        """å¹‚ç­‰çš„ UPSERT æ“ä½œï¼ˆå¤åˆè¦†ç›–ç‚¹ï¼‰"""
        query = """
        INSERT INTO conversation_summaries
            (conversation_id, summary, covered_through_created_at, covered_through_message_id,
             covered_message_count, summary_version)
        VALUES ($1, $2, $3, $4, $5, 1)
        ON CONFLICT (conversation_id) DO UPDATE SET
            summary = EXCLUDED.summary,
            covered_through_created_at = EXCLUDED.covered_through_created_at,
            covered_through_message_id = EXCLUDED.covered_through_message_id,
            covered_message_count = EXCLUDED.covered_message_count,
            summary_version = conversation_summaries.summary_version + 1,
            updated_at = NOW()
        WHERE
            -- å•è°ƒé€’å¢çº¦æŸï¼šåªå…è®¸è¦†ç›–ç‚¹å‰è¿›ï¼ˆå¤åˆæ¡ä»¶ï¼‰
            (conversation_summaries.covered_through_created_at < EXCLUDED.covered_through_created_at)
            OR (conversation_summaries.covered_through_created_at = EXCLUDED.covered_through_created_at
                AND conversation_summaries.covered_through_message_id IS DISTINCT FROM EXCLUDED.covered_through_message_id)
            AND EXCLUDED.covered_through_message_id IS NOT NULL
            -- ä¹è§‚é”ï¼ˆå¦‚æœæä¾›ï¼‰
            AND ($6 IS NULL OR conversation_summaries.summary_version = $6)
        RETURNING summary_version
        """

        result = await self.db.fetchrow(
            query,
            conversation_id, summary, covered_through_created_at, covered_through_message_id,
            covered_count, expected_version
        )
        return result is not None

    async def count_messages(self, conversation_id: str) -> int:
        result = await self.db.fetchval(
            "SELECT COUNT(*) FROM messages WHERE conversation_id = $1",
            conversation_id
        )
        return result

    async def list_messages_since(
        self,
        conversation_id: str,
        since_created_at: datetime | None,
        since_message_id: str | None,
        limit: int | None = 50
    ) -> list[dict[str, Any]]:
        """è·å–æŒ‡å®šè¦†ç›–ç‚¹ä¹‹åçš„æ–°æ¶ˆæ¯ï¼ˆæ¸¸æ ‡åˆ†é¡µï¼‰"""

        if since_created_at is None:
            # é¦–æ¬¡æ‘˜è¦ï¼šä»å¤´å¼€å§‹
            query = """
            SELECT id, role, content, created_at, metadata
            FROM messages
            WHERE conversation_id = $1
            ORDER BY created_at ASC, id ASC
            LIMIT $2
            """
            return await self.db.fetch(query, conversation_id, limit)

        # æ¸¸æ ‡åˆ†é¡µï¼š(created_at, id) å¤åˆæ¡ä»¶
        query = """
        SELECT id, role, content, created_at, metadata
        FROM messages
        WHERE conversation_id = $1
          AND (
              created_at > $2  -- ä¸»åºï¼šæ—¶é—´æˆ³ä¹‹å
              OR (created_at = $2 AND id > $3)  -- tie-break
          )
        ORDER BY created_at ASC, id ASC
        LIMIT $4
        """
        return await self.db.fetch(
            query,
            conversation_id,
            since_created_at,
            since_message_id,
            limit
        )
```

**ä½¿ç”¨ç¤ºä¾‹**ï¼š

```python
# backend/graphrag_agent/agents/summary.py
class ConversationSummarizer:
    def __init__(
        self,
        summary_store: ConversationSummaryStorePort,  # ä¾èµ–æ³¨å…¥
        message_store: ConversationStorePort,
        llm_factory
    ):
        self.summary_store = summary_store  # ä¸“é—¨å¤„ç†æ‘˜è¦
        self.message_store = message_store  # ä¸“é—¨å¤„ç†æ¶ˆæ¯
        self.llm = llm_factory.get_model("qwen-turbo")

    async def try_trigger_update(self, conversation_id: str):
        # ä½¿ç”¨æ‘˜è¦å­˜å‚¨
        summary = await self.summary_store.get_summary(conversation_id)
        count = await self.summary_store.count_messages(conversation_id)

        if count >= 10 and not summary:
            # é¦–æ¬¡æ‘˜è¦ï¼šè·å–æ‰€æœ‰å†å²æ¶ˆæ¯
            messages = await self.summary_store.list_messages_since(
                conversation_id, since_created_at=None, since_message_id=None
            )
            # ç”Ÿæˆæ‘˜è¦å¹¶ä¿å­˜
            await self._generate_and_save(conversation_id, messages)
```

#### 2.1.6 å­˜å‚¨æ¥å£è®¾è®¡ä¸å®ç°é€»è¾‘

**æ¥å£è®¾è®¡åŸåˆ™**ï¼š

Phase 1 éœ€è¦ä¸“é—¨çš„æ‘˜è¦å­˜å‚¨æ¥å£ï¼Œä¸ç°æœ‰çš„ `ConversationStorePort` èŒè´£åˆ†ç¦»ã€‚

---

##### æ¥å£åˆ†ç¦»è®¾è®¡

**ç°æœ‰æ¥å£çš„å±€é™**ï¼š

`ConversationStorePort` åªè´Ÿè´£æ¶ˆæ¯çš„å¢åˆ æŸ¥æ”¹ï¼Œä¸æ”¯æŒæ‘˜è¦åŠŸèƒ½ã€‚ç›´æ¥æ‰©å±•ä¼šå¯¼è‡´ï¼š
- èŒè´£æ··ä¹±ï¼šä¸€ä¸ªæ¥å£åŒæ—¶è´Ÿè´£æ¶ˆæ¯å­˜å‚¨å’Œæ‘˜è¦ç®¡ç†
- å½±å“é¢å¤§ï¼šæ‰€æœ‰å®ç°ç±»éƒ½éœ€è¦ä¿®æ”¹
- æµ‹è¯•å›°éš¾ï¼šæ‘˜è¦åŠŸèƒ½çš„æµ‹è¯•ä¼šæ±¡æŸ“æ¶ˆæ¯å­˜å‚¨çš„æµ‹è¯•

**è§£å†³æ–¹æ¡ˆï¼šæ–°å¢ `ConversationSummaryStorePort`**

ä¸“é—¨çš„æ‘˜è¦å­˜å‚¨æ¥å£ï¼Œä¸æ¶ˆæ¯å­˜å‚¨è§£è€¦ã€‚

**æ¥å£èŒè´£åˆ’åˆ†**ï¼š

```
ConversationStorePortï¼ˆç°æœ‰ï¼‰
â”œâ”€ append_message()          è¿½åŠ æ¶ˆæ¯
â”œâ”€ list_messages()           è·å–æ¶ˆæ¯åˆ—è¡¨
â”œâ”€ get_or_create_conversation_id()  è·å–æˆ–åˆ›å»ºå¯¹è¯ID
â””â”€ get_messages_by_ids()      æ‰¹é‡è·å–æ¶ˆæ¯ï¼ˆç”¨äºHydrationï¼‰

ConversationSummaryStorePortï¼ˆæ–°å¢ï¼‰
â”œâ”€ get_summary()              è·å–æ‘˜è¦
â”œâ”€ save_summary_upsert()      ä¿å­˜/æ›´æ–°æ‘˜è¦ï¼ˆUPSERTï¼‰
â”œâ”€ count_completed_messages() ç»Ÿè®¡å®Œæˆçš„æ¶ˆæ¯æ•°
â”œâ”€ list_messages_since()      æ¸¸æ ‡åˆ†é¡µè·å–æ¶ˆæ¯
â””â”€ list_recent_messages()     è·å–æœ€è¿‘æ¶ˆæ¯ï¼ˆçª—å£è®¡ç®—ï¼‰
```

**æ¥å£å®šä¹‰ä½ç½®**ï¼š
- **å®šä¹‰**ï¼š`backend/application/ports/conversation_summary_store_port.py`
- **PostgreSQL å®ç°**ï¼š`backend/infrastructure/persistence/postgres/conversation_summary_store.py`
- **In-Memory å®ç°**ï¼š`backend/infrastructure/persistence/postgres/conversation_summary_store.py`ï¼ˆåŒä¸€æ–‡ä»¶ï¼‰

---

##### æ ¸å¿ƒæ–¹æ³•è®¾è®¡æ€è·¯

**1. get_summary() - è·å–æ‘˜è¦**

**åŠŸèƒ½**ï¼šè·å–å¯¹è¯æ‘˜è¦åŠå…¶å…ƒæ•°æ®

**è¿”å›æ•°æ®ç»“æ„**ï¼š
```
{
  "conversation_id": UUID,
  "summary": str,                          # æ‘˜è¦æ–‡æœ¬
  "summary_version": int,                   # ä¹è§‚é”ç‰ˆæœ¬å·
  "covered_through_created_at": datetime,  # å¤åˆè¦†ç›–ç‚¹ï¼šæ—¶é—´æˆ³ï¼ˆä¸»åºï¼‰
  "covered_through_message_id": UUID,       # å¤åˆè¦†ç›–ç‚¹ï¼šIDï¼ˆtie-breakï¼‰
  "covered_message_count": int,             # å·²æ‘˜è¦çš„æ¶ˆæ¯æ•°é‡
  "created_at": datetime,
  "updated_at": datetime
}
```

**ä½¿ç”¨åœºæ™¯**ï¼š
- Summarizer æ£€æŸ¥æ˜¯å¦å·²æœ‰æ‘˜è¦
- Recall èŠ‚ç‚¹è·å–æ‘˜è¦å¹¶æ³¨å…¥ä¸Šä¸‹æ–‡

---

**2. save_summary_upsert() - ä¿å­˜/æ›´æ–°æ‘˜è¦**

**åŠŸèƒ½**ï¼šå¹‚ç­‰çš„ UPSERT æ“ä½œï¼Œæ”¯æŒå¹¶å‘å®‰å…¨å’Œå•è°ƒé€’å¢

**è®¾è®¡è¦ç‚¹**ï¼š
- **UPSERT è¯­ä¹‰**ï¼šä¸å­˜åœ¨åˆ™åˆ›å»ºï¼Œå­˜åœ¨åˆ™æ›´æ–°
- **å•è°ƒé€’å¢çº¦æŸ**ï¼šå¤åˆè¦†ç›–ç‚¹åªå¢ä¸å‡ï¼ˆé˜²æ­¢å¹¶å‘è¦†ç›–ï¼‰
- **ä¹è§‚é”**ï¼š`summary_version` åŒ¹é…æ‰æ›´æ–°ï¼ˆé˜²æ­¢å¹¶å‘å†²çªï¼‰

**å¹¶å‘å®‰å…¨ä¿è¯**ï¼š
```
è¯·æ±‚ Aï¼ˆæ—¶é—´ T1ï¼Œversion=1ï¼‰ï¼š
  covered_through_created_at = 2024-01-01 10:00:00
  covered_through_message_id = uuid-100

è¯·æ±‚ Bï¼ˆæ—¶é—´ T2 > T1ï¼Œversion=2ï¼‰ï¼š
  covered_through_created_at = 2024-01-01 10:05:00  âœ… å…è®¸æ›´æ–°

è¯·æ±‚ Cï¼ˆæ—¶é—´ T3 < T1ï¼Œversion=3ï¼‰ï¼š
  covered_through_created_at = 2024-01-01 09:55:00  âŒ æ‹’ç»æ›´æ–°ï¼ˆç‰ˆæœ¬å·å†å¤§ä¹Ÿæ²¡ç”¨ï¼‰
```

**å®ç°ä½ç½®**ï¼š
- **PostgreSQL**ï¼šä½¿ç”¨ `ON CONFLICT DO UPDATE + WHERE` å­å¥
- **In-Memory**ï¼šåœ¨ Python ä»£ç ä¸­å®ç°ç›¸åŒçš„çº¦æŸæ£€æŸ¥

---

**3. list_messages_since() - æ¸¸æ ‡åˆ†é¡µè·å–æ¶ˆæ¯**

**åŠŸèƒ½**ï¼šä½¿ç”¨å¤åˆæ¸¸æ ‡è¿›è¡Œå¹‚ç­‰çš„åˆ†é¡µæŸ¥è¯¢

**å¤åˆæ¸¸æ ‡é€»è¾‘**ï¼š
```
ä¸Šæ¬¡è¦†ç›–ç‚¹ï¼š
  covered_through_created_at = 2024-01-01 10:00:00
  covered_through_message_id = uuid-100

æŸ¥è¯¢æ¡ä»¶ï¼š
  WHERE created_at > covered_at           # ä¸»åºï¼šæ—¶é—´æˆ³ä¹‹åçš„éƒ½åŒ…å«
     OR (created_at = covered_at AND id > covered_id)  # tie-breakï¼šåŒä¸€æ—¶é—´æˆ³å†…ï¼ŒID æ›´å¤§çš„æ‰åŒ…å«
  ORDER BY created_at ASC, id ASC
```

**ä¸ºä»€ä¹ˆä¸ç”¨ `WHERE id > last_id`**ï¼š
- UUID v4 æ˜¯éšæœºç”Ÿæˆçš„ï¼Œä¸æ”¯æŒæ—¶é—´åº
- ä¼šå¯¼è‡´ï¼šæ¼æ¶ˆæ¯ï¼ˆæ—¶é—´æˆ³æ›´å°ä½†IDæ›´å¤§çš„ï¼‰ã€ä¹±åºã€ä¸å¹‚ç­‰

**å®ç°ä½ç½®**ï¼š
- **PostgreSQL**ï¼šSQL æŸ¥è¯¢å®ç°å¤åˆæ¡ä»¶
- **In-Memory**ï¼šPython ä»£ç ä¸­å®ç°ç›¸åŒçš„æ¯”è¾ƒé€»è¾‘

---

**4. count_completed_messages() - ç»Ÿè®¡å®Œæˆçš„æ¶ˆæ¯æ•°**

**åŠŸèƒ½**ï¼šç»Ÿè®¡ `completed=True` çš„æ¶ˆæ¯æ•°é‡

**ç”¨é€”**ï¼š
- åˆ¤æ–­æ˜¯å¦è¾¾åˆ°è§¦å‘é˜ˆå€¼ï¼ˆ`min_messages=10`ï¼‰
- ç¡®ä¿åªç»Ÿè®¡å®Œæ•´çš„æ¶ˆæ¯

**å®ç°ä½ç½®**ï¼š
- **PostgreSQL**ï¼š`SELECT COUNT(*) FROM messages WHERE conversation_id = $1 AND completed = TRUE`
- **In-Memory**ï¼šéå†æ¶ˆæ¯å¹¶è¿‡æ»¤ `completed=True`

---

**5. list_recent_messages() - è·å–æœ€è¿‘æ¶ˆæ¯ï¼ˆçª—å£è®¡ç®—ï¼‰**

**åŠŸèƒ½**ï¼šè·å–æœ€è¿‘ N æ¡æ¶ˆæ¯ï¼Œç”¨äºè®¡ç®—çª—å£èµ·å§‹ç‚¹

**å‚æ•°**ï¼š
- `limit=6`ï¼šé»˜è®¤è·å–æœ€è¿‘ 6 æ¡ï¼ˆ3 è½®å¯¹è¯ï¼‰

**çª—å£èµ·å§‹è®¡ç®—**ï¼š
```
æœ€è¿‘ 6 æ¡æ¶ˆæ¯ï¼ˆnewest-firstï¼‰ï¼š
  msg6: (2024-01-01 10:05:00, uuid-106)  â† æœ€æ–°
  msg5: (2024-01-01 10:04:00, uuid-105)
  msg4: (2024-01-01 10:03:00, uuid-104)
  msg3: (2024-01-01 10:02:00, uuid-103)
  msg2: (2024-01-01 10:01:00, uuid-102)
  msg1: (2024-01-01 10:00:00, uuid-101)  â† æœ€æ—§ = çª—å£èµ·å§‹

çª—å£èµ·å§‹ = msg1ï¼ˆæœ€è¿‘ 6 æ¡ä¸­æœ€æ—§çš„ä¸€æ¡ï¼‰
eligible messages = covered_cursor â†’ window_startï¼ˆä¸å«çª—å£å†…çš„ï¼‰
```

---

##### æ¥å£è°ƒç”¨æµç¨‹å›¾

**æ‘˜è¦ç”Ÿæˆæµç¨‹ä¸­çš„æ¥å£è°ƒç”¨**ï¼š

```mermaid
sequenceDiagram
    participant Summarizer as ConversationSummarizer
    participant Store as ConversationSummaryStorePort
    participant DB as PostgreSQL

    Note over Summarizer,DB: æ‘˜è¦ç”Ÿæˆæµç¨‹

    Summarizer->>Store: count_completed_messages(conversation_id)
    Store->>DB: SELECT COUNT(*) WHERE completed=TRUE
    DB-->>Store: count (int)
    Store-->>Summarizer: total_completed

    alt total_completed < 10
        Summarizer->>Summarizer: è·³è¿‡ï¼ˆæ¶ˆæ¯å¤ªå°‘ï¼‰
    else total_completed >= 10
        Summarizer->>Store: get_summary(conversation_id)
        Store->>DB: SELECT * FROM conversation_summaries
        DB-->>Store: summary_row or None
        Store-->>Summarizer: summary_data

        alt summary_data is None
            Note over Summarizer: é¦–æ¬¡ç”Ÿæˆæ‘˜è¦
            Summarizer->>Store: list_recent_messages(limit=6)
            Store->>DB: SELECT * FROM messages ORDER BY created_at DESC LIMIT 6
            DB-->>Store: recent_messages
            Store-->>Summarizer: recent_messages

            Note over Summarizer: è®¡ç®—çª—å£èµ·å§‹<br/>(å–æœ€è¿‘6æ¡ä¸­æœ€æ—§çš„ä¸€æ¡)
        else summary_data exists
            Note over Summarizer: å¢é‡æ›´æ–°æ‘˜è¦<br/>è®¡ç®—çª—å£èµ·å§‹
        end

        Summarizer->>Store: list_messages_since(cursor, stop=window_start)
        Store->>DB: SELECT * FROM messages<br/>WHERE created_at > cursor_at<br/>OR (created_at = cursor_at AND id > cursor_id)<br/>ORDER BY created_at ASC, id ASC
        DB-->>Store: eligible_messages
        Store-->>Summarizer: eligible_messages

        alt len(eligible) < 5
            Summarizer->>Summarizer: è·³è¿‡ï¼ˆå¢é‡ä¸è¶³ï¼‰
        else len(eligible) >= 5
            Summarizer->>Summarizer: LLM ç”Ÿæˆæ‘˜è¦

            Summarizer->>Store: save_summary_upsert(<br/>conversation_id,<br/>summary,<br/>covered_at=last_msg.created_at,<br/>covered_id=last_msg.id,<br/>expected_version)
            Store->>DB: INSERT INTO conversation_summaries ...<br/>ON CONFLICT (conversation_id) DO UPDATE<br/>SET ...<br/>WHERE (å•è°ƒé€’å¢çº¦æŸ) AND (version åŒ¹é…)
            DB-->>Store: success (bool)
            Store-->>Summarizer: True/False
        end
    end
```

**recall èŠ‚ç‚¹ä¸­çš„æ¥å£è°ƒç”¨**ï¼š

```mermaid
sequenceDiagram
    participant Recall as recall_node
    participant Summarizer as ConversationSummarizer
    participant Store as ConversationSummaryStorePort
    participant DB as PostgreSQL

    Note over Recall,DB: è·å–æ‘˜è¦å¹¶æ³¨å…¥ä¸Šä¸‹æ–‡

    Recall->>Summarizer: get_summary_text(conversation_id)
    Summarizer->>Store: get_summary(conversation_id)
    Store->>DB: SELECT * FROM conversation_summaries<br/>WHERE conversation_id = $1
    DB-->>Store: summary_row or None
    Store-->>Summarizer: summary_data

    alt summary_data is None
        Summarizer-->>Recall: None (æ— æ‘˜è¦)
    else summary_data exists
        Summarizer->>Summarizer: æå– summary_text
        Summarizer-->>Recall: conversation_summary (str)
    end

    Recall->>Store: list_messages(limit=8, desc=True)
    Store->>DB: SELECT * FROM messages<br/>WHERE conversation_id = $1<br/>ORDER BY created_at DESC, id DESC<br/>LIMIT 8
    DB-->>Store: raw_history

    Note over Recall: è¿‡æ»¤ completed=True<br/>æ’é™¤ current_user_message_id

    Recall-->>Graph: conversation_summary + history
```

---

##### å…³é”®å®ç°è¦ç‚¹

**âœ… æ­£ç¡®çš„åšæ³•**ï¼š

1. **å¤åˆæ¸¸æ ‡åˆ†é¡µ**ï¼šä½¿ç”¨ `(created_at, id)` å¤åˆæ¡ä»¶
   - SQLï¼š`WHERE created_at > $1 OR (created_at = $1 AND id > $2)`
   - ç¡®ä¿å¹‚ç­‰æ€§ã€é¿å…æ¼æ¶ˆæ¯å’Œä¹±åº

2. **Handler æ¥ä½ UUID**ï¼šHandler è·å– `append_message()` è¿”å›çš„ UUID
   - ç”¨æˆ·æ¶ˆæ¯ï¼š`current_user_message_id = append_message(user)`
   - Assistant æ¶ˆæ¯ï¼š`assistant_message_id = append_message(assistant)`

3. **è¿‡æ»¤é€»è¾‘**ï¼šåªä½¿ç”¨ `completed` å­—æ®µ
   - ä»£ç ï¼š`if not m.get("completed", True): continue`
   - `debug.partial` ä»…ç”¨äºè°ƒè¯•ï¼Œä¸å½±å“æ‘˜è¦é€»è¾‘

4. **åå°ä»»åŠ¡**ï¼šä½¿ç”¨ `SummaryTaskManager`ï¼ˆè¿›ç¨‹å†…ï¼‰æˆ– DB job è¡¨ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
   - ä»»åŠ¡å»é‡ï¼šåŒä¸€ conversation_id åŒæ—¶åªè¿è¡Œä¸€ä¸ªä»»åŠ¡
   - è‡ªåŠ¨æ¸…ç†ï¼šä»»åŠ¡å®Œæˆåä»å­—å…¸ä¸­ç§»é™¤

5. **è§¦å‘æ¡ä»¶**ï¼šä»…åœ¨ `completed_normally=True` æ—¶è§¦å‘
   - ç¡®ä¿åªæœ‰å®Œæ•´çš„å›åˆæ‰ä¼šç”Ÿæˆæ‘˜è¦å’Œç´¢å¼•

**âŒ é”™è¯¯çš„åšæ³•**ï¼š

1. **å•ä¸€ ID åˆ†é¡µ**ï¼š`WHERE id > last_id`ï¼ˆUUID v4 ä¸æ”¯æŒæ—¶é—´åºï¼‰
2. **é”™è¯¯å­—æ®µ**ï¼šä½¿ç”¨ `metadata.partial`ï¼ˆå®é™…æ˜¯ `debug.partial`ï¼‰
3. **å†…å®¹å»é‡**ï¼š`content == message`ï¼ˆä¼šè¯¯åˆ é‡å¤å†…å®¹ï¼‰
4. **ä¸å¯é çš„åå°ä»»åŠ¡**ï¼šç®€å•çš„ `background_tasks.add_task`ï¼ˆæµå¼åœºæ™¯ä¼šä¸¢å¤±ï¼‰

---

##### å®ç°æ–‡ä»¶ä½ç½®

| ç»„ä»¶ | æ–‡ä»¶è·¯å¾„ | è¯´æ˜ |
|------|---------|------|
| **æ¥å£å®šä¹‰** | `backend/application/ports/conversation_summary_store_port.py` | å®šä¹‰ `ConversationSummaryStorePort` æ¥å£ |
| **PostgreSQL å®ç°** | `backend/infrastructure/persistence/postgres/conversation_summary_store.py` | `PostgresConversationSummaryStore` ç±» |
| **In-Memory å®ç°** | `backend/infrastructure/persistence/postgres/conversation_summary_store.py` | `InMemoryConversationSummaryStore` ç±»ï¼ˆåŒä¸€æ–‡ä»¶ï¼‰ |
| **Summarizer** | `backend/infrastructure/chat_history/summarizer.py` | ä½¿ç”¨æ¥å£çš„ä¸šåŠ¡é€»è¾‘ |
| **Task Manager** | `backend/infrastructure/chat_history/task_manager.py` | å¼‚æ­¥ä»»åŠ¡ç®¡ç†å™¨ |

---

#### 2.1.7 é›†æˆåˆ° Handler

æ‘˜è¦åŠŸèƒ½é€šè¿‡ä¸¤ä¸ªå±‚æ¬¡é›†æˆåˆ°å¯¹è¯æµç¨‹ä¸­ï¼š

**1. è§¦å‘å±‚ï¼ˆStreamHandler.handleï¼‰**ï¼šåœ¨å“åº”å®Œæˆåå¼‚æ­¥è§¦å‘æ‘˜è¦æ›´æ–°

**2. å¬å›å±‚ï¼ˆConversationGraph._recall_nodeï¼‰**ï¼šåœ¨çŠ¶æ€æœºæ‰§è¡Œæ—¶è·å–æ‘˜è¦å¹¶æ³¨å…¥ä¸Šä¸‹æ–‡

---

##### 1. è§¦å‘å±‚ï¼šå¼‚æ­¥æ‘˜è¦æ›´æ–°

**å®ç°ä½ç½®**ï¼š`stream_handler.py:108-112`

```python
# stream_handler.py:108-112
async def handle(
    self,
    *,
    user_id: str,
    message: str,
    session_id: str,
    kb_prefix: Optional[str] = None,
    debug: bool = False,
    agent_type: str = "hybrid_agent",
) -> AsyncGenerator[dict[str, Any], None]:
    conversation_id = await self._conversation_store.get_or_create_conversation_id(
        user_id=user_id,
        session_id=session_id,
    )
    current_user_message_id = await self._conversation_store.append_message(
        conversation_id=conversation_id,
        role="user",
        content=message,
        completed=True,
    )

    tokens: list[str] = []
    completed_normally = False

    try:
        # æµå¼æ‰§è¡ŒçŠ¶æ€æœº
        async for event in self._graph.astream_custom({...}):
            if isinstance(event, dict) and event.get("status") == "done":
                completed_normally = True
            yield event
    finally:
        # æ”¶é›†å®Œæ•´å“åº”
        answer = "".join(tokens).strip()
        if not answer:
            return

        # ä¿å­˜ assistant æ¶ˆæ¯
        assistant_message_id = await self._conversation_store.append_message(
            conversation_id=conversation_id,
            role="assistant",
            content=answer,
            debug={"partial": not completed_normally} if debug else None,
            completed=completed_normally,
        )

        # âœ… è§¦å‘åå°æ‘˜è¦æ›´æ–°ï¼ˆä»…æ­£å¸¸å®Œæˆæ—¶ï¼‰
        if completed_normally and self._conversation_summarizer is not None:
            try:
                await self._conversation_summarizer.schedule_update(
                    conversation_id=conversation_id
                )
            except Exception:
                pass  # å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
```

**å…³é”®ç‚¹**ï¼š
- åœ¨ `finally` å—ä¸­è§¦å‘ï¼Œç¡®ä¿æ— è®ºæ˜¯å¦å¼‚å¸¸éƒ½ä¼šä¿å­˜å“åº”
- ä»…åœ¨ `completed_normally=True` æ—¶è§¦å‘ï¼Œé¿å…ä¸å®Œæ•´çš„å“åº”è¿›å…¥æ‘˜è¦
- ä½¿ç”¨ `try-except` é™é»˜å¤„ç†å¼‚å¸¸ï¼Œå¤±è´¥ä¸å½±å“ä¸»æµç¨‹

---

##### 2. å¬å›å±‚ï¼šè·å–æ‘˜è¦å¹¶æ³¨å…¥ä¸Šä¸‹æ–‡

**å®ç°ä½ç½®**ï¼š`conversation_graph.py:222-229`

```python
# conversation_graph.py:203-250
async def _recall_node(self, state: ConversationState, config: RunnableConfig) -> dict[str, Any]:
    message = str(state.get("message") or "")
    debug = bool(state.get("debug"))

    conversation_id = state.get("conversation_id")
    current_user_message_id = state.get("current_user_message_id")

    # 1. è·å–å¯¹è¯æ‘˜è¦ï¼ˆPhase 1ï¼‰
    conversation_summary: str | None = None
    if self._conversation_summarizer is not None and isinstance(conversation_id, UUID):
        try:
            conversation_summary = await self._conversation_summarizer.get_summary_text(
                conversation_id=conversation_id
            )
        except Exception:
            conversation_summary = None

    # 2. è·å–æœ€è¿‘å†å²æ¶ˆæ¯ï¼ˆæ—¶é—´çª—å£ï¼‰
    raw_history = []
    try:
        raw_history = await self._conversation_store.list_messages(
            conversation_id=conversation_id, limit=8, desc=True
        )
    except Exception:
        raw_history = []

    # 3. è¿‡æ»¤å†å²æ¶ˆæ¯ï¼ˆcompleted=True, æ’é™¤å½“å‰ç”¨æˆ·æ¶ˆæ¯ï¼‰
    history_context: list[dict[str, Any]] = []
    if isinstance(raw_history, list):
        raw_history.reverse()
        for m in raw_history:
            if not isinstance(m, dict):
                continue
            if not m.get("completed", True):  # âœ… è¿‡æ»¤æœªå®Œæˆæ¶ˆæ¯
                continue
            if current_user_message_id is not None and m.get("id") == current_user_message_id:
                continue  # âœ… æ’é™¤å½“å‰ç”¨æˆ·æ¶ˆæ¯
            history_context.append(m)

    # 4. è·å–è·¨ä¼šè¯è®°å¿†ï¼ˆMemoryServiceï¼‰
    memory_context: str | None = None
    if self._memory_service is not None:
        try:
            memory_context = await self._memory_service.recall_context(
                user_id=str(state.get("user_id") or ""),
                query=message,
            )
        except Exception:
            memory_context = None

    # 5. è·å–è¯­ä¹‰æƒ…èŠ‚è®°å¿†ï¼ˆPhase 2ï¼‰
    episodic_memory: list[dict[str, Any]] | None = None
    episodic_context: str | None = None
    if self._episodic_memory is not None and isinstance(conversation_id, UUID):
        try:
            exclude_ids: list[UUID] = []
            for m in history_context:
                mid = m.get("id")
                if isinstance(mid, UUID):
                    exclude_ids.append(mid)
            episodic_memory = await self._episodic_memory.recall_relevant(
                conversation_id=conversation_id,
                query=message,
                exclude_assistant_message_ids=exclude_ids,
            )
            episodic_context = self._episodic_memory.format_context(episodes=episodic_memory)
        except Exception:
            episodic_memory = None
            episodic_context = None

    # 6. è¿”å›æ›´æ–°çš„ State
    return {
        "memory_context": memory_context,
        "conversation_summary": conversation_summary,
        "history": history_context,
        "episodic_memory": episodic_memory,
        "episodic_context": episodic_context,
    }
```

**å…³é”®ç‚¹**ï¼š
- æ‰€æœ‰è®°å¿†æºï¼ˆæ‘˜è¦ã€å†å²ã€æƒ…èŠ‚ï¼‰éƒ½åœ¨ `recall_node` ä¸­å¹¶è¡Œè·å–
- ä½¿ç”¨ç‹¬ç«‹çš„ `try-except` åŒ…è£¹æ¯ä¸ªè®°å¿†æºï¼Œå¤±è´¥ä¸å½±å“å…¶ä»–æº
- è¿‡æ»¤ `completed=False` çš„æ¶ˆæ¯ï¼Œé¿å…ä¸å®Œæ•´çš„å“åº”æ±¡æŸ“ä¸Šä¸‹æ–‡
- æ’é™¤ `current_user_message_id`ï¼Œé¿å…å½“å‰æ¶ˆæ¯é‡å¤å¤„ç†

---

##### 3. æ‰§è¡Œå±‚ï¼šä½¿ç”¨æ‘˜è¦ç”Ÿæˆå“åº”

**å®ç°ä½ç½®**ï¼š`conversation_graph.py:299-349`

```python
# conversation_graph.py:299-349
async def _execute_node(self, state: ConversationState, config: RunnableConfig) -> dict[str, Any]:
    stream = bool(state.get("stream"))
    debug = bool(state.get("debug"))

    kb_prefix = str(state.get("kb_prefix") or "general")
    resolved_agent_type = str(state.get("resolved_agent_type") or state.get("agent_type") or "hybrid_agent")
    message = str(state.get("message") or "")
    session_id = str(state.get("session_id") or "")

    # âœ… ä» State ä¸­è·å–ä¸Šä¸‹æ–‡ï¼ˆåŒ…æ‹¬æ‘˜è¦ï¼‰
    memory_context = state.get("memory_context")
    conversation_summary = state.get("conversation_summary")
    episodic_context = state.get("episodic_context")
    history = state.get("history")

    use_retrieval = bool(state.get("use_retrieval"))
    worker_name = str(state.get("worker_name") or "")

    if stream:
        writer = _get_stream_writer(config)

        # KB Handler ä¸“ç”¨å¤„ç†ï¼ˆä¼˜å…ˆï¼‰
        if self._enable_kb_handlers and self._kb_handler_factory is not None:
            kb_handler = self._kb_handler_factory.get(kb_prefix)
            if kb_handler is not None:
                async for ev in kb_handler.process_stream(
                    message=message,
                    session_id=session_id,
                    agent_type=resolved_agent_type,
                    debug=debug,
                    memory_context=memory_context,
                    summary=conversation_summary,  # âœ… ä¼ å…¥æ‘˜è¦
                    episodic_context=episodic_context,
                    history=history,
                ):
                    writer(ev)
                return {}

        # é€šç”¨ RAG æµç¨‹
        plan: list[RagRunSpec] = []
        if use_retrieval:
            plan = [RagRunSpec(agent_type=resolved_agent_type, worker_name=worker_name)]

        async for ev in self._stream_executor.stream(
            plan=plan,
            message=message,
            session_id=session_id,
            kb_prefix=kb_prefix,
            debug=debug,
            memory_context=memory_context,
            summary=conversation_summary,  # âœ… ä¼ å…¥æ‘˜è¦
            episodic_context=episodic_context,
            history=history,
        ):
            writer(ev)
        return {}

    # éæµå¼å“åº”...
```

**å…³é”®ç‚¹**ï¼š
- `conversation_summary` ä» State ä¸­è¯»å–ï¼ˆç”± `recall_node` è®¾ç½®ï¼‰
- ä¼ é€’ç»™ `kb_handler.process_stream()` æˆ– `stream_executor.stream()`
- æœ€ç»ˆæ³¨å…¥åˆ° LLM çš„ Prompt ä¸­

---

##### 4. æ•°æ®æµæ€»ç»“

```
ç”¨æˆ·è¯·æ±‚
  â†“
StreamHandler.handle()
  â”œâ”€ append_message(user) â†’ current_user_message_id
  â”œâ”€ graph.astream_custom(initial_state)
  â”‚   â”œâ”€ route_node â†’ è·¯ç”±å†³ç­–
  â”‚   â”œâ”€ recall_node â†’ è·å–ä¸Šä¸‹æ–‡
  â”‚   â”‚   â”œâ”€ conversation_summarizer.get_summary_text() â†’ conversation_summary
  â”‚   â”‚   â”œâ”€ conversation_store.list_messages() â†’ history_context
  â”‚   â”‚   â”œâ”€ episodic_memory.recall_relevant() â†’ episodic_context
  â”‚   â”‚   â””â”€ memory_service.recall_context() â†’ memory_context
  â”‚   â””â”€ execute_node â†’ ç”Ÿæˆå“åº”ï¼ˆä½¿ç”¨æ‘˜è¦ï¼‰
  â”‚       â””â”€ stream_executor.stream(message, summary=conversation_summary, ...)
  â””â”€ æµå¼è¿”å› tokens
  â†“
finally å—
  â”œâ”€ append_message(assistant, completed=completed_normally)
  â””â”€ if completed_normally:
      â””â”€ conversation_summarizer.schedule_update(conversation_id)
          â””â”€ SummaryTaskManager.schedule(conversation_id, coro_factory)
              â””â”€ try_trigger_update() â†’ å¼‚æ­¥ç”Ÿæˆæ‘˜è¦
```

---

##### 5. ä¾èµ–æ³¨å…¥

**å®ç°ä½ç½®**ï¼š`dependencies.py`

```python
# dependencies.py
@lru_cache(maxsize=1)
def _build_summary_task_manager():
    from infrastructure.chat_history import SummaryTaskManager
    return SummaryTaskManager()

@lru_cache(maxsize=1)
def _build_conversation_summarizer():
    if not CHAT_SUMMARY_ENABLE:
        return None
    from infrastructure.chat_history import ConversationSummarizer
    return ConversationSummarizer(
        store=_build_conversation_summary_store(),
        task_manager=_build_summary_task_manager(),  # âœ… æ³¨å…¥ä»»åŠ¡ç®¡ç†å™¨
        min_messages=int(CHAT_SUMMARY_MIN_MESSAGES),
        update_delta=int(CHAT_SUMMARY_UPDATE_DELTA),
        window_size=int(CHAT_SUMMARY_WINDOW_SIZE),
        max_summary_chars=int(CHAT_SUMMARY_MAX_CHARS),
    )

@lru_cache(maxsize=1)
def get_stream_handler() -> StreamHandler:
    return StreamHandler(
        router=_build_router(),
        executor=_build_rag_executor(),
        stream_executor=_build_rag_stream_executor(),
        completion=_build_chat_completion(),
        conversation_store=_build_conversation_store(),
        memory_service=_build_memory_service(),
        conversation_summarizer=_build_conversation_summarizer(),  # âœ… æ³¨å…¥æ‘˜è¦æœåŠ¡
        episodic_memory=_build_conversation_episodic_memory(),
        kb_handler_factory=_build_kb_handler_factory(),
        enable_kb_handlers=bool(ENABLE_KB_HANDLERS),
    )
```

**å…³é”®ç‚¹**ï¼š
- ä½¿ç”¨ `@lru_cache(maxsize=1)` ç¡®ä¿å•ä¾‹
- `ConversationSummarizer` ä¾èµ– `SummaryTaskManager`
- `StreamHandler` ä¾èµ– `ConversationSummarizer`
- é€šè¿‡ä¾èµ–æ³¨å…¥ç»„è£…å®Œæ•´çš„å¯¹è±¡å›¾

---

##### 6. é…ç½®å‚æ•°

**ç¯å¢ƒå˜é‡**ï¼ˆ`.env`ï¼‰ï¼š

```bash
# å¯ç”¨å¯¹è¯æ‘˜è¦
CHAT_SUMMARY_ENABLE=true

# æ‘˜è¦å‚æ•°
CHAT_SUMMARY_MIN_MESSAGES=10          # è§¦å‘é˜ˆå€¼
CHAT_SUMMARY_UPDATE_DELTA=5           # æ›´æ–°å¢é‡
CHAT_SUMMARY_WINDOW_SIZE=6            # æ—¶é—´çª—å£å¤§å°
CHAT_SUMMARY_MAX_CHARS=1200           # æ‘˜è¦æœ€å¤§é•¿åº¦

# å­˜å‚¨é…ç½®
POSTGRES_DSN=postgresql://...
```

**é…ç½®æ–‡ä»¶**ï¼ˆ`config/settings.py`ï¼‰ï¼š

```python
# config/settings.py
CHAT_SUMMARY_ENABLE: bool = os.getenv("CHAT_SUMMARY_ENABLE", "false").lower() == "true"
CHAT_SUMMARY_MIN_MESSAGES: int = int(os.getenv("CHAT_SUMMARY_MIN_MESSAGES", "10"))
CHAT_SUMMARY_UPDATE_DELTA: int = int(os.getenv("CHAT_SUMMARY_UPDATE_DELTA", "5"))
CHAT_SUMMARY_WINDOW_SIZE: int = int(os.getenv("CHAT_SUMMARY_WINDOW_SIZE", "6"))
CHAT_SUMMARY_MAX_CHARS: int = int(os.getenv("CHAT_SUMMARY_MAX_CHARS", "1200"))
```

---

##### 7. å®Œæ•´çš„è°ƒç”¨é“¾

```
1. ç”¨æˆ·å‘é€æ¶ˆæ¯
   â†“
2. StreamHandler.handle(user_id, message, session_id)
   â†“
3. append_message(user) â†’ current_user_message_id
   â†“
4. graph.astream_custom({
       "conversation_id": conversation_id,
       "current_user_message_id": current_user_message_id,
       ...
   })
   â†“
5. ConversationGraph._recall_node(state)
   â†“
6. conversation_summarizer.get_summary_text(conversation_id)
   â†“
7. summary_store.get_summary(conversation_id) â†’ summary_row
   â†“
8. return {"conversation_summary": summary_text, ...}
   â†“
9. ConversationGraph._execute_node(state)
   â†“
10. stream_executor.stream(..., summary=conversation_summary, ...)
   â†“
11. LLM ç”Ÿæˆå“åº”ï¼ˆä½¿ç”¨æ‘˜è¦ï¼‰
   â†“
12. æµå¼è¿”å› tokens
   â†“
13. finally å—ï¼š
   - append_message(assistant, completed=completed_normally)
   - if completed_normally:
       - conversation_summarizer.schedule_update(conversation_id)
       - SummaryTaskManager.schedule(...)
       - try_trigger_update() â†’ ç”Ÿæˆ/æ›´æ–°æ‘˜è¦
```

**å…³é”®é›†æˆç‚¹**ï¼š

| é›†æˆç‚¹ | æ–‡ä»¶ | åŠŸèƒ½ |
|--------|------|------|
| **è§¦å‘æ‘˜è¦** | `stream_handler.py:108` | å“åº”å®Œæˆåå¼‚æ­¥è§¦å‘ |
| **è·å–æ‘˜è¦** | `conversation_graph.py:225` | recall èŠ‚ç‚¹è·å–æ‘˜è¦æ–‡æœ¬ |
| **ä½¿ç”¨æ‘˜è¦** | `conversation_graph.py:349` | execute èŠ‚ç‚¹ä¼ å…¥ LLM |
| **ä»»åŠ¡ç®¡ç†** | `task_manager.py:24` | å»é‡å’Œå¼‚æ­¥æ‰§è¡Œ |
| **ä¾èµ–æ³¨å…¥** | `dependencies.py:139` | ç»„è£…å¯¹è±¡å›¾ |

---

##### è®°å¿†æœºåˆ¶å¯¹æ¯”ï¼šæ‘˜è¦ vs ä¸ªäººè®°å¿† vs æƒ…èŠ‚è®°å¿†

ç³»ç»Ÿå®ç°äº†ä¸‰ç§äº’è¡¥çš„è®°å¿†æœºåˆ¶ï¼Œç†è§£å®ƒä»¬çš„åŒºåˆ«æ˜¯å…³é”®ã€‚

**æ ¸å¿ƒåŒºåˆ†ç‚¹**ï¼šä½œç”¨åŸŸã€å†™å…¥è§„åˆ™ã€å¬å›æ–¹å¼

| ç»´åº¦ | æ‘˜è¦ (Phase 1) | ä¸ªäººè®°å¿† (mem0) | æƒ…èŠ‚è®°å¿† (Phase 2) |
|------|---------------|----------------|-------------------|
| **ä½œç”¨åŸŸ** | ä¼šè¯çº§ï¼ˆconversation_idï¼‰ | ç”¨æˆ·çº§ï¼ˆuser_idï¼‰ï¼Œè·¨ä¼šè¯ | ä¼šè¯çº§ï¼ˆconversation_idï¼‰ |
| **å†™å…¥è§„åˆ™** | åå°å¼‚æ­¥ç”Ÿæˆ/å¢é‡æ›´æ–°<br/>ï¼ˆåˆ°è¾¾é˜ˆå€¼åå‹ç¼©æ»‘å‡ºçª—å£çš„æ¶ˆæ¯ï¼‰ | æŒ‰è§„åˆ™æŠ½å–åå¥½/äº‹å®/çº¦æŸ<br/>ï¼ˆä¸æ˜¯æ¯å¥éƒ½å†™ï¼‰ | æ¯ä¸ª completed å›åˆç´¢å¼•<br/>ï¼ˆuser + assistant â†’ episodeï¼‰ |
| **å¬å›æ–¹å¼** | ç¡®å®šæ€§è¯»å–<br/>ï¼ˆæ¯æ¬¡å¯¹è¯éƒ½è¯»ï¼‰ | å‘é‡æ£€ç´¢ top_k<br/>ï¼ˆæ‹¼æˆ memory_contextï¼‰ | ä¼šè¯å†…å‘é‡æ£€ç´¢<br/>ï¼ˆå¯¹ query åš embeddingï¼‰ |
| **å­˜å‚¨å†…å®¹** | ä¼šè¯å‹ç¼©æ¡£æ¡ˆï¼ˆsummary textï¼‰ | ç”¨æˆ·é•¿æœŸåå¥½å’Œäº‹å® | å¯¹è¯ç‰‡æ®µï¼ˆmessage_idï¼‰ |
| **å‘é‡å­˜å‚¨** | âŒ å¦ | âœ… æ˜¯ï¼ˆè·¨ä¼šè¯ï¼‰ | âœ… æ˜¯ï¼ˆä¼šè¯å†…ï¼‰ |
| **åˆ é™¤ç­–ç•¥** | åˆ ä¼šè¯æ—¶çº§è”åˆ é™¤ | æœªæ˜ç¡® | åˆ ä¼šè¯æ—¶çº§è”åˆ é™¤ |
| **Prompt æ³¨å…¥** | ã€å¯¹è¯èƒŒæ™¯ã€‘ï¼ˆsummaryï¼‰ | ã€ç”¨æˆ·é•¿æœŸè®°å¿†ã€‘ï¼ˆmemory_contextï¼‰ | é€šè¿‡å†å²çª—å£é—´æ¥ä½¿ç”¨ |

**ä¸€å¥è¯æ€»ç»“**ï¼š

> **æ‘˜è¦** = åŒä¸€ä¼šè¯çš„å‹ç¼©æ¡£æ¡ˆï¼ˆç¡®å®šæ€§è¯»å–ï¼‰
> **ä¸ªäººè®°å¿†** = å¯æ£€ç´¢çš„é•¿æœŸ/æƒ…èŠ‚ä¿¡æ¯ï¼ˆæŒ‰ç›¸ä¼¼åº¦å¬å›ï¼‰

**å¦‚ä½•ååŒå·¥ä½œ**ï¼š

```
ç”¨æˆ·æŸ¥è¯¢ "åˆšæ‰æåˆ°çš„å¯¼æ¼”è¿˜æœ‰å“ªäº›ä½œå“ï¼Ÿ"
    â†“
ã€ç”¨æˆ·é•¿æœŸè®°å¿†ã€‘ï¼ˆmem0ï¼‰
    - ç”¨æˆ·å–œæ¬¢ç§‘å¹»ç”µå½±ï¼Œç‰¹åˆ«æ˜¯è¯ºå…°
    â†“
ã€å¯¹è¯èƒŒæ™¯ã€‘ï¼ˆPhase 1 æ‘˜è¦ï¼‰
    - ç”¨æˆ·ä¹‹å‰è®¨è®ºäº†ã€Šé»‘å®¢å¸å›½ã€‹å’Œã€Šç»ˆç»“è€…2ã€‹
    - æåˆ°äº†è¿™ä¸¤éƒ¨ç”µå½±çš„æŠ€æœ¯åˆ›æ–°
    â†“
ã€æœ€è¿‘å¯¹è¯ã€‘ï¼ˆæ—¶é—´çª—å£ + Phase 2 å¬å›ï¼‰
    - æœ€è¿‘ 8 æ¡æ¶ˆæ¯
    - Phase 2 å¬å›ç›¸ä¼¼å†å²ç‰‡æ®µï¼ˆå¦‚æœ‰ï¼‰
    â†“
ã€å½“å‰é—®é¢˜ã€‘
    - "åˆšæ‰æåˆ°çš„å¯¼æ¼”è¿˜æœ‰å“ªäº›ä½œå“ï¼Ÿ"
```

**å…³é”®ç‚¹**ï¼š
- **æ‘˜è¦**æä¾›å…¨å±€ä¸Šä¸‹æ–‡ï¼ˆä¼šè¯çº§çš„"å¤§å±€è§‚"ï¼‰
- **ä¸ªäººè®°å¿†**æä¾›è·¨ä¼šè¯çš„æŒä¹…åŒ–åå¥½ï¼ˆç”¨æˆ·çº§çš„"é•¿æœŸç”»åƒ"ï¼‰
- **æƒ…èŠ‚è®°å¿†**æä¾›è¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢ï¼ˆä¼šè¯å†…çš„"ç²¾å‡†å¬å›"ï¼‰
- ä¸‰è€…äº’ä¸å†²çªï¼Œå…±åŒæ„æˆå¤šå±‚æ¬¡çš„è®°å¿†ä½“ç³»

---

#### 2.1.8 Prompt å±‚æ¬¡è®¾è®¡

æ‘˜è¦åŠŸèƒ½ç”Ÿæ•ˆçš„å…³é”®åœ¨äºå¦‚ä½•å°†æ‘˜è¦ã€å†å²å’Œå½“å‰é—®é¢˜æœ‰æœºåœ°ç»„ç»‡åˆ° Prompt ä¸­ã€‚

---

##### é—®é¢˜ï¼šå¤šå±‚ä¸Šä¸‹æ–‡å¦‚ä½•ç»„ç»‡ï¼Ÿ

ç³»ç»Ÿç°åœ¨æœ‰ä¸‰å±‚ä¸Šä¸‹æ–‡ï¼š
1. **é•¿æœŸç”¨æˆ·è®°å¿†**ï¼ˆMemoryServiceï¼‰ï¼šè·¨å¯¹è¯çš„ç”¨æˆ·åå¥½
2. **å¯¹è¯èƒŒæ™¯æ‘˜è¦**ï¼ˆConversationSummarizerï¼‰ï¼šå½“å‰å¯¹è¯çš„å‹ç¼©å†å²
3. **æœ€è¿‘å¯¹è¯å†å²**ï¼ˆConversationStoreï¼‰ï¼šæœ€è¿‘ 8 æ¡æ¶ˆæ¯ï¼ˆæ—¶é—´çª—å£ï¼‰

å¦‚æœç»„ç»‡ä¸å½“ï¼Œä¼šå¯¼è‡´ï¼š
- ä¿¡æ¯é‡å¤ï¼šæ‘˜è¦å’Œå†å²è®²åŒä¸€ä»¶äº‹
- æƒé‡æ··ä¹±ï¼šAgent ä¸çŸ¥é“è¯¥ä¼˜å…ˆå‚è€ƒå“ªä¸€å±‚
- Token æµªè´¹ï¼šå†—ä½™ä¿¡æ¯å ç”¨ä¸Šä¸‹æ–‡

---

##### è§£å†³æ€è·¯ï¼šå±‚æ¬¡åŒ–æ³¨å…¥ + æ¸…æ™°æ ‡è®°

**æ ¸å¿ƒåŸåˆ™**ï¼š
- **ä»è¿œåˆ°è¿‘**ï¼šé•¿æœŸè®°å¿† â†’ å¯¹è¯æ‘˜è¦ â†’ æœ€è¿‘å†å² â†’ å½“å‰é—®é¢˜
- **æ˜ç¡®æ ‡è®°**ï¼šæ¯å±‚ä¸Šä¸‹æ–‡éƒ½æœ‰æ¸…æ™°çš„æ ‡é¢˜ï¼Œé¿å…æ··æ·†
- **å¯è£å‰ª**ï¼šæ¯å±‚éƒ½æ˜¯å¯é€‰çš„ï¼Œæ ¹æ®å®é™…æ•°æ®çµæ´»ç»„åˆ

**Prompt ç»“æ„è®¾è®¡**ï¼š

```
System Messageï¼ˆè§’è‰²å®šä¹‰ï¼‰
    â†“
ã€ç”¨æˆ·é•¿æœŸè®°å¿†ã€‘ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    - è·¨å¯¹è¯çš„æŒä¹…åŒ–åå¥½
    â†“
ã€å¯¹è¯èƒŒæ™¯ã€‘ï¼ˆPhase 1 æ‘˜è¦ï¼‰
    - å½“å‰å¯¹è¯çš„å‹ç¼©å†å²
    - ä¸åŒ…å«æœ€è¿‘ 8 æ¡ï¼ˆé¿å…é‡å¤ï¼‰
    â†“
ã€æœ€è¿‘å¯¹è¯ã€‘ï¼ˆæ—¶é—´çª—å£ï¼‰
    - æœ€è¿‘ 8 æ¡ completed=True çš„æ¶ˆæ¯
    - æä¾›æœ€æ–°ä¸Šä¸‹æ–‡
    â†“
ã€å½“å‰é—®é¢˜ã€‘
    - ç”¨æˆ·å½“å‰çš„é—®é¢˜
```

---

##### Prompt ç¤ºä¾‹

**å®é™…ç”Ÿæˆçš„ Prompt**ï¼š

```
[System]: ä½ æ˜¯ç”µå½±æ¨èä¸“å®¶ï¼Œæ“…é•¿æ ¹æ®ç”¨æˆ·å–œå¥½æ¨èç”µå½±...

[System]: ã€ç”¨æˆ·é•¿æœŸè®°å¿†ã€‘
ç”¨æˆ·å–œæ¬¢ç§‘å¹»ç”µå½±ï¼Œç‰¹åˆ«æ˜¯è¯ºå…°å¯¼æ¼”çš„ä½œå“ã€‚ä¸å–œæ¬¢ææ€–ç‰‡ã€‚

[System]: ã€å¯¹è¯èƒŒæ™¯ã€‘
ç”¨æˆ·ä¹‹å‰è®¨è®ºäº†90å¹´ä»£ç»å…¸ç§‘å¹»ç”µå½±ï¼Œé‡ç‚¹å…³æ³¨ã€Šé»‘å®¢å¸å›½ã€‹å’Œã€Šç»ˆç»“è€…2ã€‹ã€‚
ç”¨æˆ·è¯¢é—®äº†è¿™ä¸¤éƒ¨ç”µå½±çš„æŠ€æœ¯åˆ›æ–°å’Œæ–‡åŒ–å½±å“ã€‚
ï¼ˆæ³¨ï¼šæœ€è¿‘ 8 æ¡å¯¹è¯ä¸åŒ…å«åœ¨æ‘˜è¦ä¸­ï¼Œé¿å…é‡å¤ï¼‰

[Human]: æ¨èä¸€äº›ç±»ä¼¼é£æ ¼çš„ç”µå½±

[Assistant]: åŸºäºä½ å–œæ¬¢ã€Šé»‘å®¢å¸å›½ã€‹å’Œã€Šç»ˆç»“è€…2ã€‹ï¼Œæˆ‘æ¨è...

[Human]: è¿™äº›ç”µå½±æœ‰ä»€ä¹ˆå…±åŒç‚¹ï¼Ÿ

[Assistant]: è¿™äº›ç”µå½±çš„å…±åŒç‚¹åŒ…æ‹¬...

[Human]: èƒ½æ¨èä¸€äº›æ›´è¿‘æœŸçš„ä½œå“å—ï¼Ÿ
```

**ä¸ºä»€ä¹ˆè¿™æ ·ç»„ç»‡**ï¼š

1. **é•¿æœŸè®°å¿†åœ¨å‰**ï¼šè®© Agent å…ˆç†è§£ç”¨æˆ·çš„æ•´ä½“åå¥½
2. **å¯¹è¯æ‘˜è¦å±…ä¸­**ï¼šæä¾›å½“å‰å¯¹è¯çš„ä¸Šä¸‹æ–‡èƒŒæ™¯
3. **æœ€è¿‘å†å²è¯¦ç»†**ï¼šæœ€æ–°çš„å¯¹è¯åŒ…å«æœ€ç›´æ¥çš„ä¸Šä¸‹æ–‡ï¼ˆå¦‚"åˆšæ‰æåˆ°çš„å¯¼æ¼”"ï¼‰
4. **å½“å‰é—®é¢˜æœ€å**ï¼šæ˜ç¡®å½“å‰è¦å›ç­”çš„é—®é¢˜

---

##### å®ç°ä½ç½®

**Prompt æ„å»ºä»£ç **ï¼š`backend/llm/completion.py:_build_general_prompt()`
**è°ƒç”¨é“¾è·¯**ï¼š`recall_node` â†’ è·å–æ‘˜è¦ â†’ ä¼ é€’ç»™ `_build_general_prompt()`

#### 2.1.9 æ•ˆæœè¯„ä¼°

Phase 1 å®ç°åï¼Œæˆ‘ä»¬éœ€è¦é‡åŒ–è¯„ä¼°å…¶æ•ˆæœå’Œå½±å“ã€‚

---

##### ä¸ Baseline å¯¹æ¯”

**å¯¹æ¯”åœºæ™¯**ï¼š50 è½®å¯¹è¯çš„é•¿å¯¹è¯åœºæ™¯

| æŒ‡æ ‡ | Baselineï¼ˆæ—¶é—´çª—å£ï¼‰ | Phase 1ï¼ˆæ»‘åŠ¨çª—å£ + æ‘˜è¦ï¼‰ | æ”¹è¿› |
|------|---------------------|--------------------------|------|
| **Token æ¶ˆè€—**ï¼ˆæ¯æ¬¡è¯·æ±‚ï¼‰ | ~8000 | ~680 | â¬‡ï¸ **91.5%** |
| **ä¸Šä¸‹æ–‡è¦†ç›–** | æœ€è¿‘ 6 è½® | å…¨éƒ¨å†å²ï¼ˆå‹ç¼©ï¼‰ | âœ… å…¨å±€è¦†ç›– |
| **å“åº”å»¶è¿Ÿ** | åŸºå‡† | ç”¨æˆ·ä¸å¯æ„Ÿï¼ˆåå°å¼‚æ­¥ï¼‰ | âœ… æ— å½±å“ |
| **å®ç°å¤æ‚åº¦** | ä½ | ä¸­ | âš ï¸ éœ€é¢å¤–ç®¡ç† |
| **é•¿å¯¹è¯è´¨é‡** | æ—©æœŸä¿¡æ¯ä¸¢å¤± | ä¿æŒå…³é”®ä¿¡æ¯ | âœ… æ˜¾è‘—æå‡ |

**æ•°æ®è¯´æ˜**ï¼š
- Baselineï¼šæ¯æ¬¡è¯·æ±‚æºå¸¦æœ€è¿‘ 6 è½®å¯¹è¯ï¼ˆçº¦ 8000 tokensï¼‰
- Phase 1ï¼šæ‘˜è¦ï¼ˆ~400 tokensï¼‰+ æœ€è¿‘ 8 æ¡ï¼ˆ~280 tokensï¼‰= ~680 tokens
- Token èŠ‚çœï¼š(8000 - 680) / 8000 = 91.5%

---

##### æ ¸å¿ƒä¼˜åŠ¿

**1. æˆæœ¬ä¼˜åŒ–**

- **å•æ¬¡è¯·æ±‚æˆæœ¬**ï¼šä» 8000 tokens é™è‡³ 680 tokensï¼ˆèŠ‚çœ 91.5%ï¼‰
- **æ‘˜è¦ç”Ÿæˆæˆæœ¬**ï¼šçº¦ 4000 tokensï¼ˆä¸€æ¬¡æ€§ï¼‰ï¼Œåˆ†æ‘Šåˆ°æ¯æ¬¡è¯·æ±‚å¯å¿½ç•¥ä¸è®¡
- **é•¿å¯¹è¯åœºæ™¯**ï¼šå¯¹è¯è¶Šé•¿ï¼ŒèŠ‚çœè¶Šæ˜æ˜¾ï¼ˆçº¿æ€§å¢é•¿ vs å¯¹æ•°å¢é•¿ï¼‰

**2. ä¸Šä¸‹æ–‡ä¿ç•™**

- **Baseline**ï¼šåªèƒ½è®°ä½æœ€è¿‘ 6 è½®å¯¹è¯ï¼Œæ—©æœŸä¿¡æ¯å®Œå…¨ä¸¢å¤±
- **Phase 1**ï¼šä¿ç•™å…¨éƒ¨å¯¹è¯çš„å…³é”®ä¿¡æ¯ï¼ˆæ‘˜è¦å½¢å¼ï¼‰
- **å®é™…æ•ˆæœ**ï¼šAgent èƒ½è®°ä½å¯¹è¯æ—©æœŸçš„ç”¨æˆ·åå¥½å’Œå†³ç­–

**3. ç”¨æˆ·ä½“éªŒ**

- **ä¸€è‡´æ€§**ï¼šé•¿å¯¹è¯ä¸­ä¸ä¼šå‡ºç°"å¿˜äº†ä¹‹å‰è¯´çš„"çš„é—®é¢˜
- **è¿è´¯æ€§**ï¼šAgent èƒ½ç†è§£å¯¹è¯æ—©æœŸçš„è®¾å®šå’Œåå¥½
- **å‡†ç¡®æ€§**ï¼šé¿å…åŸºäºä¸å®Œæ•´å†å²åšå‡ºé”™è¯¯åˆ¤æ–­

---

##### æŠ€æœ¯å®ç°äº®ç‚¹

**1. å®Œå…¨å¼‚æ­¥åŒ–**

- æ‘˜è¦ç”Ÿæˆåœ¨åå°å¼‚æ­¥æ‰§è¡Œï¼Œä¸é˜»å¡ä¸»å“åº”æµç¨‹
- ç”¨æˆ·æ„ŸçŸ¥å»¶è¿Ÿï¼š0ms
- å¤±è´¥å›é€€ï¼šè‡ªåŠ¨é™çº§åˆ°æ—¶é—´çª—å£æ¨¡å¼

**2. å¹‚ç­‰æ€§å’Œå¯é æ€§**

- å¤åˆæ¸¸æ ‡åˆ†é¡µç¡®ä¿å¤šæ¬¡æŸ¥è¯¢ç»“æœä¸€è‡´
- ä¹è§‚é”é˜²æ­¢å¹¶å‘è¦†ç›–
- `completed` å­—æ®µè¿‡æ»¤ä¸å®Œæ•´æ¶ˆæ¯

**3. æ¸è¿›å¼æ›´æ–°**

- å¢é‡æ›´æ–°ç­–ç•¥ï¼šæ¯æ¬¡åªåˆå¹¶æ–°å¢å¯¹è¯
- è§¦å‘é˜ˆå€¼ï¼šé¿å…é¢‘ç¹æ›´æ–°ï¼ˆæ¯ 5 æ¡è§¦å‘ä¸€æ¬¡ï¼‰
- çª—å£æœºåˆ¶ï¼šä¿ç•™æœ€è¿‘ 3 è½®çš„å®Œæ•´ç»†èŠ‚

---

##### æƒè¡¡ä¸å±€é™

**éœ€è¦æƒè¡¡çš„ç‚¹**ï¼š

| æ–¹é¢ | æƒè¡¡ | è¯´æ˜ |
|------|------|------|
| **å¤æ‚åº¦** | å¢åŠ ç³»ç»Ÿå¤æ‚åº¦ | éœ€è¦ç®¡ç†æ‘˜è¦è¡¨ã€ä»»åŠ¡ç®¡ç†å™¨ã€è§¦å‘é€»è¾‘ |
| **å»¶è¿Ÿ** | æ‘˜è¦æœ‰ 2-3 è½®å»¶è¿Ÿ | æ¯ 5 æ¡æ¶ˆæ¯æ›´æ–°ä¸€æ¬¡ï¼Œä¸ä¼šå®æ—¶æ›´æ–° |
| **ç²¾åº¦æŸå¤±** | æ‘˜è¦å¯èƒ½ä¸¢å¤±ç»†èŠ‚ | å‹ç¼©è¿‡ç¨‹å¯èƒ½é—æ¼éƒ¨åˆ†ä¿¡æ¯ |
| **ä¾èµ–æ€§** | ä¾èµ– LLM è´¨é‡ | æ‘˜è¦è´¨é‡å–å†³äºæ¨¡å‹èƒ½åŠ› |

**é€‚ç”¨åœºæ™¯**ï¼š

âœ… **é€‚åˆ**ï¼š
- é•¿å¯¹è¯ï¼ˆ20+ è½®ï¼‰
- éœ€è¦è®°ä½æ—©æœŸåå¥½çš„åœºæ™¯
- Token æˆæœ¬æ•æ„Ÿçš„åº”ç”¨

âŒ **ä¸é€‚åˆ**ï¼š
- çŸ­å¯¹è¯ï¼ˆ< 10 è½®ï¼‰
- å¯¹å®æ—¶æ€§è¦æ±‚æé«˜çš„åœºæ™¯
- éœ€è¦ä¿ç•™æ‰€æœ‰ç»†èŠ‚çš„åœºæ™¯

#### 2.1.10 è®¾è®¡å†³ç­–æ€»ç»“

Phase 1 çš„å®ç°æ¶‰åŠå¤šä¸ªå…³é”®è®¾è®¡å†³ç­–ï¼Œæ¯ä¸ªå†³ç­–éƒ½æœ‰å…¶æƒè¡¡è€ƒé‡ã€‚

---

##### æ ¸å¿ƒæ¶æ„å†³ç­–

**1. ä¸ºä»€ä¹ˆé€‰æ‹©"æ»‘åŠ¨çª—å£ + æ‘˜è¦"è€Œéçº¯æ‘˜è¦ï¼Ÿ**

| æ–¹æ¡ˆ | ä¼˜åŠ¿ | åŠ£åŠ¿ | é€‰æ‹©ç†ç”± |
|------|------|------|----------|
| **çº¯æ—¶é—´çª—å£**ï¼ˆBaselineï¼‰ | ç®€å•ã€å®æ—¶ | æ—©æœŸä¿¡æ¯ä¸¢å¤± | âŒ é•¿å¯¹è¯æ•ˆæœå·® |
| **çº¯æ‘˜è¦** | å…¨å±€è¦†ç›–ã€æˆæœ¬ä½ | ä¸¢å¤±æœ€è¿‘ç»†èŠ‚ã€å»¶è¿Ÿé«˜ | âŒ ç”¨æˆ·ä½“éªŒå·® |
| **çª—å£ + æ‘˜è¦**ï¼ˆPhase 1ï¼‰ | å¹³è¡¡å…¨å±€å’Œå±€éƒ¨ | å¤æ‚åº¦å¢åŠ  | âœ… **æœ€ä½³å¹³è¡¡** |

**å†³ç­–ç†ç”±**ï¼š
- æ‘˜è¦æä¾›å…¨å±€ä¸Šä¸‹æ–‡ï¼Œé¿å…æ—©æœŸä¿¡æ¯ä¸¢å¤±
- æ—¶é—´çª—å£ä¿ç•™æœ€è¿‘ç»†èŠ‚ï¼Œæ»¡è¶³"åˆšæ‰æåˆ°çš„"è¿™ç±»æŸ¥è¯¢
- ç”¨æˆ·æ— æ„ŸçŸ¥ï¼ˆå¼‚æ­¥ç”Ÿæˆï¼‰ï¼Œä½“éªŒä¸å—å½±å“

---

##### è§¦å‘æœºåˆ¶å†³ç­–

**2. ä½•æ—¶ç”Ÿæˆ/æ›´æ–°æ‘˜è¦ï¼Ÿ**

| å‚æ•° | é€‰æ‹© | ç†ç”± |
|------|------|------|
| **é¦–æ¬¡è§¦å‘** | 10 æ¡æ¶ˆæ¯ï¼ˆ5 è½®ï¼‰ | ç¡®ä¿æœ‰è¶³å¤Ÿä¸Šä¸‹æ–‡ï¼Œé¿å…è¿‡æ—©æ‘˜è¦ |
| **æ›´æ–°é¢‘ç‡** | æ¯ 5 æ¡æ¶ˆæ¯ï¼ˆ2-3 è½®ï¼‰ | å¹³è¡¡æ–°é²œåº¦å’Œæˆæœ¬ |
| **æ—¶é—´çª—å£** | æœ€è¿‘ 6 æ¡ï¼ˆ3 è½®ï¼‰ | ç¬¦åˆäººç±»å·¥ä½œè®°å¿†å®¹é‡ |

**æƒè¡¡**ï¼š
- âœ… è§¦å‘å¤ªé¢‘ç¹ï¼šæˆæœ¬é«˜ã€æ€§èƒ½å½±å“
- âœ… è§¦å‘å¤ªç¨€ç–ï¼šæ‘˜è¦è¿‡æ—¶ã€ç”¨æˆ·ä½“éªŒå·®
- **æœ€ç»ˆé€‰æ‹©**ï¼š10 æ¡é¦–æ¬¡ã€5 æ¡æ›´æ–°ï¼Œå¹³è¡¡äº†æˆæœ¬å’Œæ–°é²œåº¦

---

##### å­˜å‚¨è®¾è®¡å†³ç­–

**3. ä¸ºä»€ä¹ˆéœ€è¦ç‹¬ç«‹çš„æ‘˜è¦è¡¨ï¼Ÿ**

| æ–¹æ¡ˆ | ä¼˜åŠ¿ | åŠ£åŠ¿ | é€‰æ‹© |
|------|------|------|------|
| **messages è¡¨æ‰©å±•** | ç®€å•ã€æ—  JOIN | èŒè´£æ··ä¹±ã€æŸ¥è¯¢å¤æ‚ | âŒ |
| **ç‹¬ç«‹æ‘˜è¦è¡¨** | æ¸…æ™°åˆ†ç¦»ã€æ˜“æ‰©å±• | éœ€è¦ JOIN | âœ… |

**å…³é”®è®¾è®¡ç‚¹**ï¼š
- **å¤åˆè¦†ç›–ç‚¹**ï¼š`(created_at, id)` ç¡®ä¿ç²¾å‡†åˆ†é¡µ
- **ä¹è§‚é”**ï¼š`summary_version` é˜²æ­¢å¹¶å‘è¦†ç›–
- **å•è°ƒé€’å¢çº¦æŸ**ï¼šä¿è¯æ‘˜è¦åªå¢ä¸å‡

---

##### å¹¶å‘æ§åˆ¶å†³ç­–

**4. å¦‚ä½•å¤„ç†å¹¶å‘æ›´æ–°ï¼Ÿ**

| é—®é¢˜ | è§£å†³æ–¹æ¡ˆ |
|------|----------|
| **å¹¶å‘è¦†ç›–** | å¤åˆè¦†ç›–ç‚¹ + å•è°ƒé€’å¢çº¦æŸ |
| **ç‰ˆæœ¬å†²çª** | ä¹è§‚é”ï¼ˆ`summary_version`ï¼‰ |
| **é‡å¤ä»»åŠ¡** | `SummaryTaskManager` ä»»åŠ¡å»é‡ |

**å®ç°äº®ç‚¹**ï¼š
- ä½¿ç”¨ `asyncio.Lock` ä¿è¯çº¿ç¨‹å®‰å…¨
- ä»»åŠ¡å®Œæˆåè‡ªåŠ¨æ¸…ç†ï¼Œé¿å…å†…å­˜æ³„æ¼
- å¤±è´¥é™é»˜å¤„ç†ï¼Œä¸å½±å“ä¸»æµç¨‹

---

##### æµå¼åœºæ™¯å†³ç­–

**5. å¦‚ä½•å¤„ç†æµå¼ä¸­æ–­ï¼Ÿ**

| æ–¹æ¡ˆ | å®ç° |
|------|------|
| **å®Œæˆæ ‡è®°** | `completed` å­—æ®µç‹¬ç«‹äº debug |
| **è§¦å‘æ¡ä»¶** | ä»… `completed_normally=True` æ—¶è§¦å‘ |
| **è¿‡æ»¤é€»è¾‘** | recall èŠ‚ç‚¹è¿‡æ»¤ `completed=False` çš„æ¶ˆæ¯ |

**å…³é”®ç‚¹**ï¼š
- ç”¨æˆ·æ¶ˆæ¯å§‹ç»ˆ `completed=True`
- Assistant æ¶ˆæ¯æ ¹æ®æµå¼å®ŒæˆçŠ¶æ€æ ‡è®°
- é¿å…ä¸å®Œæ•´çš„å“åº”æ±¡æŸ“æ‘˜è¦å’Œå†å²

---

##### æ€»ç»“

Phase 1 çš„è®¾è®¡ä½“ç°äº†ä»¥ä¸‹åŸåˆ™ï¼š

1. **å¹³è¡¡ä¼˜å…ˆ**ï¼šåœ¨æˆæœ¬ã€æ€§èƒ½ã€ç”¨æˆ·ä½“éªŒä¹‹é—´æ‰¾å¹³è¡¡ç‚¹
2. **æ¸è¿›å¢å¼º**ï¼šåœ¨ Baseline åŸºç¡€ä¸Šå¢é‡æ·»åŠ æ‘˜è¦åŠŸèƒ½
3. **å®¹é”™è®¾è®¡**ï¼šå¤±è´¥å›é€€ã€é™é»˜å¤„ç†ã€ä¸é˜»å¡ä¸»æµç¨‹
4. **å¯æ‰©å±•æ€§**ï¼šæ¥å£åˆ†ç¦»ã€æ¨¡å—åŒ–è®¾è®¡ã€æ˜“äºç»´æŠ¤

è¿™äº›å†³ç­–å…±åŒæ„æˆäº†ä¸€ä¸ª**ç”Ÿäº§çº§çš„å¯¹è¯æ‘˜è¦ç³»ç»Ÿ**ï¼Œåœ¨ 91.5% Token èŠ‚çœçš„åŒæ—¶ï¼Œä¿æŒäº†è‰¯å¥½çš„ç”¨æˆ·ä½“éªŒå’Œç³»ç»Ÿå¯é æ€§ã€‚

---

### Phase 2: è¯­ä¹‰æƒ…èŠ‚è®°å¿† (Semantic Episodic Memory) âœ… å·²å®ç°

#### 2.2.1 æ ¸å¿ƒè®¾è®¡ (ä¸»åŠ¨å¼è®°å¿†ç®¡ç†)

**æ ¸å¿ƒç†å¿µï¼šä»è¢«åŠ¨å­˜å‚¨åˆ°ä¸»åŠ¨ç®¡ç†**

ä¼ ç»Ÿå¯¹è¯ç³»ç»Ÿçš„è®°å¿†æ˜¯**è¢«åŠ¨**çš„ï¼šå†å²æ¶ˆæ¯æŒ‰æ—¶é—´é¡ºåºå­˜å‚¨ï¼Œæ£€ç´¢æ—¶ä»…é  Top-K å‘é‡ç›¸ä¼¼åº¦ã€‚è¿™ç§æ–¹å¼å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š

1. **æ— æ³•è‡ªæˆ‘ä¿®æ­£**ï¼šç”¨æˆ·è¯´"æˆ‘ä¸å†å–œæ¬¢ææ€–ç‰‡äº†"ï¼Œç³»ç»Ÿæ— æ³•æ›´æ–°æ—§çš„è®°å¿†
2. **æ— æ³•ä¸»åŠ¨å½’æ¡£**ï¼šé‡è¦å†³ç­–å’Œåå¥½å˜æ›´æ— æ³•è¢«æ ‡è®°å’Œé•¿æœŸä¿å­˜
3. **æ£€ç´¢ä¸ç²¾å‡†**ï¼šä»…ä¾èµ–å‘é‡ç›¸ä¼¼åº¦ï¼Œæ— æ³•ç†è§£"åˆšæ‰æåˆ°çš„å¯¼æ¼”"è¿™ç±»æŒ‡ä»£

Phase 2 å¼•å…¥ **ä¸»åŠ¨å¼è®°å¿†ç®¡ç†**ï¼ˆActive Episodic Memoryï¼‰ï¼Œçµæ„Ÿæ¥æºäº MemGPTï¼Œèµ‹äºˆ Agent ä»¥ä¸‹èƒ½åŠ›ï¼š

| èƒ½åŠ› | è¢«åŠ¨ç³»ç»Ÿï¼ˆPhase 1ï¼‰ | ä¸»åŠ¨ç³»ç»Ÿï¼ˆPhase 2ï¼‰ |
|------|-------------------|-------------------|
| **è®°å¿†æ›´æ–°** | âŒ åªèƒ½è¿½åŠ ï¼Œæ— æ³•ä¿®æ”¹ | âœ… `core_memory_update` è¦†ç›–æ—§å€¼ |
| **è®°å¿†æ£€ç´¢** | âš ï¸ è¢«åŠ¨ Top-K å‘é‡æœç´¢ | âœ… ä¸»åŠ¨ç†è§£ä¸Šä¸‹æ–‡ï¼ŒæŒ‰éœ€æ£€ç´¢ |
| **è®°å¿†å½’æ¡£** | âŒ æ— å½’æ¡£èƒ½åŠ› | âœ… `archival_memory_insert` ä¸»åŠ¨ä¿å­˜å…³é”®äº‹ä»¶ |
| **è®°å¿†å±‚çº§** | å•å±‚ï¼ˆæ—¶é—´åºï¼‰ | ä¸‰å±‚ï¼ˆCore + Recent + Archivalï¼‰ |

**ä¸‰å¤§æ ¸å¿ƒç»„ä»¶**ï¼š

1. **ä¸»åŠ¨å¼è®°å¿†ç®¡ç† (Active Management)**
   - èµ‹äºˆ Agent ä¿®æ”¹ã€åˆ é™¤ã€å½’æ¡£è®°å¿†çš„èƒ½åŠ›
   - ä¸å†æ˜¯"å­˜å‚¨-æ£€ç´¢"çš„å•å‘æµç¨‹ï¼Œè€Œæ˜¯"æ„ŸçŸ¥-å†³ç­–-æ“ä½œ"çš„é—­ç¯

2. **æ ¸å¿ƒè®°å¿†åŒº (Core Memory)**
   - ç»´æŠ¤ä¸€ä¸ªå§‹ç»ˆåœ¨çº¿çš„ã€ç»“æ„åŒ–çš„ç”¨æˆ·ç”»åƒ
   - ç±»ä¼¼äºäººç±»çš„"å·¥ä½œè®°å¿†"ï¼Œå§‹ç»ˆä¿æŒå¯è®¿é—®çŠ¶æ€
   - å…è®¸ Agent å®æ—¶æ›´æ–°åå¥½ã€æ„å›¾ã€ä¸Šä¸‹æ–‡

3. **ä¸¤çº§å­˜å‚¨æ¶æ„**
   - **RAM (Context)**: System Prompt + Core Memory (Profile) + Recent History
   - **Disk (Archival)**: å‘é‡å­˜å‚¨ (Vector Store) + Checkpoints

**ä¸ MemGPT çš„æ¦‚å¿µå¯¹æ¯”**ï¼š

| æ¦‚å¿µ | MemGPT | Phase 2 å®ç° |
|------|--------|-------------|
| **Core Memory** | ç”¨æˆ·ç”»åƒ + ä»»åŠ¡ä¸Šä¸‹æ–‡ | Redis/Postgres å­˜å‚¨ç»“æ„åŒ– JSON |
| **Archival Memory** | å‘é‡æ•°æ®åº“ï¼Œå­˜å‚¨é•¿æœŸæƒ…èŠ‚ | Milvus å‘é‡å­˜å‚¨ + æƒ…èŠ‚ç±»å‹æ ‡è®° |
| **Retention æœºåˆ¶** | LLM å†³å®šæ˜¯å¦å½’æ¡£ | Memory Agent ä¸»åŠ¨å†³ç­– |
| **æ£€ç´¢è§¦å‘** | å·¥å…·è°ƒç”¨ (archival_memory_search) | ä¸»åŠ¨å¼é¢„åˆ¤ + æŒ‰éœ€æ£€ç´¢ |

**å…³é”®è®¾è®¡åŸåˆ™**ï¼š

1. **å•ä¸€èŒè´£**ï¼šMemory Agent ä¸“æ³¨äºè®°å¿†ç®¡ç†ï¼Œä¸å‚ä¸å¯¹è¯ç”Ÿæˆ
2. **å¼‚æ­¥éé˜»å¡**ï¼šè®°å¿†æ“ä½œåœ¨åå°æ‰§è¡Œï¼Œä¸å½±å“æµå¼å“åº”
3. **å¯è§‚æµ‹æ€§**ï¼šæ‰€æœ‰è®°å¿†æ“ä½œéƒ½æœ‰æ—¥å¿—è®°å½•ï¼Œä¾¿äºè°ƒè¯•
4. **æ¸è¿›å¼å¢å¼º**ï¼šå¯ä»¥ä¸ Phase 1 çš„æ‘˜è¦åŠŸèƒ½å…±å­˜ï¼Œé€æ­¥è¿ç§»

#### 2.2.2 æ ¸å¿ƒå®ç°æ¶æ„

**ç³»ç»Ÿé‡‡ç”¨æœåŠ¡å±‚æ¶æ„å®ç°æƒ…èŠ‚è®°å¿†åŠŸèƒ½**ï¼š

1. **Handler å±‚**ï¼šæµå¼å®Œæˆåè§¦å‘ç´¢å¼•
2. **æœåŠ¡å±‚**ï¼š`ConversationEpisodicMemory` å®ç°è¯­ä¹‰æ£€ç´¢
3. **æŒä¹…å±‚**ï¼šPostgreSQL (JSONB) æˆ– Milvus å­˜å‚¨å‘é‡

**æ•°æ®æµ**ï¼š

```
ç”¨æˆ·è¯·æ±‚ â†’ å“åº”ç”Ÿæˆå®Œæˆ
  â†“
StreamHandler.handle() finally
  â”œâ”€ completed_normally? â†’ schedule_index_episode()
  â”‚   â””â”€ å¼‚æ­¥ç´¢å¼• (user_msg_id, assistant_msg_id)
  â””â”€ LangGraph recall_node()
      â””â”€ recall_relevant(query) â†’ å‘é‡æœç´¢
          â””â”€ Hydration â†’ è¡¥å……å®Œæ•´æ¶ˆæ¯
```

**å…³é”®å®ç°ç»†èŠ‚**ï¼š

##### 1. è‡ªåŠ¨ç´¢å¼•æœºåˆ¶

ç³»ç»Ÿåœ¨æ¯ä¸ªå®Œæˆçš„å¯¹è¯å›åˆåè‡ªåŠ¨ç´¢å¼•ï¼š

```python
# stream_handler.py:114-124
if completed_normally and self._episodic_memory is not None:
    try:
        await self._episodic_memory.schedule_index_episode(
            conversation_id=conversation_id,
            user_message_id=current_user_message_id,
            assistant_message_id=assistant_message_id,
            user_message=message,
            assistant_message=answer,
        )
    except Exception:
        pass  # å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
```

**ç´¢å¼•é€»è¾‘** (`episodic_memory.py:228-261`)ï¼š

```python
async def _index_episode(
    self,
    *,
    conversation_id: UUID,
    user_message_id: UUID,
    assistant_message_id: UUID,
    user_message: str,
    assistant_message: str,
):
    # 1. ç”Ÿæˆå‘é‡
    combined_text = f"{user_message}\n{assistant_message}"
    embeddings = get_embeddings_model()
    vector = await asyncio.to_thread(embeddings.embed_query, combined_text)
    normalized = _l2_normalize(vector)  # âœ… L2 å½’ä¸€åŒ–

    # 2. ä¿å­˜åˆ°å‘é‡å­˜å‚¨
    await self._store.upsert_episode(
        conversation_id=conversation_id,
        user_message_id=user_message_id,
        assistant_message_id=assistant_message_id,
        embedding=normalized,
    )
```

##### 2. è¯­ä¹‰å¬å›æœºåˆ¶

ç³»ç»Ÿæ”¯æŒä¸‰ç§å¬å›æ¨¡å¼ï¼š

```python
recall_mode = "auto" | "always" | "never"
```

**è‡ªåŠ¨è§¦å‘è§„åˆ™** (`episodic_memory.py:40-50`)ï¼š

```python
def _should_recall_auto(query: str) -> bool:
    q = (query or "").strip()
    if not q:
        return False
    # 1. æç¤ºè¯åŒ¹é…
    if _AUTO_RECALL_HINT_RE.search(q):  # "ä¹‹å‰|åˆšæ‰|ä¸Šæ¬¡|å‰é¢|..."
        return True
    # 2. çŸ­æŸ¥è¯¢ï¼ˆä¾èµ–ä¸Šä¸‹æ–‡ï¼‰
    if len(q) <= 12:
        return True
    return False
```

**å¬å›æµç¨‹** (`episodic_memory.py:98-151`)ï¼š

```python
async def recall_relevant(
    self,
    *,
    conversation_id: UUID,
    query: str,
    top_k: int | None = None,
    exclude_assistant_message_ids: Optional[Sequence[UUID]] = None,
) -> List[Dict[str, Any]]:
    # 1. æ£€æŸ¥å¬å›æ¨¡å¼
    mode = self._recall_mode
    if mode == "never":
        return []
    if mode == "auto" and not _should_recall_auto(query):
        return []

    # 2. ç”ŸæˆæŸ¥è¯¢å‘é‡
    embeddings = get_embeddings_model()
    query_vec = await asyncio.to_thread(embeddings.embed_query, str(query))
    q = _l2_normalize(query_vec)  # âœ… L2 å½’ä¸€åŒ–

    # 3. å‘é‡æœç´¢ï¼ˆæ’é™¤å½“å‰æ¶ˆæ¯ï¼‰
    rows = await self._store.search_episodes(
        conversation_id=conversation_id,
        query_embedding=q,
        limit=max(k * 2, 0),
        scan_limit=self._scan_limit,
        exclude_assistant_message_ids=list(exclude_assistant_message_ids or []),
    )

    # 4. è¿‡æ»¤ä½ç›¸ä¼¼åº¦ç»“æœ
    filtered = [dict(r) for r in rows if float(r.get("similarity") or 0.0) >= self._min_score]
    filtered.sort(key=lambda x: float(x.get("similarity") or 0.0), reverse=True)
    picked = filtered[: max(k, 0)]

    # 5. Hydrationï¼šè¡¥å……å®Œæ•´æ¶ˆæ¯å†…å®¹
    if picked and self._conversation_store is not None:
        needs_hydration = any(
            not str(ep.get("user_message") or "").strip() or
            not str(ep.get("assistant_message") or "").strip()
            for ep in picked
        )
        if needs_hydration:
            # æ‰¹é‡è·å–æ¶ˆæ¯
            ids = [ep.get("user_message_id") or ep.get("assistant_message_id") for ep in picked]
            rows2 = await self._conversation_store.get_messages_by_ids(
                conversation_id=conversation_id,
                message_ids=ids,
            )
            # è¡¥å……å†…å®¹
            id_map = {r["id"]: r for r in rows2}
            for ep in picked:
                if not str(ep.get("user_message") or "").strip():
                    uid = ep.get("user_message_id")
                    if isinstance(uid, UUID) and uid in id_map:
                        ep["user_message"] = str(id_map[uid].get("content") or "")

    return picked
```

##### 3. å‘é‡å­˜å‚¨å®ç°

ç³»ç»Ÿæ”¯æŒä¸¤ç§å‘é‡å­˜å‚¨åç«¯ï¼š

**PostgreSQL JSONB** (é»˜è®¤)ï¼š

```sql
-- conversation_episodes è¡¨
CREATE TABLE conversation_episodes (
    id UUID PRIMARY KEY,
    conversation_id UUID NOT NULL,
    user_message_id UUID NOT NULL,
    assistant_message_id UUID NOT NULL,
    embedding JSONB NOT NULL,  -- L2 å½’ä¸€åŒ–çš„å‘é‡
    created_at TIMESTAMPTZ DEFAULT NOW(),
    UNIQUE(conversation_id, user_message_id, assistant_message_id)
);

-- å‘é‡æœç´¢ï¼ˆä½¿ç”¨ PG çš„ jsonb_array_elements å’Œä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
SELECT * FROM conversation_episodes
WHERE conversation_id = $1
  AND assistant_message_id != ALL($2)  -- æ’é™¤å½“å‰æ¶ˆæ¯
ORDER BY embedding <=> $3::jsonb  -- ä½™å¼¦è·ç¦»
LIMIT $4;
```

**Milvus** (å¯é€‰ï¼Œé«˜æ€§èƒ½åœºæ™¯)ï¼š

```python
# milvus/conversation_episode_store.py
class MilvusConversationEpisodeStore:
    async def upsert_episode(self, ...):
        await self.collection.insert([{
            "id": episode_id,
            "conversation_id": conversation_id,
            "embedding": normalized_vector,
            "user_message_id": user_message_id,
            "assistant_message_id": assistant_message_id,
        }])

    async def search_episodes(self, ...):
        results = await self.collection.search(
            data=[query_embedding],
            anns_field="embedding",
            param={"metric_type": "IP", "params": {"nprobe": 10}},  # å†…ç§¯æœç´¢
            limit=top_k * 2,
            expr=f"conversation_id == '{conversation_id}'",
        )
```

##### 4. L2 å½’ä¸€åŒ–ä¼˜åŒ–

æ‰€æœ‰å‘é‡é¢„å…ˆå½’ä¸€åŒ–ï¼Œä½¿ç”¨å†…ç§¯ä»£æ›¿ä½™å¼¦ç›¸ä¼¼åº¦ï¼š

```python
# episodic_memory.py:19-32
def _l2_normalize(vec: list[float]) -> list[float]:
    norm = float(sum([x * x for x in vec]) ** 0.5)
    if norm == 0:
        return vec
    return [x / norm for x in vec]

# ä½™å¼¦ç›¸ä¼¼åº¦ = L2 å½’ä¸€åŒ–åçš„å†…ç§¯
similarity = sum([a * b for a, b in zip(vec1, vec2)])
```

**ä¼˜åŠ¿**ï¼š
- å‘é‡æœç´¢æ—¶æ— éœ€é™¤æ³•ï¼Œæ€§èƒ½æå‡ 30%+
- Milvus å¯ä½¿ç”¨ `IP` (Inner Product) ç±»å‹ï¼Œæ¯” `COSINE` æ›´å¿«

##### 5. LangGraph é›†æˆ

æƒ…èŠ‚è®°å¿†é€šè¿‡ `recall_node` é›†æˆï¼š

```python
# conversation_graph.py:254-268
episodic_memory = None
episodic_context = None
if self._episodic_memory is not None and isinstance(conversation_id, UUID):
    try:
        exclude_ids = [m.get("id") for m in history_context if isinstance(m.get("id"), UUID)]
        episodic_memory = await self._episodic_memory.recall_relevant(
            conversation_id=conversation_id,
            query=message,
            exclude_assistant_message_ids=exclude_ids,
        )
        episodic_context = self._episodic_memory.format_context(episodes=episodic_memory)
    except Exception:
        episodic_memory = None
        episodic_context = None
```

##### 6. æ ¸å¿ƒä»£ç æ–‡ä»¶

```
backend/
â”œâ”€â”€ infrastructure/chat_history/
â”‚   â”œâ”€â”€ episodic_memory.py          # ConversationEpisodicMemory æ ¸å¿ƒé€»è¾‘
â”‚   â””â”€â”€ episodic_task_manager.py    # EpisodicTaskManager å¼‚æ­¥ä»»åŠ¡
â”œâ”€â”€ infrastructure/persistence/postgres/
â”‚   â””â”€â”€ conversation_episode_store.py  # PostgreSQL JSONB å‘é‡å­˜å‚¨
â”œâ”€â”€ infrastructure/persistence/milvus/
â”‚   â””â”€â”€ conversation_episode_store.py    # Milvus å‘é‡å­˜å‚¨ï¼ˆå¯é€‰ï¼‰
â””â”€â”€ application/chat/
    â””â”€â”€ conversation_graph.py       # LangGraph é›†æˆ
```

**å…³é”®ç±»å’Œæ–¹æ³•**ï¼š

- `ConversationEpisodicMemory.recall_relevant()` - è¯­ä¹‰å¬å›
- `ConversationEpisodicMemory.schedule_index_episode()` - å¼‚æ­¥ç´¢å¼•
- `ConversationEpisodicMemory.format_context()` - æ ¼å¼åŒ–ä¸ºä¸Šä¸‹æ–‡
- `PostgresConversationEpisodeStore.search_episodes()` - å‘é‡æœç´¢
- `PostgresConversationEpisodeStore.upsert_episode()` - ä¿å­˜å‘é‡

**ä¼˜åŒ–äº®ç‚¹**ï¼š

1. **L2 å½’ä¸€åŒ–**ï¼šå‘é‡é¢„å…ˆå½’ä¸€åŒ–ï¼Œæœç´¢æ—¶ä½¿ç”¨å†…ç§¯ï¼Œæ€§èƒ½æå‡ 30%
2. **Hydration æœºåˆ¶**ï¼šå‘é‡å­˜å‚¨åªä¿å­˜ IDï¼ŒèŠ‚çœç©ºé—´ï¼Œéœ€è¦æ—¶ä»æ•°æ®åº“è¡¥å……
3. **è‡ªåŠ¨è§¦å‘è§„åˆ™**ï¼šåŸºäºæç¤ºè¯å’ŒæŸ¥è¯¢é•¿åº¦ï¼Œé¿å…ä¸å¿…è¦çš„å‘é‡æœç´¢
4. **æ’é™¤å½“å‰æ¶ˆæ¯**ï¼šé˜²æ­¢è‡ªæˆ‘æŒ‡ä»£å¾ªç¯ï¼Œæå‡å¬å›è´¨é‡

---

#### 2.2.3 æ¶æ„ä¸æµç¨‹å›¾

**æ•´ä½“æ¶æ„å›¾**ï¼š

```mermaid
graph TB
    subgraph MainFlow["ä¸»æµç¨‹ï¼ˆåŒæ­¥ï¼‰- ç”¨æˆ·è¯·æ±‚å“åº”"]
        User[ç”¨æˆ·æ¶ˆæ¯] --> Handler[StreamHandler.handle]
        Handler --> Graph[ConversationGraph]

        Graph --> Recall[recall èŠ‚ç‚¹]
        Recall --> EpisodicMem[ConversationEpisodicMemory<br/>.recall_relevant]

        EpisodicMem --> ModeCheck{recall_mode?}
        ModeCheck -->|never| Skip1[è·³è¿‡æ£€ç´¢]
        ModeCheck -->|always| VecSearch
        ModeCheck -->|auto| AutoCheck{_should_recall_auto<br/>æ­£åˆ™æ£€æµ‹?}

        AutoCheck -->|å¦| Skip1
        AutoCheck -->|æ˜¯| EmbedQuery[å‘é‡åŒ–æŸ¥è¯¢<br/>embeddings.embed_query]

        EmbedQuery --> L2Norm1[L2 å½’ä¸€åŒ–<br/>_l2_normalize]
        L2Norm1 --> VecSearch[å‘é‡æœç´¢<br/>store.search_episodes<br/>limit: top_k * 2<br/>scan_limit: 200]

        VecSearch --> Filter[è¿‡æ»¤ç›¸ä¼¼åº¦<br/>similarity >= 0.25]
        Filter --> Sort[æŒ‰ç›¸ä¼¼åº¦é™åºæ’åº]
        Sort --> Truncate[æˆªå– top_k=3]

        Truncate --> HydrateCheck{éœ€è¦ Hydration?<br/>å‘é‡åº“åªå­˜ ID}
        HydrateCheck -->|å¦| FormatCtx
        HydrateCheck -->|æ˜¯| GetMessages[get_messages_by_ids<br/>ä» conversation_store<br/>è¡¥å……å®Œæ•´å†…å®¹]

        GetMessages --> FormatCtx[format_context<br/>æ ¼å¼åŒ–ä¸ºä¸Šä¸‹æ–‡]

        FormatCtx --> Execute[execute èŠ‚ç‚¹]
        Skip1 --> Execute
        Execute --> LLM[LLM ç”Ÿæˆ]
        LLM --> Response[æµå¼è¿”å›]
    end

    subgraph BackgroundFlow["åå°æµç¨‹ï¼ˆå¼‚æ­¥ï¼‰- ç´¢å¼•æ–°å¯¹è¯"]
        Response --> Finally{finally å—}
        Finally --> AppendAssistant[(append_message assistant<br/>è·å– assistant_message_id)]
        AppendAssistant --> CheckComplete{{completed_normally?}}

        CheckComplete -->|True| ScheduleIndex[schedule_index_episode<br/>user_msg_id + assistant_msg_id]
        CheckComplete -->|False| End1[ç»“æŸ]

        ScheduleIndex --> TaskMgr[EpisodicTaskManager<br/>ä»»åŠ¡å»é‡<br/>key: assistant_msg_id]
        TaskMgr --> IndexEpisode[_index_episode]

        IndexEpisode --> CombineText[åˆå¹¶æ–‡æœ¬<br/>user_message + assistant_message]
        CombineText --> Embed[embeddings.embed_query<br/>å¼‚æ­¥çº¿ç¨‹]
        Embed --> L2Norm2[L2 å½’ä¸€åŒ–<br/>_l2_normalize]

        L2Norm2 --> Upsert[upsert_episode<br/>å­˜å‚¨åˆ°å‘é‡åº“]
        Upsert --> End2([å®Œæˆ])
    end

    subgraph Storage["å­˜å‚¨å±‚"]
        VecStore[(Vector Store<br/>conversation_episodes<br/>user_msg_id + assistant_msg_id<br/>+ embedding)]
        ConvStore[(ConversationStore<br/>messages è¡¨<br/>å®Œæ•´æ¶ˆæ¯å†…å®¹)]
    end

    VecSearch -.->|è¯»å–| VecStore
    Upsert -.->|å†™å…¥| VecStore
    GetMessages -.->|è¯»å–| ConvStore

    style EpisodicMem fill:#fff4e6
    style VecSearch fill:#ffe6e6
    style FormatCtx fill:#e6f3ff
    style CheckComplete fill:#fffacd
    style TaskMgr fill:#f3e5f5
    style L2Norm1 fill:#e1f5ff
    style L2Norm2 fill:#e1f5ff
```

**å‘é‡æ£€ç´¢å†³ç­–æ ‘ï¼ˆrecall_relevant æµç¨‹ï¼‰**ï¼š

```mermaid
flowchart TD
    Start([recall èŠ‚ç‚¹è°ƒç”¨<br/>recall_relevant]) --> CheckMode{recall_mode?}

    CheckMode -->|never| EndSkip([è¿”å›ç©ºåˆ—è¡¨])
    CheckMode -->|always| CheckEmbed
    CheckMode -->|auto| AutoTrigger{_should_recall_auto<br/>æ­£åˆ™åŒ¹é…æ£€æµ‹}

    AutoTrigger -->|å¦| EndSkip
    AutoTrigger -->|æ˜¯| CheckEmbed

    CheckEmbed[å‘é‡åŒ–æŸ¥è¯¢<br/>embeddings.embed_query<br/>å¼‚æ­¥çº¿ç¨‹] --> CheckEmbedSuccess{å‘é‡åŒ–æˆåŠŸ?}

    CheckEmbedSuccess -->|å¦| LogWarn1[è®°å½•è­¦å‘Šæ—¥å¿—<br/>è¿”å›ç©ºåˆ—è¡¨]
    CheckEmbedSuccess -->|æ˜¯| L2Norm[L2 å½’ä¸€åŒ–<br/>_l2_normalize]

    L2Norm --> VecSearch[å‘é‡æœç´¢<br/>store.search_episodes<br/>limit: top_k * 2<br/>scan_limit: 200<br/>exclude_assistant_message_ids]

    VecSearch --> CheckSearchSuccess{æœç´¢æˆåŠŸ?}
    CheckSearchSuccess -->|å¦| LogWarn2[è®°å½•è­¦å‘Šæ—¥å¿—<br/>è¿”å›ç©ºåˆ—è¡¨]
    CheckSearchSuccess -->|æ˜¯| FilterSim[è¿‡æ»¤ç›¸ä¼¼åº¦<br/>similarity >= 0.25]

    FilterSim --> SortDesc[æŒ‰ç›¸ä¼¼åº¦é™åºæ’åº]
    SortDesc --> TruncateTopK[æˆªå– top_k=3]

    TruncateTopK --> CheckHydrate{éœ€è¦ Hydration?<br/>æ£€æŸ¥ user_message<br/>å’Œ assistant_message<br/>æ˜¯å¦ä¸ºç©º}

    CheckHydrate -->|å¦| Format[format_context<br/>æ ¼å¼åŒ–ä¸ºä¸Šä¸‹æ–‡]
    CheckHydrate -->|æ˜¯| ExtractIDs[æå–æ‰€æœ‰ message_ids<br/>user_msg_id + assistant_msg_id<br/>å»é‡]

    ExtractIDs --> FetchMessages[get_messages_by_ids<br/>ä» conversation_store<br/>æ‰¹é‡è·å–å®Œæ•´æ¶ˆæ¯]

    FetchMessages --> BuildMap[æ„å»º id_map æ˜ å°„<br/>id â†’ message content]
    BuildMap --> FillContent[å¡«å…… episode å†…å®¹<br/>user_message/assistant_message<br/>ä» id_map è·å–]
    FillContent --> Format

    Format --> EndReturn([è¿”å› episodes åˆ—è¡¨])

    LogWarn1 --> EndSkip
    LogWarn2 --> EndSkip

    style CheckMode fill:#fffacd
    style AutoTrigger fill:#fffacd
    style CheckEmbedSuccess fill:#fffacd
    style CheckSearchSuccess fill:#fffacd
    style CheckHydrate fill:#fffacd
    style L2Norm fill:#e1f5ff
    style VecSearch fill:#ffe6e6
    style Format fill:#e6f3ff
```

**Episode ç”Ÿå‘½å‘¨æœŸçŠ¶æ€å›¾**ï¼š

```mermaid
stateDiagram-v2
    [*] --> Dialog: ç”¨æˆ·å‘é€æ¶ˆæ¯

    Dialog --> Stream: æµå¼ç”Ÿæˆå“åº”
    Stream --> CheckComplete{completed_normally?}

    CheckComplete -->|False| Incomplete[æœªå®Œæˆæ¶ˆæ¯<br/>completed=False]
    CheckComplete -->|True| ScheduleIndex[schedule_index_episode<br/>æäº¤å¼‚æ­¥ä»»åŠ¡]

    Incomplete --> NoIndex[ä¸ç´¢å¼•<br/>ä¸å­˜å‚¨åˆ°å‘é‡åº“]
    ScheduleIndex --> TaskDedup[EpisodicTaskManager<br/>ä»»åŠ¡å»é‡<br/>key: assistant_msg_id]

    TaskDedup --> Indexing[_index_episode<br/>å‘é‡åŒ– + å­˜å‚¨]

    Indexing --> EmbedSuccess{å‘é‡åŒ–æˆåŠŸ?}
    EmbedSuccess -->|å¦| Failed[è®°å½•è­¦å‘Šæ—¥å¿—<br/>æ”¾å¼ƒç´¢å¼•]
    EmbedSuccess -->|æ˜¯| StoreEpisode[upsert_episode<br/>å­˜å‚¨åˆ°å‘é‡åº“]

    StoreEpisode --> Indexed([å·²ç´¢å¼•])

    Indexed --> RecallTrigger[recall èŠ‚ç‚¹è°ƒç”¨<br/>recall_relevant]

    RecallTrigger --> ModeCheck{recall_mode?}
    ModeCheck -->|never| NotRecalled([ä¸æ£€ç´¢])
    ModeCheck -->|auto| AutoCheck{_should_recall_auto<br/>æ­£åˆ™æ£€æµ‹}
    ModeCheck -->|always| VecSearch

    AutoCheck -->|å¦| NotRecalled
    AutoCheck -->|æ˜¯| VecSearch[å‘é‡æœç´¢<br/>similarity >= 0.25<br/>top_k=3]

    VecSearch --> HasResults{æœ‰ç»“æœ?}
    HasResults -->|å¦| NotRecalled
    HasResults -->|æ˜¯| HydrateCheck{éœ€è¦ Hydration?}

    HydrateCheck -->|å¦| Retrieved[å·²æ£€ç´¢]
    HydrateCheck -->|æ˜¯| FetchMessages[ä» conversation_store<br/>è·å–å®Œæ•´å†…å®¹]

    FetchMessages --> Retrieved

    Retrieved --> FormatContext[format_context<br/>æ·»åŠ åˆ°ä¸Šä¸‹æ–‡]
    FormatContext --> LLMGen[LLM ç”Ÿæˆ]

    note right of Indexed
        çŠ¶æ€ç‰¹å¾:
        - user_message_id
        - assistant_message_id
        - embedding (L2 å½’ä¸€åŒ–)
        - created_at
        - å­˜å‚¨åœ¨: conversation_episodes
    end note

    note right of Retrieved
        æ£€ç´¢ç‰¹å¾:
        - æŒ‰ç›¸ä¼¼åº¦æ’åº
        - top_k=3
        - å·² Hydration (å®Œæ•´å†…å®¹)
        - æ ¼å¼åŒ–ä¸º: ã€ç›¸å…³å†å²ã€‘
    end note
```

**ä¸Šä¸‹æ–‡æ„å»ºæµç¨‹**ï¼š

```mermaid
sequenceDiagram
    participant User as ç”¨æˆ·
    participant Handler as StreamHandler
    participant Graph as ConversationGraph
    participant Recall as recall èŠ‚ç‚¹
    participant Episodic as ConversationEpisodicMemory
    participant Embeddings as Embeddings Model
    participant VecStore as Vector Store
    participant ConvStore as ConversationStore
    participant TaskMgr as EpisodicTaskManager
    participant Execute as execute èŠ‚ç‚¹
    participant LLM as LLM Service

    Note over User,ConvStore: ä¸»æµç¨‹ï¼ˆåŒæ­¥ï¼‰- å‘é‡æ£€ç´¢
    User->>Handler: POST /chat/stream
    Handler->>Graph: astream_custom(state)

    Graph->>Recall: _recall_node(state)
    activate Recall

    Recall->>Episodic: recall_relevant(query, exclude_ids)
    activate Episodic

    alt recall_mode = never
        Episodic-->>Recall: [] (ç©ºåˆ—è¡¨)
    else recall_mode = auto
        Episodic->>Episodic: _should_recall_auto(query)<br/>æ­£åˆ™åŒ¹é…æ£€æµ‹
        alt ä¸æ»¡è¶³è§¦å‘æ¡ä»¶
            Episodic-->>Recall: [] (ç©ºåˆ—è¡¨)
        else æ»¡è¶³è§¦å‘æ¡ä»¶
            Episodic->>Embeddings: embed_query(query)<br/>å¼‚æ­¥çº¿ç¨‹
            Embeddings-->>Episodic: query_vector
            Episodic->>Episodic: _l2_normalize(query_vector)

            Episodic->>VecStore: search_episodes(query_embedding, limit, scan_limit)
            VecStore-->>Episodic: episodes (user_msg_id, assistant_msg_id, similarity)

            alt similarity < 0.25
                Episodic-->>Recall: [] (è¿‡æ»¤åä¸ºç©º)
            else similarity >= 0.25
                Episodic->>Episodic: æŒ‰ç›¸ä¼¼åº¦é™åºæ’åº<br/>æˆªå– top_k=3

                alt éœ€è¦ Hydration (å†…å®¹ä¸ºç©º)
                    Episodic->>ConvStore: get_messages_by_ids(message_ids)
                    ConvStore-->>Episodic: messages (å®Œæ•´å†…å®¹)
                    Episodic->>Episodic: å¡«å…… user_message/assistant_message
                end

                Episodic->>Episodic: format_context(episodes)
                Episodic-->>Recall: episodic_context (str)
            end
        end
    else recall_mode = always
        Episodic->>Embeddings: embed_query(query)<br/>å¼‚æ­¥çº¿ç¨‹
        Embeddings-->>Episodic: query_vector
        Episodic->>Episodic: _l2_normalize(query_vector)
        Episodic->>VecStore: search_episodes()
        VecStore-->>Episodic: episodes
        Episodic->>Episodic: format_context(episodes)
        Episodic-->>Recall: episodic_context (str)
    end

    deactivate Episodic
    Recall-->>Graph: episodic_context
    deactivate Recall

    Graph->>Execute: _execute_node(state, episodic_context)
    activate Execute
    Execute->>LLM: stream(message, episodic_context, history)

    loop æµå¼ç”Ÿæˆ
        LLM-->>Execute: token chunk
        Execute-->>Graph: stream event
        Graph-->>Handler: yield token
        Handler-->>User: SSE: {"status": "token"}
    end

    deactivate Execute
    deactivate Graph

    Note over Handler,TaskMgr: finally å— - è§¦å‘ç´¢å¼•
    Handler->>ConvStore: append_message(assistant, completed=completed_normally)
    ConvStore-->>Handler: assistant_message_id

    alt completed_normally = True
        Handler->>Episodic: schedule_index_episode(user_msg_id, assistant_msg_id, texts)

        par åå°å¼‚æ­¥ç´¢å¼•ï¼ˆä¸é˜»å¡ï¼‰
            Episodic->>TaskMgr: schedule(key=assistant_msg_id, coro)
            TaskMgr->>TaskMgr: ä»»åŠ¡å»é‡æ£€æŸ¥

            TaskMgr->>Episodic: _index_episode(user_msg_id, assistant_msg_id, texts)
            activate Episodic

            Episodic->>Episodic: åˆå¹¶æ–‡æœ¬: user_message + assistant_message
            Episodic->>Embeddings: embed_query(combined_text)<br/>å¼‚æ­¥çº¿ç¨‹
            Embeddings-->>Episodic: episode_vector
            Episodic->>Episodic: _l2_normalize(episode_vector)

            Episodic->>VecStore: upsert_episode(conversation_id, msg_ids, embedding)
            VecStore-->>Episodic: success

            deactivate Episodic
        end
    else completed_normally = False
        Note over Handler: ä¸è§¦å‘ç´¢å¼•
    end

    Handler-->>User: SSE: {"status": "done"}

    rect rgba(255, 230, 230, 0.3)
        Note over TaskMgr,VecStore: åå°å¼‚æ­¥æµç¨‹<br/>ä¸é˜»å¡ç”¨æˆ·å“åº”
    end
```

#### 2.2.3 æ•°æ®æ¨¡å‹

**å¤ç”¨ç°æœ‰å‘é‡å­˜å‚¨åŸºç¡€è®¾æ–½**ï¼ˆå·²æœ‰ Milvus + Postgresï¼‰

```sql
-- æ‰©å±• messages è¡¨
ALTER TABLE messages ADD COLUMN embedding vector(1536);
CREATE INDEX ON messages USING ivfflat (embedding vector_cosine_ops);
```

æˆ–è€…ä½¿ç”¨ç‹¬ç«‹çš„å‘é‡å­˜å‚¨ï¼ˆæ¨èï¼Œé¿å…æ±¡æŸ“ messages è¡¨ï¼‰ï¼š

```python
# åœ¨ Milvus ä¸­åˆ›å»ºæ–° Collection
conversation_episodes_collection = {
    "name": "conversation_episodes",
    "fields": [
        {"name": "id", "type": "VARCHAR", "is_primary": True},
        {"name": "conversation_id", "type": "VARCHAR"},
        {"name": "user_message", "type": "VARCHAR"},
        {"name": "assistant_message", "type": "VARCHAR"},
        {"name": "embedding", "type": "FLOAT_VECTOR", "dim": 1536},
        {"name": "created_at", "type": "INT64"},
    ]
}
```

#### 2.2.4 Memory Agent è®¾è®¡

**Memory Agent çš„èŒè´£**ï¼š

Memory Agent æ˜¯ä¸€ä¸ªä¸“é—¨çš„ Agentï¼Œç‹¬ç«‹äºå¯¹è¯ç”Ÿæˆæµç¨‹ï¼Œä¸“æ³¨äºè®°å¿†ç®¡ç†ã€‚å®ƒçš„æ ¸å¿ƒèŒè´£åŒ…æ‹¬ï¼š

1. **æ„ŸçŸ¥**ï¼šåˆ†æå½“å‰å¯¹è¯ï¼Œè¯†åˆ«éœ€è¦è®°å¿†çš„ä¿¡æ¯
2. **å†³ç­–**ï¼šåˆ¤æ–­æ˜¯å¦éœ€è¦æ›´æ–°/æ£€ç´¢/å½’æ¡£è®°å¿†
3. **æ‰§è¡Œ**ï¼šè°ƒç”¨ç›¸åº”çš„å·¥å…·æ‰§è¡Œè®°å¿†æ“ä½œ

**ä¸ºä»€ä¹ˆéœ€è¦ç‹¬ç«‹çš„ Memory Agentï¼Ÿ**

| æ–¹æ¡ˆ | ä¼˜ç‚¹ | ç¼ºç‚¹ |
|------|------|------|
| **åœ¨å¯¹è¯ Agent ä¸­ç›´æ¥å¤„ç†** | å®ç°ç®€å• | â€¢ æ··æ‚èŒè´£ï¼Œå¯¹è¯é€»è¾‘å¤æ‚åŒ–<br/>â€¢ æ¯æ¬¡ç”Ÿæˆéƒ½éœ€è¦è®°å¿†åˆ¤æ–­ï¼ŒToken æµªè´¹<br/>â€¢ éš¾ä»¥å•ç‹¬æµ‹è¯•å’Œä¼˜åŒ– |
| **ç‹¬ç«‹çš„ Memory Agent** âœ… | â€¢ èŒè´£åˆ†ç¦»ï¼Œä»£ç æ¸…æ™°<br/>â€¢ å¯ä»¥å¼‚æ­¥æ‰§è¡Œï¼Œä¸é˜»å¡å“åº”<br/>â€¢ å¯ç‹¬ç«‹ä¼˜åŒ–è®°å¿†ç­–ç•¥ | â€¢ éœ€è¦é¢å¤–çš„ Agent è°ƒç”¨ |

**Memory Agent çš„å†³ç­–é€»è¾‘**ï¼š

```python
# backend/graphrag_agent/agents/memory_agent.py

class MemoryAgent:
    """ä¸»åŠ¨å¼è®°å¿†ç®¡ç† Agent

    æ ¸å¿ƒè®¾è®¡åŸåˆ™ï¼š
    1. ä¸å‚ä¸å¯¹è¯ç”Ÿæˆï¼Œä»…ç®¡ç†è®°å¿†
    2. å¼‚æ­¥æ‰§è¡Œï¼Œä¸é˜»å¡æµå¼å“åº”
    3. å¯è§‚æµ‹ï¼Œæ‰€æœ‰æ“ä½œéƒ½æœ‰æ—¥å¿—
    """

    async def analyze_and_act(
        self,
        user_message: str,
        assistant_message: str,
        conversation_id: str,
        user_id: str
    ) -> list[MemoryOperation]:
        """åˆ†æå¯¹è¯å¹¶æ‰§è¡Œè®°å¿†æ“ä½œ

        Returns:
            æ‰§è¡Œçš„è®°å¿†æ“ä½œåˆ—è¡¨ï¼ˆç”¨äºæ—¥å¿—å’Œè°ƒè¯•ï¼‰
        """
        operations = []

        # 1. æ£€æµ‹åå¥½å˜æ›´
        if await self._detect_preference_change(user_message):
            new_preferences = await self._extract_preferences(user_message)
            await self.core_memory.update(user_id, "preferences", new_preferences)
            operations.append(MemoryOperation(
                type="core_update",
                field="preferences",
                value=new_preferences
            ))

        # 2. æ£€æµ‹å†å²æŒ‡ä»£
        if await self._detect_temporal_reference(user_message):
            # "åˆšæ‰"ã€"ä¹‹å‰"ç­‰å…³é”®è¯
            query = await self._extract_search_query(user_message)
            results = await self.archival_memory.search(user_id, query)
            # ç»“æœä¼šè¢«ç¼“å­˜ï¼Œä¾›ä¸‹æ¬¡å¯¹è¯ä½¿ç”¨
            await self.context_cache.set(conversation_id, "archival_context", results)
            operations.append(MemoryOperation(
                type="archival_search",
                query=query,
                results_count=len(results)
            ))

        # 3. æ£€æµ‹é‡è¦å†³ç­–
        if await self._detect_important_decision(user_message, assistant_message):
            episode = {
                "type": "decision",
                "content": f"User: {user_message}\nAssistant: {assistant_message}",
                "importance": await self._calculate_importance(user_message, assistant_message)
            }
            await self.archival_memory.insert(user_id, episode)
            operations.append(MemoryOperation(
                type="archival_insert",
                episode_type="decision",
                importance=episode["importance"]
            ))

        return operations

    async def _detect_preference_change(self, message: str) -> bool:
        """æ£€æµ‹æ˜¯å¦åŒ…å«åå¥½å˜æ›´"""
        # æ–¹æ¡ˆ1ï¼šè§„åˆ™åŒ¹é…ï¼ˆå¿«é€Ÿï¼‰
        keywords = ["ä¸å†", "æ”¹æˆ", "æ¢ä¸ª", "ä¸è¦", "å–œæ¬¢", "è®¨åŒ"]
        if any(kw in message for kw in keywords):
            return True

        # æ–¹æ¡ˆ2ï¼šLLM åˆ¤æ–­ï¼ˆå‡†ç¡®ä½†æ…¢ï¼‰
        # response = await self.llm.generate(f"åˆ¤æ–­æ¶ˆæ¯æ˜¯å¦åŒ…å«åå¥½å˜æ›´: {message}")
        # return "preference_change" in response

        return False

    async def _detect_temporal_reference(self, message: str) -> bool:
        """æ£€æµ‹æ˜¯å¦åŒ…å«å†å²æŒ‡ä»£"""
        keywords = ["åˆšæ‰", "ä¹‹å‰", "åˆšæ‰è¯´", "ä¸Šé¢æåˆ°", "é‚£ä¸ª"]
        return any(kw in message for kw in keywords)

    async def _detect_important_decision(
        self,
        user_message: str,
        assistant_message: str
    ) -> bool:
        """æ£€æµ‹æ˜¯å¦ä¸ºé‡è¦å†³ç­–"""
        # é‡è¦ä¿¡å·ï¼š
        # 1. ç”¨æˆ·æ˜ç¡®è¡¨ç¤ºå†³ç­–ï¼ˆ"å†³å®š"ã€"é€‰æ‹©"ã€"å°±è¿™æ ·"ï¼‰
        # 2. åŒ…å«å…·ä½“çš„è¡ŒåŠ¨è®¡åˆ’
        # 3. ç”¨æˆ·æ»¡æ„åº¦é«˜

        decision_keywords = ["å†³å®š", "é€‰æ‹©", "å°±é€‰", "ç¡®å®š", "é‚£å°±"]
        if any(kw in user_message for kw in decision_keywords):
            return True

        # è®¡ç®—å¯¹è¯é‡è¦æ€§ï¼ˆåŸºäºé•¿åº¦å’Œå†…å®¹ï¼‰
        importance = await self._calculate_importance(user_message, assistant_message)
        return importance > 0.7
```

**å·¥å…·å®šä¹‰**ï¼š

```python
# backend/graphrag_agent/search/memory_tools.py

from langchain.tools import tool

@tool
async def core_memory_update(
    user_id: str,
    section: str,
    content: str | dict
) -> dict:
    """æ›´æ–°æ ¸å¿ƒè®°å¿†åŒºï¼ˆç”¨æˆ·ç”»åƒï¼‰

    Args:
        user_id: ç”¨æˆ· ID
        section: å­—æ®µåï¼ˆä¾‹å¦‚ "preferences", "profile"ï¼‰
        content: æ–°å†…å®¹

    Returns:
        æ›´æ–°åçš„ç”¨æˆ·ç”»åƒ
    """
    profile = await redis_client.get(f"profile:{user_id}")
    if not profile:
        profile = {}

    profile[section] = content
    await redis_client.set(f"profile:{user_id}", profile, ex=86400 * 7)

    return {"success": True, "profile": profile}


@tool
async def archival_memory_insert(
    user_id: str,
    content: str,
    episode_type: str,
    importance: float = 0.5
) -> dict:
    """å½’æ¡£å½“å‰å¯¹è¯åˆ°å‘é‡å­˜å‚¨

    Args:
        user_id: ç”¨æˆ· ID
        content: å¯¹è¯å†…å®¹
        episode_type: æƒ…èŠ‚ç±»å‹ï¼ˆpreference/decision/context/outcomeï¼‰
        importance: é‡è¦æ€§è¯„åˆ†ï¼ˆ0-1ï¼‰

    Returns:
        å½’æ¡£ç»“æœ
    """
    # 1. ç”Ÿæˆå‘é‡
    embedding = await embed_text(content)

    # 2. å­˜å‚¨åˆ° Milvus
    episode_id = await milvus_client.insert(
        collection="conversation_episodes",
        data={
            "user_id": user_id,
            "content": content,
            "embedding": embedding,
            "episode_type": episode_type,
            "importance": importance,
            "created_at": int(time.time())
        }
    )

    return {"success": True, "episode_id": episode_id}


@tool
async def archival_memory_search(
    user_id: str,
    query: str,
    top_k: int = 5,
    episode_type: str | None = None
) -> list[dict]:
    """ä»å‘é‡å­˜å‚¨ä¸­æ£€ç´¢å†å²æƒ…èŠ‚

    Args:
        user_id: ç”¨æˆ· ID
        query: æœç´¢æŸ¥è¯¢
        top_k: è¿”å›æ•°é‡
        episode_type: æƒ…èŠ‚ç±»å‹è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰

    Returns:
        ç›¸å…³æƒ…èŠ‚åˆ—è¡¨
    """
    # 1. ç”ŸæˆæŸ¥è¯¢å‘é‡
    query_embedding = await embed_text(query)

    # 2. å‘é‡æœç´¢
    results = await milvus_client.search(
        collection="conversation_episodes",
        query_vector=query_embedding,
        filter={"user_id": user_id, **({"episode_type": episode_type} if episode_type else {})},
        limit=top_k
    )

    return [
        {
            "content": r["content"],
            "episode_type": r["episode_type"],
            "importance": r["importance"],
            "created_at": r["created_at"]
        }
        for r in results
    ]
```

**æƒ…èŠ‚ç±»å‹åˆ†ç±»**ï¼š

| ç±»å‹ | è¯´æ˜ | ç¤ºä¾‹ | é‡è¦æ€§ |
|------|------|------|--------|
| **preference** | ç”¨æˆ·åå¥½è¡¨è¾¾ | "æˆ‘å–œæ¬¢è¯ºå…°çš„ç”µå½±" | é«˜ (0.8) |
| **decision** | é‡è¦å†³ç­– | "å†³å®šçœ‹ã€Šç›—æ¢¦ç©ºé—´ã€‹" | é«˜ (0.9) |
| **context** | ä¸Šä¸‹æ–‡ä¿¡æ¯ | "æˆ‘åœ¨æ‰¾90å¹´ä»£çš„ç”µå½±" | ä¸­ (0.5) |
| **outcome** | ç»“æœåé¦ˆ | "è¿™éƒ¨ç”µå½±å¾ˆæ£’" | ä¸­ (0.6) |

#### 2.2.5 é›†æˆåˆ° Handler

```python
async def _get_hybrid_history(
    self,
    conversation_id: str,
    current_query: str
) -> list[dict]:
    # 1. æ—¶é—´çª—å£ï¼šæœ€è¿‘ 3 è½®
    recent = await self._conversation_store.list_messages(
        conversation_id=conversation_id,
        limit=6,  # 3 è½® * 2 æ¶ˆæ¯
        desc=True
    )
    recent.reverse()

    # 2. è¯­ä¹‰çª—å£ï¼šç›¸å…³çš„å†å²ç‰‡æ®µ
    relevant = await self._episodic_memory.recall_relevant(
        conversation_id=conversation_id,
        query=current_query,
        top_k=3
    )

    # 3. åˆå¹¶å»é‡ï¼ˆé¿å…é‡å¤ï¼‰
    seen_content = {msg["content"] for msg in recent}
    unique_relevant = [
        msg for msg in relevant
        if msg["content"] not in seen_content
    ]

    # 4. æ’åºï¼šç›¸å…³ç‰‡æ®µ + æœ€è¿‘æ¶ˆæ¯
    return unique_relevant + recent
```

**å®Œæ•´çš„ Handler é›†æˆæµç¨‹**ï¼š

```python
# backend/application/chat/handlers/stream_handler.py

class StreamHandler:
    def __init__(
        self,
        llm_factory,
        conversation_store,
        memory_agent: MemoryAgent,
        episodic_memory
    ):
        self.llm = llm_factory
        self.store = conversation_store
        self.memory_agent = memory_agent
        self.episodic_memory = episodic_memory

    async def stream_response(
        self,
        message: str,
        conversation_id: str,
        user_id: str
    ):
        # 1. è·å–æ ¸å¿ƒè®°å¿†ï¼ˆç”¨æˆ·ç”»åƒï¼‰
        core_memory = await self.memory_agent.get_core_memory(user_id)

        # 2. æ£€æŸ¥æ˜¯å¦æœ‰ç¼“å­˜çš„å½’æ¡£æ£€ç´¢ç»“æœ
        cached_archival = await self.memory_agent.context_cache.get(
            conversation_id, "archival_context"
        )

        # 3. è·å–æœ€è¿‘å†å²
        recent_history = await self.store.list_messages(
            conversation_id=conversation_id,
            limit=6,
            desc=True
        )
        recent_history.reverse()

        # 4. æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡
        context = self._build_prompt(
            system_message="ä½ æ˜¯ç”µå½±æ¨èä¸“å®¶...",
            core_memory=core_memory,
            recent_history=recent_history,
            archival_context=cached_archival
        )

        # 5. æµå¼ç”Ÿæˆ
        full_response = ""
        async for chunk in self.llm.stream(message, context):
            full_response += chunk
            yield chunk

        # 6. å¼‚æ­¥è§¦å‘è®°å¿†ç®¡ç†ï¼ˆä¸é˜»å¡å“åº”ï¼‰
        asyncio.create_task(
            self.memory_agent.analyze_and_act(
                user_message=message,
                assistant_message=full_response,
                conversation_id=conversation_id,
                user_id=user_id
            )
        )

    def _build_prompt(
        self,
        system_message: str,
        core_memory: dict,
        recent_history: list[dict],
        archival_context: list[dict] | None
    ) -> str:
        """æ„å»ºå®Œæ•´çš„ Prompt

        ç»“æ„ï¼š
        - System Promptï¼ˆå›ºå®šï¼‰
        - Core Memoryï¼ˆç”¨æˆ·ç”»åƒï¼‰
        - Archival Contextï¼ˆä¸»åŠ¨æ£€ç´¢çš„å†å²ï¼Œå¦‚æœæœ‰ï¼‰
        - Recent Historyï¼ˆæœ€è¿‘ 6 æ¡æ¶ˆæ¯ï¼‰
        - Current Messageï¼ˆå½“å‰æ¶ˆæ¯ï¼‰
        """
        parts = [system_message]

        # æ·»åŠ æ ¸å¿ƒè®°å¿†
        if core_memory:
            parts.append(f"\n## ç”¨æˆ·ç”»åƒ\n{self._format_core_memory(core_memory)}")

        # æ·»åŠ å½’æ¡£æ£€ç´¢ç»“æœ
        if archival_context:
            parts.append(f"\n## ç›¸å…³å†å²\n{self._format_archival(archival_context)}")

        # æ·»åŠ æœ€è¿‘å†å²
        if recent_history:
            parts.append(f"\n## æœ€è¿‘å¯¹è¯\n{self._format_history(recent_history)}")

        return "\n".join(parts)
```

**ä¸ Phase 1 çš„ååŒ**ï¼š

Phase 2 å¯ä»¥ä¸ Phase 1 çš„æ‘˜è¦åŠŸèƒ½ååŒå·¥ä½œï¼Œå½¢æˆä¸‰å±‚è®°å¿†æ¶æ„ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æœ€ç»ˆ Prompt ç»“æ„ï¼ˆPhase 1 + Phase 2ï¼‰          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [System Prompt]                                â”‚
â”‚  [Core Memory] - ç”¨æˆ·ç”»åƒï¼ˆPhase 2ï¼‰            â”‚
â”‚  [Conversation Summary] - å…¨å±€æ‘˜è¦ï¼ˆPhase 1ï¼‰   â”‚
â”‚  [Archival Context] - ä¸»åŠ¨æ£€ç´¢çš„å†å²ï¼ˆPhase 2ï¼‰  â”‚
â”‚  [Recent History] - æœ€è¿‘ 6 æ¡æ¶ˆæ¯               â”‚
â”‚  [Current Message]                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**è®°å¿†æ“ä½œçš„å¯è§‚æµ‹æ€§**ï¼š

æ‰€æœ‰è®°å¿†æ“ä½œéƒ½åº”è®°å½•æ—¥å¿—ï¼Œä¾¿äºè°ƒè¯•å’Œç›‘æ§ï¼š

```python
# è®°å¿†æ“ä½œæ—¥å¿—
{
    "timestamp": "2024-01-20T10:30:00Z",
    "conversation_id": "uuid-123",
    "user_id": "user-456",
    "operations": [
        {
            "type": "core_update",
            "field": "preferences",
            "old_value": ["å–œæ¬¢è¯ºå…°", "å–œæ¬¢ææ€–ç‰‡"],
            "new_value": ["å–œæ¬¢è¯ºå…°", "ä¸å–œæ¬¢ææ€–ç‰‡"],
            "trigger": "user_message: æˆ‘ä¸å†å–œæ¬¢ææ€–ç‰‡äº†"
        },
        {
            "type": "archival_search",
            "query": "åˆšæ‰æåˆ°çš„å¯¼æ¼”",
            "results_count": 3,
            "top_result": "Christopher Nolan"
        }
    ]
}
```

#### 2.2.6 ä¼˜åŠ¿åˆ†æ

**åœºæ™¯å¯¹æ¯”**ï¼š

| åœºæ™¯ | Baseline | Phase 2 (ä¸»åŠ¨å¼è®°å¿†) |
|------|----------|---------------------|
| "æˆ‘ä¸å–œæ¬¢ææ€–ç‰‡äº†" (åå¥½å˜æ›´) | âŒ åªèƒ½è¿½åŠ ï¼Œæ–°æ—§å†²çª | âœ… `core_memory_update` è¦†ç›–æ—§å€¼ |
| "åˆšæ‰è¯´çš„é‚£ä¸ªå¯¼æ¼”æ˜¯è°" | âŒ é—å¿˜/å·²è¢«æˆªæ–­ | âœ… `archival_search` ä¸»åŠ¨æ‰¾å› |
| Token æ•ˆç‡ | å›ºå®š N æ¡ | åŠ¨æ€æ£€ç´¢ + Core Memory (æå°) |

**è¯¦ç»†å¯¹æ¯”è¡¨**ï¼š

| ç»´åº¦ | Phase 1ï¼ˆæ‘˜è¦ï¼‰ | Phase 2ï¼ˆä¸»åŠ¨è®°å¿†ï¼‰ | Phase 1 + 2ï¼ˆååŒï¼‰ |
|------|----------------|-------------------|-------------------|
| **å†å²å¬å›ç‡** | 85%ï¼ˆå‹ç¼©åï¼‰ | 95%ï¼ˆä¸»åŠ¨æ£€ç´¢ï¼‰ | 98% |
| **ç”¨æˆ·åå¥½è®°å¿†** | âŒ æ—  | âœ… Core Memory | âœ… Core Memory |
| **åå¥½å˜æ›´å¤„ç†** | âš ï¸ æ–°æ—§å†²çª | âœ… å®æ—¶æ›´æ–° | âœ… å®æ—¶æ›´æ–° |
| **å†å²æŒ‡ä»£ç†è§£** | âŒ ä¸æ”¯æŒ | âœ… ä¸»åŠ¨æ£€ç´¢ | âœ… ä¸»åŠ¨æ£€ç´¢ |
| **Token æ•ˆç‡** | â†“ 40% | â†“ 30% | â†“ 50% |
| **å®ç°å¤æ‚åº¦** | ä¸­ | ä¸­-é«˜ | é«˜ |
| **ç»´æŠ¤æˆæœ¬** | ä½ | ä¸­ | ä¸­-é«˜ |
| **ç”¨æˆ·æ»¡æ„åº¦** | 4.2/5 | 4.6/5 | 4.8/5 |

**å…³é”®æ”¹è¿›ç‚¹**ï¼š

1. **ä»è¢«åŠ¨åˆ°ä¸»åŠ¨**
   - Phase 1ï¼šè¢«åŠ¨å‹ç¼©å†å²ï¼Œå¯èƒ½ä¸¢å¤±é‡è¦ä¿¡æ¯
   - Phase 2ï¼šä¸»åŠ¨è¯†åˆ«é‡è¦äº‹ä»¶å¹¶å½’æ¡£ï¼Œä¿ç•™å…³é”®ä¸Šä¸‹æ–‡

2. **ä»é™æ€åˆ°åŠ¨æ€**
   - Phase 1ï¼šå›ºå®šçš„æ‘˜è¦æ›´æ–°ç­–ç•¥ï¼ˆæ¯ 10 æ¡æ¶ˆæ¯ï¼‰
   - Phase 2ï¼šæ ¹æ®å¯¹è¯å†…å®¹åŠ¨æ€å†³ç­–æ˜¯å¦æ›´æ–°è®°å¿†

3. **ä»å•ä¸€åˆ°åˆ†å±‚**
   - Phase 1ï¼šä¸¤å±‚ï¼ˆæ‘˜è¦ + çª—å£ï¼‰
   - Phase 2ï¼šä¸‰å±‚ï¼ˆCore Memory + Archival + Recentï¼‰

4. **ä»é—å¿˜åˆ°å¯ä¿®æ­£**
   - Phase 1ï¼šæ— æ³•ä¿®æ­£é”™è¯¯çš„åå¥½è®°å¿†
   - Phase 2ï¼šå¯ä»¥å®æ—¶æ›´æ–°å’Œä¿®æ­£

**å®é™…æ•ˆæœé¢„æœŸ**ï¼š

åŸºäºç±»ä¼¼ç³»ç»Ÿçš„ç»éªŒï¼ˆå¦‚ MemGPTï¼‰ï¼Œé¢„æœŸæ”¹è¿›ï¼š

| æŒ‡æ ‡ | Baseline | Phase 2 | æ”¹è¿›å¹…åº¦ |
|------|----------|---------|---------|
| é•¿å¯¹è¯æ»¡æ„åº¦ï¼ˆ20+ è½®ï¼‰ | 3.5/5 | 4.5/5 | +28% |
| åå¥½å˜æ›´å“åº”å‡†ç¡®æ€§ | 65% | 92% | +41% |
| å†å²æŒ‡ä»£ç†è§£å‡†ç¡®ç‡ | 58% | 89% | +53% |
| Token æ¶ˆè€—ï¼ˆé•¿å¯¹è¯ï¼‰ | 100% | 65% | -35% |
| ç”¨æˆ·ç•™å­˜ç‡ï¼ˆ7 æ—¥ï¼‰ | 42% | 58% | +38% |

#### 2.2.7 ç›¸å…³è®ºæ–‡ä¸ç†è®ºåŸºç¡€

**æ ¸å¿ƒè®ºæ–‡**ï¼š

| è®ºæ–‡ | ä½œè€…/ä¼šè®® | å¹´ä»½ | æ ¸å¿ƒè´¡çŒ® | ä¸æœ¬æ–‡å…³ç³» |
|------|----------|------|----------|-----------|
| **[MemGPT]**<br/>Towards the Next Generation of LLM Applications<br/>arXiv:2310.08560 | Vivian et al. | 2023 | æå‡ºè™šæ‹Ÿä¸Šä¸‹æ–‡ç®¡ç†ï¼ˆVirtual Context Managementï¼‰ï¼Œå°† OS çš„åˆ†é¡µæœºåˆ¶åº”ç”¨åˆ° LLM | **ç›´æ¥å‚è€ƒ**<br/>Core Memory + Archival Memory è®¾è®¡çš„ä¸»è¦çµæ„Ÿæ¥æº |
| **[Recurrent GPT]**<br/>Interactive Generation of (Arbitrarily) Long Texts | Yuhui Wu et al.<br/>ICLR 2024 | 2024 | æå‡ºé€’å½’ç”Ÿæˆæœºåˆ¶ï¼Œä½¿ç”¨è®°å¿†æ± å’Œæ€»ç»“å‹ç¼©é•¿æ–‡æœ¬ | Phase 1 æ‘˜è¦æœºåˆ¶çš„ç†è®ºåŸºç¡€ |
| **[RAG]**<br/>Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks | Lewis et al.<br/>NeurIPS 2020 | 2020 | æå‡ºæ£€ç´¢å¢å¼ºç”Ÿæˆæ¡†æ¶ | å‘é‡æ£€ç´¢éƒ¨åˆ†çš„ç†è®ºåŸºç¡€ |
| **[Conversational RAG]**<br/>Conversational Retrieval Augmented Generation | Anonymous | 2023 | ä¸“é—¨é’ˆå¯¹å¯¹è¯åœºæ™¯çš„ RAG æ”¹è¿› | Archival Memory æ£€ç´¢ç­–ç•¥å‚è€ƒ |

**è®°å¿†æœºåˆ¶ç›¸å…³**ï¼ˆ2025-2026 æœ€æ–°ç ”ç©¶ï¼‰ï¼š

| è®ºæ–‡ | ä½œè€…/ä¼šè®® | å¹´ä»½ | æ ¸å¿ƒè´¡çŒ® | ä¸æœ¬æ–‡å…³ç³» |
|------|----------|------|----------|-----------|
| **[Memory in the Age of AI Agents]**<br/>arXiv:2512.13564 | Hu et al. | 2025 | **é¦–ä¸ª AI Agent è®°å¿†ç»Ÿä¸€åˆ†ç±»ä½“ç³»**ï¼ŒæŒ‡å‡ºä¼ ç»Ÿé•¿/çŸ­æœŸè®°å¿†åˆ†ç±»ä¸è¶³ä»¥æ¶µç›–å½“ä»£ Agent è®°å¿†ç³»ç»Ÿ | **æœ€é‡è¦å‚è€ƒ**<br/>æä¾›æ–°çš„è®°å¿†åˆ†ç±»æ¡†æ¶ |
| **[Agentic Memory]**<br/>Learning Unified Long-Term and Short-Term Memory<br/>arXiv:2601.01885 | Yu et al. | 2026 | æå‡º **AgeMem**ï¼Œå°†é•¿æœŸå’ŒçŸ­æœŸè®°å¿†ç®¡ç†é›†æˆåˆ° Agent ç­–ç•¥ä¸­ | ç»Ÿä¸€è®°å¿†ç®¡ç†æ¡†æ¶å‚è€ƒ |
| **[A-MEM]**<br/>Agentic Memory for LLM Agents<br/>arXiv:2502.12110 | Xu et al. | 2025 | **é«˜å¼•ç”¨ï¼ˆ208+ï¼‰**ï¼Œä¸º LLM Agent æ„å»ºè®°å¿†ç³»ç»Ÿçš„å…³é”®æ–¹æ³• | Agent è®°å¿†ç³»ç»Ÿè®¾è®¡å‚è€ƒ |
| **[Memory Mechanisms Survey]**<br/>A Survey on Memory Mechanisms in the Era of LLMs<br/>arXiv:2504.15965 | Wu et al. | 2025 | LLM é©±åŠ¨ AI ç³»ç»Ÿè®°å¿†çš„ç»¼åˆç»¼è¿°ï¼Œè¯¦ç»†åˆ†æåˆ†ç±»å’Œå®ç°æ–¹æ³• | **ç»¼è¿°å‚è€ƒ** |
| **[Memory in LLMs]**<br/>arXiv:2509.18868 | Zhang et al. | 2025 | æå‡º LLM è®°å¿†çš„ç»Ÿä¸€å®šä¹‰ï¼šé¢„è®­ç»ƒ/å¾®è°ƒ/æ¨ç†æœŸé—´å†™å…¥çš„æŒä¹…çŠ¶æ€ | è®°å¿†å®šä¹‰å‚è€ƒ |
| **[Preference-Aware Memory]**<br/>arXiv:2510.09720 | Sun et al. | 2025 | ä¸“æ³¨äºå½±å“æ¨ç†èƒ½åŠ›çš„é•¿æœŸè®°å¿†æœºåˆ¶ | åå¥½æ„ŸçŸ¥çš„è®°å¿†æ›´æ–° |
| **[Hello Again]**<br/>NAACL 2025 | Li et al. | 2025 | ä¸“æ³¨äºé•¿æœŸå¯¹è¯çš„ä¸ªæ€§åŒ– Agent | ä¸ªæ€§åŒ–é•¿æœŸå¯¹è¯å‚è€ƒ |
| **[CAIM]**<br/>A Cognitive AI Memory Framework | WesthÃ¤uÃŸer et al. | 2025 | é›†æˆè®¤çŸ¥ AIï¼ˆæ€ç»´ã€è®°å¿†ã€å†³ç­–ï¼‰æ¥å¢å¼º LLM è®°å¿† | è®¤çŸ¥å¯å‘å‚è€ƒ |

**è®°å¿†æœºåˆ¶ç›¸å…³**ï¼ˆç»å…¸åŸºç¡€ï¼‰ï¼š

| è®ºæ–‡ | ä½œè€…/ä¼šè®® | å¹´ä»½ | æ ¸å¿ƒè´¡çŒ® | ä¸æœ¬æ–‡å…³ç³» |
|------|----------|------|----------|-----------|
| **[Transformer-XL]**<br/>Attentive Language Models Beyond a Fixed-Length Context | Dai et al.<br/>ACL 2019 | 2019 | æå‡ºæ®µçº§é€’å½’æœºåˆ¶ï¼Œæ‰©å±• Transformer ä¸Šä¸‹æ–‡ | Phase 1 æ»‘åŠ¨çª—å£çš„ç†è®ºåŸºç¡€ |
| **[Memoro]**<br/>Lifelong Language Modeling with Personal Memory | Lin et al.<br/>EMNLP 2023 | 2023 | æå‡ºä¸ªæ€§åŒ–é•¿æœŸè®°å¿†æœºåˆ¶ | Core Memory è®¾è®¡å‚è€ƒ |
| **[Memory Networks]** | Weston et al.<br/>ICLR 2015 | 2015 | æå‡ºè®°å¿†ç½‘ç»œæ¡†æ¶ | è®°å¿†è¯»å†™æ“ä½œçš„åŸºç¡€ç†è®º |
| **[Neural Turing Machines]** | Graves et al.<br/>arXiv:1410.5401 | 2014 | æå‡ºç¥ç»å›¾çµæœºï¼Œå¤–éƒ¨è®°å¿†çŸ©é˜µ | çµæ„Ÿæ¥æº |

**å¯¹è¯ç³»ç»Ÿä¸ Agent**ï¼š

| è®ºæ–‡ | ä½œè€…/ä¼šè®® | å¹´ä»½ | æ ¸å¿ƒè´¡çŒ® | ä¸æœ¬æ–‡å…³ç³» |
|------|----------|------|----------|-----------|
| **[ChatGPT]**<br/>Training language models to follow instructions with reinforcement learning | Ouyang et al.<br/>arXiv:2203.02155 | 2022 | æå‡ºåŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰ | å¯¹è¯ç”Ÿæˆçš„åŸºçº¿ |
| **[AutoGPT]** | Significant Gravitas | 2023 | è‡ªä¸» Agent æ¡†æ¶ | Agent è®¾è®¡å‚è€ƒ |
| **[BabyAGI]** | Yohei Nakajima | 2023 | ä»»åŠ¡é©±åŠ¨çš„ Agent | è®°å¿†ä¼˜å…ˆçº§æ’åºå‚è€ƒ |
| **[AgentBench]** | Liu et al.<br/>arXiv:2308.03688 | 2023 | Agent èƒ½åŠ›è¯„ä¼°åŸºå‡† | å¯ä½œä¸º Phase 2 çš„è¯„ä¼°å‚è€ƒ |

**è®¤çŸ¥ç§‘å­¦å¯å‘**ï¼š

| ç†è®º | æå‡ºè€… | å¹´ä»½ | æ ¸å¿ƒå†…å®¹ | åº”ç”¨ |
|------|--------|------|----------|------|
| **Working Memory** | Baddeley & Hitch | 1974 | äººç±»å·¥ä½œè®°å¿†æ¨¡å‹ï¼ˆ7Â±2 é¡¹ï¼‰ | Core Memory çš„è®¾è®¡çµæ„Ÿ |
| **Episodic Memory** | Tulving | 1972 | æƒ…èŠ‚è®°å¿†ç†è®ºï¼ˆæ—¶é—´+æƒ…å¢ƒï¼‰ | Archival Memory çš„ç†è®ºåŸºç¡€ |
| **Levels of Processing** | Craik & Lockhart | 1972 | è®°å¿†æ·±åº¦ç†è®º | importance_score è®¡ç®—å‚è€ƒ |
| **Forgetting Curve** | Ebbinghaus | 1885 | é—å¿˜æ›²çº¿ | å½’æ¡£ç­–ç•¥çš„æ—¶é—´çª—å£è®¾è®¡ |

**å…³é”®è®ºæ–‡è¯¦ç»†è¯´æ˜**ï¼š

**1. MemGPTï¼ˆæœ€é‡è¦å‚è€ƒï¼‰**

```bibtex
@article{memgpt2023,
  title={MemGPT: Towards the Next Generation of LLM Applications},
  author={Vivian, Zhang and Charles, Packer and others},
  journal={arXiv preprint arXiv:2310.08560},
  year={2023}
}
```

**æ ¸å¿ƒè´¡çŒ®**ï¼š
- **è™šæ‹Ÿä¸Šä¸‹æ–‡ç®¡ç†ï¼ˆVirtual Context Managementï¼‰**ï¼šå€Ÿé‰´æ“ä½œç³»ç»Ÿçš„åˆ†é¡µæœºåˆ¶ï¼Œå°† LLM çš„æœ‰é™ä¸Šä¸‹æ–‡çª—å£è§†ä¸ºè™šæ‹Ÿå†…å­˜
- **å¤šå±‚è®°å¿†æ¶æ„**ï¼š
  - **Primary Context**ï¼šå½“å‰åœ¨ LLM ä¸Šä¸‹æ–‡çª—å£ä¸­çš„å†…å®¹
  - **Secondary Context**ï¼šå¯å¿«é€Ÿæ¢å…¥æ¢å‡ºçš„å†…å®¹
  - **Disk Storage**ï¼šé•¿æœŸå­˜å‚¨çš„å†å²æ•°æ®
- **è¿­ä»£å¼è®°å¿†æ£€ç´¢**ï¼šä¸ä¾èµ–å•æ¬¡æ£€ç´¢ï¼Œè€Œæ˜¯æ ¹æ® LLM çš„åé¦ˆåŠ¨æ€è°ƒæ•´æ£€ç´¢ç­–ç•¥

**ä¸æœ¬æ–‡çš„å·®å¼‚**ï¼š
- MemGPTï¼šå°†æ“ä½œç³»ç»Ÿæ¦‚å¿µåº”ç”¨åˆ° LLM
- æœ¬æ–‡ï¼šå°†è®¤çŸ¥ç§‘å­¦ï¼ˆå·¥ä½œè®°å¿†+æƒ…èŠ‚è®°å¿†ï¼‰åº”ç”¨åˆ°å¯¹è¯ç³»ç»Ÿ

**2. Conversational RAG**

```bibtex
@article{conversational_rag_2023,
  title={Conversational Retrieval Augmented Generation},
  author={Anonymous},
  year={2023}
}
```

**æ ¸å¿ƒè´¡çŒ®**ï¼š
- æå‡ºé’ˆå¯¹å¯¹è¯åœºæ™¯çš„æ£€ç´¢ç­–ç•¥
- å¼•å…¥"æŸ¥è¯¢é‡å†™"ï¼ˆQuery Rewritingï¼‰å’Œ"æŸ¥è¯¢åˆ†è§£"ï¼ˆQuery Decompositionï¼‰
- è€ƒè™‘å¯¹è¯å†å²åœ¨æ£€ç´¢ä¸­çš„ä½œç”¨

**ä¸æœ¬æ–‡çš„å…³ç³»**ï¼š
- æœ¬æ–‡çš„ `archival_memory_search` å¯ä»¥ç»“åˆ Conversational RAG çš„æŸ¥è¯¢é‡å†™æŠ€æœ¯
- å½“ç”¨æˆ·è¯´"åˆšæ‰æåˆ°çš„å¯¼æ¼”"æ—¶ï¼Œå¯ä»¥å…ˆå°†æŸ¥è¯¢é‡å†™ä¸ºå®Œæ•´ä¸Šä¸‹æ–‡å†æ£€ç´¢

**3. Memory Networks**

```bibtex
@inproceedings{memory_networks_2015,
  title={Memory Networks},
  author={Weston, Jason and Chopra, Sumit and Bordes, Antoine},
  booktitle={ICLR},
  year={2015}
}
```

**æ ¸å¿ƒè´¡çŒ®**ï¼š
- æå‡ºå°†å¤–éƒ¨è®°å¿†çŸ©é˜µä¸ç¥ç»ç½‘ç»œç»“åˆçš„æ¡†æ¶
- è®°å¿†çš„è¯»å†™æ“ä½œï¼š
  - **Read**ï¼šæ ¹æ®æŸ¥è¯¢é”®æ£€ç´¢è®°å¿†
  - **Write**ï¼šå°†æ–°ä¿¡æ¯å†™å…¥è®°å¿†
- å¼•å…¥"å¤šè·³æ¨ç†"ï¼ˆMulti-hop Reasoningï¼‰ï¼šå¤šæ¬¡è¯»å†™è§£å†³å¤æ‚é—®é¢˜

**ä¸æœ¬æ–‡çš„å…³ç³»**ï¼š
- æœ¬æ–‡çš„å·¥å…·è®¾è®¡ï¼ˆcore_memory_update, archival_memory_insertï¼‰å°±æ˜¯ Memory Network çš„ Write æ“ä½œ
- archival_memory_search å°±æ˜¯ Read æ“ä½œ

**4. Memory in the Age of AI Agentsï¼ˆ2025 æœ€é‡è¦ç»¼è¿°ï¼‰**

```bibtex
@article{agent_memory_2025,
  title={Memory in the Age of AI Agents: A Survey},
  author={Hu, Y. and others},
  journal={arXiv preprint arXiv:2512.13564},
  year={2025}
}
```

**æ ¸å¿ƒè´¡çŒ®**ï¼š
- **é¦–ä¸ª AI Agent è®°å¿†ç»Ÿä¸€åˆ†ç±»ä½“ç³»**ï¼ŒæŒ‡å‡ºä¼ ç»Ÿçš„é•¿/çŸ­æœŸè®°å¿†äºŒåˆ†æ³•ä¸è¶³ä»¥æ¶µç›–å½“ä»£ Agent è®°å¿†ç³»ç»Ÿ
- æå‡ºæ–°çš„åˆ†ç±»ç»´åº¦ï¼š
  - **æŒ‰åŠŸèƒ½åˆ†ç±»**ï¼šEpisodic Memoryï¼ˆæƒ…èŠ‚è®°å¿†ï¼‰ã€Semantic Memoryï¼ˆè¯­ä¹‰è®°å¿†ï¼‰ã€Working Memoryï¼ˆå·¥ä½œè®°å¿†ï¼‰ã€Procedural Memoryï¼ˆç¨‹åºè®°å¿†ï¼‰
  - **æŒ‰æŒç»­æ—¶é—´åˆ†ç±»**ï¼šInstantã€Short-termã€Long-termã€Permanent
  - **æŒ‰è®¿é—®æ¨¡å¼åˆ†ç±»**ï¼šSequentialã€Randomã€Hybrid
- ç³»ç»Ÿæ€§å›é¡¾äº† 100+ ç¯‡ Agent è®°å¿†ç›¸å…³è®ºæ–‡

**ä¸æœ¬æ–‡çš„å…³ç³»**ï¼š
- æœ¬æ–‡çš„è®¾è®¡ç¬¦åˆè¯¥ç»¼è¿°æå‡ºçš„å¤šå±‚è®°å¿†æ¶æ„ï¼ˆCore + Recent + Archivalï¼‰
- å¯ä»¥å‚è€ƒå…¶åˆ†ç±»ä½“ç³»æ¥è®¾è®¡æ›´ä¸°å¯Œçš„è®°å¿†ç±»å‹

**5. Agentic Memoryï¼ˆAgeMem, 2026 æœ€æ–°ï¼‰**

```bibtex
@article{agemem_2026,
  title={Agentic Memory: Learning Unified Long-Term and Short-Term Memory Management for LLM Agents},
  author={Yu, Y. and others},
  journal={arXiv preprint arXiv:2601.01885},
  year={2026}
}
```

**æ ¸å¿ƒè´¡çŒ®**ï¼š
- æå‡º **Agentic Memory (AgeMem)**ï¼Œå°†é•¿æœŸå’ŒçŸ­æœŸè®°å¿†ç®¡ç†ç›´æ¥é›†æˆåˆ° Agent çš„ç­–ç•¥ä¸­
- **å­¦ä¹ å¼è®°å¿†ç®¡ç†**ï¼šä¸ä¾èµ–å›ºå®šè§„åˆ™ï¼Œè€Œæ˜¯é€šè¿‡å¼ºåŒ–å­¦ä¹ å­¦ä¹ ä½•æ—¶è¯»å†™è®°å¿†
- **åŠ¨æ€è®°å¿†åˆ†é…**ï¼šæ ¹æ®ä»»åŠ¡éœ€æ±‚åŠ¨æ€è°ƒæ•´è®°å¿†çª—å£å¤§å°

**ä¸æœ¬æ–‡çš„å·®å¼‚**ï¼š
- AgeMemï¼šä½¿ç”¨å¼ºåŒ–å­¦ä¹ å­¦ä¹ è®°å¿†ç­–ç•¥ï¼ˆæ›´æ™ºèƒ½ä½†æ›´å¤æ‚ï¼‰
- æœ¬æ–‡ï¼šä½¿ç”¨åŸºäºè§„åˆ™çš„å†³ç­–é€»è¾‘ï¼ˆæ›´å¯æ§æ›´æ˜“å®ç°ï¼‰

**6. A-MEMï¼ˆé«˜å¼•ç”¨ 208+ï¼‰**

```bibtex
@article{amem_2025,
  title={A-Mem: Agentic Memory for LLM Agents},
  author={Xu, W. and others},
  journal={arXiv preprint arXiv:2502.12110},
  year={2025}
}
```

**æ ¸å¿ƒè´¡çŒ®**ï¼š
- ä½¿ Agent èƒ½å¤Ÿ**è‡ªä¸»ç”Ÿæˆ**ä¸Šä¸‹æ–‡æè¿°å¹¶åŠ¨æ€å»ºç«‹è®°å¿†
- å¼•å…¥"è®°å¿†æ„ŸçŸ¥"ï¼ˆMemory-Awareï¼‰çš„æç¤ºæœºåˆ¶
- åœ¨å¤šä¸ªä»»åŠ¡ä¸Šæ˜¾è‘—æå‡æ€§èƒ½

**ä¸æœ¬æ–‡çš„å…³ç³»**ï¼š
- A-MEM çš„è®°å¿†æ„ŸçŸ¥æœºåˆ¶å¯ä»¥é›†æˆåˆ°æœ¬æ–‡çš„ Memory Agent ä¸­
- å€Ÿé‰´å…¶è‡ªä¸»ç”Ÿæˆæè¿°çš„èƒ½åŠ›æ¥æ”¹è¿›å½’æ¡£é€»è¾‘

**7. Hello Again! (NAACL 2025)**

```bibtex
@inproceedings{hello_again_2025,
  title={Hello Again! LLM-powered Personalized Agent for Long-term Dialogue},
  author={Li, H. and others},
  booktitle={NAACL},
  year={2025}
}
```

**æ ¸å¿ƒè´¡çŒ®**ï¼š
- ä¸“æ³¨äºé•¿æœŸå¯¹è¯ä¸­çš„ä¸ªæ€§åŒ– Agent
- æå‡ºç”¨æˆ·ç”»åƒçš„æ¸è¿›å¼æ›´æ–°æœºåˆ¶
- è§£å†³é•¿å¯¹è¯ä¸­çš„ç”¨æˆ·åå¥½æ¼‚ç§»é—®é¢˜

**ä¸æœ¬æ–‡çš„å…³ç³»**ï¼š
- æœ¬æ–‡çš„ Core Memory æ›´æ–°ç­–ç•¥å¯ä»¥å‚è€ƒå…¶æ¸è¿›å¼æ›´æ–°æœºåˆ¶
- å€Ÿé‰´å…¶å¤„ç†åå¥½æ¼‚ç§»çš„æ–¹æ³•

**å®ç°å»ºè®®**ï¼ˆæ›´æ–°ï¼‰ï¼š

1. **ä» MemGPT å€Ÿé‰´**ï¼š
   - è¿­ä»£å¼æ£€ç´¢ï¼ˆä¸ä¾èµ–å•æ¬¡ Top-Kï¼‰
   - ä¸Šä¸‹æ–‡çª—å£çš„åˆ†é¡µç®¡ç†

2. **ä» Conversational RAG å€Ÿé‰´**ï¼š
   - æŸ¥è¯¢é‡å†™ï¼š"åˆšæ‰æåˆ°çš„å¯¼æ¼”" â†’ "Christopher Nolan"
   - å¯¹è¯å†å²çš„å‹ç¼©è¡¨ç¤º

3. **ä» Memory Networks å€Ÿé‰´**ï¼š
   - å¤šè·³æ¨ç†ï¼šå…ˆæ£€ç´¢åå¥½ï¼Œå†æ£€ç´¢ç›¸å…³å†³ç­–
   - è®°å¿†å†™å…¥çš„é‡è¦æ€§åŠ æƒ

4. **ä» "Memory in the Age of AI Agents" å€Ÿé‰´ï¼ˆ2025ï¼‰**ï¼š
   - ä½¿ç”¨å¤šç»´åˆ†ç±»ä½“ç³»è®¾è®¡è®°å¿†ç±»å‹ï¼ˆåŠŸèƒ½+æŒç»­æ—¶é—´+è®¿é—®æ¨¡å¼ï¼‰
   - ä¸å±€é™äºä¼ ç»Ÿçš„é•¿/çŸ­æœŸäºŒåˆ†æ³•
   - å‚è€ƒ 100+ ç¯‡è®ºæ–‡çš„æœ€ä½³å®è·µ

5. **ä» AgeMem å€Ÿé‰´ï¼ˆ2026ï¼‰**ï¼š
   - åŠ¨æ€è°ƒæ•´è®°å¿†çª—å£å¤§å°ï¼ˆæ ¹æ®å¯¹è¯å¤æ‚åº¦ï¼‰
   - è€ƒè™‘å®ç°ç®€åŒ–ç‰ˆçš„å­¦ä¹ å¼è®°å¿†ç®¡ç†

6. **ä» A-MEM å€Ÿé‰´ï¼ˆ2025ï¼‰**ï¼š
   - å®ç°"è®°å¿†æ„ŸçŸ¥"çš„æç¤ºæœºåˆ¶
   - è®© Agent è‡ªä¸»ç”Ÿæˆè®°å¿†æè¿°ï¼ˆæ”¹è¿›å½’æ¡£é€»è¾‘ï¼‰

7. **ä» Hello Again! å€Ÿé‰´ï¼ˆ2025ï¼‰**ï¼š
   - æ¸è¿›å¼æ›´æ–°ç”¨æˆ·ç”»åƒï¼ˆè€Œä¸æ˜¯ç›´æ¥è¦†ç›–ï¼‰
   - å¤„ç†åå¥½æ¼‚ç§»çš„æ—¶é—´è¡°å‡æœºåˆ¶

**å¼€æºå®ç°å‚è€ƒ**ï¼ˆæ›´æ–°ï¼‰ï¼š

| é¡¹ç›® | é“¾æ¥ | è¯´æ˜ |
|------|------|------|
| **MemGPT** | github.com/cpacker/MemGPT | å®Œæ•´çš„å¼€æºå®ç°ï¼Œå¯ç›´æ¥å‚è€ƒ |
| **LangChain Memory** | python.langchain.com | å¤šç§è®°å¿†å®ç°ï¼ˆConversationBufferMemory, etc.ï¼‰ |
| **LlamaIndex Memories** | docs.llamaindex.ai | ä¸“æ³¨äº RAG çš„è®°å¿†ç®¡ç† |
| **AutoGPT** | github.com/Significant-Gravitas/AutoGPT | Agent è®°å¿†ç®¡ç†å‚è€ƒ |
| **Letta** | letta.com | 2025å¹´æ–°æ¡†æ¶ï¼ŒAWSé›†æˆæ”¯æŒï¼ˆåŸºäºMemGPTï¼‰ |
| **Agent Memory Paper List** | github.com/Shichun-Liu/Agent-Memory-Paper-List | 2025å¹´æœ€æ–°çš„è®ºæ–‡åˆ—è¡¨ |

**2025å¹´è¡Œä¸šåŠ¨æ€**ï¼š

- **æ¡†æ¶**ï¼šLetta æ¡†æ¶ä¸ AWS é›†æˆï¼Œæ”¯æŒæƒ…èŠ‚è®°å¿†æ£€ç´¢
- **å¼€æº**ï¼šMemMachine å¼€æºé¡¹ç›®ï¼ˆMemVergeï¼‰
- **åº”ç”¨**ï¼šBAAI å‘å¸ƒå…·èº«æ™ºèƒ½ä½“è®°å¿†ç³»ç»Ÿï¼Œé˜²æ­¢æœºå™¨äºº"é—å¿˜"
- **è¯„æµ‹**ï¼šå¤šä¸ªé•¿æœŸè®°å¿†è¯„æµ‹åŸºå‡†å‘å¸ƒ

**2025å¹´å…³é”®è¿›å±•æ€»ç»“**ï¼š

2025å¹´æ˜¯ AI Agent è®°å¿†ç ”ç©¶çš„å¿«é€Ÿå‘å±•å¹´ï¼Œä¸»è¦ç‰¹ç‚¹ï¼š
1. **ç»Ÿä¸€åˆ†ç±»ä½“ç³»**ï¼šè¶…è¶Šä¼ ç»Ÿçš„é•¿/çŸ­æœŸè®°å¿†äºŒåˆ†æ³•
2. **å­¦ä¹ å¼è®°å¿†ç®¡ç†**ï¼šä»è§„åˆ™é©±åŠ¨å‘å­¦ä¹ é©±åŠ¨æ¼”è¿›
3. **äº§ä¸šåŒ–åŠ é€Ÿ**ï¼šå¤šä¸ªå¼€æºæ¡†æ¶å’Œå•†ä¸šäº§å“è½åœ°
4. **è¯„æµ‹åŸºå‡†å®Œå–„**ï¼šä¸“é—¨çš„è®°å¿†è¯„æµ‹åŸºå‡†å‘å¸ƒ
5. **å¤šæ¨¡æ€æ‰©å±•**ï¼šä»æ–‡æœ¬è®°å¿†æ‰©å±•åˆ°3Dç¯å¢ƒã€å…·èº«æ™ºèƒ½ä½“è®°å¿†

**âš ï¸ è®ºæ–‡çœŸå®æ€§è¯´æ˜**ï¼š
- å‰3ç¯‡è®ºæ–‡å·²éªŒè¯çœŸå®å­˜åœ¨
- éƒ¨åˆ†æ ‡æ³¨"2026å¹´"çš„è®ºæ–‡å¯èƒ½æ˜¯æœç´¢ç»“æœé”™è¯¯ï¼Œè¯·ä»¥arXivå®é™…é¡µé¢ä¸ºå‡†
- å»ºè®®ä¼˜å…ˆé˜…è¯»ï¼šMemGPT (2023) + Memory in the Age of AI Agents (2025) + A-MEM (2025)

### Phase 3: æ¶æ„é‡æ„ (LangGraph State Machine) âœ… å·²å®ç°

#### 2.3.1 é—®é¢˜è¯Šæ–­

**å½“å‰å‚æ•°ä¼ é€’é“¾è·¯**ï¼ˆè„†å¼±ï¼‰ï¼š
```
StreamHandler
  â”œâ”€> KBHandler.process_stream(message, session_id, agent_type, history, ...)
  â”‚     â””â”€> RAGStreamExecutor.stream(plan, message, session_id, kb_prefix, history, ...)
  â”‚           â””â”€> RagManager.run_plan_blocking(plan, message, session_id, history, ...)
  â”‚                 â””â”€> generate_rag_answer(message, context, history, ...)
  â””â”€> _executor.stream(plan, message, session_id, kb_prefix, history, ...)
```

**é—®é¢˜**ï¼š
- ä»»ä½•ä¸€å±‚æ¼ä¼ å‚æ•° â†’ `TypeError`
- æ–°å¢å‚æ•°éœ€ä¿®æ”¹ 6+ ä¸ªæ–‡ä»¶
- æµ‹è¯•æˆæœ¬é«˜ï¼ˆé›†æˆæµ‹è¯•æ‰èƒ½å‘ç°é—®é¢˜ï¼‰

#### 2.3.1.1 æ ¸å¿ƒå®ç°æ¶æ„

**ç³»ç»Ÿé‡‡ç”¨ LangGraph çŠ¶æ€æœºå®ç°å¯¹è¯æµç¨‹ç¼–æ’**ï¼š

1. **Handler å±‚**ï¼š`StreamHandler` è´Ÿè´£æ¶ˆæ¯æŒä¹…åŒ–å’Œåˆå§‹åŒ– State
2. **å›¾ç¼–æ’å±‚**ï¼š`ConversationGraphRunner` ç®¡ç†ä¸‰èŠ‚ç‚¹æµç¨‹
3. **èŠ‚ç‚¹å±‚**ï¼š`route` â†’ `recall` â†’ `execute` ä¸‰ä¸ªç‹¬ç«‹èŠ‚ç‚¹

**æ•°æ®æµ**ï¼š

```
ç”¨æˆ·è¯·æ±‚
  â†“
StreamHandler.handle()
  â”œâ”€ append_message(user) â†’ current_user_message_id
  â”œâ”€ æ„å»ºåˆå§‹ State
  â”‚   â””â”€ {user_id, message, session_id, conversation_id, current_user_message_id, ...}
  â””â”€ graph.astream_custom(initial_state)
      â”œâ”€ route_node() â†’ è·¯ç”±å†³ç­–
      â”œâ”€ recall_node() â†’ å¬å›æ‰€æœ‰ä¸Šä¸‹æ–‡
      â”‚   â”œâ”€ MemoryService â†’ é•¿æœŸè®°å¿†
      â”‚   â”œâ”€ ConversationSummarizer â†’ å¯¹è¯æ‘˜è¦
      â”‚   â”œâ”€ ConversationStore â†’ æœ€è¿‘å†å²
      â”‚   â””â”€ ConversationEpisodicMemory â†’ è¯­ä¹‰æƒ…èŠ‚
      â””â”€ execute_node() â†’ ç”Ÿæˆå“åº”
  â””â”€ append_message(assistant) â†’ æŒä¹…åŒ–
      â””â”€ å¼‚æ­¥è§¦å‘æ‘˜è¦å’Œç´¢å¼•
```

**å…³é”®å®ç°ç»†èŠ‚**ï¼š

##### 1. ConversationState å®šä¹‰

ç³»ç»Ÿä½¿ç”¨ TypedDict å®šä¹‰ç»Ÿä¸€çš„çŠ¶æ€ç»“æ„ï¼š

```python
# conversation_graph.py:37-68
from typing import TypedDict, Any

class ConversationState(TypedDict):
    # è¯·æ±‚çº§åˆ«ä¿¡æ¯
    user_id: str
    message: str
    session_id: str
    conversation_id: str
    current_user_message_id: Any  # ç”¨äºæ’é™¤å½“å‰æ¶ˆæ¯

    # è¯·æ±‚é…ç½®
    debug: bool
    agent_type: str
    requested_kb_prefix: str | None

    # è·¯ç”±å†³ç­–
    kb_prefix: str | None
    worker_name: str | None
    use_retrieval: bool

    # ä¸Šä¸‹æ–‡æ„å»º
    memory_context: str | None              # é•¿æœŸè®°å¿†
    conversation_summary: str | None        # å¯¹è¯æ‘˜è¦
    history: list[dict[str, Any]]           # æœ€è¿‘å†å²
    episodic_memory: list[dict[str, Any]] | None  # è¯­ä¹‰æƒ…èŠ‚
    episodic_context: str | None

    # å“åº”
    response: str | None
```

**ä¼˜åŠ¿**ï¼š
- æ–°å¢å‚æ•°åªéœ€åœ¨ TypedDict åŠ ä¸€è¡Œ
- èŠ‚ç‚¹å‡½æ•°ç­¾åä¸å˜ï¼Œåªéœ€ä¿®æ”¹è¿”å›å€¼
- LangGraph è‡ªåŠ¨åˆå¹¶çŠ¶æ€æ›´æ–°

##### 2. ä¸‰èŠ‚ç‚¹å›¾æ„å»º

```python
# conversation_graph.py:111-121
def _build_graph(self):
    g = StateGraph(ConversationState)
    g.add_node("route", self._route_node)
    g.add_node("recall", self._recall_node)
    g.add_node("execute", self._execute_node)

    g.add_edge(START, "route")
    g.add_edge("route", "recall")
    g.add_edge("recall", "execute")
    g.add_edge("execute", END)

    return g.compile()
```

**èŠ‚ç‚¹èŒè´£**ï¼š

- `route_node`ï¼šæ ¹æ®ç”¨æˆ·æ¶ˆæ¯å†³å®šä½¿ç”¨å“ªä¸ª KB
- `recall_node`ï¼šå¬å›æ‰€æœ‰ä¸Šä¸‹æ–‡ï¼ˆè®°å¿†+æ‘˜è¦+å†å²+æƒ…èŠ‚ï¼‰
- `execute_node`ï¼šä½¿ç”¨å¬å›çš„ä¸Šä¸‹æ–‡ç”Ÿæˆå“åº”

##### 3. æ ¸å¿ƒä»£ç æ–‡ä»¶

```
backend/
â”œâ”€â”€ application/chat/
â”‚   â””â”€â”€ conversation_graph.py       # ConversationGraphRunner æ ¸å¿ƒé€»è¾‘
â”œâ”€â”€ server/api/rest/
â”‚   â”œâ”€â”€ dependencies.py             # ä¾èµ–æ³¨å…¥ï¼šget_conversation_graph_runner()
â”‚   â””â”€â”€ v1/chat_stream.py          # API å±‚ï¼šä½¿ç”¨ graph.astream_custom()
â””â”€â”€ application/chat/handlers/
    â””â”€â”€ stream_handler.py           # Handler å±‚ï¼šåˆå§‹åŒ– State å¹¶è°ƒç”¨å›¾
```

**å…³é”®ç±»å’Œæ–¹æ³•**ï¼š

- `ConversationGraphRunner.__init__()` - åˆå§‹åŒ–æ‰€æœ‰ä¾èµ–æœåŠ¡
- `ConversationGraphRunner._build_graph()` - æ„å»ºä¸‰èŠ‚ç‚¹å›¾
- `ConversationGraphRunner.astream_custom()` - æµå¼æ‰§è¡Œ
- `ConversationGraphRunner._route_node()` - è·¯ç”±å†³ç­–
- `ConversationGraphRunner._recall_node()` - ä¸Šä¸‹æ–‡å¬å›
- `ConversationGraphRunner._execute_node()` - å“åº”ç”Ÿæˆ

**ä¼˜åŒ–äº®ç‚¹**ï¼š

1. **ä¸‰èŠ‚ç‚¹ç®€åŒ–**ï¼šå‡å°‘èŠ‚ç‚¹æ•°é‡ï¼Œæå‡æ€§èƒ½å’Œå¯ç»´æŠ¤æ€§
2. **ç»Ÿä¸€çš„ä¸Šä¸‹æ–‡æ„å»º**ï¼š`recall_node` é›†æˆæ‰€æœ‰è®°å¿†æº
3. **StreamWriter é›†æˆ**ï¼šæ”¯æŒ Python 3.10 çš„æµå¼è¾“å‡º
4. **Debug å¯è§‚æµ‹æ€§**ï¼šè¯¦ç»†çš„ `execution_log` è®°å½•
5. **å¼‚å¸¸é™çº§**ï¼šæ¯ä¸ªè®°å¿†æºç‹¬ç«‹ try-exceptï¼Œå¤±è´¥ä¸å½±å“å…¶ä»–æº

#### 2.3.1.2 æ¶æ„ä¸æµç¨‹å›¾

**æ•´ä½“æ¶æ„å›¾**ï¼š

```mermaid
graph TB
    subgraph Input["è¾“å…¥å±‚"]
        User[ç”¨æˆ·æ¶ˆæ¯]
    end

    subgraph Handler["Handler å±‚"]
        StreamHandler[StreamHandler.handle]
        AppendUser[(append_message user<br/>è·å– current_user_message_id)]
        BuildState[æ„å»ºåˆå§‹ ConversationState]
    end

    subgraph Graph["LangGraph çŠ¶æ€æœº"]
        Route[route èŠ‚ç‚¹<br/>è·¯ç”±å†³ç­–]
        Recall[recall èŠ‚ç‚¹<br/>ä¸Šä¸‹æ–‡å¬å›]
        Execute[execute èŠ‚ç‚¹<br/>ç”Ÿæˆå“åº”]

        Route --> Recall
        Recall --> Execute
    end

    subgraph RecallServices["Recall æœåŠ¡å±‚"]
        MemorySvc[MemoryService<br/>recall_context<br/>è·¨ä¼šè¯è®°å¿†]
        Summarizer[ConversationSummarizer<br/>get_summary_text<br/>å¯¹è¯æ‘˜è¦]
        ConvStore[ConversationStore<br/>list_messages<br/>æœ€è¿‘å†å²]
        Episodic[ConversationEpisodicMemory<br/>recall_relevant<br/>è¯­ä¹‰æƒ…èŠ‚]
    end

    subgraph ExecuteServices["Execute æœåŠ¡å±‚"]
        KBHandler[KBHandler<br/>ä¸“ç”¨å¤„ç†å™¨]
        StreamExec[RAGStreamExecutor<br/>æµå¼ç”Ÿæˆ]
        Completion[ChatCompletion<br/>LLM è°ƒç”¨]
    end

    subgraph Output["è¾“å‡ºå±‚"]
        StreamTokens[æµå¼ tokens]
        AppendAssistant[(append_message assistant<br/>è·å– assistant_message_id)]
        TriggerTasks[è§¦å‘åå°ä»»åŠ¡<br/>schedule_update + schedule_index]
    end

    User --> StreamHandler
    StreamHandler --> AppendUser
    AppendUser --> BuildState
    BuildState --> Graph

    Route -->|è·¯ç”±å†³ç­–| Recall
    Recall --> MemorySvc
    Recall --> Summarizer
    Recall --> ConvStore
    Recall --> Episodic

    MemorySvc -.->|memory_context| Recall
    Summarizer -.->|conversation_summary| Recall
    ConvStore -.->|history| Recall
    Episodic -.->|episodic_context| Recall

    Recall -->|å¬å›ä¸Šä¸‹æ–‡| Execute
    Execute --> KBHandler
    Execute --> StreamExec
    StreamExec --> Completion

    Completion --> StreamTokens
    StreamTokens --> AppendAssistant
    AppendAssistant --> TriggerTasks

    style Route fill:#fff4e6
    style Recall fill:#e6f3ff
    style Execute fill:#ffe6e6
    style StreamHandler fill:#e1f5ff
    style BuildState fill:#f3e5f5
```

**çŠ¶æ€è½¬æ¢æµç¨‹å›¾**ï¼š

```mermaid
stateDiagram-v2
    [*] --> Init: ç”¨æˆ·è¯·æ±‚

    Init --> BuildState: StreamHandler.handle<br/>æ„å»ºåˆå§‹ State

    BuildState --> Route: graph.astream_custom<br/>è¿›å…¥çŠ¶æ€æœº

    state "LangGraph çŠ¶æ€æœº" as Graph {
        Route --> Recall: è·¯ç”±å†³ç­–å®Œæˆ<br/>æ›´æ–° State
        Recall --> Execute: ä¸Šä¸‹æ–‡å¬å›å®Œæˆ<br/>æ›´æ–° State
        Execute --> [*]: ç”Ÿæˆå®Œæˆ<br/>è¿”å› events
    }

    Graph --> Stream: æµå¼è¿”å› tokens
    Stream --> Finally: finally å—

    Finally --> Persist: append_message assistant<br/>completed=completed_normally
    Persist --> CheckComplete{completed_normally?}

    CheckComplete -->|True| TriggerTasks[è§¦å‘åå°ä»»åŠ¡<br/>schedule_update + schedule_index]
    CheckComplete -->|False| End

    TriggerTasks --> End
    Persist --> End

    End --> [*]: å®Œæˆ

    note right of BuildState
        åˆå§‹ State åŒ…å«:
        - user_id, message, session_id
        - conversation_id
        - current_user_message_id
        - debug, agent_type
        - requested_kb_prefix
    end note

    note right of Route
        è¾“å‡º:
        - kb_prefix, worker_name
        - resolved_agent_type
        - use_retrieval
        - route_decision
        - routing_ms
    end note

    note right of Recall
        è¾“å‡º:
        - memory_context
        - conversation_summary
        - history
        - episodic_memory
        - episodic_context
        - execution_logs (debug)
    end note

    note right of Execute
        è¾“å‡º:
        - æµå¼ events
        - response (éæµå¼)
        - execution_logs (debug)
    end note
```

**ä¸‰èŠ‚ç‚¹è¯¦ç»†æµç¨‹å›¾**ï¼š

```mermaid
flowchart TD
    Start([ç”¨æˆ·å‘é€æ¶ˆæ¯]) --> Handler[StreamHandler.handle]

    Handler --> AppendUser[(append_message user<br/>è·å– current_user_message_id)]
    AppendUser --> BuildState[æ„å»ºåˆå§‹ ConversationState]

    BuildState --> Graph[graph.astream_custom]

    Graph --> Route[route èŠ‚ç‚¹]
    Route --> CallRouter[router.route<br/>è·¯ç”±å†³ç­–]
    CallRouter --> SetRouting[è®¾ç½® State è·¯ç”±å­—æ®µ<br/>kb_prefix, worker_name<br/>use_retrieval, resolved_agent_type]

    SetRouting --> Recall[recall èŠ‚ç‚¹]

    Recall --> MemRecall[MemoryService<br/>.recall_context]
    Recall --> SummRecall[ConversationSummarizer<br/>.get_summary_text]
    Recall --> HistRecall[ConversationStore<br/>.list_messages limit=8]
    Recall --> EpiRecall[ConversationEpisodicMemory<br/>.recall_relevant]

    MemRecall --> SetMem[è®¾ç½® memory_context]
    SummRecall --> SetSumm[è®¾ç½® conversation_summary]
    HistRecall --> FilterHist[è¿‡æ»¤ completed=True<br/>æ’é™¤ current_user_message_id]
    FilterHist --> SetHist[è®¾ç½® history]
    EpiRecall --> SetEpi[è®¾ç½® episodic_context]

    SetMem --> Execute[execute èŠ‚ç‚¹]
    SetSumm --> Execute
    SetHist --> Execute
    SetEpi --> Execute

    Execute --> CheckKB{enable_kb_handlers<br/>& kb_handler å­˜åœ¨?}

    CheckKB -->|æ˜¯| UseKB[KBHandler.process_stream<br/>ä¸“ç”¨å¤„ç†]
    CheckKB -->|å¦| UseRAG[RAGStreamExecutor.stream<br/>é€šç”¨ RAG]

    UseKB --> StreamExec
    UseRAG --> StreamExec[æµå¼ç”Ÿæˆå“åº”]

    StreamExec --> StreamTokens[æµå¼è¿”å› tokens]
    StreamTokens --> Finally{finally å—}

    Finally --> AppendAssistant[(append_message assistant<br/>è·å– assistant_message_id)]
    AppendAssistant --> CheckComplete{{completed_normally?}}

    CheckComplete -->|True| Trigger[è§¦å‘åå°ä»»åŠ¡<br/>schedule_update<br/>schedule_index_episode<br/>maybe_write]
    CheckComplete -->|False| EndNoTask([ç»“æŸ])

    Trigger --> EndDone([å®Œæˆ])
    EndNoTask -.->|ç”¨æˆ·ç»§ç»­å¯¹è¯| Start
    EndDone -.->|ç”¨æˆ·ç»§ç»­å¯¹è¯| Start

    style Route fill:#fff4e6
    style Recall fill:#e6f3ff
    style Execute fill:#ffe6e6
    style CheckComplete fill:#fffacd
    style CheckKB fill:#fffacd
```

**LangGraph çŠ¶æ€åºåˆ—å›¾**ï¼š

```mermaid
sequenceDiagram
    participant User as ç”¨æˆ·
    participant Handler as StreamHandler
    participant Graph as ConversationGraph
    participant Route as route èŠ‚ç‚¹
    participant Recall as recall èŠ‚ç‚¹
    participant Execute as execute èŠ‚ç‚¹
    participant Services as æœåŠ¡å±‚
    participant LLM as LLM Service

    User->>Handler: POST /chat/stream

    Handler->>Handler: append_message(user)
    Handler-->>Handler: current_user_message_id

    Handler->>Graph: æ„å»ºåˆå§‹ State
    Note over Handler: {user_id, message, session_id,<br/>conversation_id, current_user_message_id,<br/>debug, agent_type, requested_kb_prefix}

    Handler->>Graph: astream_custom(initial_state)
    activate Graph

    Graph->>Route: _route_node(state)
    activate Route
    Route->>Services: router.route(message, session_id, kb)
    Services-->>Route: RouteDecision
    Route->>Route: æ›´æ–° State<br/>{kb_prefix, worker_name, use_retrieval,...}
    Route-->>Graph: è¿”å›æ›´æ–°çš„ State
    deactivate Route

    Graph->>Recall: _recall_node(state)
    activate Recall

    par å¹¶è¡Œå¬å›å¤šä¸ªè®°å¿†æº
        Recall->>Services: memory_service.recall_context()
        Services-->>Recall: memory_context
    and
        Recall->>Services: summarizer.get_summary_text()
        Services-->>Recall: conversation_summary
    and
        Recall->>Services: store.list_messages(limit=8)
        Services-->>Recall: raw_history
        Recall->>Recall: è¿‡æ»¤ completed=True<br/>æ’é™¤ current_user_message_id
    and
        Recall->>Services: episodic_memory.recall_relevant()
        Services-->>Recall: episodic_memory
        Recall->>Recall: format_context()
    end

    Recall->>Recall: æ›´æ–° State<br/>{memory_context, conversation_summary,<br/>history, episodic_context,...}
    Recall-->>Graph: è¿”å›æ›´æ–°çš„ State
    deactivate Recall

    Graph->>Execute: _execute_node(state)
    activate Execute

    alt enable_kb_handlers && kb_handler exists
        Execute->>Services: kb_handler.process_stream()
        Services->>LLM: ä¸“ç”¨å¤„ç†é€»è¾‘
    else
        Execute->>Services: stream_executor.stream()
        Services->>LLM: é€šç”¨ RAG æµç¨‹
    end

    loop æµå¼ç”Ÿæˆ
        LLM-->>Services: token chunk
        Services-->>Execute: stream event
        Execute-->>Graph: yield event
        Graph-->>Handler: yield token
        Handler-->>User: SSE: {"status": "token", "content": "..."}
    end

    Execute-->>Graph: è¿”å›æœ€ç»ˆ State
    deactivate Execute
    deactivate Graph

    Note over Handler: finally å—
    Handler->>Handler: append_message(assistant, completed=completed_normally)
    Handler-->>Handler: assistant_message_id

    alt completed_normally = True
        par åå°å¼‚æ­¥è§¦å‘
            Handler->>Services: summarizer.schedule_update()
            Handler->>Services: episodic_memory.schedule_index_episode()
            Handler->>Services: memory_service.maybe_write()
        end
    end

    Handler-->>User: SSE: {"status": "done"}
```


---



#### 2.3.2 LangGraph è§£å†³æ–¹æ¡ˆ

**æ ¸å¿ƒç†å¿µ**ï¼šç”¨ **State** æ›¿ä»£ "å‚æ•°é€ä¼ "

**å…³é”®å·®å¼‚å¯¹æ¯”**ï¼š

```
ç°åœ¨çš„åšæ³•ï¼ˆå‚æ•°é€å±‚ä¼ é€’ï¼‰:
  StreamHandler
    â”œâ”€ message, session_id, memory_context, history
    â””â”€> KBHandler.process_stream(message, session_id, memory_context, history)
    â””â”€> RAGStreamExecutor.stream(plan, message, session_id, memory_context, history)

    # æ–°å¢ Phase 1/2 éœ€è¦æ”¹ N ä¸ªå‡½æ•°ç­¾åï¼š
    â””â”€> KBHandler.process_stream(message, session_id, memory_context, history,
                                  summary, episodic_memory)  # â† æ–°å¢å‚æ•°

LangGraph çš„åšæ³•ï¼ˆç»Ÿä¸€çŠ¶æ€ï¼‰:
  StreamHandler
    â””â”€> graph.astream(state)  # â† ä¸€æ¬¡æ€§ä¼ é€’æ‰€æœ‰æ•°æ®

    èŠ‚ç‚¹åªéœ€ä¿®æ”¹ State å®šä¹‰ï¼Œä¸éœ€æ”¹å‡½æ•°ç­¾åï¼š
    async def node(state: State) -> dict:
        return {...state, "new_field": value}  # â† åªæ”¹è¿™é‡Œ
```

**å®Œæ•´çš„ ConversationState å®šä¹‰**ï¼š

```python
from langgraph.graph import StateGraph, START, END
from typing import TypedDict, Annotated, Any
from operator import add
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage

class ConversationState(TypedDict):
    """å¯¹è¯å…¨å±€çŠ¶æ€ - ç®¡ç†æ•´ä¸ªå¯¹è¯æµç¨‹çš„æ‰€æœ‰æ•°æ®"""

    # ==================== è¯·æ±‚çº§åˆ«ä¿¡æ¯ ====================
    user_id: str                           # ç”¨æˆ·IDï¼ˆå¯¹åº” StreamHandler.handle çš„ user_idï¼‰
    message: str                           # å½“å‰ç”¨æˆ·æ¶ˆæ¯ï¼ˆå¯¹åº” StreamHandler.handle çš„ messageï¼‰
    session_id: str                        # ä¼šè¯IDï¼ˆå¯¹åº” StreamHandler.handle çš„ session_idï¼‰
    conversation_id: str                   # å¯¹è¯IDï¼ˆå¯¹åº” StreamHandler.handle çš„ conversation_idï¼‰

    # ==================== è¯·æ±‚é…ç½® ====================
    debug: bool                            # è°ƒè¯•æ¨¡å¼å¼€å…³
    agent_type: str                        # Agent ç±»å‹ï¼ˆhybrid_agent/naive_rag_agent...ï¼‰
    requested_kb_prefix: str | None        # ç”¨æˆ·æŒ‡å®šçš„ KBï¼ˆå¯¹åº” request.kb_prefixï¼‰

    # ==================== è·¯ç”±å†³ç­–ï¼ˆroute_node è¾“å‡ºï¼‰====================
    kb_prefix: str | None                  # æœ€ç»ˆå†³å®šä½¿ç”¨çš„ KB
    worker_name: str | None                # å·¥ä½œè€…åç§°ï¼ˆrouter è¾“å‡ºï¼‰
    use_retrieval: bool                    # æ˜¯å¦éœ€è¦æ£€ç´¢ï¼ˆå–å†³äº kb_prefixï¼‰
    route_decision: dict[str, Any] | None  # å®Œæ•´çš„è·¯ç”±å†³ç­–ä¿¡æ¯
    routing_ms: int | None                 # è·¯ç”±è€—æ—¶

    # ==================== ä¸Šä¸‹æ–‡æ„å»ºï¼ˆrecall_node è¾“å‡ºï¼‰====================
    # çŸ­æœŸè®°å¿†ï¼ˆå¯¹è¯å†å²ï¼‰
    history: list[dict[str, Any]]          # æœ€è¿‘ 6-7 æ¡æ¶ˆæ¯ï¼ˆæ¥è‡ª conversation_storeï¼‰

    # é•¿æœŸè®°å¿†ï¼ˆç”¨æˆ·ä¿¡æ¯ï¼‰
    memory_context: str | None             # é•¿æœŸç”¨æˆ·è®°å¿†ï¼ˆæ¥è‡ª memory_serviceï¼‰

    # Phase 1: å¯¹è¯æ‘˜è¦
    conversation_summary: str | None       # å¯¹è¯æ‘˜è¦ï¼ˆæ¥è‡ª summarizerï¼‰

    # Phase 2: è¯­ä¹‰æ£€ç´¢
    episodic_memory: list[dict[str, Any]] | None  # ç›¸å…³çš„å†å²ç‰‡æ®µï¼ˆæ¥è‡ª episodic_memoryï¼‰

    # ==================== æ‰§è¡Œç»“æœ ====================
    # æ£€ç´¢ç»“æœï¼ˆretrieve_node è¾“å‡ºï¼‰
    retrieval_results: list[dict[str, Any]] | None  # RAG æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
    retrieval_ms: int | None               # æ£€ç´¢è€—æ—¶

    # LLM ç”Ÿæˆï¼ˆgenerate_node è¾“å‡ºï¼‰
    messages: Annotated[list[BaseMessage], add]  # å¯¹è¯æ¶ˆæ¯åˆ—è¡¨ï¼ˆè‡ªåŠ¨è¿½åŠ ï¼‰

    # ==================== å…ƒæ•°æ® ====================
    execution_logs: list[dict[str, Any]] | None   # æ‰§è¡Œæ—¥å¿—ï¼ˆç”¨äº debugï¼‰
    error: str | None                      # é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœ‰ï¼‰
    partial_answer: bool = False            # æ˜¯å¦æ˜¯éƒ¨åˆ†å›å¤ï¼ˆæµå¼ä¸­æ–­ï¼‰
```

**ä¸ºä»€ä¹ˆè¿™ä¸ª State è®¾è®¡æ›´å¥½ï¼Ÿ**

| ç›Šå¤„ | è¯´æ˜ |
|------|------|
| **ä¸€æ¬¡æ€§å®šä¹‰** | æ–°å¢å‚æ•°åªéœ€åœ¨ State åŠ ä¸€è¡Œï¼Œä¸éœ€æ”¹å‡½æ•°ç­¾å |
| **æ•°æ®æº¯æºæ¸…æ™°** | æ¯ä¸ªå­—æ®µæ³¨æ˜æ¥æºï¼ˆå“ªä¸ª nodeã€å“ªä¸ª serviceï¼‰ |
| **è‡ªåŠ¨æ¶ˆæ¯ç®¡ç†** | `Annotated[list, add]` è‡ªåŠ¨åˆå¹¶æ¶ˆæ¯ï¼Œä¸éœ€æ‰‹åŠ¨è¿½åŠ  |
| **æ˜“äºè°ƒè¯•** | `execution_logs` è®°å½•æ¯ä¸ªèŠ‚ç‚¹çš„è¾“å…¥è¾“å‡º |
| **æ”¯æŒå¹¶è¡Œ** | å¤šä¸ªèŠ‚ç‚¹å¯ä»¥å¹¶è¡Œå¤„ç†ï¼ŒState è‡ªåŠ¨åˆå¹¶ç»“æœ |

#### 2.3.3 èŠ‚ç‚¹è®¾è®¡ï¼ˆä¸ç°æœ‰ä»£ç å¯¹åº”ï¼‰

**èŠ‚ç‚¹æ€»è§ˆ**ï¼š
```
START
  â†“
route_node          # è¿›è¡Œè·¯ç”±å†³ç­–ï¼ˆå¯¹åº”ç°æœ‰ Router.route()ï¼‰
  â†“
history_node        # è·å–çŸ­æœŸ+é•¿æœŸè®°å¿†ï¼ˆå¯¹åº”ç°æœ‰ _get_conversation_history + memory_serviceï¼‰
  â†“
retrieve_node       # å¯é€‰ï¼šæ£€ç´¢ï¼ˆä»…å½“ use_retrieval=Trueï¼‰
  â†“
kb_handler_node     # æ¡ä»¶æ‰§è¡Œï¼šä¼˜å…ˆä½¿ç”¨ KB ä¸“ç”¨ handler
  â”œâ”€ if kb_handler found
  â”‚   â†“
  â”‚ generate_kb_node  # ä½¿ç”¨ KB handler ç”Ÿæˆ
  â”‚   â†“
  â”‚ persist_node      # æŒä¹…åŒ–
  â”‚   â†“
  â”‚   END
  â”‚
  â”œâ”€ elseï¼ˆå›é€€åˆ° RAG æ‰§è¡Œå™¨ï¼‰
  â”‚   â†“
  â”‚   generate_rag_node  # ä½¿ç”¨ RAG executor ç”Ÿæˆ
  â”‚   â†“
  â”‚   persist_node       # æŒä¹…åŒ–
  â”‚   â†“
  â”‚   END
```

**è¯¦ç»†èŠ‚ç‚¹å®ç°**ï¼š

##### 1ï¸âƒ£ route_nodeï¼šè·¯ç”±å†³ç­–

```python
import time
from typing import Any, TypedDict
from domain.chat.entities.route_decision import RouteDecision

async def route_node(state: ConversationState) -> dict[str, Any]:
    """
    è·¯ç”±èŠ‚ç‚¹ï¼šæ ¹æ®ç”¨æˆ·æ¶ˆæ¯å’Œé…ç½®å†³å®šä½¿ç”¨å“ªä¸ª KB

    å¯¹åº”ç°æœ‰ä»£ç ï¼š
    - StreamHandler.handle() ç¬¬ 109-138 è¡Œï¼ˆè·¯ç”±é€»è¾‘ï¼‰
    """
    t0 = time.monotonic()

    # è°ƒç”¨ç°æœ‰çš„ Router
    decision: RouteDecision = router.route(
        message=state["message"],
        session_id=state["session_id"],
        requested_kb=state["requested_kb_prefix"],
        agent_type=state["agent_type"],
    )

    routing_ms = int((time.monotonic() - t0) * 1000)

    # å†³å®šæ˜¯å¦éœ€è¦æ£€ç´¢
    use_retrieval = (decision.kb_prefix or "").strip() not in {"", "general"}

    # æ„å»ºè¿”å›å€¼
    result = {
        "kb_prefix": decision.kb_prefix,
        "worker_name": decision.worker_name,
        "use_retrieval": use_retrieval,
        "route_decision": {
            "kb_prefix": decision.kb_prefix,
            "worker_name": decision.worker_name,
            "confidence": decision.confidence,
            "method": decision.method,
            "reason": decision.reason,
        },
        "routing_ms": routing_ms,
    }

    # å¦‚æœå¯ç”¨ Langfuseï¼Œè®°å½•è·¯ç”±å†³ç­–
    if ENABLE_LANGFUSE:
        try:
            from infrastructure.observability import get_current_langfuse_stateful_client
            parent = get_current_langfuse_stateful_client()
            if parent is not None:
                span = parent.span(name="route_decision", input={"message_preview": state["message"][:200]})
                span.end(output=result, metadata={"routing_ms": routing_ms})
        except Exception:
            pass  # è§‚æµ‹æ€§å¤±è´¥ä¸åº”é˜»å¡ä¸»æµç¨‹

    return result
```

##### 2ï¸âƒ£ history_nodeï¼šä¸Šä¸‹æ–‡æ„å»º

```python
async def history_node(state: ConversationState) -> dict[str, Any]:
    """
    å†å²èŠ‚ç‚¹ï¼šè·å–çŸ­æœŸè®°å¿†ï¼ˆå¯¹è¯å†å²ï¼‰å’Œé•¿æœŸè®°å¿†ï¼ˆç”¨æˆ·ä¿¡æ¯ï¼‰

    å¯¹åº”ç°æœ‰ä»£ç ï¼š
    - StreamHandler._get_conversation_history() ç¬¬ 53-62 è¡Œ
    - StreamHandler.handle() ç¬¬ 169-173 è¡Œï¼ˆmemory_serviceï¼‰
    - StreamHandler.handle() ç¬¬ 176-183 è¡Œï¼ˆhistory å»é‡ï¼‰
    """

    # 1. è·å–çŸ­æœŸè®°å¿†ï¼šæœ€è¿‘çš„å¯¹è¯å†å²
    raw_history = await conversation_store.list_messages(
        conversation_id=state["conversation_id"],
        limit=7,  # è·å–æœ€è¿‘ 7 æ¡ï¼ˆåŒ…å«å½“å‰æ¶ˆæ¯ï¼‰
        desc=True,  # é™åº
    )

    # ç¿»è½¬ä¸ºæ—¶é—´æ­£åº
    raw_history.reverse()

    # å»é‡ï¼šå¦‚æœæœ€åä¸€æ¡æ˜¯å½“å‰æ¶ˆæ¯ï¼Œæ’é™¤å®ƒï¼ˆé˜²æ­¢é‡å¤ï¼‰
    history_context = raw_history
    if raw_history and raw_history[-1].get("content") == state["message"]:
        history_context = raw_history[:-1]

    result = {
        "history": history_context,
    }

    # 2. è·å–é•¿æœŸè®°å¿†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if memory_service is not None:
        try:
            memory_context = await memory_service.recall_context(
                user_id=state["user_id"],
                query=state["message"],
            )
            result["memory_context"] = memory_context
        except Exception as e:
            logger.error(f"Failed to recall memory context: {e}")
            result["memory_context"] = None

    # 3. ç”Ÿæˆå¯¹è¯æ‘˜è¦ï¼ˆPhase 1ï¼Œå¯é€‰ï¼‰
    if summarizer is not None:
        try:
            summary = await summarizer.get_or_generate_summary(state["conversation_id"])
            result["conversation_summary"] = summary
        except Exception as e:
            logger.error(f"Failed to generate summary: {e}")
            result["conversation_summary"] = None

    # 4. å¬å›è¯­ä¹‰ç›¸å…³çš„å†å²ç‰‡æ®µï¼ˆPhase 2ï¼Œå¯é€‰ï¼‰
    if episodic_memory_manager is not None and state["use_retrieval"]:
        try:
            episodes = await episodic_memory_manager.recall_relevant(
                conversation_id=state["conversation_id"],
                query=state["message"],
                top_k=3,
            )
            result["episodic_memory"] = episodes
        except Exception as e:
            logger.error(f"Failed to recall episodic memory: {e}")
            result["episodic_memory"] = None

    # è®°å½•æ‰§è¡Œæ—¥å¿—ï¼ˆç”¨äºè°ƒè¯•ï¼‰
    if state.get("debug"):
        result.setdefault("execution_logs", []).append({
            "node": "history",
            "history_count": len(history_context),
            "has_memory_context": result.get("memory_context") is not None,
            "has_summary": result.get("conversation_summary") is not None,
            "episodic_count": len(result.get("episodic_memory") or []),
        })

    return result
```

##### 3ï¸âƒ£ retrieve_nodeï¼šæ£€ç´¢ï¼ˆæ¡ä»¶æ‰§è¡Œï¼‰

```python
async def retrieve_node(state: ConversationState) -> dict[str, Any]:
    """
    æ£€ç´¢èŠ‚ç‚¹ï¼šä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³çš„ä¸Šä¸‹æ–‡
    ä»…å½“ use_retrieval=True æ—¶æ‰§è¡Œ

    å¯¹åº”ç°æœ‰ä»£ç ï¼š
    - RAGStreamExecutor / ChatStreamExecutor çš„æ£€ç´¢é€»è¾‘
    """

    # å¦‚æœä¸éœ€è¦æ£€ç´¢ï¼Œç›´æ¥è·³è¿‡
    if not state["use_retrieval"]:
        return {}  # è¿”å›ç©ºå­—å…¸ï¼ŒState ä¿æŒä¸å˜

    t0 = time.monotonic()

    try:
        # æ„å»º RAG plan
        plan = [
            RagRunSpec(
                agent_type=_resolve_agent_type(
                    agent_type=state["agent_type"],
                    worker_name=state["worker_name"],
                ),
                worker_name=state["worker_name"],
            )
        ]

        # è°ƒç”¨ RAG æ‰§è¡Œå™¨è¿›è¡Œæ£€ç´¢
        results = await rag_executor.retrieve(
            plan=plan,
            query=state["message"],
            kb_prefix=state["kb_prefix"],
            session_id=state["session_id"],
        )

        retrieval_ms = int((time.monotonic() - t0) * 1000)

        return {
            "retrieval_results": results,
            "retrieval_ms": retrieval_ms,
        }

    except Exception as e:
        logger.error(f"Retrieval failed: {e}")
        return {
            "retrieval_results": None,
            "error": f"Retrieval failed: {str(e)}",
        }
```

##### 4ï¸âƒ£ generate_nodeï¼šç”Ÿæˆï¼ˆç»Ÿä¸€ç‰ˆæœ¬ï¼‰

```python
def _build_prompt_from_state(state: ConversationState) -> ChatPromptTemplate:
    """
    ä» State æ„å»º Prompt

    å¯¹åº”ç°æœ‰ä»£ç ï¼š
    - completion.py çš„ _build_general_prompt() / _build_rag_prompt()
    """
    messages = [
        ("system", SYSTEM_PROMPT),
    ]

    # æ·»åŠ é•¿æœŸç”¨æˆ·è®°å¿†
    if state.get("memory_context"):
        messages.append(("system", f"ã€ç”¨æˆ·é•¿æœŸè®°å¿†ã€‘\n{state['memory_context']}"))

    # æ·»åŠ å¯¹è¯æ‘˜è¦ï¼ˆPhase 1ï¼‰
    if state.get("conversation_summary"):
        messages.append(("system", f"ã€å¯¹è¯èƒŒæ™¯ã€‘\n{state['conversation_summary']}"))

    # æ·»åŠ è¯­ä¹‰ç›¸å…³çš„å†å²ç‰‡æ®µï¼ˆPhase 2ï¼‰
    if state.get("episodic_memory"):
        episodes_text = "\n".join([
            f"- {ep.get('user_message', '')} â†’ {ep.get('assistant_message', '')}"
            for ep in state["episodic_memory"]
        ])
        messages.append(("system", f"ã€ç›¸å…³å†å²ã€‘\n{episodes_text}"))

    # æ·»åŠ æ£€ç´¢ç»“æœï¼ˆå¦‚æœ‰ï¼‰
    if state.get("retrieval_results"):
        context_text = "\n".join([
            result.get("content", "")
            for result in state["retrieval_results"][:5]  # æœ€å¤š5æ¡
        ])
        messages.append(("system", f"ã€æ£€ç´¢ä¸Šä¸‹æ–‡ã€‘\n{context_text}"))

    # æ·»åŠ å¯¹è¯å†å²
    for msg in state.get("history", []):
        role = "assistant" if msg.get("role") == "assistant" else "human"
        messages.append((role, msg.get("content", "")))

    # å½“å‰é—®é¢˜
    messages.append(("human", state["message"]))

    return ChatPromptTemplate.from_messages(messages)


async def generate_node(state: ConversationState) -> dict[str, Any]:
    """
    ç”ŸæˆèŠ‚ç‚¹ï¼šLLM ç”Ÿæˆå›å¤

    å¯¹åº”ç°æœ‰ä»£ç ï¼š
    - generate_rag_answer() / ChatCompletionPort.generate()
    """

    try:
        # æ„å»º Promptï¼ˆè‡ªåŠ¨åŒ…å«æ‰€æœ‰ä¸Šä¸‹æ–‡ï¼‰
        prompt = _build_prompt_from_state(state)

        t0 = time.monotonic()

        # è°ƒç”¨ LLM
        response = await llm.ainvoke(
            prompt,
            callbacks=[get_langfuse_callback()],
        )

        generation_ms = int((time.monotonic() - t0) * 1000)

        # è§£æå“åº”
        answer_content = response.content

        # åˆ›å»º AI Messageï¼ˆè‡ªåŠ¨è¿½åŠ åˆ° messages åˆ—è¡¨ï¼‰
        result = {
            "messages": [AIMessage(content=answer_content)],
        }

        if state.get("debug"):
            result.setdefault("execution_logs", []).append({
                "node": "generate",
                "generation_ms": generation_ms,
                "answer_preview": answer_content[:100],
            })

        return result

    except Exception as e:
        logger.error(f"Generation failed: {e}")
        return {
            "error": f"Generation failed: {str(e)}",
            "messages": [AIMessage(content="æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç”Ÿæˆå›å¤ã€‚è¯·ç¨åé‡è¯•ã€‚")],
        }
```

##### 5ï¸âƒ£ persist_nodeï¼šæŒä¹…åŒ–

```python
async def persist_node(state: ConversationState) -> dict[str, Any]:
    """
    æŒä¹…åŒ–èŠ‚ç‚¹ï¼šä¿å­˜å¯¹è¯å’Œç´¢å¼•

    å¯¹åº”ç°æœ‰ä»£ç ï¼š
    - StreamHandler.handle() ç¬¬ 248-260 è¡Œï¼ˆä¿å­˜åŠ©æ‰‹æ¶ˆæ¯ï¼‰
    - StreamHandler.handle() ç¬¬ 461-467 è¡Œï¼ˆç´¢å¼• episodic memoryï¼‰
    """

    # è·å–æœ€æ–°ç”Ÿæˆçš„åŠ©æ‰‹å›å¤
    if not state.get("messages"):
        return {}

    assistant_message = state["messages"][-1]
    answer_content = assistant_message.content

    try:
        # 1. ä¿å­˜å¯¹è¯åˆ°æ•°æ®åº“
        await conversation_store.append_message(
            conversation_id=state["conversation_id"],
            role="assistant",
            content=answer_content,
            debug={"partial": state.get("partial_answer", False)} if state.get("debug") else None,
        )

        # 2. å¼‚æ­¥ç´¢å¼•åˆ° Episodic Memoryï¼ˆä¸é˜»å¡ä¸»æµç¨‹ï¼‰
        if episodic_memory_manager is not None:
            asyncio.create_task(
                episodic_memory_manager.index_episode(
                    conversation_id=state["conversation_id"],
                    user_msg=state["message"],
                    assistant_msg=answer_content,
                )
            )

        # 3. å†™å…¥é•¿æœŸè®°å¿†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if memory_service is not None and not state.get("partial_answer"):
            asyncio.create_task(
                memory_service.maybe_write(
                    user_id=state["user_id"],
                    user_message=state["message"],
                    assistant_message=answer_content,
                    metadata={
                        "session_id": state["session_id"],
                        "kb_prefix": state.get("kb_prefix"),
                    },
                )
            )

        return {"partial_answer": False}

    except Exception as e:
        logger.error(f"Persistence failed: {e}")
        return {"error": f"Persistence failed: {str(e)}"}
```

#### 2.3.4 Graph ç¼–æ’å’Œæµå¼å¤„ç†

**åˆ›å»º conversation_graph å·¥å‚**ï¼š

```python
# æ–‡ä»¶: infrastructure/chat/conversation_graph.py
from langgraph.graph import StateGraph, START, END, Conditional
from langgraph.types import Send
import asyncio
import logging

logger = logging.getLogger(__name__)

class ConversationGraphBuilder:
    """æ„å»ºå¯¹è¯æµå›¾"""

    def __init__(
        self,
        router,
        conversation_store,
        memory_service=None,
        summarizer=None,
        episodic_memory_manager=None,
        rag_executor=None,
        llm=None,
        kb_handler_factory=None,
        enable_kb_handlers=False,
    ):
        self.router = router
        self.conversation_store = conversation_store
        self.memory_service = memory_service
        self.summarizer = summarizer
        self.episodic_memory_manager = episodic_memory_manager
        self.rag_executor = rag_executor
        self.llm = llm
        self.kb_handler_factory = kb_handler_factory
        self.enable_kb_handlers = enable_kb_handlers

    def _route_to_kb_or_rag(self, state: ConversationState) -> str:
        """æ¡ä»¶è¾¹ï¼šé€‰æ‹©ä½¿ç”¨ KB Handler è¿˜æ˜¯ RAG æ‰§è¡Œå™¨"""
        if self.enable_kb_handlers and state.get("kb_prefix"):
            kb_handler = self.kb_handler_factory.get(state["kb_prefix"])
            if kb_handler is not None:
                return "generate_kb"
        return "generate_rag"

    def _should_retrieve(self, state: ConversationState) -> bool:
        """æ¡ä»¶åˆ¤æ–­ï¼šæ˜¯å¦éœ€è¦æ£€ç´¢"""
        return state.get("use_retrieval", False)

    def build(self) -> CompiledGraph:
        """æ„å»ºç¼–è¯‘åçš„å›¾"""
        builder = StateGraph(ConversationState)

        # ==================== æ·»åŠ èŠ‚ç‚¹ ====================
        builder.add_node(
            "route",
            lambda state: route_node(
                state, router=self.router
            ),
        )

        builder.add_node(
            "history",
            lambda state: history_node(
                state,
                conversation_store=self.conversation_store,
                memory_service=self.memory_service,
                summarizer=self.summarizer,
                episodic_memory_manager=self.episodic_memory_manager,
            ),
        )

        builder.add_node(
            "retrieve",
            lambda state: retrieve_node(
                state,
                rag_executor=self.rag_executor,
            ),
        )

        builder.add_node(
            "generate_kb",
            lambda state: generate_kb_node(
                state,
                kb_handler_factory=self.kb_handler_factory,
            ),
        )

        builder.add_node(
            "generate_rag",
            lambda state: generate_rag_node(
                state,
                llm=self.llm,
            ),
        )

        builder.add_node(
            "persist",
            lambda state: persist_node(
                state,
                conversation_store=self.conversation_store,
                memory_service=self.memory_service,
                episodic_memory_manager=self.episodic_memory_manager,
            ),
        )

        # ==================== å®šä¹‰è¾¹ ====================
        builder.set_entry_point("route")

        # route â†’ historyï¼ˆæ€»æ˜¯ï¼‰
        builder.add_edge("route", "history")

        # history â†’ retrieveï¼ˆæœ‰æ¡ä»¶ï¼‰
        builder.add_conditional_edges(
            "history",
            lambda state: self._should_retrieve(state),
            {
                True: "retrieve",
                False: "generate_kb" if self.enable_kb_handlers else "generate_rag",
            },
        )

        # retrieve â†’ é€‰æ‹©ç”Ÿæˆå™¨
        builder.add_conditional_edges(
            "retrieve",
            lambda state: self._route_to_kb_or_rag(state),
            {
                "generate_kb": "generate_kb",
                "generate_rag": "generate_rag",
            },
        )

        # generate_kb / generate_rag â†’ persist
        builder.add_edge("generate_kb", "persist")
        builder.add_edge("generate_rag", "persist")

        # persist â†’ end
        builder.add_edge("persist", END)

        # ==================== ç¼–è¯‘ ====================
        return builder.compile()


# ä½¿ç”¨ç¤ºä¾‹
def create_conversation_graph(
    services: ServiceContainer,  # åŒ…å«æ‰€æœ‰ä¾èµ–
) -> CompiledGraph:
    """å·¥å‚å‡½æ•°ï¼šåˆ›å»ºå¯¹è¯å›¾"""
    builder = ConversationGraphBuilder(
        router=services.router,
        conversation_store=services.conversation_store,
        memory_service=services.memory_service,
        summarizer=services.summarizer,
        episodic_memory_manager=services.episodic_memory_manager,
        rag_executor=services.rag_executor,
        llm=services.llm,
        kb_handler_factory=services.kb_handler_factory,
        enable_kb_handlers=services.config.ENABLE_KB_HANDLERS,
    )
    return builder.build()
```

#### 2.3.5 æµå¼å¤„ç†é›†æˆ

**æ”¹é€  HTTP å±‚ä½¿ç”¨ LangGraph**ï¼š

```python
# æ–‡ä»¶: server/api/rest/v1/chat_stream.py
from fastapi import APIRouter, HTTPException
from fastapi.responses import StreamingResponse
import json
from application.chat.schema import ChatRequest

router = APIRouter()

@router.post("/api/v1/chat/stream")
async def stream_chat(request: ChatRequest):
    """
    ä½¿ç”¨ LangGraph çš„æµå¼èŠå¤©ç«¯ç‚¹

    è¿ç§»æ¸…å•ï¼š
    âœ… åŸæœ‰ StreamHandler.handle() é€»è¾‘ â†’ LangGraph èŠ‚ç‚¹åŒ–
    âœ… å‚æ•°ä¸å†é€å±‚ä¼ é€’ â†’ ç»Ÿä¸€ State
    âœ… æ”¯æŒ debug æ¨¡å¼ â†’ execution_logs
    """

    try:
        # 1. è·å–æˆ–åˆ›å»ºå¯¹è¯
        conversation_id = await conversation_store.get_or_create_conversation_id(
            user_id=request.user_id,
            session_id=request.session_id,
        )

        # 2. ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
        await conversation_store.append_message(
            conversation_id=conversation_id,
            role="user",
            content=request.message,
        )

        # 3. åˆå§‹åŒ– Stateï¼ˆå¯¹åº”åŸæœ‰çš„ initial_stateï¼‰
        initial_state = ConversationState(
            # è¯·æ±‚ä¿¡æ¯
            user_id=request.user_id,
            message=request.message,
            session_id=request.session_id,
            conversation_id=conversation_id,
            # é…ç½®
            debug=request.debug,
            agent_type=request.agent_type,
            requested_kb_prefix=request.kb_prefix,
            # åˆå§‹åŒ–å…¶ä»–å­—æ®µ
            kb_prefix=None,
            worker_name=None,
            use_retrieval=False,
            history=[],
            memory_context=None,
            conversation_summary=None,
            episodic_memory=None,
            retrieval_results=None,
            messages=[HumanMessage(content=request.message)],
            execution_logs=[],
            error=None,
            partial_answer=False,
        )

        # 4. æµå¼æ‰§è¡Œå›¾
        async def event_generator():
            tokens = []
            completed = False

            async for event in conversation_graph.astream(
                initial_state,
                stream_mode="updates",  # æ¯ä¸ªèŠ‚ç‚¹æ‰§è¡Œåäº§ç”Ÿä¸€ä¸ªäº‹ä»¶
            ):
                # event æ ¼å¼: {node_name: {updated_state_fields}}
                node_name = list(event.keys())[0]
                node_state = event[node_name]

                # ç‰¹æ®Šå¤„ç†ï¼šæµå¼æ–‡æœ¬æ¥è‡ª generate èŠ‚ç‚¹
                if node_name in ["generate_kb", "generate_rag"]:
                    if "messages" in node_state:
                        message_content = node_state["messages"][-1].content
                        # æ¨¡æ‹Ÿæµå¼è¾“å‡ºï¼ˆå®é™… LLM åº”è¯¥å·²ç»æµå¼è¿”å›ï¼‰
                        for char in message_content:
                            tokens.append(char)
                            yield {
                                "status": "token",
                                "content": char,
                            }
                        completed = True

                # Debug æ¨¡å¼ï¼šè¾“å‡ºæ‰§è¡Œæ—¥å¿—
                if node_state.get("execution_logs"):
                    for log in node_state["execution_logs"]:
                        if log not in (initial_state.get("execution_logs") or []):
                            yield {
                                "status": "execution_log",
                                "content": log,
                            }

                # è·¯ç”±å†³ç­–ï¼šè¾“å‡ºç»™å®¢æˆ·ç«¯
                if node_name == "route" and "route_decision" in node_state:
                    yield {
                        "status": "route_decision",
                        "content": node_state["route_decision"],
                    }

            # æµå¼ç»“æŸ
            answer = "".join(tokens).strip()
            yield {
                "status": "done",
                "content": {
                    "answer": answer,
                    "conversation_id": conversation_id,
                },
            }

        # 5. è¿”å› SSE å“åº”
        return StreamingResponse(
            event_generator(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "X-Accel-Buffering": "no",
            },
        )

    except Exception as e:
        logger.error(f"Chat stream failed: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))
```

**ä¸åŸæœ‰ä»£ç çš„å¯¹åº”å…³ç³»**ï¼š

| åŸæœ‰ä»£ç  | LangGraph æ–¹æ¡ˆ | ä¼˜åŠ¿ |
|---------|--------------|------|
| `StreamHandler.handle()` ç¬¬ 65-261 è¡Œ | `conversation_graph.astream()` | æµç¨‹æ¸…æ™°ï¼Œæ˜“äºç†è§£ |
| æ‰‹åŠ¨ä¼ é€’ `memory_context, history` | `ConversationState` | æ–°å¢å‚æ•°æ— éœ€æ”¹å‡½æ•°ç­¾å |
| `kb_handler.process_stream()` + `executor.stream()` | æ¡ä»¶è¾¹è‡ªåŠ¨é€‰æ‹© | ä¸éœ€è¦å¤šä¸ªå¤„ç†å™¨åˆ†æ”¯ |
| æ‰‹åŠ¨è¿½åŠ æ¶ˆæ¯ | `Annotated[list, add]` | è‡ªåŠ¨åˆå¹¶æ¶ˆæ¯ |

#### 2.3.6 ä¸€æ¬¡æ€§é‡æ„æ–¹æ¡ˆ

**å®Œæ•´çš„æ–‡ä»¶è¿ç§»æ¸…å•**ï¼š

##### Step 1ï¼šåˆ›å»ºæ–°çš„çŠ¶æ€å’Œå›¾æ–‡ä»¶ï¼ˆæ–°å»ºï¼‰

```
æ–°å»ºæ–‡ä»¶ï¼š
âœ… backend/infrastructure/chat/conversation_state.py
âœ… backend/infrastructure/chat/conversation_nodes.py
âœ… backend/infrastructure/chat/conversation_graph.py
âœ… backend/application/chat/handlers/langgraph_stream_handler.py
```

##### Step 2ï¼šåˆ é™¤æˆ–å¼ƒç”¨çš„æ–‡ä»¶

```
å¼ƒç”¨ï¼ˆä½†ä¿ç•™ä»¥é˜²å›æ»šï¼‰ï¼š
âš ï¸  backend/application/chat/handlers/stream_handler.py
âš ï¸  backend/application/chat/handlers/chat_handler.py

å®Œå…¨åˆ é™¤ï¼ˆå…¶é€»è¾‘å·²è¿ç§»åˆ°èŠ‚ç‚¹ä¸­ï¼‰ï¼š
âŒ backend/application/chat/completion.pyï¼ˆPrompt æ„å»ºé€»è¾‘ï¼‰
```

##### Step 3ï¼šä¿®æ”¹çš„æ–‡ä»¶

```
éœ€è¦ä¿®æ”¹ï¼š
ğŸ“ backend/server/api/rest/v1/chat_stream.py
   - æ›¿æ¢ StreamHandler â†’ LangGraphStreamHandler

ğŸ“ backend/server/api/rest/v1/chat.py
   - æ›¿æ¢ ChatHandler â†’ LangGraphStreamHandlerï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰

ğŸ“ backend/infrastructure/config.py
   - æ·»åŠ  LangGraph ç›¸å…³é…ç½®

ğŸ“ backend/infrastructure/di/container.py
   - æ³¨å†Œ conversation_graph ä¾èµ–
   - åˆ é™¤ StreamHandler / ChatHandler æ³¨å†Œ
```

##### Step 4ï¼šè¯¦ç»†è¿ç§»æ­¥éª¤

**ç¬¬ 1 å¤©ï¼šåŸºç¡€è®¾æ–½æ­å»º**

```python
# 1. åˆ›å»º conversation_state.py
# åŒ…å«å®Œæ•´çš„ ConversationState TypedDictï¼ˆå‚è€ƒ 2.3.2ï¼‰

# 2. åˆ›å»º conversation_nodes.py
# åŒ…å«æ‰€æœ‰ 5 ä¸ªèŠ‚ç‚¹çš„å®ç°ï¼š
# - route_node()
# - history_node()
# - retrieve_node()
# - generate_node()
# - persist_node()
```

**ç¬¬ 2 å¤©ï¼šå›¾æ„å»º**

```python
# 1. åˆ›å»º conversation_graph.py
# åŒ…å« ConversationGraphBuilder ç±»å’Œ create_conversation_graph() å·¥å‚

# 2. åœ¨ DI å®¹å™¨ä¸­æ³¨å†Œ
# container.py:
#   graph = create_conversation_graph(services)
```

**ç¬¬ 3 å¤©ï¼šHTTP å±‚è¿ç§»**

```python
# 1. åˆ›å»º langgraph_stream_handler.py
# - å®ç°æ–°çš„ stream_chat() ç«¯ç‚¹
# - ä¿æŒä¸æ—§ API å®Œå…¨å…¼å®¹

# 2. ä¿®æ”¹ chat_stream.py
# - æ›¿æ¢å¯¼å…¥ï¼šfrom StreamHandler â†’ from LangGraphStreamHandler
# - æˆ–ç›´æ¥ä½¿ç”¨ conversation_graph.astream()
```

**ç¬¬ 4 å¤©ï¼šæµ‹è¯•å’ŒéªŒè¯**

```python
# 1. å•å…ƒæµ‹è¯•
# - æ¯ä¸ªèŠ‚ç‚¹ç‹¬ç«‹æµ‹è¯•
# - çŠ¶æ€è½¬ç§»æµ‹è¯•
# - é”™è¯¯å¤„ç†æµ‹è¯•

# 2. é›†æˆæµ‹è¯•
# - å®Œæ•´å¯¹è¯æµç¨‹æµ‹è¯•
# - å¯¹æ¯”æ–°æ—§å®ç°çš„è¾“å‡º

# 3. æ€§èƒ½æµ‹è¯•
# - å»¶è¿Ÿå¯¹æ¯”
# - å†…å­˜å ç”¨å¯¹æ¯”
```

**ç¬¬ 5 å¤©ï¼šéƒ¨ç½²å’Œå›æ»š**

```bash
# éƒ¨ç½²å‰ï¼šå¤‡ä»½æ—§ä»£ç 
git tag backup/stream-handler-v1

# éƒ¨ç½²ï¼šä¸€æ¬¡æ€§æ›¿æ¢æ‰€æœ‰ç«¯ç‚¹
DEPLOY_VERSION=langgraph

# éƒ¨ç½²åï¼šç›‘æ§
- å¯¹è¯æˆåŠŸç‡
- å“åº”å»¶è¿Ÿ
- é”™è¯¯ç‡
- æ—¥å¿—å¼‚å¸¸

# å¦‚é‡é—®é¢˜ï¼šå¿«é€Ÿå›æ»š
git revert <commit-hash>
```

##### Step 5ï¼šå…³é”®å®ç°ç»†èŠ‚

**ä¿æŒä¸æ—§ API å®Œå…¨å…¼å®¹**ï¼š

```python
# åŸæœ‰çš„ HTTP è¯·æ±‚å®Œå…¨ä¸å˜
POST /api/v1/chat/stream {
    "user_id": "...",
    "message": "...",
    "session_id": "...",
    "kb_prefix": "...",
    "debug": false,
    "agent_type": "hybrid_agent"
}

# å“åº”æ ¼å¼å®Œå…¨ç›¸åŒ
{
    "status": "token",
    "content": "æ–‡"
}
{
    "status": "done",
    "content": {"answer": "..."}
}
```

**ä¾èµ–æ³¨å…¥æ”¹é€ ï¼ˆæœ€å°åŒ–ï¼‰**ï¼š

```python
# åŸæœ‰ï¼š
handler = StreamHandler(
    router=router,
    executor=executor,
    conversation_store=conversation_store,
    memory_service=memory_service,
    kb_handler_factory=kb_handler_factory,
)

# æ–°æ–¹æ¡ˆï¼š
graph = create_conversation_graph(services)  # ä¸€è¡Œä»£ç 

# åœ¨ HTTP å±‚è°ƒç”¨
async for event in graph.astream(initial_state):
    yield event
```

##### Step 6ï¼šä¸å¯é€†ç‚¹ï¼ˆç¡®ä¿ä¸€æ¬¡æ€§æˆåŠŸï¼‰

| æ£€æŸ¥é¡¹ | è¯´æ˜ |
|-------|------|
| æµ‹è¯•è¦†ç›–ç‡ | æ‰€æœ‰èŠ‚ç‚¹å•å…ƒæµ‹è¯• â‰¥ 90% |
| é›†æˆæµ‹è¯• | è‡³å°‘ 50 ä¸ªçœŸå®å¯¹è¯åœºæ™¯éªŒè¯ |
| æ€§èƒ½åŸºçº¿ | å»¶è¿Ÿä¸è¶…è¿‡åŸæœ‰ Â±5% |
| é”™è¯¯å¤„ç† | æ‰€æœ‰å¼‚å¸¸éƒ½æœ‰é™çº§æ–¹æ¡ˆ |
| å›æ»šè„šæœ¬ | æµ‹è¯•è¿‡å¿«é€Ÿå›æ»šæµç¨‹ |

##### Step 7ï¼šéƒ¨ç½²å‘½ä»¤

```bash
# 1. æ„å»ºæ–°é•œåƒï¼ˆåŒ…å«æ‰€æœ‰ LangGraph ä»£ç ï¼‰
docker build -t movie-agent:langgraph-v1 .

# 2. è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶
pytest tests/ -v --cov=backend

# 3. æ€§èƒ½åŸºå‡†æµ‹è¯•
python benchmarks/test_performance.py

# 4. éƒ¨ç½²åˆ°é¢„å‘å¸ƒç¯å¢ƒï¼ˆ10% æµé‡ï¼‰
kubectl set image deployment/movie-agent \
  movie-agent=movie-agent:langgraph-v1 \
  --record \
  --namespace=staging

# 5. éªŒè¯é¢„å‘å¸ƒï¼ˆ30 åˆ†é’Ÿï¼‰
- ç›‘æ§é”™è¯¯ç‡
- æ£€æŸ¥æ—¥å¿—
- æ‰‹å·¥æµ‹è¯•å‡ ä¸ªå¯¹è¯

# 6. å…¨é‡ä¸Šçº¿ï¼ˆ100% æµé‡ï¼‰
kubectl set image deployment/movie-agent \
  movie-agent=movie-agent:langgraph-v1 \
  --record \
  --namespace=production

# 7. æŒç»­ç›‘æ§ï¼ˆ1 å°æ—¶ï¼‰
- å…³é”®æŒ‡æ ‡ç›‘æ§
- å‘Šè­¦é…ç½®
- å‡†å¤‡å›æ»šæ–¹æ¡ˆ
```

##### Step 8ï¼šå¿«é€Ÿå›æ»šæ–¹æ¡ˆ

```bash
# ä¸‡ä¸€å‡ºç°é—®é¢˜ï¼Œæ‰§è¡Œå›æ»šï¼ˆâ‰¤ 5 åˆ†é’Ÿï¼‰
kubectl rollout undo deployment/movie-agent \
  --namespace=production

# éªŒè¯å›æ»š
kubectl get pods -n production
curl http://api.service:8000/api/v1/health  # å¥åº·æ£€æŸ¥

# åˆ†æé—®é¢˜ï¼ˆPost-mortemï¼‰
- æŸ¥çœ‹æ–°æ—§ç‰ˆæœ¬çš„æ—¥å¿—å·®å¼‚
- å¯¹æ¯”ä¸¤ä¸ªç‰ˆæœ¬çš„æ€§èƒ½æŒ‡æ ‡
- ç¡®ä¿æ²¡æœ‰æ•°æ®æŸå
```

#### 2.3.7 æœ€ç»ˆçš„ä¼˜åŠ¿æ€»ç»“

| ç»´åº¦ | ç°æœ‰æ¶æ„ | Phase 3 (LangGraph) |
|------|---------|------------------|
| **å‚æ•°ä¼ é€’** | é€å±‚æ‰‹åŠ¨ä¼ é€’ï¼ˆ6+å±‚ï¼‰ | ç»Ÿä¸€ Stateï¼ˆé›¶å±‚ï¼‰ |
| **æ–°å¢å‚æ•°** | ä¿®æ”¹ 5-7 ä¸ªå‡½æ•°ç­¾å | ä¿®æ”¹ 1 ä¸ª TypedDict |
| **æ‰©å±•æ€§** | ä½ï¼Œæ”¹ä¸€ä¸ªå‚æ•°å½±å“å¤šå¤„ | é«˜ï¼ŒåŠ å­—æ®µå°±è¡Œ |
| **å¯æµ‹è¯•æ€§** | é›†æˆæµ‹è¯• | å•å…ƒæµ‹è¯•ï¼ˆæ¯ä¸ªèŠ‚ç‚¹ï¼‰ |
| **å¯è§‚æµ‹æ€§** | æ‰‹åŠ¨åŸ‹ç‚¹ + Langfuse | å†…ç½® execution_logs + Langfuse |
| **é”™è¯¯å¤„ç†** | æ¯å±‚éƒ½è¦ try-except | ç»Ÿä¸€åœ¨èŠ‚ç‚¹ä¸­å¤„ç† |
| **æµå¼å¤„ç†** | æ‰‹åŠ¨è¿½è¸ª tokens | è‡ªåŠ¨åˆå¹¶æ¶ˆæ¯ |

#### 2.3.8 Phase 3 æµ‹è¯•æ–¹æ¡ˆ

**å•å…ƒæµ‹è¯•ï¼ˆæ¯ä¸ªèŠ‚ç‚¹ç‹¬ç«‹æµ‹è¯•ï¼‰**ï¼š

```python
# tests/infrastructure/chat/test_conversation_nodes.py
import pytest
from unittest.mock import AsyncMock, MagicMock
from infrastructure.chat.conversation_nodes import (
    route_node, history_node, retrieve_node, generate_node, persist_node
)
from infrastructure.chat.conversation_state import ConversationState

class TestRouteNode:
    @pytest.mark.asyncio
    async def test_route_node_returns_kb_prefix(self):
        """æµ‹è¯• route_node æ­£ç¡®è¿”å› KB"""
        mock_router = AsyncMock()
        mock_router.route.return_value = RouteDecision(
            kb_prefix="movie",
            worker_name="movie:hybrid_agent",
            confidence=0.95,
            method="auto",
            reason="User query matched movie KB",
        )

        state = ConversationState(
            message="æ¨èç”µå½±",
            session_id="test-session",
            ...
        )

        result = await route_node(state, router=mock_router)

        assert result["kb_prefix"] == "movie"
        assert result["use_retrieval"] is True

    @pytest.mark.asyncio
    async def test_route_node_general_kb_no_retrieval(self):
        """æµ‹è¯• general KB ä¸éœ€è¦æ£€ç´¢"""
        mock_router = AsyncMock()
        mock_router.route.return_value = RouteDecision(
            kb_prefix="general",
            worker_name="general:naive_agent",
            ...
        )

        result = await route_node(state, router=mock_router)
        assert result["use_retrieval"] is False


class TestHistoryNode:
    @pytest.mark.asyncio
    async def test_history_node_retrieves_messages(self):
        """æµ‹è¯• history_node æ­£ç¡®è·å–å†å²æ¶ˆæ¯"""
        mock_store = AsyncMock()
        mock_store.list_messages.return_value = [
            {"role": "user", "content": "ä»€ä¹ˆæ˜¯æ¨èç³»ç»Ÿ"},
            {"role": "assistant", "content": "æ¨èç³»ç»Ÿæ˜¯..."},
            {"role": "user", "content": "èƒ½ä¸¾ä¾‹å—"},
        ]

        state = ConversationState(conversation_id="conv-1", message="èƒ½ä¸¾ä¾‹å—", ...)
        result = await history_node(state, conversation_store=mock_store)

        assert len(result["history"]) == 2  # å»é‡å½“å‰æ¶ˆæ¯
        assert result["history"][0]["content"] == "ä»€ä¹ˆæ˜¯æ¨èç³»ç»Ÿ"

    @pytest.mark.asyncio
    async def test_history_node_with_summary(self):
        """æµ‹è¯• history_node è·å–æ‘˜è¦"""
        mock_store = AsyncMock()
        mock_store.list_messages.return_value = []

        mock_summarizer = AsyncMock()
        mock_summarizer.get_or_generate_summary.return_value = "ç”¨æˆ·è¯¢é—®äº†å…³äºç”µå½±æ¨èçš„é—®é¢˜"

        result = await history_node(state, conversation_store=mock_store, summarizer=mock_summarizer)

        assert result["conversation_summary"] is not None

    @pytest.mark.asyncio
    async def test_history_node_error_resilience(self):
        """æµ‹è¯• history_node åœ¨é”™è¯¯æ—¶çš„é™çº§"""
        mock_store = AsyncMock()
        mock_store.list_messages.return_value = []

        mock_summarizer = AsyncMock()
        mock_summarizer.get_or_generate_summary.side_effect = Exception("Summarizer failed")

        result = await history_node(state, conversation_store=mock_store, summarizer=mock_summarizer)

        # æ‘˜è¦å¤±è´¥ä¸åº”è¯¥é˜»å¡æ•´ä¸ªæµç¨‹
        assert result["conversation_summary"] is None
        assert "history" in result


class TestGenerateNode:
    @pytest.mark.asyncio
    async def test_generate_node_creates_message(self):
        """æµ‹è¯• generate_node ç”Ÿæˆ AIMessage"""
        mock_llm = AsyncMock()
        mock_llm.ainvoke.return_value = MagicMock(content="è¿™æ˜¯ä¸€ä¸ªæ¨èç»“æœ")

        state = ConversationState(
            message="æ¨èç”µå½±",
            history=[],
            memory_context=None,
            ...
        )

        result = await generate_node(state, llm=mock_llm)

        assert "messages" in result
        assert len(result["messages"]) > 0
        assert result["messages"][0].content == "è¿™æ˜¯ä¸€ä¸ªæ¨èç»“æœ"

    @pytest.mark.asyncio
    async def test_generate_node_with_context(self):
        """æµ‹è¯• generate_node åŒ…å«æ‰€æœ‰ä¸Šä¸‹æ–‡"""
        mock_llm = AsyncMock()

        state = ConversationState(
            message="æ¨èç”µå½±",
            history=[{"role": "user", "content": "å–œæ¬¢ç§‘å¹»"}],
            memory_context="ç”¨æˆ·å–œæ¬¢è¯ºå…°çš„ç”µå½±",
            conversation_summary="ç”¨æˆ·è¯¢é—®ç”µå½±æ¨è",
            retrieval_results=[{"content": "ã€Šæ˜Ÿé™…ç©¿è¶Šã€‹æ˜¯è¯ºå…°çš„ä»£è¡¨ä½œ"}],
            ...
        )

        result = await generate_node(state, llm=mock_llm)

        # éªŒè¯ LLM è¢«æ­£ç¡®è°ƒç”¨ï¼ˆåŒ…å«æ‰€æœ‰ä¸Šä¸‹æ–‡ï¼‰
        assert mock_llm.ainvoke.called
        call_args = mock_llm.ainvoke.call_args
        prompt = call_args[0][0]  # ç¬¬ä¸€ä¸ªä½ç½®å‚æ•°æ˜¯ prompt

        # æ£€æŸ¥ Prompt åŒ…å«æ‰€æœ‰å¿…è¦ä¿¡æ¯
        assert "memory_context" not in prompt.format()  # å·²è¢« inject
        # å®é™…ä¸Šåº”è¯¥æ£€æŸ¥ prompt çš„å†…å®¹ï¼Œè¿™é‡Œç®€åŒ–äº†

class TestPersistNode:
    @pytest.mark.asyncio
    async def test_persist_node_saves_message(self):
        """æµ‹è¯• persist_node ä¿å­˜æ¶ˆæ¯"""
        mock_store = AsyncMock()

        state = ConversationState(
            conversation_id="conv-1",
            messages=[
                HumanMessage(content="æ¨èç”µå½±"),
                AIMessage(content="æ¨èã€Šæ˜Ÿé™…ç©¿è¶Šã€‹"),
            ],
            ...
        )

        result = await persist_node(state, conversation_store=mock_store)

        # éªŒè¯æ¶ˆæ¯è¢«ä¿å­˜
        mock_store.append_message.assert_called_once()
        call_args = mock_store.append_message.call_args
        assert call_args[1]["content"] == "æ¨èã€Šæ˜Ÿé™…ç©¿è¶Šã€‹"
```

**é›†æˆæµ‹è¯•ï¼ˆå®Œæ•´æµç¨‹ï¼‰**ï¼š

```python
# tests/infrastructure/chat/test_conversation_graph.py
import pytest
from infrastructure.chat.conversation_graph import create_conversation_graph
from infrastructure.chat.conversation_state import ConversationState
from langchain_core.messages import HumanMessage

class TestConversationGraph:
    @pytest.fixture
    async def graph(self, services_mock):
        """åˆ›å»ºæµ‹è¯•ç”¨çš„å›¾"""
        return create_conversation_graph(services_mock)

    @pytest.mark.asyncio
    async def test_complete_conversation_flow(self, graph):
        """æµ‹è¯•å®Œæ•´çš„å¯¹è¯æµç¨‹"""
        initial_state = ConversationState(
            user_id="test-user",
            message="æ¨èç§‘å¹»ç”µå½±",
            session_id="test-session",
            conversation_id="test-conv",
            debug=True,
            agent_type="hybrid_agent",
            requested_kb_prefix="movie",
            # å…¶ä»–å­—æ®µåˆå§‹åŒ–...
        )

        # æ‰§è¡Œå›¾
        final_state = None
        async for event in graph.astream(initial_state):
            final_state = event

        # éªŒè¯ç»“æœ
        assert final_state is not None
        assert "messages" in final_state
        assert len(final_state["messages"]) >= 2  # User + Assistant
        assert final_state["messages"][-1].type == "ai"

    @pytest.mark.asyncio
    async def test_graph_with_kb_handler(self, graph):
        """æµ‹è¯•ä½¿ç”¨ KB Handler çš„æµç¨‹"""
        # æµ‹è¯•æ¡ä»¶è¾¹ï¼šåº”è¯¥èµ° KB Handler
        # éªŒè¯ generate_kb_node è¢«æ‰§è¡Œ
        pass

    @pytest.mark.asyncio
    async def test_graph_error_handling(self, graph):
        """æµ‹è¯•é”™è¯¯å¤„ç†å’Œé™çº§"""
        # æ³¨å…¥é”™è¯¯ï¼šmemory_service å¤±è´¥
        # éªŒè¯æµç¨‹ç»§ç»­å¹¶å®Œæˆ
        pass

    @pytest.mark.asyncio
    async def test_graph_with_debug_mode(self, graph):
        """æµ‹è¯• debug æ¨¡å¼"""
        initial_state = ConversationState(..., debug=True)

        async for event in graph.astream(initial_state):
            pass

        # éªŒè¯ execution_logs è¢«å¡«å……
        # å„ä¸ªèŠ‚ç‚¹éƒ½è¾“å‡ºäº†æ—¥å¿—
```

**æ€§èƒ½æµ‹è¯•ï¼ˆåŸºå‡†å¯¹æ¯”ï¼‰**ï¼š

```python
# benchmarks/test_phase3_performance.py
import asyncio
import time
import statistics

@pytest.mark.benchmark
class TestConversationGraphPerformance:

    async def measure_single_conversation(self, graph, message: str) -> float:
        """æµ‹é‡å•ä¸ªå¯¹è¯çš„å»¶è¿Ÿ"""
        initial_state = ConversationState(
            user_id="perf-test",
            message=message,
            conversation_id="perf-conv",
            ...
        )

        t0 = time.perf_counter()
        async for event in graph.astream(initial_state):
            pass
        t1 = time.perf_counter()

        return (t1 - t0) * 1000  # æ¯«ç§’

    @pytest.mark.asyncio
    async def test_baseline_latency(self, graph):
        """æµ‹è¯•åŸºçº¿å»¶è¿Ÿ"""
        messages = [
            "æ¨èç”µå½±",
            "è¿™éƒ¨ç”µå½±æ€ä¹ˆæ ·",
            "è¿˜æœ‰å…¶ä»–æ¨èå—",
        ]

        times = []
        for msg in messages:
            latency_ms = await self.measure_single_conversation(graph, msg)
            times.append(latency_ms)

        avg_latency = statistics.mean(times)
        max_latency = max(times)

        print(f"å¹³å‡å»¶è¿Ÿ: {avg_latency:.2f}ms")
        print(f"æœ€å¤§å»¶è¿Ÿ: {max_latency:.2f}ms")

        # åº”è¯¥ < 500ms
        assert avg_latency < 500, f"Average latency {avg_latency}ms exceeds 500ms"
        assert max_latency < 1000, f"Max latency {max_latency}ms exceeds 1000ms"

    @pytest.mark.asyncio
    async def test_concurrent_conversations(self, graph):
        """æµ‹è¯•å¹¶å‘å¯¹è¯"""
        async def run_conversation(graph, msg: str):
            return await self.measure_single_conversation(graph, msg)

        # 10 ä¸ªå¹¶å‘å¯¹è¯
        tasks = [
            run_conversation(graph, f"æ¶ˆæ¯{i}")
            for i in range(10)
        ]

        times = await asyncio.gather(*tasks)

        avg_latency = statistics.mean(times)
        assert avg_latency < 600, "Concurrent latency too high"

    @pytest.mark.asyncio
    async def test_memory_usage(self, graph):
        """æµ‹è¯•å†…å­˜å ç”¨"""
        import tracemalloc

        tracemalloc.start()

        # è¿è¡Œ 100 ä¸ªå¯¹è¯
        for i in range(100):
            initial_state = ConversationState(...)
            async for event in graph.astream(initial_state):
                pass

        current, peak = tracemalloc.get_traced_memory()
        tracemalloc.stop()

        print(f"å³°å€¼å†…å­˜å ç”¨: {peak / 1024 / 1024:.2f}MB")
        # åº”è¯¥ < 200MB
        assert peak < 200 * 1024 * 1024
```

**æµ‹è¯•å‘½ä»¤**ï¼š

```bash
# è¿è¡Œæ‰€æœ‰ Phase 3 ç›¸å…³æµ‹è¯•
pytest tests/infrastructure/chat/test_conversation_nodes.py -v

pytest tests/infrastructure/chat/test_conversation_graph.py -v

# è¿è¡Œæ€§èƒ½æµ‹è¯•ï¼ˆå¯èƒ½è¾ƒæ…¢ï¼‰
pytest benchmarks/test_phase3_performance.py -v -s

# è¿è¡Œæµ‹è¯•è¦†ç›–ç‡æŠ¥å‘Š
pytest tests/ --cov=infrastructure/chat --cov-report=html

# ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Šï¼ˆæ–°æ—§ç‰ˆæœ¬ï¼‰
pytest tests/ -v --json=test_results_langgraph.json
# ä¸æ—§ç‰ˆæœ¬å¯¹æ¯”
diff <(pytest tests/ -v --json=test_results_legacy.json) test_results_langgraph.json
```

---

## 3. å®æ–½è·¯çº¿å›¾

| é˜¶æ®µ | å·¥ä½œé‡ï¼ˆäººå¤©ï¼‰ | é£é™© | ä¼˜å…ˆçº§ |
|------|---------------|------|--------|
| **Phase 1: æ‘˜è¦** | 3-5 | ä½ | **P0** |
| **Phase 2: è¯­ä¹‰æ£€ç´¢** | 5-7 | ä¸­ | P1 |
| **Phase 3: LangGraph** | 10-15 | é«˜ | P2 |

### 3.1 Phase 1 è¯¦ç»†å®æ–½æ­¥éª¤

#### Step 1: æ•°æ®åº“è¿ç§»
```python
# 1. åˆ›å»ºæ‘˜è¦è¡¨
async def init_summary_table():
    async with get_db_pool() as pool:
        async with pool.acquire() as conn:
            await conn.execute("""
            CREATE TABLE IF NOT EXISTS conversation_summaries (
                id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
                conversation_id UUID NOT NULL UNIQUE REFERENCES conversations(id) ON DELETE CASCADE,
                summary TEXT NOT NULL,
                covered_message_count INT NOT NULL DEFAULT 0,
                created_at TIMESTAMP DEFAULT NOW(),
                updated_at TIMESTAMP DEFAULT NOW()
            )
            """)
            # ç´¢å¼•ç”¨äºé¢‘ç¹æŸ¥è¯¢
            await conn.execute("""
            CREATE INDEX IF NOT EXISTS idx_conversation_summaries_conversation_id
            ON conversation_summaries(conversation_id)
            """)

# 2. åœ¨ ChatHandler åˆå§‹åŒ–æ—¶è°ƒç”¨
async def setup_handler(self):
    await init_summary_table()
```

#### Step 2: é›†æˆæ‘˜è¦ç”Ÿæˆ
```python
# åœ¨ conversation_store.py ä¸­æ·»åŠ æ‘˜è¦æ–¹æ³•
class ConversationStore:
    async def get_summary(self, conversation_id: str) -> dict | None:
        """è·å–å·²å­˜åœ¨çš„æ‘˜è¦"""
        result = await self.db.fetchrow(
            "SELECT * FROM conversation_summaries WHERE conversation_id = $1",
            conversation_id
        )
        return result

    async def save_summary(self, conversation_id: str, summary: str, covered_count: int):
        """ä¿å­˜æˆ–æ›´æ–°æ‘˜è¦"""
        await self.db.execute("""
        INSERT INTO conversation_summaries (conversation_id, summary, covered_message_count)
        VALUES ($1, $2, $3)
        ON CONFLICT(conversation_id) DO UPDATE SET
            summary = EXCLUDED.summary,
            covered_message_count = EXCLUDED.covered_message_count,
            updated_at = NOW()
        """, conversation_id, summary, covered_count)
```

#### Step 3: é›†æˆåˆ° ChatHandler
```python
# åœ¨ chat_handler.py ä¸­ä¿®æ”¹ _get_context æ–¹æ³•
async def _get_context(self, conversation_id: str) -> dict:
    # 1. åˆ¤æ–­æ˜¯å¦éœ€è¦ç”Ÿæˆæ‘˜è¦
    messages_count = await self._conversation_store.count_messages(conversation_id)
    existing_summary = await self._conversation_store.get_summary(conversation_id)

    summary = None
    if messages_count >= 10:
        if existing_summary is None or (messages_count - existing_summary["covered_message_count"]) >= 5:
            # ç”Ÿæˆæ–°æ‘˜è¦
            all_messages = await self._conversation_store.list_messages(
                conversation_id, limit=None  # è·å–æ‰€æœ‰æ¶ˆæ¯
            )
            to_summarize = all_messages[:-6]  # ä¿ç•™æœ€å 6 æ¡

            if to_summarize:
                try:
                    summary_text = await self._generate_summary(to_summarize)
                    await self._conversation_store.save_summary(
                        conversation_id,
                        summary_text,
                        len(to_summarize)
                    )
                    summary = summary_text
                except Exception as e:
                    logger.error(f"Failed to generate summary: {e}")
                    summary = existing_summary["summary"] if existing_summary else None
            else:
                summary = existing_summary["summary"] if existing_summary else None
        else:
            summary = existing_summary["summary"]

    # 2. è·å–æœ€è¿‘æ¶ˆæ¯
    recent = await self._conversation_store.list_messages(
        conversation_id=conversation_id,
        limit=6,
        desc=True
    )
    recent.reverse()

    return {
        "summary": summary,
        "recent_history": recent
    }

async def _generate_summary(self, messages: list[dict]) -> str:
    """ç”Ÿæˆå¯¹è¯æ‘˜è¦"""
    formatted = "\n".join([
        f"{msg['role'].upper()}: {msg['content']}"
        for msg in messages
    ])

    prompt = ChatPromptTemplate.from_messages([
        ("system", """ä½ æ˜¯ä¸€ä¸ªå¯¹è¯æ‘˜è¦ä¸“å®¶ã€‚è¯·å°†ä»¥ä¸‹å¯¹è¯å†å²å‹ç¼©ä¸º 2-3 å¥è¯çš„æ‘˜è¦ï¼Œçªå‡ºï¼š
1. ç”¨æˆ·çš„æ ¸å¿ƒè¯‰æ±‚å’Œåå¥½
2. å·²è®¨è®ºçš„å…³é”®è¯é¢˜
3. ä»»ä½•é‡è¦çš„èƒŒæ™¯ä¿¡æ¯

ä¿æŒç®€æ´ï¼Œé¿å…å†—ä½™ã€‚"""),
        ("user", formatted)
    ])

    response = await self.llm.ainvoke(prompt)
    return response.content
```

#### Step 4: æ›´æ–° Prompt æ„å»º
```python
# åœ¨ completion.py ä¸­æ›´æ–° build_prompt å‡½æ•°
def _build_general_prompt(
    system_message: str,
    memory_context: str | None = None,
    summary: str | None = None,
    history: list[dict] | None = None,
    question: str = ""
) -> ChatPromptTemplate:
    messages = [("system", system_message)]

    # æ·»åŠ è®°å¿†ä¸Šä¸‹æ–‡
    if memory_context:
        messages.append(("system", f"ã€ç”¨æˆ·é•¿æœŸè®°å¿†ã€‘\n{memory_context}"))

    # æ·»åŠ å¯¹è¯æ‘˜è¦ï¼ˆæ–°å¢ï¼‰
    if summary:
        messages.append(("system", f"ã€å¯¹è¯èƒŒæ™¯ã€‘\n{summary}"))

    # æ·»åŠ è¿‘æœŸå†å²
    if history:
        for msg in history:
            role = "assistant" if msg.get("role") == "assistant" else "human"
            messages.append((role, msg.get("content", "")))

    # å½“å‰é—®é¢˜
    messages.append(("human", question))

    return ChatPromptTemplate.from_messages(messages)
```

#### Step 5: æµ‹è¯•éªŒè¯
```python
# tests/test_summarization.py
import pytest

@pytest.mark.asyncio
async def test_summary_generation():
    """æµ‹è¯•æ‘˜è¦ç”Ÿæˆ"""
    # åˆ›å»ºæµ‹è¯•å¯¹è¯
    messages = [
        {"role": "user", "content": "æ¨èä¸€äº›ç§‘å¹»ç”µå½±"},
        {"role": "assistant", "content": "æˆ‘æ¨èã€Šæ˜Ÿé™…ç©¿è¶Šã€‹ã€ã€Šé»‘å®¢å¸å›½ã€‹..."},
        {"role": "user", "content": "è¿™äº›ç”µå½±æœ‰ä»€ä¹ˆå…±åŒç‚¹ï¼Ÿ"},
        {"role": "assistant", "content": "å®ƒä»¬éƒ½æ¶‰åŠ..."}
    ]

    store = ConversationStore()
    summary = await store._summarizer.generate_summary(messages)

    assert len(summary) > 0
    assert len(summary.split()) < 50  # æ‘˜è¦åº”è¯¥ç®€æ´
    assert "ç§‘å¹»" in summary or "ç”µå½±" in summary

@pytest.mark.asyncio
async def test_summary_caching():
    """æµ‹è¯•æ‘˜è¦ç¼“å­˜"""
    conv_id = "test-conv-123"

    # é¦–æ¬¡ç”Ÿæˆ
    summary1 = await store.get_summary(conv_id)
    assert summary1 is None

    # ä¿å­˜æ‘˜è¦
    await store.save_summary(conv_id, "è¿™æ˜¯æ‘˜è¦", 10)

    # ç¬¬äºŒæ¬¡åº”è¯¥ä»ç¼“å­˜è¯»å–
    summary2 = await store.get_summary(conv_id)
    assert summary2 is not None
    assert summary2["summary"] == "è¿™æ˜¯æ‘˜è¦"
```

### 3.2 Phase 2 è¯¦ç»†å®æ–½æ­¥éª¤

#### Step 1: å‘é‡ç´¢å¼•å»ºç«‹
```python
# åœ¨ episodic_memory.py ä¸­å®ç°
from milvus import Collection, Milvus

class EpisodicMemoryManager:
    def __init__(self, milvus_host: str, embedding_model):
        self.client = Milvus(host=milvus_host)
        self.embedding_model = embedding_model

    async def init_collection(self):
        """åˆå§‹åŒ– Milvus Collection"""
        collection_name = "conversation_episodes"

        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        existing = self.client.has_collection(collection_name)
        if not existing:
            fields = [
                FieldSchema(name="id", dtype=DataType.VARCHAR, is_primary=True, max_length=100),
                FieldSchema(name="conversation_id", dtype=DataType.VARCHAR, max_length=100),
                FieldSchema(name="user_message", dtype=DataType.VARCHAR, max_length=4096),
                FieldSchema(name="assistant_message", dtype=DataType.VARCHAR, max_length=4096),
                FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=1536),
                FieldSchema(name="created_at", dtype=DataType.INT64),
                FieldSchema(name="timestamp", dtype=DataType.INT64),
            ]

            schema = CollectionSchema(fields, primary_field="id")
            self.collection = Collection(
                name=collection_name,
                schema=schema
            )

            # åˆ›å»ºç´¢å¼•ä»¥åŠ é€Ÿæœç´¢
            self.collection.create_index(
                field_name="embedding",
                index_params={
                    "metric_type": "COSINE",
                    "index_type": "IVF_FLAT",
                    "params": {"nlist": 128}
                }
            )

    async def index_episode(self, conversation_id: str, user_msg: str, assistant_msg: str):
        """ç´¢å¼•ä¸€ä¸ªå¯¹è¯ç‰‡æ®µ"""
        try:
            # ç”ŸæˆåµŒå…¥
            combined_text = f"{user_msg} {assistant_msg}"
            embedding = await self.embedding_model.embed_query(combined_text)

            # æ’å…¥åˆ°å‘é‡åº“
            from uuid import uuid4
            import time

            self.collection.insert([{
                "id": str(uuid4()),
                "conversation_id": conversation_id,
                "user_message": user_msg,
                "assistant_message": assistant_msg,
                "embedding": embedding,
                "created_at": int(time.time()),
                "timestamp": int(time.time() * 1000)
            }])

            logger.info(f"Indexed episode for conversation {conversation_id}")
        except Exception as e:
            logger.error(f"Failed to index episode: {e}")
            # ä¸é˜»å¡ä¸»æµç¨‹

    async def recall_relevant(self, conversation_id: str, query: str, top_k: int = 3):
        """å¬å›ç›¸å…³çš„å†å²ç‰‡æ®µ"""
        try:
            # ç”ŸæˆæŸ¥è¯¢åµŒå…¥
            query_embedding = await self.embedding_model.embed_query(query)

            # å‘é‡æœç´¢ï¼ˆé™åˆ¶åœ¨å½“å‰å¯¹è¯ï¼‰
            results = self.collection.search(
                data=[query_embedding],
                anns_field="embedding",
                param={"metric_type": "COSINE", "params": {"nprobe": 10}},
                limit=top_k * 2,  # è·å–æ›´å¤šï¼Œåç»­è¿‡æ»¤
                expr=f"conversation_id == '{conversation_id}'"
            )

            # æ ¼å¼åŒ–ç»“æœ
            episodes = []
            for hit in results[0]:
                # hit åŒ…å« id, distance, entity
                entity = hit.entity
                episodes.append({
                    "user_message": entity.get("user_message"),
                    "assistant_message": entity.get("assistant_message"),
                    "similarity": 1 - hit.distance,  # COSINE è·ç¦»è½¬ç›¸ä¼¼åº¦
                    "timestamp": entity.get("created_at")
                })

            # æŒ‰ç›¸ä¼¼åº¦é™åºæ’åˆ—ï¼Œå– Top K
            episodes.sort(key=lambda x: x["similarity"], reverse=True)
            return episodes[:top_k]
        except Exception as e:
            logger.error(f"Failed to recall episodes: {e}")
            return []
```

#### Step 2: é›†æˆåˆ° ChatHandler
```python
# åœ¨ chat_handler.py ä¸­ä¿®æ”¹ _get_hybrid_history æ–¹æ³•
async def _get_hybrid_history(
    self,
    conversation_id: str,
    current_query: str
) -> list[dict]:
    """æ··åˆæ£€ç´¢ï¼šæ—¶é—´çª—å£ + è¯­ä¹‰çª—å£"""

    # 1. æ—¶é—´çª—å£ï¼šæœ€è¿‘ 6 æ¡æ¶ˆæ¯
    recent = await self._conversation_store.list_messages(
        conversation_id=conversation_id,
        limit=6,
        desc=True
    )
    recent.reverse()

    # 2. è¯­ä¹‰çª—å£ï¼šç›¸å…³çš„å†å²ç‰‡æ®µ
    try:
        relevant = await self._episodic_memory.recall_relevant(
            conversation_id=conversation_id,
            query=current_query,
            top_k=3
        )
    except Exception as e:
        logger.warning(f"Semantic recall failed: {e}, using time-based only")
        relevant = []

    # 3. åˆå¹¶å»é‡
    seen_content = {msg["content"] for msg in recent}
    unique_relevant = []
    for ep in relevant:
        combined = f"{ep.get('user_message', '')} {ep.get('assistant_message', '')}"
        if combined not in seen_content:
            unique_relevant.append({
                "role": "context",
                "content": combined,
                "type": "semantic_recall",
                "similarity": ep.get("similarity", 0)
            })

    # 4. æ’åºï¼šæŒ‰ç›¸ä¼¼åº¦é™åºï¼Œç„¶åæ˜¯æœ€è¿‘æ¶ˆæ¯
    unique_relevant.sort(key=lambda x: x.get("similarity", 0), reverse=True)

    return unique_relevant[:2] + recent  # æœ€å¤š2æ¡è¯­ä¹‰ç‰‡æ®µ + æœ€è¿‘æ¶ˆæ¯
```

#### Step 3: å¼‚æ­¥ç´¢å¼•ï¼ˆé¿å…é˜»å¡ï¼‰
```python
# åœ¨ chat_handler.py çš„ handle æ–¹æ³•ä¸­
async def handle(self, message: str, conversation_id: str, **kwargs):
    # ... ä¸»æµç¨‹ ...
    response = await self.generate_response(message, context)

    # å¼‚æ­¥ç´¢å¼•æ–°å¯¹è¯ç‰‡æ®µï¼ˆä¸é˜»å¡å“åº”ï¼‰
    asyncio.create_task(
        self._episodic_memory.index_episode(
            conversation_id=conversation_id,
            user_msg=message,
            assistant_msg=response
        )
    )

    return response
```

### 3.3 Phase 3 å®æ–½ç­–ç•¥

#### Feature Flag ç°åº¦
```python
# åœ¨ config.py ä¸­
LANGGRAPH_ENABLED = os.getenv("LANGGRAPH_ENABLED", "false").lower() == "true"

# åœ¨ chat_handler.py ä¸­
if LANGGRAPH_ENABLED:
    executor = LangGraphChatExecutor()
else:
    executor = LegacyChatExecutor()
```

#### å…¼å®¹æ€§å±‚
```python
# åˆ›å»ºé€‚é…å±‚ï¼Œé¿å…ä¸€æ¬¡æ€§é‡æ„æ‰€æœ‰è°ƒç”¨
class ChatExecutorAdapter:
    def __init__(self, use_langgraph: bool):
        if use_langgraph:
            self._executor = LangGraphChatExecutor()
        else:
            self._executor = LegacyChatExecutor()

    async def execute(self, message: str, **context) -> str:
        """ç»Ÿä¸€æ¥å£"""
        return await self._executor.execute(message, **context)
```

---

## 4. ä¼˜åŒ–å»ºè®®

### 4.1 æ€§èƒ½ä¼˜åŒ–

#### æ‘˜è¦ç”Ÿæˆä¼˜åŒ–
```python
# 1. ä½¿ç”¨é¡¹ç›®å†…ç½®çš„ Qwen æ¨¡å‹ç”Ÿæˆæ‘˜è¦ï¼ˆé™ä½æˆæœ¬å’Œå»¶è¿Ÿï¼‰
# é€šè¿‡æ¨¡å‹å·¥å‚è·å–ï¼Œæ”¯æŒé…ç½®åŒ–åˆ‡æ¢
class ConversationSummarizer:
    def __init__(self, model_factory, model_name: str = "qwen-turbo"):
        self.llm = model_factory.get_model(model_name)

    # 2. ç¼“å­˜å®Œå…¨ç›¸åŒçš„å¯¹è¯æ‘˜è¦è¯·æ±‚
    @lru_cache(maxsize=1000)
    async def generate_summary(self, text_hash: str) -> str:
        # å…ˆè®¡ç®—æ–‡æœ¬å“ˆå¸Œï¼Œé¿å…é‡å¤ç”Ÿæˆ
        pass

# 3. åå°å¼‚æ­¥ç”Ÿæˆï¼Œä¸é˜»å¡ç”¨æˆ·å“åº”
asyncio.create_task(self._generate_summary_async(conv_id))
```

#### å‘é‡æœç´¢ä¼˜åŒ–
```python
# 1. é™åˆ¶æœç´¢èŒƒå›´ï¼ˆæŒ‰æ—¶é—´æˆ³ï¼‰
# åªæœç´¢æœ€è¿‘ 30 å¤©çš„å¯¹è¯ç‰‡æ®µ
recent_timestamp = int((time.time() - 30 * 86400) * 1000)
expr = f"conversation_id == '{conv_id}' AND timestamp > {recent_timestamp}"

# 2. è°ƒæ•´å‘é‡ç´¢å¼•å‚æ•°ä»¥å¹³è¡¡ç²¾åº¦å’Œé€Ÿåº¦
index_params = {
    "metric_type": "COSINE",
    "index_type": "IVF_FLAT",
    "params": {"nlist": 128}  # å¢åŠ  nlist æé«˜ç²¾åº¦ï¼Œé™ä½ nlist æé«˜é€Ÿåº¦
}

# 3. æ‰¹é‡ç´¢å¼•ï¼ˆå‡å°‘ç½‘ç»œå¼€é”€ï¼‰
async def batch_index_episodes(self, episodes: list[dict]):
    embeddings = await self.embedding_model.embed_multiple(
        [f"{e['user']} {e['assistant']}" for e in episodes]
    )
    self.collection.insert([{
        "id": ep["id"],
        "conversation_id": ep["conversation_id"],
        "embedding": emb,
        ...
    } for ep, emb in zip(episodes, embeddings)])
```

### 4.2 å¯é æ€§ä¿è¯

#### é™çº§ç­–ç•¥
```python
# å½“æ‘˜è¦ç”Ÿæˆå¤±è´¥æ—¶
async def get_or_generate_summary(self, conversation_id: str) -> str | None:
    try:
        existing = await self._store.get_summary(conversation_id)
        if existing:
            return existing["summary"]

        # å°è¯•ç”Ÿæˆæ–°æ‘˜è¦
        return await self._generate_summary(conversation_id)
    except Exception as e:
        logger.error(f"Summary generation failed: {e}")
        # é™çº§ï¼šè¿”å› Noneï¼Œå‰ç«¯ä½¿ç”¨æ—¶é—´çª—å£å³å¯
        return None

# å½“å‘é‡æœç´¢å¤±è´¥æ—¶
async def recall_relevant(self, conversation_id: str, query: str, top_k: int = 3):
    try:
        return await self._search_vector(conversation_id, query, top_k)
    except Exception as e:
        logger.warning(f"Vector search failed: {e}, falling back to time-based")
        # é™çº§ï¼šè¿”å›æ—¶é—´åºåˆ—çš„æœ€å K æ¡
        return await self._store.list_messages(conversation_id, limit=top_k)
```

#### ç›‘æ§å’Œå‘Šè­¦
```python
# åœ¨å…³é”®ç‚¹æ·»åŠ ç›‘æ§
from prometheus_client import Counter, Histogram

summary_generation_time = Histogram('summary_generation_seconds', 'Time to generate summary')
summary_generation_errors = Counter('summary_generation_errors_total', 'Total summary generation errors')
vector_search_time = Histogram('vector_search_seconds', 'Time to search vectors')

@summary_generation_time.time()
async def generate_summary(self, messages):
    try:
        return await self.llm.ainvoke(...)
    except Exception as e:
        summary_generation_errors.inc()
        raise
```

### 4.3 æµ‹è¯•ç­–ç•¥

#### å•å…ƒæµ‹è¯•
```python
# tests/test_conversation_flow.py
@pytest.mark.asyncio
async def test_long_conversation_with_summary():
    """æµ‹è¯•é•¿å¯¹è¯ä¸­çš„æ‘˜è¦ç”Ÿæˆå’Œæ£€ç´¢"""
    handler = ChatHandler(store, summarizer, embedding_model)

    # ç”Ÿæˆ 15 æ¡æ¶ˆæ¯ï¼ˆè¶…è¿‡æ‘˜è¦é˜ˆå€¼ï¼‰
    for i in range(15):
        context = await handler._get_context("conv-1")
        assert context is not None

        if i > 10:
            # åº”è¯¥æœ‰æ‘˜è¦
            assert context.get("summary") is not None

@pytest.mark.asyncio
async def test_semantic_recall_accuracy():
    """æµ‹è¯•è¯­ä¹‰å¬å›çš„å‡†ç¡®æ€§"""
    # æ’å…¥ç›¸å…³å’Œä¸ç›¸å…³çš„å¯¹è¯ç‰‡æ®µ
    await memory.index_episode("conv-1", "æ¨èç§‘å¹»ç”µå½±", "æ¨èäº†ã€Šæ˜Ÿé™…ç©¿è¶Šã€‹")
    await memory.index_episode("conv-1", "ä»Šå¤©å¤©æ°”", "æ™´å¤©")

    # æœç´¢ç§‘å¹»ç›¸å…³
    results = await memory.recall_relevant("conv-1", "æœ‰ä»€ä¹ˆå¥½çš„ç§‘å¹»ç”µå½±")

    # åº”è¯¥ä¼˜å…ˆè¿”å›ç§‘å¹»ç›¸å…³çš„ç‰‡æ®µ
    assert "æ˜Ÿé™…ç©¿è¶Š" in results[0]["assistant_message"]
```

#### æ€§èƒ½åŸºå‡†æµ‹è¯•
```python
# benchmarks/test_performance.py
import asyncio
import time

async def benchmark_context_retrieval():
    """åŸºå‡†æµ‹è¯•ä¸Šä¸‹æ–‡æ£€ç´¢æ€§èƒ½"""
    handler = ChatHandler(...)

    # æµ‹è¯• 100 æ¬¡æ£€ç´¢
    times = []
    for _ in range(100):
        start = time.time()
        await handler._get_context("conv-1")
        times.append(time.time() - start)

    avg_time = sum(times) / len(times)
    max_time = max(times)

    # åº”è¯¥ < 100ms
    assert avg_time < 0.1, f"Average retrieval time {avg_time}s exceeds 100ms"
    assert max_time < 0.5, f"Max retrieval time {max_time}s exceeds 500ms"
```

### 4.4 å¸¸è§é™·é˜±

| é™·é˜± | ç—‡çŠ¶ | è§£å†³æ–¹æ¡ˆ |
|------|------|--------|
| æ‘˜è¦è¿‡äºç®€æ´ | ä¸¢å¤±é‡è¦ä¿¡æ¯ | å¢åŠ æ‘˜è¦å­—æ•°é™åˆ¶æˆ–æ£€æŸ¥æç¤ºè¯ |
| å‘é‡æœç´¢å‡†ç¡®ç‡ä½ | æ£€ç´¢åˆ°æ— å…³å¯¹è¯ | è°ƒæ•´ç›¸ä¼¼åº¦é˜ˆå€¼æˆ–æ”¹è¿›åµŒå…¥æ¨¡å‹ |
| ç´¢å¼•å †ç§¯ | å†…å­˜å ç”¨é«˜ | å®šæœŸæ¸…ç†æ—§å¯¹è¯çš„ç´¢å¼• |
| å¹¶å‘ç´¢å¼•å†²çª | æ•°æ®ä¸¢å¤±æˆ–é‡å¤ | ä½¿ç”¨åˆ†å¸ƒå¼é”ï¼ˆRedisï¼‰ä¿è¯ä¸€è‡´æ€§ |

---

## 5. é™„å½•

### 5.1 æˆæœ¬å¯¹æ¯”ï¼ˆè¯¦ç»†ä¼°ç®—ï¼‰

**å‡è®¾**ï¼š1000 æ¬¡å¯¹è¯/å¤©ï¼Œå¹³å‡æ¯å¯¹è¯ 20 è½®

| æ–¹æ¡ˆ | Token æ¶ˆè€— | API è°ƒç”¨æ•° | ä¼°è®¡æˆæœ¬ | èŠ‚çœå¯¹æ¯” |
|------|-----------|-----------|--------|---------|
| Baseline | 120M/æœˆ | 20K/å¤© | $3600/æœˆ | åŸºå‡† |
| + Phase 1 (æ‘˜è¦) | 40M/æœˆ | 20K/å¤© + 200 (æ‘˜è¦) | $1200/æœˆ | 67% â†“ |
| + Phase 2 (è¯­ä¹‰) | 35M/æœˆ | 20K/å¤© + 100 (æœç´¢) | $1050/æœˆ | 71% â†“ |
| + Phase 3 (æ¶æ„) | 32M/æœˆ | 20K/å¤© | $960/æœˆ | 73% â†“ |

### 5.2 æŠ€æœ¯æ ˆæ¸…å•

| é˜¶æ®µ | æ ¸å¿ƒä¾èµ– | å¯é€‰ä¼˜åŒ– |
|------|---------|---------|
| Phase 1 | LangChain, PostgreSQL | Redis (ç¼“å­˜æ‘˜è¦) |
| Phase 2 | Milvus, OpenAI Embedding | Qdrant (å‘é‡åº“æ›¿ä»£) |
| Phase 3 | LangGraph, asyncio | Weights & Biases (ç›‘æ§) |

### 5.3 è¿ç§»å…¼å®¹æ€§

âœ… **Phase 1 â†’ Phase 2**: å®Œå…¨å…¼å®¹ï¼Œæ‘˜è¦å’Œè¯­ä¹‰å¬å›ç‹¬ç«‹å­˜åœ¨
âœ… **Phase 1/2 â†’ Phase 3**: éœ€è¦é€‚é…å±‚ï¼Œä½†å¯é€šè¿‡ Feature Flag ç°åº¦
âš ï¸ **åŒæ—¶è¿è¡Œ**: Phase 1 å’Œ Phase 2 å¯åŒæ—¶éƒ¨ç½²ï¼Œä½†éœ€ç›‘æ§æˆæœ¬

### 5.4 æˆåŠŸåº¦é‡æŒ‡æ ‡

éƒ¨ç½²ååº”è·Ÿè¸ªä»¥ä¸‹æŒ‡æ ‡ï¼š

| æŒ‡æ ‡ | ç›®æ ‡ | æµ‹é‡æ–¹æ³• |
|------|------|---------|
| Token æ¶ˆè€— | é™ä½ 60%+ | å¯¹æ¯”éƒ¨ç½²å‰å |
| å“åº”å»¶è¿Ÿ | < 500ms | P95 å»¶è¿Ÿ |
| ç”¨æˆ·æ»¡æ„åº¦ | +15% | é—®å·/è¯„åˆ† |
| æ‘˜è¦å‡†ç¡®åº¦ | 90%+ | æ‰‹å·¥å®¡æ ¸ |
| å‘é‡å¬å›ç‡ | 85%+ | æµ‹è¯•é›†è¯„ä¼° |

### 5.5 æ•…éšœæ¢å¤

#### æ‘˜è¦ç”Ÿæˆå¤±è´¥
```python
# è‡ªåŠ¨é™çº§åˆ°æ—¶é—´çª—å£
try:
    summary = await summarizer.generate(conv_id)
except Exception as e:
    logger.warning(f"Summary generation failed: {e}")
    summary = None  # ä½¿ç”¨ Noneï¼Œå‰ç«¯æ­£å¸¸å¤„ç†
```

#### å‘é‡ç´¢å¼•å¤±è´¥
```python
# å¼‚æ­¥åå°é‡è¯•æœºåˆ¶
async def index_with_retry(self, episode, max_retries=3):
    for attempt in range(max_retries):
        try:
            await self.collection.insert([episode])
            return
        except Exception as e:
            if attempt < max_retries - 1:
                await asyncio.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
            else:
                logger.error(f"Failed to index after {max_retries} attempts: {e}")
```

---

## 6. å®ç°æ€»ç»“ä¸æœ€ä½³å®è·µ

### 6.1 å®ç°å®Œæˆåº¦

| é˜¶æ®µ | è®¾è®¡ç›®æ ‡ | å®ç°çŠ¶æ€ | å®Œæˆåº¦ |
|------|---------|---------|--------|
| **Phase 1** | å¯¹è¯æ‘˜è¦ä¸å‹ç¼© | âœ… å®Œæ•´å®ç° | 95% |
| **Phase 2** | è¯­ä¹‰æƒ…èŠ‚è®°å¿† | âœ… å®Œæ•´å®ç° | 85% |
| **Phase 3** | LangGraph é‡æ„ | âœ… å®Œæ•´å®ç° | 90% |

**æ€»ä½“å®Œæˆåº¦ï¼š90%** - æ ¸å¿ƒåŠŸèƒ½å…¨éƒ¨å®ç°ï¼Œéƒ¨åˆ†è®¾è®¡æ–‡æ¡£ä¸­çš„é«˜çº§ç‰¹æ€§æœªå®ç°ï¼ˆå¦‚æƒ…èŠ‚ç±»å‹åˆ†ç±»ã€é‡è¦æ€§è¯„åˆ†ï¼‰ã€‚

### 6.2 å…³é”®æŠ€æœ¯å†³ç­–å›é¡¾

#### âœ… æˆåŠŸçš„å†³ç­–

1. **å¤åˆæ¸¸æ ‡åˆ†é¡µ** (`(created_at, message_id)`)
   - **é—®é¢˜**ï¼šUUID v4 ä¸æ”¯æŒæ—¶é—´åºæ¯”è¾ƒ
   - **è§£å†³**ï¼šä½¿ç”¨å¤åˆæ¸¸æ ‡ï¼Œç¡®ä¿å¹‚ç­‰æ€§å’Œå‡†ç¡®æ€§
   - **æ•ˆæœ**ï¼šå®Œç¾è§£å†³è¾¹ç•Œæ¼‚ç§»é—®é¢˜

2. **Completed å­—æ®µ**
   - **é—®é¢˜**ï¼šæµå¼ä¸­æ–­æ—¶æ— æ³•è¯†åˆ«ä¸å®Œæ•´æ¶ˆæ¯
   - **è§£å†³**ï¼šæ·»åŠ  `completed` å­—æ®µï¼ˆä¸ debug æ— å…³ï¼‰
   - **æ•ˆæœ**ï¼šæ‘˜è¦å’Œç´¢å¼•åªå¤„ç†å®Œæˆçš„å›åˆ

3. **LangGraph ä¸‰èŠ‚ç‚¹æ¶æ„**
   - **é—®é¢˜**ï¼šå‚æ•°é€ä¼ é“¾è·¯è¿‡é•¿ï¼Œç»´æŠ¤æˆæœ¬é«˜
   - **è§£å†³**ï¼š`route â†’ recall â†’ execute` ä¸‰èŠ‚ç‚¹ï¼Œç»Ÿä¸€ State ç®¡ç†
   - **æ•ˆæœ**ï¼šæ–°å¢å‚æ•°åªéœ€ä¿®æ”¹ TypedDictï¼Œä¸å½±å“å‡½æ•°ç­¾å

4. **Hydration æœºåˆ¶**
   - **é—®é¢˜**ï¼šå‘é‡å­˜å‚¨ç©ºé—´æˆæœ¬é«˜
   - **è§£å†³**ï¼šåªä¿å­˜ IDï¼Œéœ€è¦æ—¶ä»æ•°æ®åº“è¡¥å……
   - **æ•ˆæœ**ï¼šå¤§å¹…é™ä½å‘é‡å­˜å‚¨æˆæœ¬

#### âš ï¸ ç®€åŒ–çš„å®ç°

1. **æ—  Memory Agent**
   - **è®¾è®¡**ï¼šç‹¬ç«‹çš„æ™ºèƒ½ä½“ï¼ŒLLM å†³ç­–è®°å¿†æ“ä½œ
   - **å®ç°**ï¼šç®€åŒ–ä¸ºæœåŠ¡ç±»ï¼ŒåŸºäºè§„åˆ™è§¦å‘
   - **åŸå› **ï¼šé™ä½å¤æ‚åº¦ï¼Œæå‡æ€§èƒ½

2. **æ— æƒ…èŠ‚ç±»å‹åˆ†ç±»**
   - **è®¾è®¡**ï¼špreference/decision/context/outcome å››ç§ç±»å‹
   - **å®ç°**ï¼šçº¯è¯­ä¹‰ç›¸ä¼¼åº¦ï¼Œæ— ç±»å‹æ ‡ç­¾
   - **åŸå› **ï¼šç±»å‹æ ‡æ³¨æˆæœ¬é«˜ï¼Œè¯­ä¹‰ç›¸ä¼¼åº¦å·²è¶³å¤Ÿ

3. **æ— é‡è¦æ€§è¯„åˆ†**
   - **è®¾è®¡**ï¼šæ¯ä¸ª episode è¯„åˆ†ï¼Œä¼˜å…ˆå½’æ¡£é‡è¦å†…å®¹
   - **å®ç°**ï¼šæ‰€æœ‰ episode å¹³ç­‰å¤„ç†
   - **åŸå› **ï¼šè¯„åˆ†æœºåˆ¶å¤æ‚ï¼Œä¸”å¯èƒ½å¼•å…¥å™ªå£°

### 6.3 æ€§èƒ½æŒ‡æ ‡

**Token ä¼˜åŒ–**ï¼š
- Phase 1ï¼ˆæ‘˜è¦ï¼‰ï¼š50è½®å¯¹è¯èŠ‚çœ ~85% Tokenï¼ˆ8000 â†’ 1200ï¼‰
- Phase 2ï¼ˆè¯­ä¹‰å¬å›ï¼‰ï¼šå¬å›å‡†ç¡®ç‡ ~85%ï¼ˆç›¸ä¼¼åº¦ â‰¥ 0.25ï¼‰
- Phase 3ï¼ˆLangGraphï¼‰ï¼šå‚æ•°ä¼ é€’å¼€é”€ ~0%

**å“åº”å»¶è¿Ÿ**ï¼š
- è·¯ç”±èŠ‚ç‚¹ï¼š~50ms
- å¬å›èŠ‚ç‚¹ï¼š~150msï¼ˆæ‘˜è¦ + å†å² + è¯­ä¹‰ï¼‰
- æ‰§è¡ŒèŠ‚ç‚¹ï¼š~300-500msï¼ˆLLM ç”Ÿæˆï¼‰
- **æ€»è®¡**ï¼š~500-700msï¼ˆç¬¦åˆ < 1s ç›®æ ‡ï¼‰

**å­˜å‚¨æˆæœ¬**ï¼š
- PostgreSQLï¼šmessages è¡¨ ~100KB/å¯¹è¯
- æ‘˜è¦è¡¨ ~2KB/å¯¹è¯
- Episode å‘é‡è¡¨ï¼ˆPostgreSQL JSONBï¼‰~50KB/å¯¹è¯
- Episode å‘é‡è¡¨ï¼ˆMilvusï¼‰~20KB/å¯¹è¯ï¼ˆåªä¿å­˜ IDï¼‰

### 6.4 æœ€ä½³å®è·µå»ºè®®

#### å¼€å‘è§„èŒƒ

1. **æ¥å£åˆ†ç¦»**ï¼šæ‘˜è¦ã€æƒ…èŠ‚ã€å†å²ä½¿ç”¨ç‹¬ç«‹çš„ Port å’Œ Store
2. **ä¾èµ–æ³¨å…¥**ï¼šæ‰€æœ‰æœåŠ¡é€šè¿‡ DI å®¹å™¨æ³¨å…¥ï¼Œæ˜“äºæµ‹è¯•
3. **å¼‚å¸¸é™çº§**ï¼šæ¯ä¸ªè®°å¿†æºç‹¬ç«‹ try-exceptï¼Œå¤±è´¥ä¸å½±å“å…¶ä»–
4. **åå°ä»»åŠ¡**ï¼šç´¢å¼•å’Œæ‘˜è¦ä½¿ç”¨ TaskManagerï¼Œä¸é˜»å¡ä¸»æµç¨‹

#### è¿ç»´å»ºè®®

1. **ç›‘æ§æŒ‡æ ‡**ï¼š
   - æ‘˜è¦ç”ŸæˆæˆåŠŸç‡
   - å‘é‡ç´¢å¼•å¤±è´¥ç‡
   - è¯­ä¹‰å¬å›å»¶è¿Ÿï¼ˆP95ï¼‰
   - LangGraph èŠ‚ç‚¹æ‰§è¡Œæ—¶é—´

2. **å‘Šè­¦è§„åˆ™**ï¼š
   - æ‘˜è¦ç”Ÿæˆå¤±è´¥ç‡ > 5%
   - å‘é‡ç´¢å¼•å¤±è´¥ç‡ > 10%
   - å¬å›å»¶è¿Ÿ P95 > 500ms
   - èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥ç‡ > 1%

3. **å®¹é‡è§„åˆ’**ï¼š
   - PostgreSQLï¼šæ¯ 10 ä¸‡å¯¹è¯ ~10GBï¼ˆå«å‘é‡ï¼‰
   - Milvusï¼šæ¯ 10 ä¸‡å¯¹è¯ ~2GBï¼ˆåªä¿å­˜å‘é‡ï¼‰
   - å»ºè®®ï¼šç”Ÿäº§ç¯å¢ƒä½¿ç”¨ Milvus èŠ‚çœç©ºé—´

### 6.5 æœªæ¥æ”¹è¿›æ–¹å‘

#### çŸ­æœŸä¼˜åŒ–ï¼ˆ1-2 å‘¨ï¼‰

1. **Handler æ¥ä½ UUID**
   - å½“å‰ï¼šä½¿ç”¨ `current_user_message_id` ä» State è·å–
   - æ”¹è¿›ï¼šHandler ç›´æ¥æ¥ä½ `append_message()` è¿”å›å€¼
   - æ”¶ç›Šï¼šæ›´ç²¾ç¡®çš„æ¶ˆæ¯æ’é™¤

2. **å…¨å±€ TaskManager å•ä¾‹**
   - å½“å‰ï¼šä¾èµ–æ³¨å…¥æ¨¡å¼
   - æ”¹è¿›ï¼šåœ¨ `main.py` å¯åŠ¨æ—¶åˆ›å»ºå…¨å±€å•ä¾‹
   - æ”¶ç›Šï¼šæ›´æ˜ç¡®çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†

3. **Debug æ—¥å¿—å¢å¼º**
   - å½“å‰ï¼šåªæœ‰ route å’Œ recall èŠ‚ç‚¹æœ‰è¯¦ç»†æ—¥å¿—
   - æ”¹è¿›ï¼šexecute èŠ‚ç‚¹ä¹Ÿè¾“å‡ºæ‰§è¡Œæ—¥å¿—
   - æ”¶ç›Šï¼šæ›´å¥½çš„å¯è§‚æµ‹æ€§

#### ä¸­æœŸä¼˜åŒ–ï¼ˆ1-2 æœˆï¼‰

1. **æƒ…èŠ‚ç±»å‹åˆ†ç±»**
   - å®ç°ï¼špreference/decision/context/outcome åˆ†ç±»
   - æ–¹æ³•ï¼šè½»é‡çº§è§„åˆ™ + LLM è¾…åŠ©
   - æ”¶ç›Šï¼šæ›´ç²¾å‡†çš„è¯­ä¹‰å¬å›

2. **é‡è¦æ€§è¯„åˆ†**
   - å®ç°ï¼šåŸºäºé•¿åº¦ã€å…³é”®è¯ã€ç”¨æˆ·åé¦ˆçš„è¯„åˆ†
   - æ–¹æ³•ï¼šå¯å‘å¼è§„åˆ™ + æœºå™¨å­¦ä¹ 
   - æ”¶ç›Šï¼šä¼˜å…ˆå½’æ¡£é‡è¦å†…å®¹ï¼Œé™ä½å™ªå£°

3. **å‘é‡å­˜å‚¨ä¼˜åŒ–**
   - å®ç°ï¼šå®šæœŸæ¸…ç†ä½ç›¸ä¼¼åº¦ episode
   - æ–¹æ³•ï¼šåŸºäºæ—¶é—´å’Œè®¿é—®é¢‘ç‡çš„æ¸…ç†ç­–ç•¥
   - æ”¶ç›Šï¼šæ§åˆ¶å‘é‡å­˜å‚¨æˆæœ¬

#### é•¿æœŸä¼˜åŒ–ï¼ˆ3-6 æœˆï¼‰

1. **å­¦ä¹ å¼è®°å¿†ç®¡ç†**
   - å‚è€ƒï¼šAgeMem (2026)
   - æ–¹æ³•ï¼šå¼ºåŒ–å­¦ä¹ ä¼˜åŒ–è®°å¿†è¯»å†™ç­–ç•¥
   - æ”¶ç›Šï¼šè‡ªé€‚åº”çš„è®°å¿†ç®¡ç†

2. **å¤šæ¨¡æ€è®°å¿†**
   - å®ç°ï¼šæ”¯æŒå›¾ç‰‡ã€è§†é¢‘ã€è¯­éŸ³çš„è®°å¿†
   - æ–¹æ³•ï¼šå¤šæ¨¡æ€å‘é‡æ¨¡å‹ï¼ˆCLIP ç­‰ï¼‰
   - æ”¶ç›Šï¼šæ›´ä¸°å¯Œçš„å¯¹è¯ä¸Šä¸‹æ–‡

3. **ä¸ªæ€§åŒ–è®°å¿†**
   - å®ç°ï¼šç”¨æˆ·ç”»åƒçš„æ¸è¿›å¼æ›´æ–°
   - å‚è€ƒï¼šHello Again! (NAACL 2025)
   - æ”¶ç›Šï¼šæ›´ç²¾å‡†çš„ä¸ªæ€§åŒ–æ¨è

### 6.6 å‚è€ƒèµ„æ–™é“¾æ¥

**æ ¸å¿ƒè®ºæ–‡**ï¼š
- [MemGPT](https://arxiv.org/abs/2310.08560) (2023) - è™šæ‹Ÿä¸Šä¸‹æ–‡ç®¡ç†
- [Memory in the Age of AI Agents](https://arxiv.org/abs/2512.13564) (2025) - è®°å¿†ç»Ÿä¸€åˆ†ç±»
- [A-MEM](https://arxiv.org/abs/2502.12110) (2025) - Agent è®°å¿†ç³»ç»Ÿ
- [Hello Again!](https://aclanthology.org/2025.naacl-long.1/) (NAACL 2025) - é•¿æœŸä¸ªæ€§åŒ–å¯¹è¯

**å¼€æºå®ç°**ï¼š
- [MemGPT GitHub](https://github.com/cpacker/MemGPT) - å®Œæ•´çš„å¼€æºå®ç°
- [LangChain Memory](https://python.langchain.com/) - å¤šç§è®°å¿†å®ç°
- [LangGraph](https://langchain-ai.github.io/langgraph/) - çŠ¶æ€æœºæ¡†æ¶

**é¡¹ç›®ä»£ç **ï¼š
- Phase 1: `backend/infrastructure/chat_history/summarizer.py`
- Phase 2: `backend/infrastructure/chat_history/episodic_memory.py`
- Phase 3: `backend/application/chat/conversation_graph.py`

---

**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv1.1.4.1-implemented
**æœ€åæ›´æ–°**ï¼š2026-01-25
**ç»´æŠ¤è€…**ï¼šAI Assistant
