# å¤šæ ·åŒ– Agent å®ç°æ·±åº¦è§£æ

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç» GraphRAG ç³»ç»Ÿä¸­çš„ 5 ç§ Agent å®ç°ï¼ŒåŒ…æ‹¬è®¾è®¡ç†å¿µã€æŠ€æœ¯ç»†èŠ‚ã€å·¥ä½œæµç¨‹ã€é€‚ç”¨åœºæ™¯å’Œæ€§èƒ½å¯¹æ¯”ã€‚

---

## ğŸ“Š Agent å…¨æ™¯å¯¹æ¯”

| Agent ç±»å‹ | å¤æ‚åº¦ | æœç´¢ç­–ç•¥ | ï¿½ï¿½ï¿½ç†èƒ½åŠ› | é€‚ç”¨åœºæ™¯ | å“åº”é€Ÿåº¦ |
|-----------|--------|---------|---------|---------|---------|
| **NaiveRagAgent** | â­ | å‘é‡æ£€ç´¢ | ç®€å• | åŸºç¡€é—®ç­” | âš¡âš¡âš¡ æœ€å¿« |
| **HybridAgent** | â­â­ | æ··åˆæ£€ç´¢ | ä¸­ç­‰ | é€šç”¨é—®ç­” | âš¡âš¡ å¿« |
| **GraphAgent** | â­â­â­ | å›¾+å‘é‡ | ä¸­é«˜ | ç»“æ„åŒ–çŸ¥è¯† | âš¡ ä¸­ç­‰ |
| **DeepResearchAgent** | â­â­â­â­ | å¤šè½®æ¨ç† | é«˜ | å¤æ‚é—®é¢˜ | ğŸŒ æ…¢ |
| **FusionGraphRAGAgent** | â­â­â­â­â­ | å¤šAgentåä½œ | æé«˜ | ç ”ç©¶æŠ¥å‘Š | ğŸŒğŸŒ æœ€æ…¢ |

---

## 1ï¸âƒ£ NaiveRagAgent - åŸºç¡€å‘é‡æ£€ç´¢

### æ ¸å¿ƒè®¾è®¡ç†å¿µ

**"ç®€å•å¿«é€Ÿï¼Œæ»¡è¶³åŸºæœ¬éœ€æ±‚"**

NaiveRagAgent æ˜¯æœ€ç®€å•çš„å®ç°ï¼Œä»…ä½¿ç”¨å‘é‡æ£€ç´¢ï¼Œé€‚åˆå¿«é€ŸåŸå‹å¼€å‘å’ŒåŸºç¡€é—®ç­”åœºæ™¯ã€‚

### æŠ€æœ¯æ¶æ„

```
ç”¨æˆ·é—®é¢˜
    â†“
å‘é‡ç¼–ç  (Embeddings)
    â†“
Neo4j å‘é‡ç´¢å¼•æ£€ç´¢
    â†“
Top-K ç›¸ä¼¼ Chunks
    â†“
LLM ç”Ÿæˆç­”æ¡ˆ
    â†“
è¿”å›ç»“æœ
```

### å…³é”®ä»£ç å®ç°

**æ–‡ä»¶**: `backend/graphrag_agent/agents/naive_rag_agent.py`

```python
class NaiveRagAgent(BaseAgent):
    """ä½¿ç”¨ç®€å•å‘é‡æ£€ç´¢çš„Naive RAG Agentå®ç°"""

    def __init__(self):
        # ğŸ”‘ åªåˆå§‹åŒ–ä¸€ä¸ªå·¥å…·ï¼šNaiveSearchTool
        self.search_tool = NaiveSearchTool()
        self.cache_dir = "./cache/naive_agent"
        super().__init__(cache_dir=self.cache_dir)

    def _setup_tools(self) -> List:
        """è®¾ç½®å·¥å…· - åªæœ‰ä¸€ä¸ªå‘é‡æ£€ç´¢å·¥å…·"""
        return [
            self.search_tool.get_tool(),  # â† åªæœ‰è¿™ä¸€ä¸ªå·¥å…·
        ]

    def _extract_keywords(self, query: str) -> Dict[str, List[str]]:
        """ä¸åšå…³é”®è¯æå–ï¼Œè¿”å›ç©ºåˆ—è¡¨"""
        return {"low_level": [], "high_level": []}

    def _generate_node(self, state):
        """ç”Ÿæˆå›ç­” - ç›´æ¥ä½¿ç”¨æ£€ç´¢ç»“æœ"""
        messages = state["messages"]

        # è·å–é—®é¢˜å’Œæ£€ç´¢ç»“æœ
        question = messages[-3].content
        docs = messages[-1].content  # NaiveSearchTool è¿”å›çš„æ–‡æœ¬

        # æ£€æŸ¥ç¼“å­˜
        cached_result = self.cache_manager.get(question, thread_id=thread_id)
        if cached_result:
            return {"messages": [AIMessage(content=cached_result)]}

        # ğŸ”‘ ç®€å•çš„ Prompt + LLM ç”Ÿæˆ
        prompt = ChatPromptTemplate.from_messages([
            ("system", NAIVE_PROMPT),
            ("human", NAIVE_RAG_HUMAN_PROMPT),
        ])

        rag_chain = prompt | self.llm | StrOutputParser()
        response = rag_chain.invoke({
            "context": docs,
            "question": question,
            "response_type": response_type
        })

        return {"messages": [AIMessage(content=response)]}
```

### NaiveSearchTool å®ç°

**æ–‡ä»¶**: `backend/graphrag_agent/search/tool/naive_search_tool.py`

```python
class NaiveSearchTool:
    """æœ€ç®€å•çš„å‘é‡æ£€ç´¢å·¥å…·"""

    def search(self, query: str) -> str:
        """
        æ‰§è¡Œå‘é‡æ£€ç´¢

        å·¥ä½œæµç¨‹:
        1. å°†æŸ¥è¯¢ç¼–ç ä¸ºå‘é‡
        2. åœ¨ Neo4j chunk_index ä¸­æ‰§è¡Œç›¸ä¼¼åº¦æœç´¢
        3. è¿”å› Top-K ä¸ªæœ€ç›¸ä¼¼çš„æ–‡æœ¬å—
        """
        # 1. å‘é‡åŒ–æŸ¥è¯¢
        query_embedding = self.embeddings.embed_query(query)

        # 2. Neo4j å‘é‡æ£€ç´¢
        vector_store = Neo4jVector.from_existing_index(
            self.embeddings,
            index_name="chunk_index",  # â† åªç”¨ chunk ç´¢å¼•
            retrieval_query="""
                MATCH (chunk:__Chunk__)
                WHERE chunk.id = $chunk_id
                RETURN chunk.text AS text
            """
        )

        # 3. ç›¸ä¼¼åº¦æœç´¢
        docs = vector_store.similarity_search(query, k=5)

        # 4. æ‹¼æ¥æ–‡æœ¬
        return "\n\n".join([doc.page_content for doc in docs])
```

### å·¥ä½œæµç¨‹å›¾

```
ã€STARTã€‘
    â†“
ã€agent èŠ‚ç‚¹ã€‘
    - æ¥æ”¶ç”¨æˆ·é—®é¢˜
    - å†³å®šè°ƒç”¨ naive_search_tool
    â†“
ã€retrieve èŠ‚ç‚¹ã€‘
    - å‘é‡ç¼–ç : "æ—·è¯¾å¤šå°‘å­¦æ—¶ä¼šè¢«é€€å­¦ï¼Ÿ"
    - Neo4j å‘é‡æ£€ç´¢: chunk_index.similarity_search(vector, k=5)
    - è¿”å›: ["chunk1æ–‡æœ¬", "chunk2æ–‡æœ¬", ...]
    â†“
ã€generate èŠ‚ç‚¹ã€‘
    - Prompt: åŸºäºä»¥ä¸‹ä¿¡æ¯å›ç­”é—®é¢˜: {context}
    - LLM ç”Ÿæˆ: "æ ¹æ®è§„å®šï¼Œæ—·è¯¾ç´¯è®¡è¾¾åˆ°40å­¦æ—¶..."
    â†“
ã€ENDã€‘
```

### ä¼˜ç¼ºç‚¹åˆ†æ

#### âœ… ä¼˜ç‚¹

1. **æå¿«å“åº”é€Ÿåº¦**
   - å•æ¬¡å‘é‡æ£€ç´¢ï¼Œå¹³å‡è€—æ—¶ < 500ms
   - é€‚åˆå®æ—¶å¯¹è¯åœºæ™¯

2. **ç®€å•æ˜“ç†è§£**
   - ä»£ç é‡å°‘ï¼Œæ˜“äºç»´æŠ¤
   - é€‚åˆå­¦ä¹ å’ŒåŸå‹å¼€å‘

3. **ä½èµ„æºæ¶ˆè€—**
   - åªéœ€ä¸€æ¬¡ LLM è°ƒç”¨
   - å†…å­˜å ç”¨å°

#### âŒ ç¼ºç‚¹

1. **æ£€ç´¢è´¨é‡æœ‰é™**
   - æ— æ³•åˆ©ç”¨å›¾ç»“æ„ä¿¡æ¯
   - åªèƒ½æ£€ç´¢åˆ°ç›¸ä¼¼æ–‡æœ¬å—

2. **ç¼ºä¹æ¨ç†èƒ½åŠ›**
   - æ— å¤šè·³æ¨ç†
   - æ— æ³•å¤„ç†å¤æ‚é—®é¢˜

3. **ä¸Šä¸‹æ–‡æœ‰é™**
   - Top-K é™åˆ¶å¯èƒ½é—æ¼é‡è¦ä¿¡æ¯
   - æ— æ³•æ•´åˆå¤šä¸ªçŸ¥è¯†æº

### é€‚ç”¨åœºæ™¯

âœ… **é€‚åˆ**:
- ç®€å•äº‹å®é—®ç­”ï¼ˆ"è°æ˜¯æŸäººï¼Ÿ"ï¼‰
- FAQ ç³»ç»Ÿ
- å¿«é€ŸåŸå‹å¼€å‘
- èµ„æºå—é™ç¯å¢ƒ

âŒ **ä¸é€‚åˆ**:
- éœ€è¦æ¨ç†çš„é—®é¢˜ï¼ˆ"ä¸ºä»€ä¹ˆ...ï¼Ÿ"ï¼‰
- å¤šæ­¥éª¤é—®é¢˜
- éœ€è¦å›¾ç»“æ„ä¿¡æ¯çš„æŸ¥è¯¢

---

## 2ï¸âƒ£ HybridAgent - æ··åˆæ£€ç´¢ç­–ç•¥

### æ ¸å¿ƒè®¾è®¡ç†å¿µ

**"ç»“åˆå®ä½“ç»†èŠ‚å’Œä¸»é¢˜æ¦‚å¿µï¼Œå¹³è¡¡ç²¾åº¦ä¸è¦†ç›–é¢"**

HybridAgent ä½¿ç”¨æ··åˆæœç´¢ç­–ç•¥ï¼ŒåŒæ—¶åˆ©ç”¨ï¼š
- **ä½çº§å…³é”®è¯** (Low-level): å®ä½“åç§°ã€å…·ä½“ç»†èŠ‚
- **é«˜çº§å…³é”®è¯** (High-level): ä¸»é¢˜ã€æ¦‚å¿µã€ç±»åˆ«

### æŠ€æœ¯æ¶æ„

```
ç”¨æˆ·é—®é¢˜
    â†“
å…³é”®è¯æå– (LLM)
    â”œâ”€ ä½çº§å…³é”®è¯: ["æ—·è¯¾", "40å­¦æ—¶", "é€€å­¦"]
    â””â”€ é«˜çº§å…³é”®è¯: ["å­¦ç”Ÿç®¡ç†", "å¤„åˆ†åˆ¶åº¦", "å­¦ç±ç®¡ç†"]
    â†“
å¹¶è¡Œæ£€ç´¢
    â”œâ”€ Local Search (å®ä½“ä¸­å¿ƒ)
    â””â”€ Global Search (ç¤¾åŒºèšåˆ)
    â†“
ç»“æœèåˆ
    â†“
LLM ç”Ÿæˆç­”æ¡ˆ
```

### å…³é”®ä»£ç å®ç°

**æ–‡ä»¶**: `backend/graphrag_agent/agents/hybrid_agent.py`

```python
class HybridAgent(BaseAgent):
    """ä½¿ç”¨æ··åˆæœç´¢çš„Agentå®ç°"""

    def __init__(self):
        # ğŸ”‘ åˆå§‹åŒ–æ··åˆæœç´¢å·¥å…·
        self.search_tool = HybridSearchTool()
        self.cache_dir = "./cache/hybrid_agent"
        super().__init__(cache_dir=self.cache_dir)

    def _setup_tools(self) -> List:
        """è®¾ç½®å·¥å…· - æœ¬åœ°å’Œå…¨å±€æœç´¢"""
        return [
            self.search_tool.get_tool(),         # â† Local Search
            self.search_tool.get_global_tool(),  # â† Global Search
        ]

    def _extract_keywords(self, query: str) -> Dict[str, List[str]]:
        """æå–æŸ¥è¯¢å…³é”®è¯ - åŒå±‚å…³é”®è¯"""
        keywords = self.search_tool.extract_keywords(query)

        # è¿”å›æ ¼å¼:
        # {
        #     "low_level": ["æ—·è¯¾", "40å­¦æ—¶", "é€€å­¦"],
        #     "high_level": ["å­¦ç”Ÿç®¡ç†", "å¤„åˆ†åˆ¶åº¦"]
        # }
        return keywords

    def _generate_node(self, state):
        """ç”Ÿæˆå›ç­” - åŸºäºæ··åˆæ£€ç´¢ç»“æœ"""
        messages = state["messages"]
        question = messages[-3].content
        docs = messages[-1].content

        # ç¼“å­˜æ£€æŸ¥
        cached_result = self.cache_manager.get(question, thread_id=thread_id)
        if cached_result:
            return {"messages": [AIMessage(content=cached_result)]}

        # ğŸ”‘ ä½¿ç”¨æ··åˆæ£€ç´¢ç»“æœç”Ÿæˆç­”æ¡ˆ
        prompt = ChatPromptTemplate.from_messages([
            ("system", LC_SYSTEM_PROMPT),
            ("human", HYBRID_AGENT_GENERATE_PROMPT),
        ])

        rag_chain = prompt | self.llm | StrOutputParser()
        response = rag_chain.invoke({
            "context": docs,  # â† æ··åˆæ£€ç´¢çš„ç»“æœ
            "question": question,
            "response_type": response_type
        })

        return {"messages": [AIMessage(content=response)]}
```

### HybridSearchTool å®ç°

**æ–‡ä»¶**: `backend/graphrag_agent/search/tool/hybrid_tool.py`

```python
class HybridSearchTool:
    """æ··åˆæœç´¢å·¥å…·"""

    def __init__(self):
        # åˆå§‹åŒ–æœ¬åœ°å’Œå…¨å±€æœç´¢å™¨
        self.local_searcher = LocalSearch(llm, embeddings)
        self.global_searcher = GlobalSearch(llm, embeddings)

    def search(self, query: str, keywords: Dict) -> str:
        """
        æ‰§è¡Œæ··åˆæœç´¢

        æ­¥éª¤:
        1. æå–ä½çº§å’Œé«˜çº§å…³é”®è¯
        2. æœ¬åœ°æœç´¢: åŸºäºå®ä½“çš„é‚»åŸŸæ‰©å±•
        3. å…¨å±€æœç´¢: åŸºäºç¤¾åŒºçš„ä¸»é¢˜èšåˆ
        4. èåˆç»“æœ
        """
        low_level = keywords.get("low_level", [])
        high_level = keywords.get("high_level", [])

        # 1. æœ¬åœ°æœç´¢ (å®ä½“ä¸­å¿ƒ)
        local_result = self.local_searcher.search(
            query=query,
            entities=low_level  # â† ä½¿ç”¨ä½çº§å…³é”®è¯
        )

        # 2. å…¨å±€æœç´¢ (ç¤¾åŒºèšåˆ)
        global_result = self.global_searcher.search(
            query=query,
            concepts=high_level  # â† ä½¿ç”¨é«˜çº§å…³é”®è¯
        )

        # 3. èåˆç»“æœ
        combined = f"""
        ã€å®ä½“è¯¦ç»†ä¿¡æ¯ã€‘
        {local_result}

        ã€ä¸»é¢˜æ¦‚å¿µæ€»ç»“ã€‘
        {global_result}
        """

        return combined

    def extract_keywords(self, query: str) -> Dict:
        """
        æå–åŒå±‚å…³é”®è¯

        ä½¿ç”¨ LLM æå–:
        - low_level: å®ä½“åç§°ã€å…·ä½“ç»†èŠ‚
        - high_level: ä¸»é¢˜ã€æ¦‚å¿µã€ç±»åˆ«
        """
        prompt = f"""
        åˆ†æä»¥ä¸‹æŸ¥è¯¢ï¼Œæå–å…³é”®è¯:

        æŸ¥è¯¢: {query}

        è¯·æå–:
        1. ä½çº§å…³é”®è¯ (å®ä½“ã€æ•°å­—ã€å…·ä½“åè¯)
        2. é«˜çº§å…³é”®è¯ (ä¸»é¢˜ã€æ¦‚å¿µã€ç±»åˆ«)

        è¿”å› JSON æ ¼å¼:
        {{
            "low_level": ["å…³é”®è¯1", "å…³é”®è¯2"],
            "high_level": ["ä¸»é¢˜1", "ä¸»é¢˜2"]
        }}
        """

        result = self.llm.invoke(prompt)
        return json.loads(result.content)
```

### æ£€ç´¢ç¤ºä¾‹

**æŸ¥è¯¢**: "æ—·è¯¾å¤šå°‘å­¦æ—¶ä¼šè¢«é€€å­¦ï¼Ÿ"

**å…³é”®è¯æå–**:
```json
{
    "low_level": ["æ—·è¯¾", "40å­¦æ—¶", "é€€å­¦", "å¤„åˆ†"],
    "high_level": ["å­¦ç”Ÿç®¡ç†åˆ¶åº¦", "å­¦ç±ç®¡ç†", "è¿çºªå¤„ç†"]
}
```

**Local Search** (å®ä½“ä¸­å¿ƒ):
```
ã€æ£€ç´¢æµç¨‹ã€‘
1. å‘é‡æ£€ç´¢: "æ—·è¯¾" â†’ Entity: "æ—·è¯¾å¤„åˆ†"
2. é‚»åŸŸæ‰©å±•:
   - (æ—·è¯¾å¤„åˆ†)-[:ç´¯è®¡è¾¾åˆ°]->(40å­¦æ—¶)
   - (æ—·è¯¾å¤„åˆ†)-[:å¯¼è‡´]->(é€€å­¦å¤„åˆ†)
3. è¿”å›: å®ä½“è¯¦ç»†æè¿° + å…³ç³»é“¾
```

**Global Search** (ç¤¾åŒºèšåˆ):
```
ã€æ£€ç´¢æµç¨‹ã€‘
1. åŒ¹é…ç¤¾åŒº: "å­¦ç”Ÿç®¡ç†åˆ¶åº¦" â†’ Community #5
2. ç¤¾åŒºæ‘˜è¦:
   - åŒ…å«: æ—·è¯¾ç®¡ç†ã€å¤„åˆ†æµç¨‹ã€å­¦ç±ç®¡ç†
   - æ‘˜è¦: è¯¦ç»†é˜è¿°å­¦ç”Ÿç®¡ç†è§„å®š...
3. è¿”å›: ç¤¾åŒºçº§åˆ«çš„ä¸»é¢˜æ€»ç»“
```

**èåˆç»“æœ**:
```
ã€å®ä½“è¯¦ç»†ä¿¡æ¯ã€‘
æ—·è¯¾å¤„åˆ†è§„å®š:
- ç´¯è®¡æ—·è¯¾è¾¾åˆ° 40 å­¦æ—¶ï¼Œç»™äºˆé€€å­¦å¤„åˆ†
- å¤„ç†æµç¨‹: é€šçŸ¥å®¶é•¿ â†’ å­¦ç”Ÿè¾©æŠ¤ â†’ å­¦æ ¡å®¡æ‰¹
- ç›¸å…³è§„å®š: ã€Šå­¦ç”Ÿè¿çºªå¤„åˆ†æ¡ä¾‹ã€‹ç¬¬12æ¡

ã€ä¸»é¢˜æ¦‚å¿µæ€»ç»“ã€‘
å­¦ç”Ÿç®¡ç†åˆ¶åº¦æ¶µç›–:
1. è€ƒå‹¤ç®¡ç†: æ—·è¯¾ç»Ÿè®¡ã€è¯·å‡æµç¨‹
2. å¤„åˆ†ç±»å‹: è­¦å‘Šã€ä¸¥é‡è­¦å‘Šã€é€€å­¦
3. æ•‘æµé€”å¾„: ç”³è¯‰æµç¨‹ã€å¤è®®æœºåˆ¶
```

### ä¼˜ç¼ºç‚¹åˆ†æ

#### âœ… ä¼˜ç‚¹

1. **æ£€ç´¢è´¨é‡é«˜**
   - åŒå±‚å…³é”®è¯æé«˜å¬å›ç‡
   - ç»“åˆå®ä½“ç»†èŠ‚å’Œä¸»é¢˜æ¦‚å¿µ

2. **è¦†ç›–é¢å¹¿**
   - Local Search æä¾›ç²¾ç¡®ä¿¡æ¯
   - Global Search æä¾›èƒŒæ™¯çŸ¥è¯†

3. **å¹³è¡¡æ€§å¥½**
   - å“åº”é€Ÿåº¦é€‚ä¸­ (1-3 ç§’)
   - ç­”æ¡ˆè´¨é‡è¾ƒé«˜

#### âŒ ç¼ºç‚¹

1. **å…³é”®è¯æå–ä¾èµ– LLM**
   - é¢å¤–ä¸€æ¬¡ LLM è°ƒç”¨
   - å¯èƒ½æå–ä¸å‡†ç¡®

2. **ç»“æœèåˆç®€å•**
   - åªæ˜¯æ‹¼æ¥ï¼Œæœªæ·±åº¦æ•´åˆ
   - å¯èƒ½å­˜åœ¨å†—ä½™ä¿¡æ¯

### é€‚ç”¨åœºæ™¯

âœ… **é€‚åˆ**:
- é€šç”¨é—®ç­”ç³»ç»Ÿ **(æ¨èé»˜è®¤é€‰æ‹©)**
- éœ€è¦å¹³è¡¡é€Ÿåº¦å’Œè´¨é‡
- ä¸­ç­‰å¤æ‚åº¦é—®é¢˜

âŒ **ä¸é€‚åˆ**:
- æç®€å•é—®é¢˜ï¼ˆå¯ç”¨ NaiveRagï¼‰
- æå¤æ‚é—®é¢˜ï¼ˆéœ€ç”¨ DeepResearchï¼‰

---

## 3ï¸âƒ£ GraphAgent - å›¾ç»“æ„æ¨ç†

### æ ¸å¿ƒè®¾è®¡ç†å¿µ

**"åˆ©ç”¨å›¾ç»“æ„ï¼Œæ”¯æŒè¯„åˆ†å’Œèšåˆæ“ä½œ"**

GraphAgent å……åˆ†åˆ©ç”¨çŸ¥è¯†å›¾è°±çš„ç»“æ„ä¿¡æ¯ï¼Œæ”¯æŒï¼š
- **æ–‡æ¡£è¯„åˆ†**: åˆ¤æ–­æ£€ç´¢ç»“æœè´¨é‡
- **Reduce æ“ä½œ**: å¯¹å…¨å±€æœç´¢ç»“æœè¿›è¡Œèšåˆ
- **å¤šè·³æ¨ç†**: æ²¿ç€å›¾ç»“æ„è¿›è¡Œæ¨ç†

### æŠ€æœ¯æ¶æ„

```
ç”¨æˆ·é—®é¢˜
    â†“
å…³é”®è¯æå– (LLM)
    â†“
Local/Global Search å†³ç­–
    â”œâ”€ Local Search â†’ æ–‡æ¡£è¯„åˆ†
    â”‚       â”œâ”€ è´¨é‡å¥½ â†’ Generate
    â”‚       â””â”€ è´¨é‡å·® â†’ é‡æ–°æ£€ç´¢
    â”‚
    â””â”€ Global Search â†’ Reduce èŠ‚ç‚¹
            â†“
        Map-Reduce èšåˆ
            â†“
        ç”Ÿæˆç­”æ¡ˆ
```

### å…³é”®ä»£ç å®ç°

**æ–‡ä»¶**: `backend/graphrag_agent/agents/graph_agent.py`

```python
class GraphAgent(BaseAgent):
    """ä½¿ç”¨å›¾ç»“æ„çš„Agentå®ç°"""

    def __init__(self):
        # ğŸ”‘ æœ¬åœ°å’Œå…¨å±€æœç´¢å·¥å…·
        self.local_tool = LocalSearchTool()
        self.global_tool = GlobalSearchTool()
        self.cache_dir = "./cache/graph_agent"
        super().__init__(cache_dir=self.cache_dir)

    def _setup_tools(self) -> List:
        """è®¾ç½®å·¥å…·"""
        return [
            self.local_tool.get_tool(),   # â† Local Search
            self.global_tool.search,       # â† Global Search
        ]

    def _add_retrieval_edges(self, workflow):
        """ğŸ”‘ æ·»åŠ æ¡ä»¶è·¯ç”± - æ ¸å¿ƒç‰¹è‰²"""

        # 1. æ·»åŠ  reduce èŠ‚ç‚¹
        workflow.add_node("reduce", self._reduce_node)

        # 2. ğŸ”‘ æ·»åŠ æ¡ä»¶è¾¹ - æ–‡æ¡£è¯„åˆ†å†³å®šè·¯ç”±
        workflow.add_conditional_edges(
            "retrieve",
            self._grade_documents,  # â† è¯„åˆ†å‡½æ•°
            {
                "generate": "generate",  # â† è´¨é‡å¥½ï¼Œç›´æ¥ç”Ÿæˆ
                "reduce": "reduce"       # â† å…¨å±€æœç´¢ï¼Œéœ€è¦èšåˆ
            }
        )

        # 3. Reduce åç›´æ¥ç»“æŸ
        workflow.add_edge("reduce", END)

    def _grade_documents(self, state) -> str:
        """
        ğŸ”‘ æ–‡æ¡£è¯„åˆ† - å†³å®šè·¯ç”±æ–¹å‘

        è¿”å›:
        - "generate": ä½¿ç”¨ Local Searchï¼Œæ–‡æ¡£è´¨é‡å¥½
        - "reduce": ä½¿ç”¨ Global Searchï¼Œéœ€è¦ Map-Reduce
        """
        messages = state["messages"]
        retrieve_message = messages[-2]

        # 1. æ£€æŸ¥æ˜¯å¦ä¸ºå…¨å±€æ£€ç´¢
        tool_calls = retrieve_message.additional_kwargs.get("tool_calls", [])
        if tool_calls and tool_calls[0].get("function", {}).get("name") == "global_retriever":
            return "reduce"  # â† å…¨å±€æœç´¢ â†’ Reduce

        # 2. è¯„ä¼°æ–‡æ¡£è´¨é‡
        question = messages[-3].content
        docs = messages[-1].content

        # æ£€æŸ¥æ–‡æ¡£é•¿åº¦
        if not docs or len(docs) < 100:
            # æ–‡æ¡£ä¸è¶³ï¼Œå°è¯•é‡æ–°æ£€ç´¢
            try:
                local_result = self.local_tool.search(question)
                if local_result and len(local_result) > 100:
                    messages[-1].content = local_result
            except Exception as e:
                print(f"æœ¬åœ°æœç´¢å¤±è´¥: {e}")

        # 3. æ£€æŸ¥å…³é”®è¯è¦†ç›–
        keywords = self._extract_keywords_from_message(messages[-3])
        keyword_coverage = self._calculate_keyword_coverage(docs, keywords)

        if keyword_coverage > 0.5:  # è¦†ç›–ç‡ > 50%
            return "generate"  # â† è´¨é‡å¥½
        else:
            return "generate"  # â† é»˜è®¤ç”Ÿæˆï¼ˆé¿å…æ­»å¾ªç¯ï¼‰

    def _reduce_node(self, state):
        """
        ğŸ”‘ Reduce èŠ‚ç‚¹ - Map-Reduce èšåˆ

        ç”¨äºå¤„ç†å…¨å±€æœç´¢çš„ç»“æœï¼Œé€šè¿‡ Map-Reduce æ•´åˆå¤šä¸ªç¤¾åŒºçš„ä¿¡æ¯
        """
        messages = state["messages"]
        question = messages[-3].content
        search_results = messages[-1].content

        # 1. è§£æå…¨å±€æœç´¢ç»“æœ (å¤šä¸ªç¤¾åŒºçš„æ‘˜è¦)
        community_summaries = self._parse_community_results(search_results)

        # 2. Map é˜¶æ®µ: æ¯ä¸ªç¤¾åŒºç”Ÿæˆå±€éƒ¨ç­”æ¡ˆ
        partial_answers = []
        for community in community_summaries:
            prompt = f"""
            åŸºäºä»¥ä¸‹ç¤¾åŒºæ‘˜è¦å›ç­”é—®é¢˜:

            ç¤¾åŒºæ‘˜è¦: {community["summary"]}
            é—®é¢˜: {question}

            æå–ä¸é—®é¢˜ç›¸å…³çš„ä¿¡æ¯ã€‚
            """
            partial_answer = self.llm.invoke(prompt).content
            partial_answers.append(partial_answer)

        # 3. Reduce é˜¶æ®µ: æ•´åˆæ‰€æœ‰å±€éƒ¨ç­”æ¡ˆ
        reduce_prompt = GRAPH_AGENT_REDUCE_PROMPT.format(
            question=question,
            partial_answers="\n\n".join(partial_answers),
            response_type=response_type
        )

        final_answer = self.llm.invoke(reduce_prompt).content

        return {"messages": [AIMessage(content=final_answer)]}

    def _generate_node(self, state):
        """æ ‡å‡†ç”ŸæˆèŠ‚ç‚¹ - å¤„ç† Local Search ç»“æœ"""
        messages = state["messages"]
        question = messages[-3].content
        docs = messages[-1].content

        # ç¼“å­˜æ£€æŸ¥...

        # ç”Ÿæˆç­”æ¡ˆ
        prompt = ChatPromptTemplate.from_messages([
            ("system", LC_SYSTEM_PROMPT),
            ("human", GRAPH_AGENT_GENERATE_PROMPT),
        ])

        rag_chain = prompt | self.llm | StrOutputParser()
        response = rag_chain.invoke({
            "context": docs,
            "question": question,
            "response_type": response_type
        })

        return {"messages": [AIMessage(content=response)]}
```

### å·¥ä½œæµç¨‹å›¾

```
ã€STARTã€‘
    â†“
ã€agent èŠ‚ç‚¹ã€‘
    - æå–å…³é”®è¯
    - å†³å®šè°ƒç”¨ local_tool æˆ– global_tool
    â†“
ã€retrieve èŠ‚ç‚¹ã€‘
    â”œâ”€ Local Search è°ƒç”¨
    â”‚   - å®ä½“ä¸­å¿ƒæ£€ç´¢
    â”‚   - è¿”å›: å®ä½“+å…³ç³»+é‚»å±…
    â”‚
    â””â”€ Global Search è°ƒç”¨
        - ç¤¾åŒºçº§èšåˆ
        - è¿”å›: å¤šä¸ªç¤¾åŒºæ‘˜è¦
    â†“
ã€_grade_documentsã€‘æ¡ä»¶åˆ¤æ–­
    â”œâ”€ æ£€æµ‹åˆ° Global Search â†’ "reduce"
    â”‚       â†“
    â”‚   ã€reduce èŠ‚ç‚¹ã€‘
    â”‚       â”œâ”€ Map: æ¯ä¸ªç¤¾åŒºç”Ÿæˆå±€éƒ¨ç­”æ¡ˆ
    â”‚       â””â”€ Reduce: æ•´åˆä¸ºæœ€ç»ˆç­”æ¡ˆ
    â”‚       â†“
    â”‚   ã€ENDã€‘
    â”‚
    â””â”€ Local Search / è´¨é‡å¥½ â†’ "generate"
            â†“
        ã€generate èŠ‚ç‚¹ã€‘
            - åŸºäºå®ä½“ä¿¡æ¯ç”Ÿæˆç­”æ¡ˆ
            â†“
        ã€ENDã€‘
```

### Map-Reduce ç¤ºä¾‹

**æŸ¥è¯¢**: "å­¦æ ¡æœ‰å“ªäº›å¥–å­¦é‡‘ç±»å‹ï¼Ÿ"

**Global Search è¿”å›**:
```
Community #1 æ‘˜è¦:
- åŒ…å«: å›½å®¶å¥–å­¦é‡‘ã€åŠ±å¿—å¥–å­¦é‡‘ã€åŠ©å­¦é‡‘
- è¯„é€‰æ¡ä»¶: æˆç»©ä¼˜å¼‚ã€å®¶åº­å›°éš¾

Community #2 æ‘˜è¦:
- åŒ…å«: æ ¡çº§å¥–å­¦é‡‘ã€ä¼ä¸šå¥–å­¦é‡‘
- å‘æ”¾æµç¨‹: ç”³è¯·ã€è¯„å®¡ã€å…¬ç¤º

Community #3 æ‘˜è¦:
- åŒ…å«: å•é¡¹å¥–å­¦é‡‘ã€åˆ›æ–°å¥–å­¦é‡‘
- å¥–åŠ±èŒƒå›´: å­¦æœ¯ã€æ–‡ä½“ã€åˆ›æ–°
```

**Map é˜¶æ®µ** (æ¯ä¸ªç¤¾åŒº):
```python
# Community #1 å±€éƒ¨ç­”æ¡ˆ
"å­¦æ ¡æä¾›å›½å®¶å¥–å­¦é‡‘ã€åŠ±å¿—å¥–å­¦é‡‘å’ŒåŠ©å­¦é‡‘ï¼Œä¸»è¦é¢å‘æˆç»©ä¼˜å¼‚æˆ–å®¶åº­å›°éš¾çš„å­¦ç”Ÿã€‚"

# Community #2 å±€éƒ¨ç­”æ¡ˆ
"å­¦æ ¡æä¾›æ ¡çº§å¥–å­¦é‡‘å’Œä¼ä¸šå¥–å­¦é‡‘ï¼Œéœ€ç»è¿‡ç”³è¯·ã€è¯„å®¡å’Œå…¬ç¤ºæµç¨‹ã€‚"

# Community #3 å±€éƒ¨ç­”æ¡ˆ
"å­¦æ ¡æä¾›å•é¡¹å¥–å­¦é‡‘å’Œåˆ›æ–°å¥–å­¦é‡‘ï¼Œå¥–åŠ±å­¦æœ¯ã€æ–‡ä½“å’Œåˆ›æ–°æ–¹é¢çš„çªå‡ºè¡¨ç°ã€‚"
```

**Reduce é˜¶æ®µ** (æ•´åˆ):
```python
final_answer = """
å­¦æ ¡å¥–å­¦é‡‘ä½“ç³»åŒ…æ‹¬ä»¥ä¸‹ç±»å‹:

1. å›½å®¶çº§å¥–å­¦é‡‘:
   - å›½å®¶å¥–å­¦é‡‘ã€åŠ±å¿—å¥–å­¦é‡‘ã€åŠ©å­¦é‡‘
   - é¢å‘æˆç»©ä¼˜å¼‚æˆ–å®¶åº­å›°éš¾çš„å­¦ç”Ÿ

2. æ ¡çº§å¥–å­¦é‡‘:
   - æ ¡çº§ç»¼åˆå¥–å­¦é‡‘ã€ä¼ä¸šå¥–å­¦é‡‘
   - éœ€ç»è¿‡ç”³è¯·ã€è¯„å®¡å’Œå…¬ç¤ºæµç¨‹

3. ä¸“é¡¹å¥–å­¦é‡‘:
   - å•é¡¹å¥–å­¦é‡‘ã€åˆ›æ–°å¥–å­¦é‡‘
   - å¥–åŠ±å­¦æœ¯ã€æ–‡ä½“å’Œåˆ›æ–°æ–¹é¢çš„çªå‡ºè¡¨ç°

ç”³è¯·æµç¨‹: æäº¤ç”³è¯· â†’ èµ„æ ¼å®¡æŸ¥ â†’ è¯„å®¡æ‰“åˆ† â†’ å…¬ç¤º â†’ å‘æ”¾
"""
```

### ä¼˜ç¼ºç‚¹åˆ†æ

#### âœ… ä¼˜ç‚¹

1. **ç»“æ„åŒ–æ¨ç†**
   - åˆ©ç”¨å›¾ç»“æ„ä¿¡æ¯
   - å¤šè·³æ¨ç†èƒ½åŠ›

2. **æ™ºèƒ½è·¯ç”±**
   - æ–‡æ¡£è¯„åˆ†æœºåˆ¶
   - æ ¹æ®è´¨é‡åŠ¨æ€è°ƒæ•´

3. **Map-Reduce èšåˆ**
   - æ•´åˆå¤šä¸ªç¤¾åŒºä¿¡æ¯
   - é€‚åˆå…¨å±€æ€§é—®é¢˜

#### âŒ ç¼ºç‚¹

1. **å¤æ‚åº¦é«˜**
   - æ¡ä»¶è·¯ç”±å¢åŠ å¤æ‚æ€§
   - Reduce éœ€è¦å¤šæ¬¡ LLM è°ƒç”¨

2. **è¯„åˆ†ä¸å¤Ÿç²¾ç¡®**
   - ç®€å•çš„é•¿åº¦å’Œè¦†ç›–ç‡åˆ¤æ–­
   - å¯èƒ½è¯¯åˆ¤

### é€‚ç”¨åœºæ™¯

âœ… **é€‚åˆ**:
- éœ€è¦å›¾ç»“æ„ä¿¡æ¯çš„æŸ¥è¯¢
- å…¨å±€æ€§ã€æ€»ç»“æ€§é—®é¢˜
- éœ€è¦å¤šè·³æ¨ç†

âŒ **ä¸é€‚åˆ**:
- ç®€å•äº‹å®æŸ¥è¯¢
- å¯¹å“åº”é€Ÿåº¦è¦æ±‚æé«˜çš„åœºæ™¯

---

## 4ï¸âƒ£ DeepResearchAgent - å¤šæ­¥éª¤æ¨ç†é“¾

### æ ¸å¿ƒè®¾è®¡ç†å¿µ

**"åƒç ”ç©¶å‘˜ä¸€æ ·æ€è€ƒï¼šå¤šè½®æ€è€ƒ-æœç´¢-æ¨ç†å¾ªç¯"**

DeepResearchAgent å®ç°äº† Chain of Exploration (CoE) èŒƒå¼ï¼Œé€šè¿‡å¤šè½®è¿­ä»£æ·±å…¥æ¢ç´¢çŸ¥è¯†å›¾è°±ã€‚

### æŠ€æœ¯æ¶æ„

```
ç”¨æˆ·é—®é¢˜
    â†“
ã€ç¬¬ 1 è½®è¿­ä»£ã€‘
    â”œâ”€ æ€è€ƒ: æˆ‘éœ€è¦æ‰¾ä»€ä¹ˆä¿¡æ¯ï¼Ÿ
    â”œâ”€ æœç´¢: KBæ£€ç´¢
    â”œâ”€ æ¨ç†: ä¿¡æ¯æ˜¯å¦å……åˆ†ï¼Ÿ
    â””â”€ å†³ç­–: ç»§ç»­ or ç»“æŸ
    â†“
ã€ç¬¬ 2 è½®è¿­ä»£ã€‘
    â”œâ”€ æ€è€ƒ: è¿˜ç¼ºå°‘ä»€ä¹ˆï¼Ÿ
    â”œâ”€ æœç´¢: é’ˆå¯¹æ€§æ£€ç´¢
    â”œâ”€ æ¨ç†: æ•´åˆæ–°ä¿¡æ¯
    â””â”€ å†³ç­–: ç»§ç»­ or ç»“æŸ
    â†“
ã€ç¬¬ N è½®è¿­ä»£ã€‘
    â””â”€ æœ€ç»ˆç­”æ¡ˆ
```

### å…³é”®ä»£ç å®ç°

**æ–‡ä»¶**: `backend/graphrag_agent/agents/deep_research_agent.py`

```python
class DeepResearchAgent(BaseAgent):
    """
    æ·±åº¦ç ”ç©¶Agent

    ç‰¹ç‚¹:
    1. æ˜¾å¼æ¨ç†è¿‡ç¨‹ (Chain of Thought)
    2. è¿­ä»£å¼æœç´¢ (Chain of Exploration)
    3. é«˜è´¨é‡çŸ¥è¯†æ•´åˆ
    4. æ”¯æŒæµå¼è¾“å‡ºæ€è€ƒè¿‡ç¨‹
    5. ç¤¾åŒºæ„ŸçŸ¥å’ŒçŸ¥è¯†å›¾è°±å¢å¼º
    6. å¤šåˆ†æ”¯æ¨ç†å’ŒçŸ›ç›¾æ£€æµ‹
    """

    def __init__(self, use_deeper_tool=True):
        # ğŸ”‘ é€‰æ‹©ç ”ç©¶å·¥å…·ç‰ˆæœ¬
        self.use_deeper_tool = use_deeper_tool

        if use_deeper_tool:
            # å¢å¼ºç‰ˆ: DeeperResearchTool
            self.research_tool = DeeperResearchTool()
            self.exploration_tool = self.research_tool.get_exploration_tool()
            self.reasoning_analysis_tool = self.research_tool.get_reasoning_analysis_tool()
        else:
            # æ ‡å‡†ç‰ˆ: DeepResearchTool
            self.research_tool = DeepResearchTool()

        self.stream_tool = self.research_tool.get_thinking_stream_tool()
        self.show_thinking = False  # æ˜¯å¦æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹

        super().__init__(cache_dir="./cache/enhanced_research_agent")

    def _setup_tools(self) -> List:
        """è®¾ç½®å·¥å…· - æ ¹æ®æ¨¡å¼åŠ¨æ€é€‰æ‹©"""
        tools = []

        # åŸºç¡€ç ”ç©¶å·¥å…·
        if self.show_thinking:
            tools.append(self.research_tool.get_thinking_tool())
        else:
            tools.append(self.research_tool.get_tool())

        # å¢å¼ºå·¥å…·
        if self.use_deeper_tool:
            tools.append(self.exploration_tool)        # çŸ¥è¯†å›¾è°±æ¢ç´¢
            tools.append(self.reasoning_analysis_tool) # æ¨ç†é“¾åˆ†æ

        # æµå¼å·¥å…·
        tools.append(self.stream_tool)

        return tools

    def ask_with_thinking(self, query: str, thread_id: str = "default"):
        """
        ğŸ”‘ å¸¦æ€è€ƒè¿‡ç¨‹çš„é—®ç­”

        è¿”å›:
        {
            "answer": "æœ€ç»ˆç­”æ¡ˆ",
            "thinking_process": "ã€æ·±åº¦ç ”ç©¶ã€‘ç¬¬1è½®...",
            "execution_logs": [...]
        }
        """
        # 1. å¯ç”¨æ€è€ƒè¿‡ç¨‹æ¨¡å¼
        original_thinking = self.show_thinking
        self.show_thinking = True
        self._setup_tools()  # é‡æ–°è®¾ç½®å·¥å…·

        try:
            # 2. æ‰§è¡Œæ ‡å‡†æµç¨‹
            config = {
                "configurable": {
                    "thread_id": thread_id,
                    "recursion_limit": 10  # å…è®¸æ›´å¤šè¿­ä»£
                }
            }

            inputs = {"messages": [HumanMessage(content=query)]}

            # 3. é€æ­¥æ‰§è¡Œå·¥ä½œæµ
            for output in self.graph.stream(inputs, config=config):
                pass

            # 4. è·å–å®Œæ•´å¯¹è¯å†å²
            chat_history = self.memory.get(config)["channel_values"]["messages"]

            # 5. æå–æ€è€ƒè¿‡ç¨‹å’Œæœ€ç»ˆç­”æ¡ˆ
            thinking_process = ""
            final_answer = ""

            for msg in chat_history:
                if isinstance(msg, ToolMessage):
                    # å·¥å…·è¿”å›çš„å†…å®¹å¯èƒ½åŒ…å«æ€è€ƒè¿‡ç¨‹
                    content = msg.content
                    if "[æ·±åº¦ç ”ç©¶]" in content or "[KBæ£€ç´¢]" in content:
                        thinking_process += content + "\n\n"

                if isinstance(msg, AIMessage) and msg.content:
                    final_answer = msg.content

            return {
                "answer": final_answer,
                "thinking_process": thinking_process,
                "execution_logs": self.execution_log
            }

        finally:
            # 6. æ¢å¤åŸå§‹è®¾ç½®
            self.show_thinking = original_thinking
            self._setup_tools()
```

### DeepResearchTool å®ç°

**æ–‡ä»¶**: `backend/graphrag_agent/search/tool/deep_research_tool.py`

```python
class DeepResearchTool:
    """æ·±åº¦ç ”ç©¶å·¥å…· - å®ç° Chain of Exploration"""

    def research(self, query: str, show_thinking: bool = False) -> str:
        """
        æ‰§è¡Œæ·±åº¦ç ”ç©¶

        å·¥ä½œæµç¨‹:
        1. åˆå§‹åŒ–æ¢ç´¢çŠ¶æ€
        2. å¤šè½®è¿­ä»£:
           a. ç”Ÿæˆæœç´¢è®¡åˆ’
           b. æ‰§è¡ŒçŸ¥è¯†åº“æ£€ç´¢
           c. è¯„ä¼°ä¿¡æ¯å……åˆ†æ€§
           d. å†³å®šæ˜¯å¦ç»§ç»­
        3. æ•´åˆæ‰€æœ‰ä¿¡æ¯
        4. ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
        """
        max_iterations = 5
        iteration = 0
        collected_info = []

        while iteration < max_iterations:
            iteration += 1

            # ğŸ”‘ ç¬¬ 1 æ­¥: æ€è€ƒ - æˆ‘éœ€è¦æ‰¾ä»€ä¹ˆï¼Ÿ
            thinking_prompt = f"""
            ã€æ·±åº¦ç ”ç©¶ - ç¬¬ {iteration} è½®ã€‘

            é—®é¢˜: {query}

            å·²æ”¶é›†ä¿¡æ¯:
            {chr(10).join(collected_info) if collected_info else "ï¼ˆæ— ï¼‰"}

            è¯·æ€è€ƒ:
            1. ç°åœ¨è¿˜ç¼ºå°‘ä»€ä¹ˆä¿¡æ¯ï¼Ÿ
            2. ä¸‹ä¸€æ­¥åº”è¯¥æœç´¢ä»€ä¹ˆï¼Ÿ
            3. æœç´¢å…³é”®è¯æ˜¯ä»€ä¹ˆï¼Ÿ

            è¿”å› JSON:
            {{
                "missing_info": "ç¼ºå°‘çš„ä¿¡æ¯",
                "search_keywords": ["å…³é”®è¯1", "å…³é”®è¯2"],
                "should_continue": true/false
            }}
            """

            thinking_result = self.llm.invoke(thinking_prompt)
            thinking_data = json.loads(thinking_result.content)

            # å¦‚æœåˆ¤æ–­ä¿¡æ¯å……åˆ†ï¼Œç»“æŸè¿­ä»£
            if not thinking_data.get("should_continue", False):
                break

            # ğŸ”‘ ç¬¬ 2 æ­¥: æœç´¢ - æ‰§è¡Œ KB æ£€ç´¢
            if show_thinking:
                output = f"\n[æ·±åº¦ç ”ç©¶] ç¬¬ {iteration} è½®\n"
                output += f"æ€è€ƒ: {thinking_data['missing_info']}\n"

            search_keywords = thinking_data.get("search_keywords", [])
            search_results = []

            for keyword in search_keywords:
                if show_thinking:
                    output += f"\n[KBæ£€ç´¢] å…³é”®è¯: {keyword}\n"

                # æ‰§è¡Œå‘é‡æ£€ç´¢
                result = self.local_search.search(keyword)
                search_results.append(result)

                if show_thinking:
                    output += f"æ‰¾åˆ° {len(result)} æ¡ç›¸å…³ä¿¡æ¯\n"

            # ğŸ”‘ ç¬¬ 3 æ­¥: æ¨ç† - æ•´åˆæ–°ä¿¡æ¯
            integration_prompt = f"""
            æ•´åˆä»¥ä¸‹æ£€ç´¢ç»“æœ:

            {chr(10).join(search_results)}

            æå–ä¸é—®é¢˜ç›¸å…³çš„å…³é”®ä¿¡æ¯ã€‚
            """

            integrated_info = self.llm.invoke(integration_prompt).content
            collected_info.append(integrated_info)

            if show_thinking:
                output += f"\n[æ¨ç†] æ•´åˆä¿¡æ¯: {integrated_info[:100]}...\n"
                yield output  # æµå¼è¾“å‡ºæ€è€ƒè¿‡ç¨‹

        # ğŸ”‘ ç¬¬ 4 æ­¥: ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
        final_prompt = f"""
        åŸºäºä»¥ä¸‹æ·±åº¦ç ”ç©¶ç»“æœå›ç­”é—®é¢˜:

        é—®é¢˜: {query}

        ç ”ç©¶ç»“æœ:
        {chr(10).join(collected_info)}

        è¯·ç»™å‡ºè¯¦ç»†ã€å‡†ç¡®çš„ç­”æ¡ˆã€‚
        """

        final_answer = self.llm.invoke(final_prompt).content

        if show_thinking:
            yield f"\nã€æœ€ç»ˆç­”æ¡ˆã€‘\n{final_answer}"
        else:
            return final_answer
```

### è¿­ä»£è¿‡ç¨‹ç¤ºä¾‹

**æŸ¥è¯¢**: "å­¦æ ¡å¯¹å­¦ç”Ÿæ—·è¯¾çš„å¤„ç†æµç¨‹æ˜¯ä»€ä¹ˆï¼Ÿ"

**ç¬¬ 1 è½®è¿­ä»£**:
```
ã€æ·±åº¦ç ”ç©¶ã€‘ç¬¬ 1 è½®

[æ€è€ƒ]
- ç¼ºå°‘ä¿¡æ¯: æ—·è¯¾çš„å®šä¹‰å’Œç»Ÿè®¡æ–¹å¼
- æœç´¢å…³é”®è¯: ["æ—·è¯¾", "è€ƒå‹¤ï¿½ï¿½ï¿½ç†"]
- ç»§ç»­æ¢ç´¢: true

[KBæ£€ç´¢] å…³é”®è¯: æ—·è¯¾
æ‰¾åˆ° 5 æ¡ç›¸å…³ä¿¡æ¯:
- æ—·è¯¾å®šä¹‰: æœªç»æ‰¹å‡†ç¼ºå¸­è¯¾ç¨‹
- ç»Ÿè®¡æ–¹å¼: æŒ‰å­¦æ—¶ç´¯è®¡

[æ¨ç†]
æ—·è¯¾æ˜¯æŒ‡å­¦ç”Ÿæœªç»æ‰¹å‡†ç¼ºå¸­æ•™å­¦æ´»åŠ¨ï¼ŒæŒ‰å­¦æ—¶ç´¯è®¡ç»Ÿè®¡ã€‚
```

**ç¬¬ 2 è½®è¿­ä»£**:
```
ã€æ·±åº¦ç ”ç©¶ã€‘ç¬¬ 2 è½®

[æ€è€ƒ]
- ç¼ºå°‘ä¿¡æ¯: ä¸åŒç¨‹åº¦æ—·è¯¾çš„å¤„ç†æ–¹å¼
- æœç´¢å…³é”®è¯: ["æ—·è¯¾å¤„åˆ†", "å¤„ç†æµç¨‹"]
- ç»§ç»­æ¢ç´¢: true

[KBæ£€ç´¢] å…³é”®è¯: æ—·è¯¾å¤„åˆ†
æ‰¾åˆ° 8 æ¡ç›¸å…³ä¿¡æ¯:
- 10å­¦æ—¶: è­¦å‘Š
- 20å­¦æ—¶: ä¸¥é‡è­¦å‘Š
- 40å­¦æ—¶: é€€å­¦å¤„åˆ†

[æ¨ç†]
æ ¹æ®æ—·è¯¾å­¦æ—¶ä¸åŒï¼Œå¤„åˆ†ç¨‹åº¦é€’å¢ï¼š
10å­¦æ—¶è­¦å‘Š â†’ 20å­¦æ—¶ä¸¥é‡è­¦å‘Š â†’ 40å­¦æ—¶é€€å­¦ã€‚
```

**ç¬¬ 3 è½®è¿­ä»£**:
```
ã€æ·±åº¦ç ”ç©¶ã€‘ç¬¬ 3 è½®

[æ€è€ƒ]
- ç¼ºå°‘ä¿¡æ¯: å…·ä½“çš„å¤„ç†æµç¨‹å’Œç”³è¯‰æœºåˆ¶
- æœç´¢å…³é”®è¯: ["å¤„åˆ†æµç¨‹", "å­¦ç”Ÿç”³è¯‰"]
- ç»§ç»­æ¢ç´¢: true

[KBæ£€ç´¢] å…³é”®è¯: å¤„åˆ†æµç¨‹
æ‰¾åˆ° 6 æ¡ç›¸å…³ä¿¡æ¯:
- æµç¨‹: é€šçŸ¥å­¦ç”Ÿ â†’ è°ƒæŸ¥å–è¯ â†’ å¬è¯ â†’ å†³å®š â†’ é€è¾¾

[æ¨ç†]
å¤„åˆ†æµç¨‹åŒ…æ‹¬é€šçŸ¥ã€è°ƒæŸ¥ã€å¬è¯ã€å†³å®šå’Œé€è¾¾äº”ä¸ªæ­¥éª¤ï¼Œ
å­¦ç”Ÿæœ‰æƒåœ¨æ”¶åˆ°å¤„åˆ†åæå‡ºç”³è¯‰ã€‚
```

**æœ€ç»ˆæ•´åˆ**:
```
ã€æœ€ç»ˆç­”æ¡ˆã€‘

å­¦æ ¡å¯¹å­¦ç”Ÿæ—·è¯¾çš„å¤„ç†æµç¨‹:

ä¸€ã€æ—·è¯¾è®¤å®š
- å®šä¹‰: æœªç»æ‰¹å‡†ç¼ºå¸­æ•™å­¦æ´»åŠ¨
- ç»Ÿè®¡: æŒ‰å­¦æ—¶ç´¯è®¡

äºŒã€å¤„åˆ†æ ‡å‡†
- ç´¯è®¡ 10 å­¦æ—¶: è­¦å‘Šå¤„åˆ†
- ç´¯è®¡ 20 å­¦æ—¶: ä¸¥é‡è­¦å‘Š
- ç´¯è®¡ 40 å­¦æ—¶: é€€å­¦å¤„åˆ†

ä¸‰ã€å¤„ç†æµç¨‹
1. é€šçŸ¥å­¦ç”ŸåŠå®¶é•¿
2. è°ƒæŸ¥æ ¸å®æ—·è¯¾æƒ…å†µ
3. ç»„ç»‡å¬è¯ä¼šï¼ˆå­¦ç”Ÿå¯è¾©æŠ¤ï¼‰
4. å­¦æ ¡ä½œå‡ºå¤„åˆ†å†³å®š
5. é€è¾¾å¤„åˆ†æ–‡ä»¶

å››ã€æ•‘æµé€”å¾„
- å­¦ç”Ÿå¯åœ¨æ”¶åˆ°å¤„åˆ†å 10 æ—¥å†…æå‡ºç”³è¯‰
- ç”³è¯‰å§”å‘˜ä¼šåœ¨ 15 æ—¥å†…ä½œå‡ºå¤æŸ¥å†³å®š
```

### ä¼˜ç¼ºç‚¹åˆ†æ

#### âœ… ä¼˜ç‚¹

1. **æ¨ç†é“¾å®Œæ•´**
   - æ˜¾å¼æ€è€ƒè¿‡ç¨‹
   - å¯è¿½æº¯å†³ç­–ä¾æ®

2. **ä¿¡æ¯æ”¶é›†å…¨é¢**
   - å¤šè½®è¿­ä»£
   - ä¸»åŠ¨æ¢ç´¢ç¼ºå¤±ä¿¡æ¯

3. **ç­”æ¡ˆè´¨é‡é«˜**
   - å……åˆ†æ•´åˆçŸ¥è¯†
   - é€»è¾‘ä¸¥è°¨

4. **å¯è§£é‡Šæ€§å¼º**
   - å±•ç¤ºæ¨ç†æ­¥éª¤
   - ç”¨æˆ·å¯ç†è§£å†³ç­–è¿‡ç¨‹

#### âŒ ç¼ºç‚¹

1. **å“åº”æ—¶é—´é•¿**
   - å¤šè½®è¿­ä»£ï¼Œæ¯è½®éœ€ LLM è°ƒç”¨
   - å¹³å‡è€—æ—¶ 10-30 ç§’

2. **æˆæœ¬é«˜**
   - å¤šæ¬¡ LLM è°ƒç”¨
   - Token æ¶ˆè€—å¤§

3. **å¯èƒ½è¿‡åº¦æ¢ç´¢**
   - ç®€å•é—®é¢˜ä¹Ÿå¯èƒ½å¤šè½®è¿­ä»£
   - éœ€è¦æ™ºèƒ½åœæ­¢æœºåˆ¶

### é€‚ç”¨åœºæ™¯

âœ… **é€‚åˆ**:
- å¤æ‚ç ”ç©¶æ€§é—®é¢˜
- éœ€è¦æ·±åº¦æ¨ç†
- è¦æ±‚é«˜è´¨é‡ç­”æ¡ˆ
- å¯æ¥å—è¾ƒé•¿ç­‰å¾…æ—¶é—´

âŒ **ä¸é€‚åˆ**:
- ç®€å•äº‹å®æŸ¥è¯¢
- å®æ—¶å¯¹è¯
- èµ„æºå—é™ç¯å¢ƒ

---

## 5ï¸âƒ£ FusionGraphRAGAgent - å¤šAgentåä½œ

### æ ¸å¿ƒè®¾è®¡ç†å¿µ

**"åƒç ”ç©¶å›¢é˜Ÿä¸€æ ·åä½œï¼šPlan-Execute-Report æ¶æ„"**

FusionGraphRAGAgent æ˜¯æœ€å¤æ‚çš„å®ç°ï¼Œé€šè¿‡å¤šä¸ªä¸“é—¨åŒ– Agent åä½œå®Œæˆç ”ç©¶ä»»åŠ¡ã€‚

### æŠ€æœ¯æ¶æ„

```
ã€Plan é˜¶æ®µã€‘Planning Team
    â”œâ”€ Clarifier: æ¾„æ¸…ç”¨æˆ·æ„å›¾
    â”œâ”€ TaskDecomposer: åˆ†è§£ä»»åŠ¡
    â””â”€ PlanReviewer: å®¡æŸ¥è®¡åˆ’
    â†“
    ç”Ÿæˆ PlanSpec (ä»»åŠ¡å›¾)
    â†“
ã€Execute é˜¶æ®µã€‘Execution Team
    â”œâ”€ WorkerCoordinator: åè°ƒæ‰§è¡Œ
    â”œâ”€ RetrievalExecutor: æ£€ç´¢ä»»åŠ¡
    â”œâ”€ ResearchExecutor: ç ”ç©¶ä»»åŠ¡
    â””â”€ Reflector: åæ€ç»“æœ
    â†“
    ç”Ÿæˆ ExecutionRecords
    â†“
ã€Report é˜¶æ®µã€‘Reporting Team
    â”œâ”€ OutlineBuilder: æ„å»ºå¤§çº²
    â”œâ”€ SectionWriter: å†™ä½œç« èŠ‚ (Map-Reduce)
    â”œâ”€ ConsistencyChecker: ä¸€è‡´æ€§æ£€æŸ¥
    â””â”€ Formatter: æ ¼å¼åŒ–è¾“å‡º
    â†“
    ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
```

### å…³é”®ä»£ç å®ç°

**æ–‡ä»¶**: `backend/graphrag_agent/agents/fusion_agent.py`

```python
class FusionGraphRAGAgent:
    """Fusion GraphRAG Agent - å¤šæ™ºèƒ½ä½“ç¼–æ’"""

    def __init__(self, cache_dir: str = "./cache/fusion_graphrag"):
        self.cache_dir = cache_dir

        # ğŸ”‘ æ ¸å¿ƒ: å¤šæ™ºèƒ½ä½“é—¨é¢
        self.multi_agent = MultiAgentFacade()

        # å…¼å®¹æ¥å£
        self.memory = _MemoryShim()
        self.graph = _GraphShim()
        self.execution_log = []

        # ç¼“å­˜
        self._global_cache = {}
        self._session_cache = {}

    def ask(self, query: str, thread_id: str = "default") -> str:
        """æ ‡å‡†é—®ç­”"""
        answer, _ = self._execute(query, thread_id)
        return answer

    def ask_with_trace(self, query: str, thread_id: str = "default") -> Dict:
        """å¸¦æ‰§è¡Œè½¨è¿¹çš„é—®ç­”"""
        answer, payload = self._execute(query, thread_id)
        return {
            "answer": answer,
            "payload": payload  # åŒ…å«å®Œæ•´çš„æ‰§è¡Œè®°å½•
        }

    def _execute(
        self,
        query: str,
        thread_id: str,
        assumptions: Optional[List[str]] = None,
        report_type: Optional[str] = None
    ) -> Tuple[str, Dict]:
        """
        æ‰§è¡ŒæŸ¥è¯¢

        æ­¥éª¤:
        1. æ£€æŸ¥ç¼“å­˜
        2. è°ƒç”¨å¤šæ™ºèƒ½ä½“ç¼–æ’å™¨
        3. ç¼“å­˜ç»“æœ
        4. è¿”å›ç­”æ¡ˆå’Œæ‰§è¡Œè®°å½•
        """
        # 1. ç¼“å­˜æ£€æŸ¥
        cached = self._read_cache(query, thread_id)
        if cached is not None:
            return cached, {"status": "cached"}

        # 2. ğŸ”‘ è°ƒç”¨å¤šæ™ºèƒ½ä½“ç¼–æ’å™¨
        payload = self.multi_agent.process_query(
            query.strip(),
            assumptions=assumptions,
            report_type=report_type
        )

        # 3. æå–ç­”æ¡ˆ
        answer = self._normalize_answer(payload.get("response"))

        # 4. ç¼“å­˜ç»“æœ
        self._write_cache(query, thread_id, answer)

        # 5. è®°å½•æ‰§è¡Œæ—¥å¿—
        self.execution_log = payload.get("execution_records", [])

        return answer, payload
```

### MultiAgentFacade å®ç°

**æ–‡ä»¶**: `backend/graphrag_agent/agents/multi_agent/integration/legacy_facade.py`

```python
class MultiAgentFacade:
    """å¤šæ™ºèƒ½ä½“é—¨é¢ - å¯¹å¤–ç»Ÿä¸€æ¥å£"""

    def __init__(self):
        # ğŸ”‘ åˆå§‹åŒ–ä¸‰ä¸ªé˜¶æ®µçš„ç»„ä»¶
        self.planner = self._create_planner()
        self.executor = self._create_executor()
        self.reporter = self._create_reporter()

    def process_query(
        self,
        query: str,
        assumptions: Optional[List[str]] = None,
        report_type: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        å¤„ç†æŸ¥è¯¢ - Plan-Execute-Report æµç¨‹

        è¿”å›:
        {
            "response": "æœ€ç»ˆæŠ¥å‘Š",
            "plan": PlanSpecå¯¹è±¡,
            "execution_records": [ExecutionRecord, ...],
            "outline": æŠ¥å‘Šå¤§çº²,
            "consistency_check": ä¸€è‡´æ€§æ£€æŸ¥ç»“æœ
        }
        """
        # ========== Plan é˜¶æ®µ ==========
        print("ã€Plan é˜¶æ®µã€‘å¼€å§‹ä»»åŠ¡è§„åˆ’...")

        # 1. æ¾„æ¸…æ„å›¾
        clarified_query = self.planner.clarify(query)

        # 2. åˆ†è§£ä»»åŠ¡
        task_graph = self.planner.decompose(clarified_query)

        # 3. å®¡æŸ¥è®¡åˆ’
        plan_spec = self.planner.review(task_graph)

        print(f"ç”Ÿæˆè®¡åˆ’: {len(plan_spec.tasks)} ä¸ªä»»åŠ¡")

        # ========== Execute é˜¶æ®µ ==========
        print("ã€Execute é˜¶æ®µã€‘æ‰§è¡Œä»»åŠ¡...")

        # 4. åè°ƒæ‰§è¡Œ
        execution_records = self.executor.execute(plan_spec)

        print(f"å®Œæˆæ‰§è¡Œ: {len(execution_records)} æ¡è®°å½•")

        # ========== Report é˜¶æ®µ ==========
        print("ã€Report é˜¶æ®µã€‘ç”ŸæˆæŠ¥å‘Š...")

        # 5. æ„å»ºå¤§çº²
        outline = self.reporter.build_outline(
            query=query,
            evidence=execution_records
        )

        # 6. å†™ä½œç« èŠ‚ (Map-Reduce)
        sections = self.reporter.write_sections(
            outline=outline,
            evidence=execution_records
        )

        # 7. ä¸€è‡´æ€§æ£€æŸ¥
        consistency_result = self.reporter.check_consistency(
            sections=sections,
            evidence=execution_records
        )

        # 8. æ ¼å¼åŒ–è¾“å‡º
        final_report = self.reporter.format(
            sections=sections,
            outline=outline
        )

        return {
            "response": final_report,
            "plan": plan_spec,
            "execution_records": execution_records,
            "outline": outline,
            "consistency_check": consistency_result
        }
```

### Planner é˜¶æ®µè¯¦è§£

**æ–‡ä»¶**: `backend/graphrag_agent/agents/multi_agent/planner/task_decomposer.py`

```python
class TaskDecomposer:
    """ä»»åŠ¡åˆ†è§£å™¨"""

    def decompose(self, query: str) -> PlanSpec:
        """
        å°†æŸ¥è¯¢åˆ†è§£ä¸ºä»»åŠ¡å›¾

        è¿”å› PlanSpec:
        {
            "tasks": [
                {
                    "id": "task_1",
                    "type": "retrieval",  # æ£€ç´¢ä»»åŠ¡
                    "description": "æ£€ç´¢å­¦ç”Ÿç®¡ç†è§„å®š",
                    "dependencies": []
                },
                {
                    "id": "task_2",
                    "type": "research",   # ç ”ç©¶ä»»åŠ¡
                    "description": "åˆ†æå¤„åˆ†æµç¨‹",
                    "dependencies": ["task_1"]
                },
                {
                    "id": "task_3",
                    "type": "synthesis",  # ç»¼åˆä»»åŠ¡
                    "description": "æ•´åˆä¿¡æ¯ç”Ÿæˆç­”æ¡ˆ",
                    "dependencies": ["task_1", "task_2"]
                }
            ]
        }
        """
        prompt = f"""
        åˆ†æä»¥ä¸‹æŸ¥è¯¢ï¼Œåˆ†è§£ä¸ºå…·ä½“ä»»åŠ¡:

        æŸ¥è¯¢: {query}

        ä»»åŠ¡ç±»å‹:
        - retrieval: æ£€ç´¢ç›¸å…³æ–‡æ¡£
        - research: æ·±åº¦ç ”ç©¶ç‰¹å®šä¸»é¢˜
        - synthesis: ç»¼åˆå¤šä¸ªä¿¡æ¯æº

        è¿”å› JSON æ ¼å¼çš„ä»»åŠ¡å›¾ï¼ŒåŒ…å«ä»»åŠ¡IDã€ç±»å‹ã€æè¿°å’Œä¾èµ–å…³ç³»ã€‚
        """

        result = self.llm.invoke(prompt)
        task_data = json.loads(result.content)

        return PlanSpec(tasks=task_data["tasks"])
```

### Executor é˜¶æ®µè¯¦è§£

**æ–‡ä»¶**: `backend/graphrag_agent/agents/multi_agent/executor/worker_coordinator.py`

```python
class WorkerCoordinator:
    """å·¥ä½œåè°ƒå™¨ - æŒ‰ä¾èµ–å…³ç³»æ‰§è¡Œä»»åŠ¡"""

    def execute(self, plan_spec: PlanSpec) -> List[ExecutionRecord]:
        """
        æ‰§è¡Œä»»åŠ¡å›¾

        å·¥ä½œæµç¨‹:
        1. æ‹“æ‰‘æ’åºä»»åŠ¡ï¼ˆæŒ‰ä¾èµ–å…³ç³»ï¼‰
        2. é€ä¸ªæ‰§è¡Œä»»åŠ¡
        3. è®°å½•æ‰§è¡Œç»“æœ
        """
        # 1. æ‹“æ‰‘æ’åº
        sorted_tasks = self._topological_sort(plan_spec.tasks)

        execution_records = []

        # 2. é€ä¸ªæ‰§è¡Œ
        for task in sorted_tasks:
            # æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©æ‰§è¡Œå™¨
            if task["type"] == "retrieval":
                executor = self.retrieval_executor
            elif task["type"] == "research":
                executor = self.research_executor
            else:
                executor = self.synthesis_executor

            # æ‰§è¡Œä»»åŠ¡
            start_time = time.time()
            result = executor.execute(task)
            duration = time.time() - start_time

            # è®°å½•æ‰§è¡Œç»“æœ
            record = ExecutionRecord(
                task_id=task["id"],
                task_type=task["type"],
                result=result,
                duration=duration,
                evidence=result.get("evidence", [])
            )

            execution_records.append(record)

            print(f"å®Œæˆä»»åŠ¡ {task['id']}: {duration:.2f}s")

        return execution_records
```

### Reporter é˜¶æ®µè¯¦è§£

**æ–‡ä»¶**: `backend/graphrag_agent/agents/multi_agent/reporter/section_writer.py`

```python
class SectionWriter:
    """ç« èŠ‚å†™ä½œå™¨ - Map-Reduce æ¨¡å¼"""

    def write_sections(
        self,
        outline: List[str],
        evidence: List[ExecutionRecord]
    ) -> List[str]:
        """
        å†™ä½œæŠ¥å‘Šç« èŠ‚

        Map-Reduce æµç¨‹:
        1. Map: æ¯ä¸ªç« èŠ‚å¹¶è¡Œå†™ä½œ
        2. Reduce: æ•´åˆå¹¶ä¼˜åŒ–
        """
        sections = []

        # Map é˜¶æ®µ: å¹¶è¡Œå†™ä½œæ¯ä¸ªç« èŠ‚
        for section_title in outline:
            # æå–ç›¸å…³è¯æ®
            relevant_evidence = self._filter_evidence(
                section_title,
                evidence
            )

            # å†™ä½œç« èŠ‚
            section_content = self._write_single_section(
                title=section_title,
                evidence=relevant_evidence
            )

            sections.append({
                "title": section_title,
                "content": section_content
            })

        # Reduce é˜¶æ®µ: æ•´åˆä¼˜åŒ–
        optimized_sections = self._optimize_sections(sections)

        return optimized_sections

    def _write_single_section(
        self,
        title: str,
        evidence: List
    ) -> str:
        """å†™ä½œå•ä¸ªç« èŠ‚"""
        prompt = f"""
        å†™ä½œæŠ¥å‘Šç« èŠ‚:

        ç« èŠ‚æ ‡é¢˜: {title}

        æ”¯æŒè¯æ®:
        {chr(10).join([e.summary for e in evidence])}

        è¦æ±‚:
        1. å†…å®¹è¯¦å®ã€é€»è¾‘æ¸…æ™°
        2. å¼•ç”¨è¯æ®ï¼ˆä½¿ç”¨ [1][2] æ ¼å¼ï¼‰
        3. å­—æ•° 500-1000 å­—
        """

        section_content = self.llm.invoke(prompt).content

        return section_content
```

### å®Œæ•´æ‰§è¡Œç¤ºä¾‹

**æŸ¥è¯¢**: "è¯¦ç»†ä»‹ç»å­¦æ ¡çš„å­¦ç”Ÿç®¡ç†åˆ¶åº¦"

**Plan é˜¶æ®µè¾“å‡º**:
```json
{
    "tasks": [
        {
            "id": "retrieve_regulations",
            "type": "retrieval",
            "description": "æ£€ç´¢å­¦ç”Ÿç®¡ç†ç›¸å…³è§„ç« åˆ¶åº¦",
            "dependencies": []
        },
        {
            "id": "research_attendance",
            "type": "research",
            "description": "æ·±å…¥ç ”ç©¶è€ƒå‹¤ç®¡ç†åˆ¶åº¦",
            "dependencies": ["retrieve_regulations"]
        },
        {
            "id": "research_discipline",
            "type": "research",
            "description": "æ·±å…¥ç ”ç©¶è¿çºªå¤„åˆ†åˆ¶åº¦",
            "dependencies": ["retrieve_regulations"]
        },
        {
            "id": "synthesize_report",
            "type": "synthesis",
            "description": "ç»¼åˆä¿¡æ¯ç”Ÿæˆå®Œæ•´æŠ¥å‘Š",
            "dependencies": ["research_attendance", "research_discipline"]
        }
    ]
}
```

**Execute é˜¶æ®µè¾“å‡º**:
```python
execution_records = [
    ExecutionRecord(
        task_id="retrieve_regulations",
        result={
            "documents": [
                "å­¦ç”Ÿç®¡ç†è§„å®š.pdf",
                "è€ƒå‹¤ç®¡ç†åŠæ³•.docx",
                "è¿çºªå¤„åˆ†æ¡ä¾‹.pdf"
            ],
            "evidence": ["ç®¡ç†è§„å®šç¬¬1æ¡...", "ç®¡ç†è§„å®šç¬¬2æ¡..."]
        },
        duration=2.3
    ),
    ExecutionRecord(
        task_id="research_attendance",
        result={
            "findings": "è€ƒå‹¤ç®¡ç†åŒ…æ‹¬...",
            "evidence": ["è€ƒå‹¤ç»Ÿè®¡æ–¹å¼...", "è¯·å‡æµç¨‹..."]
        },
        duration=5.7
    ),
    # ...
]
```

**Report é˜¶æ®µè¾“å‡º**:
```markdown
# å­¦æ ¡å­¦ç”Ÿç®¡ç†åˆ¶åº¦è¯¦è§£

## ä¸€ã€æ€»åˆ™

å­¦ç”Ÿç®¡ç†åˆ¶åº¦æ˜¯å­¦æ ¡è§„èŒƒåŒ–ç®¡ç†çš„é‡è¦ç»„æˆéƒ¨åˆ†[1]ï¼Œæ—¨åœ¨ç»´æŠ¤æ­£å¸¸çš„æ•™å­¦ç§©åº...[2]

## äºŒã€è€ƒå‹¤ç®¡ç†åˆ¶åº¦

### 2.1 è€ƒå‹¤ç»Ÿè®¡æ–¹å¼
å­¦æ ¡é‡‡ç”¨ç”µå­è€ƒå‹¤ç³»ç»Ÿï¼ŒæŒ‰å­¦æ—¶ç»Ÿè®¡å‡ºå‹¤æƒ…å†µ[3]...

### 2.2 è¯·å‡æµç¨‹
å­¦ç”Ÿå› æ•…ä¸èƒ½å‚åŠ æ•™å­¦æ´»åŠ¨ï¼Œåº”æå‰åŠç†è¯·å‡æ‰‹ç»­[4]...

## ä¸‰ã€è¿çºªå¤„åˆ†åˆ¶åº¦

### 3.1 å¤„åˆ†ç±»å‹
æ ¹æ®è¿çºªæƒ…èŠ‚è½»é‡ï¼Œå¤„åˆ†åˆ†ä¸ºè­¦å‘Šã€ä¸¥é‡è­¦å‘Šã€è®°è¿‡ã€ç•™æ ¡å¯Ÿçœ‹ã€å¼€é™¤å­¦ç±äº”ç§[5]...

### 3.2 å¤„ç†æµç¨‹
1. è°ƒæŸ¥å–è¯
2. é€šçŸ¥å­¦ç”ŸåŠå®¶é•¿
3. ç»„ç»‡å¬è¯ä¼š
4. ä½œå‡ºå¤„åˆ†å†³å®š
5. é€è¾¾å¤„åˆ†æ–‡ä»¶[6]

## å››ã€æ•‘æµé€”å¾„

å­¦ç”Ÿå¯¹å¤„åˆ†å†³å®šæœ‰å¼‚è®®çš„ï¼Œå¯åœ¨æ”¶åˆ°å¤„åˆ†å10æ—¥å†…å‘å­¦æ ¡ç”³è¯‰å§”å‘˜ä¼šæå‡ºä¹¦é¢ç”³è¯‰[7]...

---

ã€å‚è€ƒæ–‡çŒ®ã€‘
[1] å­¦ç”Ÿç®¡ç†è§„å®š.pdf, ç¬¬1æ¡
[2] å­¦ç”Ÿç®¡ç†è§„å®š.pdf, ç¬¬2æ¡
[3] è€ƒå‹¤ç®¡ç†åŠæ³•.docx, ç¬¬3.1èŠ‚
...
```

### ä¼˜ç¼ºç‚¹åˆ†æ

#### âœ… ä¼˜ç‚¹

1. **ä¸“ä¸šåŒ–åˆ†å·¥**
   - æ¯ä¸ª Agent è´Ÿè´£ç‰¹å®šä»»åŠ¡
   - å›¢é˜Ÿåä½œï¼Œè´¨é‡é«˜

2. **ç”Ÿæˆé•¿ç¯‡æŠ¥å‘Š**
   - Map-Reduce æ¨¡å¼
   - æ”¯æŒæ•°åƒå­—æŠ¥å‘Š

3. **å¯è¿½æº¯æ€§å¼º**
   - å®Œæ•´çš„æ‰§è¡Œè®°å½•
   - è¯æ®é“¾æ¸…æ™°

4. **å¯æ‰©å±•æ€§å¥½**
   - æ˜“äºæ·»åŠ æ–° Agent
   - çµæ´»çš„ä»»åŠ¡ç¼–æ’

#### âŒ ç¼ºç‚¹

1. **ææ…¢å“åº”é€Ÿåº¦**
   - å¤šé˜¶æ®µå¤„ç†
   - å¹³å‡è€—æ—¶ 30-120 ç§’

2. **æˆæœ¬æé«˜**
   - å¤§é‡ LLM è°ƒç”¨
   - Token æ¶ˆè€—å¯è¾¾æ•°ä¸‡

3. **å¤æ‚åº¦æé«˜**
   - ä»£ç é‡å¤§
   - è°ƒè¯•å›°éš¾

### é€‚ç”¨åœºæ™¯

âœ… **é€‚åˆ**:
- ç”Ÿæˆç ”ç©¶æŠ¥å‘Š
- æ·±åº¦åˆ†æä»»åŠ¡
- éœ€è¦ç»“æ„åŒ–è¾“å‡º
- å¯æ¥å—é•¿æ—¶é—´ç­‰å¾…

âŒ **ä¸é€‚åˆ**:
- å®æ—¶å¯¹è¯
- ç®€å•é—®ç­”
- èµ„æºå—é™ç¯å¢ƒ

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### å“åº”æ—¶é—´å¯¹æ¯”

| Agent ç±»å‹ | å¹³å‡å“åº”æ—¶é—´ | LLM è°ƒç”¨æ¬¡æ•° | Token æ¶ˆè€— |
|-----------|------------|------------|-----------|
| **NaiveRagAgent** | 0.5-1s | 1-2 | ~1K |
| **HybridAgent** | 1-3s | 2-3 | ~2K |
| **GraphAgent** | 2-5s | 3-5 | ~3K |
| **DeepResearchAgent** | 10-30s | 10-30 | ~10K |
| **FusionGraphRAGAgent** | 30-120s | 50-200 | ~50K |

### ç­”æ¡ˆè´¨é‡å¯¹æ¯”

| Agent ç±»å‹ | å‡†ç¡®æ€§ | å®Œæ•´æ€§ | ç»“æ„åŒ– | å¯è§£é‡Šæ€§ |
|-----------|-------|-------|-------|---------|
| **NaiveRagAgent** | â­â­ | â­â­ | â­ | â­ |
| **HybridAgent** | â­â­â­ | â­â­â­ | â­â­ | â­â­ |
| **GraphAgent** | â­â­â­â­ | â­â­â­â­ | â­â­â­ | â­â­â­ |
| **DeepResearchAgent** | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­â­ |
| **FusionGraphRAGAgent** | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ |

---

## ğŸ¯ é€‰æ‹©æŒ‡å—

### å†³ç­–æ ‘

```
é—®é¢˜å¤æ‚åº¦è¯„ä¼°
    â”‚
    â”œâ”€ ç®€å•äº‹å®æŸ¥è¯¢ï¼Ÿ
    â”‚   â””â”€ YES â†’ NaiveRagAgent
    â”‚
    â”œâ”€ éœ€è¦å®æ—¶å“åº”ï¼Ÿ
    â”‚   â””â”€ YES â†’ HybridAgent
    â”‚
    â”œâ”€ éœ€è¦å›¾ç»“æ„ä¿¡æ¯ï¼Ÿ
    â”‚   â””â”€ YES â†’ GraphAgent
    â”‚
    â”œâ”€ å¤æ‚æ¨ç†é—®é¢˜ï¼Ÿ
    â”‚   â””â”€ YES â†’ DeepResearchAgent
    â”‚
    â””â”€ éœ€è¦é•¿ç¯‡æŠ¥å‘Šï¼Ÿ
        â””â”€ YES â†’ FusionGraphRAGAgent
```

### ä½¿ç”¨å»ºè®®

**é»˜è®¤é€‰æ‹©**: **HybridAgent**
- å¹³è¡¡é€Ÿåº¦å’Œè´¨é‡
- é€‚ç”¨äº 80% çš„åœºæ™¯

**ç‰¹æ®Šåœºæ™¯**:
- **å¿«é€ŸåŸå‹**: NaiveRagAgent
- **çŸ¥è¯†å›¾è°±æŸ¥è¯¢**: GraphAgent
- **ç ”ç©¶æ€§é—®é¢˜**: DeepResearchAgent
- **ç”ŸæˆæŠ¥å‘Š**: FusionGraphRAGAgent

---

## ğŸ“ æ€»ç»“

### æ ¸å¿ƒç‰¹ç‚¹

| Agent | æ ¸å¿ƒç‰¹ç‚¹ | ä¸€å¥è¯æ€»ç»“ |
|-------|---------|-----------|
| **NaiveRagAgent** | ç®€å•å¿«é€Ÿ | åŸºç¡€å‘é‡æ£€ç´¢ï¼Œå¿«é€ŸåŸå‹ |
| **HybridAgent** | å¹³è¡¡æ€§å¥½ | æ··åˆæ£€ç´¢ï¼Œé»˜è®¤é¦–é€‰ |
| **GraphAgent** | å›¾ç»“æ„ | åˆ©ç”¨å›¾ç»“æ„ï¼Œæ”¯æŒèšåˆ |
| **DeepResearchAgent** | å¤šè½®æ¨ç† | åƒç ”ç©¶å‘˜æ€è€ƒï¼Œè´¨é‡æœ€é«˜ |
| **FusionGraphRAGAgent** | å›¢é˜Ÿåä½œ | å¤šAgentç¼–æ’ï¼Œç”ŸæˆæŠ¥å‘Š |

### æŠ€æœ¯åˆ›æ–°ç‚¹

1. **NaiveRag**: è½»é‡åŒ–è®¾è®¡
2. **Hybrid**: åŒå±‚å…³é”®è¯æå–
3. **Graph**: Map-Reduce èšåˆ
4. **DeepResearch**: Chain of Exploration
5. **Fusion**: Plan-Execute-Report æ¶æ„

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**åˆ›å»ºæ—¶é—´**: 2025-12-29
**ä½œè€…**: Claude Code
**ç›¸å…³æ–‡æ¡£**:
- `docs/Chatå·¥ä½œå°å®Œæ•´è°ƒç”¨æµç¨‹.md`
- `docs/Pythoné¢å‘å¯¹è±¡_Agentè°ƒç”¨æœºåˆ¶è¯¦è§£.md`
