# ç”µå½±æ¨èç³»ç»Ÿ GraphRAG å®æ–½æ–¹æ¡ˆ

> å¦‚æœä½ è¦â€œå®Œæ•´æ›¿æ¢åŸæ¥çš„æ‰€æœ‰æ•°æ®â€ï¼Œå¹¶è®©æ•´ä¸ªåº”ç”¨åªä½¿ç”¨ç”µå½±æ•°æ®ï¼Œè¯·å…ˆé˜…è¯»ï¼š`docs/ç”µå½±æ¨èç³»ç»Ÿæ•´ä½“è¿ç§»æŒ‡å—.md`ã€‚

## ğŸ“‹ é¡¹ç›®ä¿¡æ¯

| é¡¹ç›® | ä¿¡æ¯ |
|------|------|
| **æ–¹æ¡ˆåç§°** | GraphRAG ç”µå½±æ¨èç³»ç»Ÿè¿ç§»æ–¹æ¡ˆ |
| **æ•°æ®æº** | SparrowRecSys (MovieLens Subset: 982éƒ¨ç”µå½±) |
| **ç›®æ ‡ç³»ç»Ÿ** | GraphRAG + Deep Search + Multi-Agent |
| **å®æ–½å‘¨æœŸ** | 2å‘¨ï¼ˆPOCï¼‰â†’ 4å‘¨ï¼ˆå…¨é‡ï¼‰ |
| **æ–‡æ¡£ç‰ˆæœ¬** | v1.0 |
| **åˆ›å»ºæ—¥æœŸ** | 2025-12-26 |

---

## ğŸ¯ æ€»ä½“ç›®æ ‡

å°†ç°æœ‰åŸºäº"åä¸œç†å·¥å¤§å­¦å­¦ç”Ÿç®¡ç†"çš„ GraphRAG ç³»ç»Ÿè¿ç§»ä¸º"ç”µå½±æ¨èå’ŒçŸ¥è¯†é—®ç­”"ç³»ç»Ÿï¼Œå®ç°ï¼š

1. **æ™ºèƒ½æ¨è**ï¼šåŸºäºçŸ¥è¯†å›¾è°±çš„ç”µå½±æ¨è
2. **çŸ¥è¯†é—®ç­”**ï¼šç”µå½±ç›¸å…³çš„è‡ªç„¶è¯­è¨€é—®ç­”
3. **å¯è§£é‡Šæ€§**ï¼šåŸºäºå›¾è°±çš„æ¨èç†ç”±ç”Ÿæˆ
4. **å¢é‡æ›´æ–°**ï¼šæ”¯æŒæ–°ç”µå½±å’Œæ–°è¯„åˆ†çš„åŠ¨æ€æ›´æ–°

---

## ğŸ§­ èŒƒå›´ä¸äº¤ä»˜ç‰©

### èŒƒå›´ï¼ˆæœ¬æ–¹æ¡ˆè¦†ç›–ï¼‰

1. **æ•°æ®è¿ç§»**ï¼šå°† SparrowRecSysï¼ˆMovieLens å­é›†ï¼‰çš„ç»“æ„åŒ–æ•°æ®è½¬æ¢ä¸º `files/` ä¸‹å¯æ‘„å…¥çš„æ–‡æ¡£
2. **å›¾è°±æ„å»º**ï¼šåŸºäº `infrastructure.integrations.build` å…¨é‡æ„å»º Neo4j å›¾è°±ã€å®ä½“ç´¢å¼•ã€Chunk ç´¢å¼•ã€ç¤¾åŒºæ£€æµ‹
3. **æŸ¥è¯¢ä¸æ¨è**ï¼šæ”¯æŒâ€œäº‹å®æŸ¥è¯¢ / è§£é‡Šå‹é—®ç­” / åŸºäºåå¥½çš„æ¨èâ€ä¸‰ç±»æ ¸å¿ƒåœºæ™¯
4. **å¯è§‚æµ‹æ€§**ï¼šå…³é”®æ—¥å¿—ã€åŸºç¡€ç›‘æ§æŒ‡æ ‡ã€é—®é¢˜æ’æŸ¥è·¯å¾„
5. **å¢é‡æ›´æ–°ï¼ˆæ–¹æ¡ˆçº§ï¼‰**ï¼šå®šä¹‰æ–°å¢ç”µå½±/è¯„åˆ†åå¦‚ä½•è§¦å‘å¢é‡æ›´æ–°çš„æµç¨‹ä¸éªŒæ”¶ï¼ˆå…·ä½“å®ç°å¯åœ¨é˜¶æ®µ 3 è½åœ°ï¼‰

### éç›®æ ‡ï¼ˆæœ¬æ–¹æ¡ˆä¸è¦†ç›–æˆ–å»¶åï¼‰

- è®­ç»ƒ/ä¸Šçº¿ç‹¬ç«‹çš„ååŒè¿‡æ»¤æ¨¡å‹æœåŠ¡ï¼ˆå¦‚ ALS/NN æ¨èæœåŠ¡æ‹†åˆ†éƒ¨ç½²ï¼‰
- å…¨é‡ MovieLens 25M / 100M çº§åˆ«æ•°æ®çš„å·¥ç¨‹åŒ–ï¼ˆæœ¬é¡¹ç›®ä»¥ 982 éƒ¨ç”µå½±çš„å­é›†ä¸ºä¸»ï¼‰
- å¤æ‚çš„ AB å®éªŒå¹³å°ã€å®æ—¶ç‰¹å¾æµï¼ˆå¯ä½œä¸ºåç»­æ¼”è¿›ï¼‰

### äº¤ä»˜ç‰©æ¸…å•ï¼ˆæ¯é˜¶æ®µæœ€å°å¯äº¤ä»˜ï¼‰

| é˜¶æ®µ | äº¤ä»˜ç‰© | è¯´æ˜ |
|------|--------|------|
| é˜¶æ®µ 1ï¼ˆPOCï¼‰ | `files/` ç”µå½±åŸŸæ–‡æ¡£ã€å¯è·‘é€šçš„å…¨é‡å»ºå›¾ã€å¯ç”¨é—®ç­”ä¸æ¨è Demo | é‡ç‚¹éªŒè¯â€œèƒ½è·‘é€š + æœ‰æ•ˆæœâ€ |
| é˜¶æ®µ 2ï¼ˆå¢å¼ºï¼‰ | å¯¼æ¼”/æ¼”å‘˜/å‰§æƒ…ç­‰å…ƒæ•°æ®æ–‡æ¡£ã€æ¨èè§£é‡Šå¢å¼ºã€æŸ¥è¯¢åœºæ™¯æ‰©å±• | é‡ç‚¹æå‡â€œä¿¡æ¯é‡ + å¯è§£é‡Šæ€§â€ |
| é˜¶æ®µ 3ï¼ˆç”Ÿäº§çº§ï¼‰ | å…¨é‡æ•°æ®ã€æ€§èƒ½è°ƒä¼˜ã€ç›‘æ§/è¿ç»´ã€å¢é‡æ›´æ–°æµç¨‹ | é‡ç‚¹ä¿éšœâ€œæ€§èƒ½ + ç¨³å®šæ€§â€ |

---

## âœ… å‰ç½®æ¡ä»¶ä¸ä¾èµ–

### ç¯å¢ƒä¾èµ–

- Python 3.10+ï¼ˆå»ºè®®ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒ `.venv`ï¼‰
- Docker + Docker Composeï¼ˆç”¨äº Neo4jï¼‰
- Neo4j 5.xï¼ˆæœ¬ä»“åº“ `docker-compose.yaml` é»˜è®¤è´¦å· `neo4j/12345678`ï¼‰

### è¿è¡Œé…ç½®ï¼ˆå¿…é¡»ï¼‰

- å¤åˆ¶å¹¶æŒ‰éœ€ä¿®æ”¹ `.env.example` â†’ `.env`
- è‡³å°‘é…ç½® Neo4j ä¸ LLM ç›¸å…³å˜é‡ï¼ˆå¦‚ `OPENAI_API_KEY` / `DEEPSEEK_API_KEY` ç­‰ï¼ŒæŒ‰é¡¹ç›®å½“å‰å®ç°ä¸ºå‡†ï¼‰

### ç›®å½•ä¸æ•°æ®çº¦å®šï¼ˆåŠ¡å¿…éµå®ˆï¼‰

- **åŸå§‹æ•°æ®**ï¼š`SparrowRecSys-master/.../sampledata`ï¼ˆä¿æŒåªè¯»ï¼Œä¸åœ¨æ­¤å¤„å†™å…¥ç”Ÿæˆç‰©ï¼‰
- **å¯æ‘„å…¥æ–‡æ¡£**ï¼šç»Ÿä¸€å†™å…¥ `files/`ï¼ˆGraphRAG é»˜è®¤ä» `FILES_DIR = PROJECT_ROOT / "files"` è¯»å–ï¼‰
- **ç¼“å­˜/äº§ç‰©**ï¼šå†™å…¥ `cache/` æˆ– `files/`ï¼Œä¸è¦æ··å…¥ `documents/` / `datasets/`

---

## ğŸ§© å›¾è°±å»ºæ¨¡çº¦å®šï¼ˆè½åœ°æ£€æŸ¥ç”¨ï¼‰

> è¯´æ˜ï¼šæœ¬é¡¹ç›®çš„å›¾è°±å†™å…¥åŸºäº LangChain `Neo4jGraph.add_graph_documents(..., baseEntityLabel=True)`ï¼Œå®ä½“é€šå¸¸å…·å¤‡ `__Entity__` åŸºç±»æ ‡ç­¾ï¼Œå¹¶å åŠ å…·ä½“å®ä½“ç±»å‹æ ‡ç­¾ï¼ˆå¦‚ `ç”µå½±`ã€`ç”¨æˆ·` ç­‰ï¼Œå…·ä½“ä»¥å†™å…¥ç»“æœä¸ºå‡†ï¼‰ã€‚

### æ¨èçš„å®ä½“ç±»å‹ï¼ˆå¯¹åº” `backend/graphrag_agent/config/settings.py: entity_types`ï¼‰

- `ç”µå½±`ï¼šç”µå½±åŸºæœ¬ä¿¡æ¯ï¼ˆæ ‡é¢˜ã€å¹´ä»½ã€ç±»å‹ã€è¯„åˆ†ç»Ÿè®¡ã€å‰§æƒ…ç­‰ï¼‰
- `ç”¨æˆ·`ï¼šç”¨æˆ·ç”»åƒï¼ˆè¯„åˆ†æ•°é‡ã€åå¥½ç±»å‹ç­‰ï¼‰
- `ç±»å‹`ï¼šMovieLens `genres` æ‹†åˆ†åçš„å•ä¸ªç±»å‹
- `è¯„åˆ†`ï¼šç”¨äºè¡¨è¾¾â€œç”¨æˆ·å¯¹ç”µå½±çš„è¯„åˆ†äº‹ä»¶â€ï¼ˆä¹Ÿå¯ç”¨å…³ç³»å±æ€§è¡¨è¾¾ï¼Œé˜¶æ®µ 1 å…ˆä»¥å…³ç³»å±æ€§ä¸ºä¸»ï¼‰
- `å¯¼æ¼”` / `æ¼”å‘˜`ï¼šé˜¶æ®µ 2 å¼•å…¥

### æ¨èçš„å…³ç³»ç±»å‹ï¼ˆå¯¹åº” `relationship_types`ï¼‰

- `è¯„åˆ†`ï¼š`ç”¨æˆ·` â†’ `ç”µå½±`ï¼ˆå¯å¸¦ `rating`ã€`timestamp` ç­‰å±æ€§ï¼‰
- `å±äº`ï¼š`ç”µå½±` â†’ `ç±»å‹`
- `åçˆ±`ï¼š`ç”¨æˆ·` â†’ `ç±»å‹`ï¼ˆä»è¯„åˆ†èšåˆå¾—åˆ°ï¼Œå¯åœ¨é˜¶æ®µ 1/2 ç”Ÿæˆï¼‰
- `ç›¸ä¼¼` / `åŒç±»å‹`ï¼š`ç”µå½±` â†’ `ç”µå½±`ï¼ˆç”¨äºè§£é‡Šä¸æ‰©å±•æ¨èï¼Œé˜¶æ®µ 2/3 å†ç³»ç»ŸåŒ–ï¼‰
- `æ‰§å¯¼`ï¼š`å¯¼æ¼”` â†’ `ç”µå½±`ï¼ˆé˜¶æ®µ 2ï¼‰
- `ä¸»æ¼”`ï¼š`æ¼”å‘˜` â†’ `ç”µå½±`ï¼ˆé˜¶æ®µ 2ï¼‰

### Neo4j æ ¸å¿ƒéªŒæ”¶æŸ¥è¯¢ï¼ˆå»ºè®®ï¼‰

```cypher
// æ–‡æ¡£ä¸ Chunk æ˜¯å¦å†™å…¥
MATCH (d:`__Document__`) RETURN count(d) AS documents;
MATCH (c:`__Chunk__`) RETURN count(c) AS chunks;

// å®ä½“ç±»å‹åˆ†å¸ƒï¼ˆè§‚å¯Ÿæ ‡ç­¾ä¸æ•°é‡ï¼Œç¡®è®¤å†™å…¥ç¬¦åˆé¢„æœŸï¼‰
MATCH (e:__Entity__) RETURN labels(e) AS labels, count(*) AS cnt ORDER BY cnt DESC;
```

---

## ğŸ“Š å®æ–½ç­–ç•¥ï¼šä¸‰é˜¶æ®µæ–¹æ¡ˆ

### é˜¶æ®µåˆ’åˆ†

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    é˜¶æ®µ 1: å¿«é€Ÿ POC (1-2 å‘¨)                 â”‚
â”‚  ç›®æ ‡: éªŒè¯ GraphRAG æ¡†æ¶åœ¨ç”µå½±é¢†åŸŸçš„å¯è¡Œæ€§                  â”‚
â”‚  æ•°æ®: 50 éƒ¨ç”µå½± + 50 ä½ç”¨æˆ· + 2000 æ¡è¯„åˆ†                  â”‚
â”‚  åŠŸèƒ½: åŸºç¡€æŸ¥è¯¢ + ç®€å•æ¨è                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼ (éªŒè¯é€šè¿‡)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    é˜¶æ®µ 2: å¢å¼ºç‰ˆ (2-3 å‘¨)                  â”‚
â”‚  ç›®æ ‡: æ‰©å±•å…ƒæ•°æ®ï¼Œæå‡æ¨èè´¨é‡                             â”‚
â”‚  æ•°æ®: 200 éƒ¨ç”µå½± + API æ‰©å±•å…ƒæ•°æ®                          â”‚
â”‚  åŠŸèƒ½: å®Œæ•´æ¨è + ä¸°å¯ŒæŸ¥è¯¢ + å¯è§£é‡Šæ€§                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼ (éªŒè¯é€šè¿‡)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    é˜¶æ®µ 3: ç”Ÿäº§çº§ (3-4 å‘¨)                  â”‚
â”‚  ç›®æ ‡: å…¨é‡éƒ¨ç½²ï¼Œæ€§èƒ½ä¼˜åŒ–                                   â”‚
â”‚  æ•°æ®: 982 éƒ¨ç”µå½± + å…¨é‡è¯„åˆ† + å®Œæ•´å…ƒæ•°æ®                   â”‚
â”‚  åŠŸèƒ½: ç”Ÿäº§éƒ¨ç½² + ç›‘æ§ + æŒç»­ä¼˜åŒ–                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ é˜¶æ®µ 1: å¿«é€Ÿ POCï¼ˆ1-2 å‘¨ï¼‰

### ç›®æ ‡
éªŒè¯ GraphRAG æ¡†æ¶åœ¨ç”µå½±æ¨èé¢†åŸŸçš„å¯è¡Œæ€§ï¼Œå¿«é€Ÿäº§å‡ºå¯æ¼”ç¤ºçš„ç³»ç»Ÿã€‚

### æ•°æ®å‡†å¤‡

#### 1.1 æ•°æ®é‡‡æ ·ç­–ç•¥

```python
# é‡‡æ ·ç­–ç•¥
é‡‡æ ·æ–¹æ³•: åˆ†å±‚é‡‡æ ·ï¼ˆæŒ‰è¯„åˆ†å’Œå¹´ä»½ï¼‰

ç”µå½±é€‰æ‹©:
  - é«˜åˆ†ç”µå½±: 20 éƒ¨ (avgRating >= 4.0)
  - ä¸­ç­‰è¯„åˆ†: 20 éƒ¨ (3.0 <= avgRating < 4.0)
  - ä½åˆ†ç”µå½±: 10 éƒ¨ (avgRating < 3.0)
  - å¹´ä»£åˆ†å¸ƒ: è¦†ç›– 1970s-1990s

ç”¨æˆ·é€‰æ‹©:
  - æ´»è·ƒç”¨æˆ·: 30 ä½ (ratingCount >= 100)
  - ä¸­ç­‰æ´»è·ƒ: 15 ä½ (20 <= ratingCount < 100)
  - ä½æ´»è·ƒç”¨æˆ·: 5 ä½ (ratingCount < 20)

è¯„åˆ†æ•°æ®:
  - çº¦ 2000 æ¡è¯„åˆ†è®°å½•
  - è¦†ç›–æ‰€æœ‰é‡‡æ ·ç”¨æˆ·å’Œç”µå½±
```

#### 1.2 æ•°æ®è½¬æ¢è„šæœ¬

**ä½ç½®**: `scripts/convert_poc_data.py`

```python
#!/usr/bin/env python3
"""
å°† SparrowRecSys æ•°æ®è½¬æ¢ä¸º GraphRAG å¯ç”¨çš„ Markdown æ–‡æ¡£
POC ç‰ˆæœ¬: 50 éƒ¨ç”µå½± + 50 ä½ç”¨æˆ·
"""

import csv
import random
from pathlib import Path
from collections import defaultdict

# é…ç½®
REPO_ROOT = Path(__file__).resolve().parents[1]
SPARROW_DATA_PATH = REPO_ROOT / "SparrowRecSys-master/src/main/resources/webroot/sampledata"
# å»ºè®®å†™å…¥ files/ ä¸‹çš„å­ç›®å½•ï¼Œé¿å…ä¸å…¶ä»–é¢†åŸŸæ–‡æ¡£æ··æ‚
OUTPUT_PATH = REPO_ROOT / "files" / "movielens_poc"
SAMPLE_SIZE = 50  # é‡‡æ ·ç”µå½±æ•°é‡
USER_SAMPLE_SIZE = 50  # é‡‡æ ·ç”¨æˆ·æ•°é‡
RATING_SAMPLE_SIZE = 2000  # é‡‡æ ·è¯„åˆ†æ•°é‡

# å›ºå®šéšæœºç§å­ï¼Œä¿è¯ POC å¯å¤ç°
random.seed(42)

def load_data():
    """åŠ è½½åŸå§‹ CSV æ•°æ®"""
    movies = {}
    with open(SPARROW_DATA_PATH / "movies.csv", 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            movies[row['movieId']] = row

    ratings = []
    with open(SPARROW_DATA_PATH / "ratings.csv", 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            ratings.append(row)

    return movies, ratings

def sample_movies(movies, ratings, sample_size=50):
    """é‡‡æ ·ç”µå½±ï¼ˆåˆ†å±‚é‡‡æ ·ï¼‰"""
    # è®¡ç®—æ¯éƒ¨ç”µå½±çš„å¹³å‡è¯„åˆ†
    movie_ratings = defaultdict(list)
    for r in ratings:
        movie_ratings[r['movieId']].append(float(r['rating']))

    movie_stats = []
    for movie_id, movie in movies.items():
        if movie_id in movie_ratings:
            avg_rating = sum(movie_ratings[movie_id]) / len(movie_ratings[movie_id])
            movie_stats.append((movie_id, avg_rating, movie))

    # æŒ‰è¯„åˆ†åˆ†å±‚
    high_rated = [m for m in movie_stats if m[1] >= 4.0]
    mid_rated = [m for m in movie_stats if 3.0 <= m[1] < 4.0]
    low_rated = [m for m in movie_stats if m[1] < 3.0]

    # é‡‡æ ·
    sampled = []
    sampled.extend(random.sample(high_rated, min(20, len(high_rated))))
    sampled.extend(random.sample(mid_rated, min(20, len(mid_rated))))
    sampled.extend(random.sample(low_rated, min(10, len(low_rated))))

    return {m[0]: m[2] for m in sampled}

def sample_users(ratings, sample_size=50):
    """é‡‡æ ·ç”¨æˆ·ï¼ˆæŒ‰æ´»è·ƒåº¦åˆ†å±‚ï¼‰"""
    user_counts = defaultdict(int)
    for r in ratings:
        user_counts[r['userId']] += 1

    # æŒ‰æ´»è·ƒåº¦åˆ†å±‚
    high_active = [uid for uid, cnt in user_counts.items() if cnt >= 100]
    mid_active = [uid for uid, cnt in user_counts.items() if 20 <= cnt < 100]
    low_active = [uid for uid, cnt in user_counts.items() if cnt < 20]

    # é‡‡æ ·
    sampled = set()
    sampled.update(random.sample(high_active, min(30, len(high_active))))
    sampled.update(random.sample(mid_active, min(15, len(mid_active))))
    sampled.update(random.sample(low_active, min(5, len(low_active))))

    return list(sampled)

def convert_movies_to_markdown(sampled_movies, output_path):
    """è½¬æ¢ç”µå½±æ•°æ®ä¸º Markdown"""
    output_file = output_path / "ç”µå½±åˆ—è¡¨_POC.md"

    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("# ç”µå½±åˆ—è¡¨\n\n")
        f.write("> æœ¬æ–‡æ¡£åŒ…å«ç”¨äº POC æµ‹è¯•çš„ 50 éƒ¨ç”µå½±æ•°æ®\n\n")
        f.write("---\n\n")

        for movie_id, movie in sampled_movies.items():
            title = movie['title']
            # æå–å¹´ä»½
            year = ""
            if '(' in title and ')' in title:
                year = title[title.rindex('(')+1:title.rindex(')')]
                title_clean = title[:title.rindex('(')].strip()
            else:
                title_clean = title

            f.write(f"## {title_clean} ({year})\n\n")
            f.write(f"- **ç”µå½±ID**: {movie_id}\n")
            f.write(f"- **ç±»å‹**: {movie['genres']}\n")
            f.write(f"- **ä¸Šæ˜ å¹´ä»½**: {year}\n")
            f.write("\n")

    print(f"âœ“ å·²ç”Ÿæˆ: {output_file}")

def convert_ratings_to_markdown(ratings, sampled_users, sampled_movie_ids, output_path):
    """è½¬æ¢è¯„åˆ†æ•°æ®ä¸º Markdownï¼ˆé‡‡æ ·ï¼‰"""
    # ç­›é€‰é‡‡æ ·çš„ç”¨æˆ·å’Œç”µå½±
    filtered = [r for r in ratings
                if r['userId'] in sampled_users and r['movieId'] in sampled_movie_ids]

    # éšæœºé‡‡æ · 2000 æ¡
    sampled_ratings = random.sample(filtered, min(RATING_SAMPLE_SIZE, len(filtered)))

    # æŒ‰ç”¨æˆ·åˆ†ç»„
    user_ratings = defaultdict(list)
    for r in sampled_ratings:
        user_ratings[r['userId']].append(r)

    # æŒ‰è¯„åˆ†æ•°é‡æ’åºï¼Œå–å‰ 50 ä½ç”¨æˆ·
    sorted_users = sorted(user_ratings.items(),
                         key=lambda x: len(x[1]),
                         reverse=True)[:50]

    output_file = output_path / "ç”¨æˆ·è¯„åˆ†è®°å½•_POC.md"

    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("# ç”¨æˆ·è¯„åˆ†è®°å½•\n\n")
        f.write("> æœ¬æ–‡æ¡£åŒ…å« 50 ä½ç”¨æˆ·çš„è¯„åˆ†è®°å½•ï¼ˆå…± {} æ¡ï¼‰\n\n".format(len(sampled_ratings)))
        f.write("---\n\n")

        for user_id, user_rating_list in sorted_users:
            f.write(f"## ç”¨æˆ· {user_id}\n\n")
            f.write(f"- **è¯„åˆ†æ•°é‡**: {len(user_rating_list)} æ¡\n")

            # ç»Ÿè®¡åå¥½ç±»å‹
            f.write(f"- **è¯„åˆ†åˆ†å¸ƒ**: ")

            rating_values = [float(r['rating']) for r in user_rating_list]
            avg_rating = sum(rating_values) / len(rating_values)
            f.write(f"å¹³å‡ {avg_rating:.1f} åˆ†\n\n")

            # åˆ—å‡ºè¯„åˆ†
            for r in user_rating_list[:20]:  # æ¯ä¸ªç”¨æˆ·æœ€å¤šæ˜¾ç¤º 20 æ¡
                movie_id = r['movieId']
                rating = r['rating']
                f.write(f"- ç”µå½±ID {movie_id}: **{rating}**/5.0\n")

            if len(user_rating_list) > 20:
                f.write(f"- ...è¿˜æœ‰ {len(user_rating_list)-20} æ¡è¯„åˆ†\n")

            f.write("\n")

    print(f"âœ“ å·²ç”Ÿæˆ: {output_file}")

def create_genre_description(output_path):
    """åˆ›å»ºç”µå½±ç±»å‹è¯´æ˜æ–‡æ¡£"""
    genres = {
        "Action": "åŠ¨ä½œç‰‡",
        "Adventure": "å†’é™©ç‰‡",
        "Animation": "åŠ¨ç”»ç‰‡",
        "Children": "å„¿ç«¥ç‰‡",
        "Comedy": "å–œå‰§ç‰‡",
        "Crime": "çŠ¯ç½ªç‰‡",
        "Documentary": "çºªå½•ç‰‡",
        "Drama": "å‰§æƒ…ç‰‡",
        "Fantasy": "å¥‡å¹»ç‰‡",
        "Film-Noir": "é»‘è‰²ç”µå½±",
        "Horror": "ææ€–ç‰‡",
        "Musical": "éŸ³ä¹ç‰‡",
        "Mystery": "æ‚¬ç–‘ç‰‡",
        "Romance": "çˆ±æƒ…ç‰‡",
        "Sci-Fi": "ç§‘å¹»ç‰‡",
        "Thriller": "æƒŠæ‚šç‰‡",
        "War": "æˆ˜äº‰ç‰‡",
        "Western": "è¥¿éƒ¨ç‰‡",
    }

    output_file = output_path / "ç”µå½±ç±»å‹è¯´æ˜.md"

    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("# ç”µå½±ç±»å‹è¯´æ˜\n\n")
        f.write("> æœ¬æ–‡æ¡£ä»‹ç» MovieLens æ•°æ®é›†ä¸­çš„ 19 ç§ç”µå½±ç±»å‹\n\n")
        f.write("---\n\n")

        for eng, cn in genres.items():
            f.write(f"## {cn} ({eng})\n\n")
            f.write(f"- **è‹±æ–‡åç§°**: {eng}\n")
            f.write(f"- **ä¸­æ–‡åç§°**: {cn}\n")
            f.write(f"- **ç‰¹ç‚¹**: å¾…è¡¥å……\n")
            f.write(f"- **ä»£è¡¨ä½œå“**: å¾…è¡¥å……\n\n")

    print(f"âœ“ å·²ç”Ÿæˆ: {output_file}")

def create_system_docs(output_path):
    """åˆ›å»ºç³»ç»Ÿæ–‡æ¡£"""
    output_file = output_path / "æ¨èç³»ç»Ÿæ¶æ„è¯´æ˜.md"

    content = """# æ¨èç³»ç»Ÿæ¶æ„è¯´æ˜

## ç³»ç»Ÿæ¦‚è¿°

æœ¬ç³»ç»ŸåŸºäº GraphRAGï¼ˆçŸ¥è¯†å›¾è°±å¢å¼ºçš„æ£€ç´¢ç”Ÿæˆï¼‰æ¡†æ¶ï¼Œç»“åˆ SparrowRecSys çš„ MovieLens æ•°æ®ï¼Œæ„å»ºäº†ä¸€ä¸ªæ™ºèƒ½ç”µå½±æ¨èå’ŒçŸ¥è¯†é—®ç­”ç³»ç»Ÿã€‚

## æŠ€æœ¯æ¶æ„

### 1. çŸ¥è¯†å›¾è°±å±‚
- **å›¾æ•°æ®åº“**: Neo4j
- **å®ä½“ç±»å‹**: ç”µå½±ã€ç”¨æˆ·ã€ç±»å‹ã€è¯„åˆ†
- **å…³ç³»ç±»å‹**:
  - ç”¨æˆ·-[è¯„åˆ†]->ç”µå½±
  - ç”µå½±-[å±äº]->ç±»å‹
  - ç”µå½±-[ç›¸ä¼¼]->ç”µå½±

### 2. æ£€ç´¢å±‚
- **å‘é‡æ£€ç´¢**: åŸºäºç”µå½±åµŒå…¥çš„ç›¸ä¼¼åº¦æœç´¢
- **å›¾éå†**: åŸºäºå›¾è°±å…³ç³»çš„å¤šè·³æŸ¥è¯¢
- **æ··åˆæ£€ç´¢**: èåˆå‘é‡å’Œå›¾ç»“æ„çš„ç»¼åˆæœç´¢

### 3. æ™ºèƒ½ä½“å±‚
- **NaiveRAG**: ç®€å•äº‹å®æŸ¥è¯¢
- **GraphAgent**: åŸºäºå›¾è°±çš„å…³ç³»æ¨ç†
- **HybridAgent**: å¤šç­–ç•¥èåˆæŸ¥è¯¢
- **DeepResearch**: å¤æ‚æ¢ç´¢å’Œé“¾å¼æ¨ç†

## æ¨èç®—æ³•

### ååŒè¿‡æ»¤
åŸºäºç”¨æˆ·-ç”µå½±è¯„åˆ†çŸ©é˜µï¼Œä½¿ç”¨ ALSï¼ˆAlternating Least Squaresï¼‰ç®—æ³•é¢„æµ‹ç”¨æˆ·å¯¹æœªçœ‹ç”µå½±çš„è¯„åˆ†ã€‚

### å†…å®¹æ¨è
åŸºäºç”µå½±ç±»å‹ã€ç‰¹å¾è®¡ç®—ç›¸ä¼¼åº¦ï¼Œæ¨èä¸ç”¨æˆ·å–œå¥½ç›¸ä¼¼çš„ç”µå½±ã€‚

### å›¾è°±æ¨ç†
åˆ©ç”¨çŸ¥è¯†å›¾è°±çš„å…³ç³»ç½‘ç»œï¼Œé€šè¿‡å›¾éå†å‘ç°éšå¼å…³è”ï¼ˆå¦‚åŒå¯¼æ¼”ã€åŒç±»å‹ã€ç›¸ä¼¼ç”¨æˆ·ï¼‰ã€‚

### æ··åˆæ¨è
èåˆå¤šç§æ¨èç­–ç•¥çš„ç»“æœï¼Œæä¾›æ›´å‡†ç¡®å’Œå¤šæ ·åŒ–çš„æ¨èã€‚

## ä½¿ç”¨åœºæ™¯

- **ç”µå½±æ¨è**: "æ¨èä¸€äº›ç§‘å¹»ç”µå½±"
- **ç”µå½±æŸ¥è¯¢**: "ã€Šè‚–ç”³å…‹çš„æ•‘èµã€‹çš„è¯„åˆ†æ˜¯å¤šå°‘ï¼Ÿ"
- **æ¯”è¾ƒåˆ†æ**: "è¯ºå…°å¯¼æ¼”çš„ç”µå½±æœ‰å“ªäº›ï¼Ÿ"
- **åå¥½åˆ†æ**: "åˆ†æç”¨æˆ·1çš„ç”µå½±åå¥½"
"""

    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(content)

    print(f"âœ“ å·²ç”Ÿæˆ: {output_file}")

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("GraphRAG ç”µå½±æ•°æ®è½¬æ¢è„šæœ¬ (POCç‰ˆæœ¬)")
    print("=" * 60)
    print()

    # åˆ›å»ºè¾“å‡ºç›®å½•
    OUTPUT_PATH.mkdir(parents=True, exist_ok=True)

    # åŠ è½½æ•°æ®
    print("1. åŠ è½½åŸå§‹æ•°æ®...")
    movies, ratings = load_data()
    print(f"   - ç”µå½±: {len(movies)} éƒ¨")
    print(f"   - è¯„åˆ†: {len(ratings)} æ¡")
    print()

    # é‡‡æ ·ç”µå½±
    print("2. é‡‡æ ·ç”µå½±...")
    sampled_movies = sample_movies(movies, ratings, SAMPLE_SIZE)
    print(f"   - å·²é‡‡æ ·: {len(sampled_movies)} éƒ¨ç”µå½±")
    print()

    # é‡‡æ ·ç”¨æˆ·
    print("3. é‡‡æ ·ç”¨æˆ·...")
    sampled_users = sample_users(ratings, USER_SAMPLE_SIZE)
    print(f"   - å·²é‡‡æ ·: {len(sampled_users)} ä½ç”¨æˆ·")
    print()

    # è½¬æ¢ç”µå½±æ•°æ®
    print("4. è½¬æ¢ç”µå½±æ•°æ®ä¸º Markdown...")
    convert_movies_to_markdown(sampled_movies, OUTPUT_PATH)
    print()

    # è½¬æ¢è¯„åˆ†æ•°æ®
    print("5. è½¬æ¢è¯„åˆ†ä¸º Markdown...")
    sampled_movie_ids = set(sampled_movies.keys())
    convert_ratings_to_markdown(ratings, sampled_users, sampled_movie_ids, OUTPUT_PATH)
    print()

    # åˆ›å»ºç±»å‹è¯´æ˜
    print("6. åˆ›å»ºç”µå½±ç±»å‹è¯´æ˜...")
    create_genre_description(OUTPUT_PATH)
    print()

    # åˆ›å»ºç³»ç»Ÿæ–‡æ¡£
    print("7. åˆ›å»ºç³»ç»Ÿæ¶æ„æ–‡æ¡£...")
    create_system_docs(OUTPUT_PATH)
    print()

    print("=" * 60)
    print("âœ“ æ•°æ®è½¬æ¢å®Œæˆï¼")
    print(f"âœ“ è¾“å‡ºç›®å½•: {OUTPUT_PATH.absolute()}")
    print("=" * 60)

if __name__ == "__main__":
    main()
```

### é…ç½®ä¿®æ”¹

#### 1.3 å¤‡ä»½ç°æœ‰é…ç½®

```bash
cd "$(git rev-parse --show-toplevel)"

# å¤‡ä»½é…ç½®æ–‡ä»¶
cp .env .env.backup 2>/dev/null || true
cp backend/graphrag_agent/config/settings.py backend/graphrag_agent/config/settings.py.backup

echo "âœ“ é…ç½®æ–‡ä»¶å·²å¤‡ä»½"
```

#### 1.4 ä¿®æ”¹ settings.py

**ä½ç½®**: `backend/graphrag_agent/config/settings.py`

```python
# ===== çŸ¥è¯†åº“ä¸ç³»ç»Ÿå‚æ•° =====

KB_NAME = "ç”µå½±æ¨èç³»ç»Ÿ"  # åŸå€¼: "åä¸œç†å·¥å¤§å­¦"
workers = _get_env_int("FASTAPI_WORKERS", 2) or 2

# ===== çŸ¥è¯†å›¾è°±é…ç½® =====

theme = "ç”µå½±çŸ¥è¯†å›¾è°±"  # åŸå€¼: "åä¸œç†å·¥å¤§å­¦å­¦ç”Ÿç®¡ç†"

entity_types = [
    "ç”µå½±",           # æ–°å¢
    "ç”¨æˆ·",           # æ–°å¢
    "ç±»å‹",           # æ–°å¢
    "è¯„åˆ†",           # æ–°å¢
    "å¯¼æ¼”",           # æ–°å¢ï¼ˆå¯é€‰ï¼Œé˜¶æ®µ2ï¼‰
    "æ¼”å‘˜",           # æ–°å¢ï¼ˆå¯é€‰ï¼Œé˜¶æ®µ2ï¼‰
]

relationship_types = [
    "è¯„åˆ†",           # User -> Movie
    "å±äº",           # Movie -> Genre
    "ç›¸ä¼¼",           # Movie -> Movie (åŸºäºembedding)
    "åŒç±»å‹",         # Movie -> Movie
    "åçˆ±",           # User -> Genre
]

# ===== Agent å·¥å…·æè¿° =====

lc_description = (
    "ç”¨äºéœ€è¦å…·ä½“ç”µå½±ä¿¡æ¯çš„æŸ¥è¯¢ã€‚æ£€ç´¢ç”µå½±æ•°æ®åº“ä¸­çš„å…·ä½“ç”µå½±ã€è¯„åˆ†ã€ç±»å‹ç­‰è¯¦ç»†å†…å®¹ã€‚"
    "é€‚ç”¨äº'æŸéƒ¨ç”µå½±çš„è¯„åˆ†'ã€'æŸä¸ªç±»å‹çš„ç”µå½±æœ‰å“ªäº›'ç­‰é—®é¢˜ã€‚"
)

gl_description = (
    "ç”¨äºéœ€è¦æ€»ç»“å½’çº³çš„æŸ¥è¯¢ã€‚åˆ†æç”µå½±ç±»å‹çš„æ•´ä½“ç‰¹å¾ã€ç”¨æˆ·åå¥½åˆ†å¸ƒã€æ¨èç³»ç»Ÿç­–ç•¥ç­‰å®è§‚å†…å®¹ã€‚"
    "é€‚ç”¨äº'ç”µå½±ç±»å‹åˆ†å¸ƒ'ã€'ç”¨æˆ·è§‚å½±åå¥½åˆ†æ'ç­‰éœ€è¦ç³»ç»Ÿæ€§åˆ†æçš„é—®é¢˜ã€‚"
)

naive_description = (
    "åŸºç¡€æ£€ç´¢å·¥å…·ï¼Œç›´æ¥æŸ¥æ‰¾ä¸é—®é¢˜æœ€ç›¸å…³çš„æ–‡æœ¬ç‰‡æ®µï¼Œä¸åšå¤æ‚åˆ†æã€‚"
    "å¿«é€Ÿè·å–ç”µå½±ç›¸å…³ä¿¡æ¯ï¼Œè¿”å›æœ€åŒ¹é…çš„åŸæ–‡æ®µè½ã€‚"
)

examples = [
    "æ¨èä¸€äº›ç§‘å¹»ç”µå½±",
    "ã€Šè‚–ç”³å…‹çš„æ•‘èµã€‹çš„è¯„åˆ†æ˜¯å¤šå°‘ï¼Ÿ",
    "è¯ºå…°å¯¼æ¼”çš„ç”µå½±æœ‰å“ªäº›ï¼Ÿ",
    "æœ‰å“ªäº›ç±»ä¼¼ã€Šç›—æ¢¦ç©ºé—´ã€‹çš„ç”µå½±ï¼Ÿ",
    "è¯„åˆ†æœ€é«˜çš„ç”µå½±ç±»å‹æ˜¯ä»€ä¹ˆï¼Ÿ",
]
```

### æ‰§è¡Œæ­¥éª¤

#### Step 1: ç¯å¢ƒå‡†å¤‡ï¼ˆç¬¬ 1-2 å¤©ï¼‰

```bash
# 0. è¿›å…¥é¡¹ç›®æ ¹ç›®å½•
cd "$(git rev-parse --show-toplevel)"

# 1. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒå¹¶å®‰è£…ä¾èµ–ï¼ˆé¦–æ¬¡ï¼‰
python3 -m venv .venv
source .venv/bin/activate
python -m pip install -r requirements.txt

# 2. å‡†å¤‡è¿è¡Œæ—¶é…ç½®ï¼ˆé¦–æ¬¡ï¼‰
cp -n .env.example .env

# 3. å¤‡ä»½é…ç½®ï¼ˆå¯é€‰ï¼Œä¾¿äºå›æ»šï¼‰
cp .env .env.backup 2>/dev/null || true
cp backend/graphrag_agent/config/settings.py backend/graphrag_agent/config/settings.py.backup

# 4. åˆ›å»ºè„šæœ¬ç›®å½•
mkdir -p scripts

# 5. åˆ›å»ºæ•°æ®è½¬æ¢è„šæœ¬
# å°†ä¸Šè¿° convert_poc_data.py ä¿å­˜åˆ° scripts/convert_poc_data.py

# 6. è¿è¡Œæ•°æ®è½¬æ¢ï¼ˆè¾“å‡ºåˆ° files/movielens_poc/ï¼‰
python scripts/convert_poc_data.py
```

**é¢„æœŸè¾“å‡º**:
```
âœ“ å·²ç”Ÿæˆ: .../files/movielens_poc/ç”µå½±åˆ—è¡¨_POC.md
âœ“ å·²ç”Ÿæˆ: .../files/movielens_poc/ç”¨æˆ·è¯„åˆ†è®°å½•_POC.md
âœ“ å·²ç”Ÿæˆ: .../files/movielens_poc/ç”µå½±ç±»å‹è¯´æ˜.md
âœ“ å·²ç”Ÿæˆ: .../files/movielens_poc/æ¨èç³»ç»Ÿæ¶æ„è¯´æ˜.md
```

#### Step 2: ä¿®æ”¹é…ç½®ï¼ˆç¬¬ 2 å¤©ï¼‰

```bash
# ç¼–è¾‘ backend/graphrag_agent/config/settings.py
# æŒ‰ç…§ä¸Šè¿° "1.4 ä¿®æ”¹ settings.py" è¿›è¡Œä¿®æ”¹

# éªŒè¯ä¿®æ”¹
python -c "from backend.graphrag_agent.config.settings import entity_types, relationship_types; print('å®ä½“ç±»å‹:', entity_types); print('å…³ç³»ç±»å‹:', relationship_types)"
```

**é¢„æœŸè¾“å‡º**:
```
å®ä½“ç±»å‹: ['ç”µå½±', 'ç”¨æˆ·', 'ç±»å‹', 'è¯„åˆ†', 'å¯¼æ¼”', 'æ¼”å‘˜']
å…³ç³»ç±»å‹: ['è¯„åˆ†', 'å±äº', 'ç›¸ä¼¼', 'åŒç±»å‹', 'åçˆ±']
```

#### Step 3: æ„å»ºçŸ¥è¯†å›¾è°±ï¼ˆç¬¬ 3-5 å¤©ï¼‰

```bash
# 1. å¯åŠ¨ Neo4jï¼ˆå¦‚æœæœªå¯åŠ¨ï¼‰
docker compose up -d neo4j

# 2. éªŒè¯ Neo4j è¿æ¥
docker logs neo4j

# 3. ç¡®è®¤ files/ ä¸­ä»…åŒ…å«æœ¬é˜¶æ®µè¦æ‘„å…¥çš„ç”µå½±æ–‡æ¡£ï¼ˆé¿å…æ··å…¥æ—§é¢†åŸŸæ–‡æ¡£ï¼‰
ls -la files

# 4. è¿è¡Œå…¨é‡å»ºå›¾ï¼ˆæ³¨æ„ï¼šä¼šæ¸…ç©º Neo4j æ•°æ®åº“ï¼‰
python -m backend.infrastructure.integrations.build.main

# 5. éªŒæ”¶ï¼ˆå»ºè®®å…ˆç”¨ Neo4j Browser / cypher-shell å¿«é€Ÿæ£€æŸ¥ï¼‰
cypher-shell -u neo4j -p 12345678 "MATCH (d:`__Document__`) RETURN count(d) AS documents;"
cypher-shell -u neo4j -p 12345678 "MATCH (c:`__Chunk__`) RETURN count(c) AS chunks;"
cypher-shell -u neo4j -p 12345678 "MATCH (e:__Entity__) RETURN labels(e) AS labels, count(*) AS cnt ORDER BY cnt DESC;"
```

**é¢„æœŸè¾“å‡º**:
```
[2025-12-26 10:00:00] INFO - å¼€å§‹æ•°æ®æ‘„å…¥...
[2025-12-26 10:05:00] INFO - æ–‡æœ¬åˆ‡åˆ†å®Œæˆ: 150 ä¸ªæ–‡æœ¬å—
[2025-12-26 10:10:00] INFO - å®ä½“æŠ½å–å®Œæˆ: 120 ä¸ªå®ä½“
[2025-12-26 10:15:00] INFO - å…³ç³»æŠ½å–å®Œæˆ: 300 ä¸ªå…³ç³»
[2025-12-26 10:20:00] INFO - ç¤¾åŒºæ£€æµ‹å®Œæˆ: 8 ä¸ªç¤¾åŒº
[2025-12-26 10:25:00] INFO - å‘é‡ç´¢å¼•æ„å»ºå®Œæˆ
[2025-12-26 10:30:00] INFO - çŸ¥è¯†å›¾è°±æ„å»ºå®Œæˆï¼
```

#### Step 4: å¯åŠ¨æœåŠ¡å¹¶æµ‹è¯•ï¼ˆç¬¬ 6-7 å¤©ï¼‰

```bash
# 1. å¯åŠ¨åç«¯æœåŠ¡
bash scripts/dev.sh backend
# è®¿é—®: http://localhost:8000/docs

# 2. å¯åŠ¨å‰ç«¯æœåŠ¡
streamlit run frontend/app.py
# è®¿é—®: http://localhost:8501

# 3. æµ‹è¯•æŸ¥è¯¢
curl -s http://localhost:8000/api/v1/chat \
  -H "Content-Type: backend/application/json" \
  -d '{"message":"æ¨èä¸€äº›ç§‘å¹»ç”µå½±","session_id":"poc","agent_type":"hybrid_agent","debug":false}' | head
```

**æµ‹è¯•ç”¨ä¾‹**:

```python
# test_poc_queries.py
test_cases = [
    {
        "query": "ã€Šè‚–ç”³å…‹çš„æ•‘èµã€‹çš„è¯„åˆ†æ˜¯å¤šå°‘ï¼Ÿ",
        "expected_keywords": ["è‚–ç”³å…‹çš„æ•‘èµ", "è¯„åˆ†"]
    },
    {
        "query": "æ¨èä¸€äº›ç§‘å¹»ç”µå½±",
        "expected_keywords": ["ç§‘å¹»", "æ¨è"]
    },
    {
        "query": "æœ‰å“ªäº›å–œå‰§ç”µå½±ï¼Ÿ",
        "expected_keywords": ["å–œå‰§", "ç”µå½±"]
    }
]
```

#### Step 5: POC éªŒæ”¶ï¼ˆç¬¬ 7 å¤©ï¼‰

**éªŒæ”¶æ ‡å‡†**:

| æŒ‡æ ‡ | ç›®æ ‡ | éªŒæ”¶æ–¹æ³• |
|------|------|---------|
| **æ•°æ®å¯¼å…¥** | 50éƒ¨ç”µå½±å®Œæ•´å¯¼å…¥ | Neo4j æŸ¥è¯¢ `MATCH (m:__Entity__:`ç”µå½±`) RETURN count(m);` |
| **å®ä½“æŠ½å–** | è¯†åˆ«ç”µå½±ã€ç”¨æˆ·ã€ç±»å‹å®ä½“ | æ£€æŸ¥å®ä½“åº“ |
| **æŸ¥è¯¢å“åº”** | ç®€å•æŸ¥è¯¢ < 3ç§’ | æµ‹è¯• NaiveRAG |
| **æ¨èè´¨é‡** | æ¨èç»“æœç›¸å…³ | äººå·¥è¯„ä¼°æ¨èåˆ—è¡¨ |
| **ç³»ç»Ÿç¨³å®šæ€§** | æ— å´©æºƒè¿è¡Œ 24h | ç›‘æ§æ—¥å¿— |

---

## ğŸ”§ é˜¶æ®µ 2: å¢å¼ºç‰ˆï¼ˆ2-3 å‘¨ï¼‰

### ç›®æ ‡
æ‰©å±•å…ƒæ•°æ®ï¼Œæå‡æ¨èè´¨é‡ï¼Œå¢åŠ å¯è§£é‡Šæ€§ã€‚

### æ•°æ®å‡†å¤‡

#### 2.1 æ‰©å±•ç”µå½±æ•°æ®åˆ° 200 éƒ¨

```bash
# ä¿®æ”¹é‡‡æ ·å‚æ•°
# scripts/convert_enhanced_data.py

SAMPLE_SIZE = 200  # æ‰©å±•åˆ° 200 éƒ¨
USER_SAMPLE_SIZE = 200  # æ‰©å±•åˆ° 200 ä½ç”¨æˆ·
RATING_SAMPLE_SIZE = 10000  # æ‰©å±•åˆ° 1 ä¸‡æ¡è¯„åˆ†
```

**å»ºè®®**ï¼šå¢å¼ºç‰ˆè¾“å‡ºç›®å½•ç»Ÿä¸€ä½¿ç”¨ `files/movielens_enhanced/`ï¼Œå¹¶åœ¨åˆ‡æ¢é˜¶æ®µå‰æ¸…ç†/å½’æ¡£ `files/movielens_poc/`ï¼Œé¿å…ä¸€æ¬¡å»ºå›¾æŠŠä¸¤ä¸ªé˜¶æ®µçš„æ–‡æ¡£åŒæ—¶æ‘„å…¥ã€‚

#### 2.2 é€šè¿‡ IMDb API æ‰©å±•å…ƒæ•°æ®

**è„šæœ¬**: `scripts/fetch_imdb_metadata.py`

```python
#!/usr/bin/env python3
"""
é€šè¿‡ IMDbPY è·å–ç”µå½±å…ƒæ•°æ®ï¼ˆå»ºè®®ä¼˜å…ˆä½¿ç”¨ MovieLens çš„ links.csv åšç²¾ç¡®åŒ¹é…ï¼‰

ä¸ºä»€ä¹ˆè¦ç”¨ links.csv:
- ä»…æŒ‰æ ‡é¢˜æœç´¢å®¹æ˜“è¯¯åŒ¹é…ï¼ˆåŒå/ä¸åŒå¹´ä»½/ä¸åŒåœ°åŒºç‰ˆæœ¬ï¼‰
- links.csv æä¾› movieId -> imdbId / tmdbId çš„æ˜ å°„ï¼Œå¯æ˜¾è‘—æå‡å‘½ä¸­ç‡ä¸ä¸€è‡´æ€§

ä¾èµ–:
  pip install imdbpy

è¾“å‡º:
  - files/movielens_enhanced/imdb_metadata.json  ï¼ˆæŒ‰ movieId ç´¢å¼•ï¼‰
  - files/movielens_enhanced/ç”µå½±åˆ—è¡¨_å¢å¼ºç‰ˆ.md
"""

import csv
import json
import time
from pathlib import Path

from imdb import IMDb

REPO_ROOT = Path(__file__).resolve().parents[1]
SPARROW_DATA_PATH = REPO_ROOT / "SparrowRecSys-master/src/main/resources/webroot/sampledata"
OUTPUT_PATH = REPO_ROOT / "files" / "movielens_enhanced"
OUTPUT_PATH.mkdir(parents=True, exist_ok=True)

def normalize_imdb_id(raw: str) -> str | None:
    """MovieLens imdbId å¯èƒ½ç¼ºå¤±å‰å¯¼ 0ï¼ŒIMDbPY é€šå¸¸æœŸæœ› 7 ä½å­—ç¬¦ä¸²"""
    raw = (raw or "").strip()
    if not raw:
        return None
    return raw.zfill(7)

def fetch_movie_metadata(ia: IMDb, imdb_id: str | None, movie_title: str) -> dict | None:
    """è·å–å•éƒ¨ç”µå½±å…ƒæ•°æ®ï¼ˆä¼˜å…ˆç”¨ imdbIdï¼Œå¦åˆ™å›é€€ä¸ºæ ‡é¢˜æœç´¢ï¼‰"""
    try:
        if imdb_id:
            movie = ia.get_movie(imdb_id)
        else:
            candidates = ia.search_movie(movie_title)
            if not candidates:
                return None
            movie = candidates[0]

        ia.update(movie)

    metadata = {
        "title": movie.get("title"),
        "year": movie.get("year"),
        "directors": [d.get("name") for d in movie.get("directors", []) if d.get("name")],
        "actors": [a.get("name") for a in movie.get("cast", [])[:5] if a.get("name")],  # å‰ 5 ä½æ¼”å‘˜
        "genres": movie.get("genres", []),
        "rating": movie.get("rating"),
        "plot": movie.get("plot outline", ""),
        "runtime": movie.get("runtime"),
    }
    return metadata
    except Exception:
        return None

def load_movies_with_imdb_ids(movies_csv: Path, links_csv: Path) -> list[dict]:
    """è¯»å– movies.csv + links.csvï¼Œæ‹¼å‡º movieId/title/genres/imdbId"""
    with open(links_csv, "r", encoding="utf-8") as f:
        links_reader = csv.DictReader(f)
        links_map = {
            row["movieId"]: normalize_imdb_id(row.get("imdbId", ""))
            for row in links_reader
        }

    with open(movies_csv, "r", encoding="utf-8") as f:
        movies_reader = csv.DictReader(f)
        items = []
        for row in movies_reader:
            items.append(
                {
                    "movieId": row["movieId"],
                    "title": row["title"],
                    "genres": row.get("genres", ""),
                    "imdbId": links_map.get(row["movieId"]),
                }
            )
        return items

def batch_fetch_movies(items: list[dict], output_file: Path) -> dict:
    """æ‰¹é‡è·å–ç”µå½±å…ƒæ•°æ®ï¼Œè¿”å› {movieId: metadata}"""
    ia = IMDb()
    results: dict[str, dict] = {}

    for i, item in enumerate(items):
        print(f"æ­£åœ¨è·å– {i+1}/{len(items)}: {item['title']}")
        metadata = fetch_movie_metadata(ia, item.get("imdbId"), item["title"])
        if metadata:
            results[item["movieId"]] = metadata

        # é™æµï¼ˆIMDbPY å¯èƒ½è§¦å‘é£æ§ï¼Œå»ºè®®ä¿å®ˆä¸€äº›ï¼‰
        time.sleep(1)

    output_file.write_text(json.dumps(results, ensure_ascii=False, indent=2), encoding="utf-8")
    print(f"âœ“ å·²ä¿å­˜åˆ°: {output_file}")
    return results

def create_enhanced_movie_docs(items: list[dict], metadata_map: dict, output_dir: Path):
    """åˆ›å»ºå¢å¼ºç‰ˆç”µå½±æ–‡æ¡£ï¼ˆmovieId å¯¹é½ï¼‰"""
    output_file = output_dir / "ç”µå½±åˆ—è¡¨_å¢å¼ºç‰ˆ.md"

    with open(output_file, "w", encoding="utf-8") as f:
        f.write("# ç”µå½±åˆ—è¡¨ï¼ˆå¢å¼ºç‰ˆï¼‰\n\n")
        f.write("> åŒ…å«å¯¼æ¼”ã€æ¼”å‘˜ã€å‰§æƒ…ç­‰è¯¦ç»†ä¿¡æ¯\n\n")
        f.write("---\n\n")

        for item in items:
            title = item["title"]
            year = ""
            if "(" in title and ")" in title:
                year = title[title.rindex("(") + 1 : title.rindex(")")]
                title_clean = title[: title.rindex("(")].strip()
            else:
                title_clean = title

            f.write(f"## {title_clean} ({year})\n\n")
            f.write(f"- **ç”µå½±ID**: {item['movieId']}\n")
            f.write(f"- **ç±»å‹**: {item.get('genres', '')}\n")
            if item.get("imdbId"):
                f.write(f"- **IMDb ID**: tt{item['imdbId']}\n")

            # æ·»åŠ å¢å¼ºä¿¡æ¯
            metadata = metadata_map.get(item["movieId"])
            if metadata:
                if metadata.get("directors"):
                    f.write(f"- **å¯¼æ¼”**: {', '.join(metadata['directors'])}\n")

                if metadata.get("actors"):
                    f.write(f"- **ä¸»æ¼”**: {', '.join(metadata['actors'])}\n")

                if metadata.get("plot"):
                    f.write(f"- **å‰§æƒ…ç®€ä»‹**: {metadata['plot']}\n")

                if metadata.get("rating"):
                    f.write(f"- **IMDb è¯„åˆ†**: {metadata['rating']}/10\n")

            f.write("\n")

    print(f"âœ“ å·²ç”Ÿæˆ: {output_file}")

if __name__ == "__main__":
    print("1. è·å– IMDb å…ƒæ•°æ®...")
    items = load_movies_with_imdb_ids(
        SPARROW_DATA_PATH / "movies.csv",
        SPARROW_DATA_PATH / "links.csv",
    )
    metadata_map = batch_fetch_movies(items, OUTPUT_PATH / "imdb_metadata.json")

    print("\n2. ç”Ÿæˆå¢å¼ºç‰ˆç”µå½±æ–‡æ¡£...")
    create_enhanced_movie_docs(items, metadata_map, OUTPUT_PATH)
```

#### 2.3 åˆ›å»ºæ¼”å‘˜å’Œå¯¼æ¼”æ–‡æ¡£

```python
# scripts/create_person_docs.py

import json
from collections import defaultdict
from pathlib import Path

REPO_ROOT = Path(__file__).resolve().parents[1]
INPUT_JSON = REPO_ROOT / "files" / "movielens_enhanced" / "imdb_metadata.json"
OUTPUT_DIR = REPO_ROOT / "files" / "movielens_enhanced"

def create_director_docs(metadata_json, output_path):
    """åˆ›å»ºå¯¼æ¼”æ–‡æ¡£"""
    with open(metadata_json, 'r', encoding='utf-8') as f:
        metadata_map = json.load(f)  # {movieId: metadata}

    # æå–æ‰€æœ‰å¯¼æ¼”
    directors = defaultdict(list)
    for movie_id, metadata in metadata_map.items():
        title = metadata.get("title") or movie_id
        for director in metadata.get("directors", []):
            directors[director].append(title)

    # ç”Ÿæˆæ–‡æ¡£
    output_file = output_path / "å¯¼æ¼”èµ„æ–™.md"

    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("# å¯¼æ¼”èµ„æ–™\n\n")
        f.write("> åŒ…å«å¯¼æ¼”åŠå…¶ä»£è¡¨ä½œå“\n\n")
        f.write("---\n\n")

        for director, movies in sorted(directors.items()):
            f.write(f"## {director}\n\n")
            f.write(f"- **ä»£è¡¨ä½œå“æ•°é‡**: {len(movies)} éƒ¨\n")
            f.write(f"- **ä½œå“åˆ—è¡¨**:\n")
            for movie in movies[:10]:  # æœ€å¤šæ˜¾ç¤º 10 éƒ¨
                f.write(f"  - {movie}\n")
            if len(movies) > 10:
                f.write(f"  - ...è¿˜æœ‰ {len(movies)-10} éƒ¨ä½œå“\n")
            f.write("\n")

    print(f"âœ“ å·²ç”Ÿæˆ: {output_file}")

def create_actor_docs(metadata_json, output_path):
    """åˆ›å»ºæ¼”å‘˜æ–‡æ¡£"""
    with open(metadata_json, "r", encoding="utf-8") as f:
        metadata_map = json.load(f)  # {movieId: metadata}

    actors = defaultdict(list)
    for movie_id, metadata in metadata_map.items():
        title = metadata.get("title") or movie_id
        for actor in metadata.get("actors", []):
            actors[actor].append(title)

    output_file = output_path / "æ¼”å‘˜èµ„æ–™.md"

    with open(output_file, "w", encoding="utf-8") as f:
        f.write("# æ¼”å‘˜èµ„æ–™\n\n")
        f.write("> åŒ…å«æ¼”å‘˜åŠå…¶ä»£è¡¨ä½œå“\n\n")
        f.write("---\n\n")

        for actor, movies in sorted(actors.items()):
            f.write(f"## {actor}\n\n")
            f.write(f"- **ä»£è¡¨ä½œå“æ•°é‡**: {len(movies)} éƒ¨\n")
            f.write("- **ä½œå“åˆ—è¡¨**:\n")
            for movie in movies[:10]:
                f.write(f"  - {movie}\n")
            if len(movies) > 10:
                f.write(f"  - ...è¿˜æœ‰ {len(movies)-10} éƒ¨ä½œå“\n")
            f.write("\n")

    print(f"âœ“ å·²ç”Ÿæˆ: {output_file}")

if __name__ == "__main__":
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    create_director_docs(INPUT_JSON, OUTPUT_DIR)
    create_actor_docs(INPUT_JSON, OUTPUT_DIR)
```

### é…ç½®ä¿®æ”¹

#### 2.4 æ›´æ–° settings.py

```python
entity_types = [
    "ç”µå½±",
    "ç”¨æˆ·",
    "ç±»å‹",
    "è¯„åˆ†",
    "å¯¼æ¼”",           # é˜¶æ®µ2å¯ç”¨
    "æ¼”å‘˜",           # é˜¶æ®µ2å¯ç”¨
]

relationship_types = [
    "è¯„åˆ†",
    "å±äº",
    "ç›¸ä¼¼",
    "åŒç±»å‹",
    "åçˆ±",
    "æ‰§å¯¼",           # æ–°å¢
    "ä¸»æ¼”",           # æ–°å¢
]
```

### æ‰§è¡Œæ­¥éª¤

#### Week 1: æ‰©å±•æ•°æ® + å…ƒæ•°æ®è·å–

```bash
# Day 1-2: æ‰©å±•æ•°æ®åˆ° 200 éƒ¨ç”µå½±
python scripts/convert_enhanced_data.py

# Day 3-4: è·å– IMDb å…ƒæ•°æ®
python -m pip install imdbpy
python scripts/fetch_imdb_metadata.py

# Day 5: åˆ›å»ºäººç‰©æ–‡æ¡£
python scripts/create_person_docs.py
```

#### Week 2: é‡å»ºçŸ¥è¯†å›¾è°± + æµ‹è¯•

```bash
# Day 1-3: é‡å»ºçŸ¥è¯†å›¾è°±
# æ³¨æ„ï¼šè¯·ç¡®ä¿ files/ ä¸­ä¸å†åŒ…å«æ—§é¢†åŸŸï¼ˆå­¦ç”Ÿç®¡ç†ï¼‰æ–‡æ¡£ï¼Œé¿å…æ··å…¥æ‘„å…¥
python -m backend.infrastructure.integrations.build.main

# Day 4-5: æµ‹è¯•å¢å¼ºåŠŸèƒ½
# æµ‹è¯•å¯¼æ¼”ç›¸å…³æŸ¥è¯¢
# æµ‹è¯•æ¼”å‘˜ç›¸å…³æŸ¥è¯¢
# æµ‹è¯•æ¨èè§£é‡Šæ€§
```

---

## ğŸš€ é˜¶æ®µ 3: ç”Ÿäº§çº§ï¼ˆ3-4 å‘¨ï¼‰

### ç›®æ ‡
å…¨é‡éƒ¨ç½²ï¼Œæ€§èƒ½ä¼˜åŒ–ï¼Œç”Ÿäº§ç›‘æ§ã€‚

### æ•°æ®å‡†å¤‡

#### 3.1 å…¨é‡æ•°æ®å¯¼å…¥ï¼ˆ982 éƒ¨ç”µå½±ï¼‰

```bash
# scripts/convert_full_data.py

SAMPLE_SIZE = 982  # å…¨é‡
USER_SAMPLE_SIZE = 500  # å‰ 500 ä½æ´»è·ƒç”¨æˆ·
RATING_SAMPLE_SIZE = 50000  # 5 ä¸‡æ¡è¯„åˆ†ï¼ˆé‡‡æ ·ï¼‰
```

#### 3.2 æ€§èƒ½ä¼˜åŒ–é…ç½®

**æ¨èæ–¹å¼**: é€šè¿‡ `.env` è¦†ç›–ç¯å¢ƒå˜é‡ï¼ˆ`backend/graphrag_agent/config/settings.py` ä¼šè¯»å–å¹¶ç”Ÿæ•ˆï¼‰ï¼Œé¿å…ç›´æ¥æ”¹ä»£ç ã€‚

```python
# æ€§èƒ½è°ƒä¼˜
MAX_WORKERS = 8  # å¢åŠ å¹¶è¡Œåº¦
BATCH_SIZE = 200  # å¢åŠ æ‰¹å¤„ç†å¤§å°
ENTITY_BATCH_SIZE = 100
CHUNK_BATCH_SIZE = 200

# Neo4j ä¼˜åŒ–
GDS_MEMORY_LIMIT = 8  # å¢åŠ å†…å­˜
GDS_CONCURRENCY = 8  # å¢åŠ å¹¶å‘

# ç¼“å­˜ä¼˜åŒ–
CACHE_MAX_MEMORY_SIZE = 500  # å¢åŠ å†…å­˜ç¼“å­˜
CACHE_MAX_VECTORS = 50000  # å¢åŠ å‘é‡ç¼“å­˜
```

å¯¹åº” `.env` ç¤ºä¾‹ï¼š

```bash
MAX_WORKERS=8
BATCH_SIZE=200
ENTITY_BATCH_SIZE=100
CHUNK_BATCH_SIZE=200
GDS_MEMORY_LIMIT=8
GDS_CONCURRENCY=8
CACHE_MAX_MEMORY_SIZE=500
CACHE_MAX_VECTORS=50000
```

### éƒ¨ç½²æ¶æ„

#### 3.3 ç”Ÿäº§ç¯å¢ƒé…ç½®

```yaml
# docker-compose.prod.yml
version: '3.8'

services:
  neo4j:
    image: neo4j:5.22.0
    container_name: neo4j-prod
    environment:
      - NEO4J_dbms_memory_heap_max__size=4G
      - NEO4J_dbms_memory_pagecache_size=8G
      - NEO4J_dbms_connector_bolt_advertised__address=:7687
      - NEO4J_dbms_connector_http_advertised__address=:7474
    volumes:
      - neo4j-data:/data
      - neo4j-logs:/logs
    ports:
      - "7474:7474"
      - "7687:7687"
    restart: always

  redis:
    image: redis:7-alpine
    container_name: redis-prod
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data
    ports:
      - "6379:6379"
    restart: always

volumes:
  neo4j-data:
  neo4j-logs:
  redis-data:
```

#### 3.4 æœåŠ¡éƒ¨ç½²

```bash
# åç«¯æœåŠ¡ (ä½¿ç”¨ gunicorn)
bash scripts/prod.sh \
  --workers 4 \
  --bind 0.0.0.0:8000 \
  --daemon

# å‰ç«¯æœåŠ¡ (ä½¿ç”¨ streamlit)
streamlit run frontend/app.py \
  --server.port 8501 \
  --server.address 0.0.0.0 &

# Nginx åå‘ä»£ç†
nginx -c /path/to/nginx.conf
```

### ç›‘æ§å’Œè¿ç»´

#### 3.5 æ—¥å¿—ç›‘æ§

```python
# æ·»åŠ æ—¥å¿—è®°å½•
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/graphrag_agent.log'),
        logging.StreamHandler()
    ]
)
```

#### 3.6 æ€§èƒ½ç›‘æ§

```bash
# ä½¿ç”¨ Prometheus + Grafana
# prometheus.yml
scrape_configs:
  - job_name: 'graphrag_agent'
    static_configs:
      - targets: ['localhost:8000']
```

---

## ğŸ“ˆ è¯„ä¼°ä¸æµ‹è¯•æ–¹æ³•

### è¯„ä¼°å¯¹è±¡

- **é—®ç­”è´¨é‡**ï¼šäº‹å®æ˜¯å¦æ­£ç¡®ã€å¼•ç”¨è¯æ®æ˜¯å¦æ¥è‡ª `files/`ã€å›ç­”æ˜¯å¦è¦†ç›–ç”¨æˆ·é—®é¢˜
- **æ¨èè´¨é‡**ï¼šç›¸å…³æ€§ã€å¤šæ ·æ€§ã€æ–°é¢–æ€§ï¼ˆé¿å…åªæ¨èçƒ­é—¨ï¼‰ã€å¯è§£é‡Šæ€§
- **ç³»ç»Ÿè´¨é‡**ï¼šå»¶è¿Ÿã€ç¨³å®šæ€§ã€å¯æ¢å¤æ€§ï¼ˆé‡å¯/æ–­è¿ï¼‰ã€æˆæœ¬ï¼ˆLLM è°ƒç”¨é‡ï¼‰

### åœºæ™¯åŒ–æµ‹è¯•é›†ï¼ˆé˜¶æ®µ 1 èµ·å°±è¦å‡†å¤‡ï¼‰

å»ºè®®æŒ‰â€œé—®é¢˜ç±»å‹ Ã— éš¾åº¦â€å‡†å¤‡æœ€å° 20ï½50 æ¡æµ‹è¯•ç”¨ä¾‹ï¼Œå¹¶å›ºå®šä¸ºå›å½’é›†ï¼š

1. **äº‹å®æŸ¥è¯¢ï¼ˆLocal/Naiveï¼‰**ï¼šè¯„åˆ†ã€ç±»å‹ã€ä¸Šæ˜ å¹´ä»½ã€æ¼”å‘˜/å¯¼æ¼”ï¼ˆé˜¶æ®µ 2ï¼‰
2. **æ¨èï¼ˆHybridï¼‰**ï¼šæŒ‰ç±»å‹ã€æŒ‰ç›¸ä¼¼ç”µå½±ã€æŒ‰ç”¨æˆ·åå¥½ï¼ˆéœ€è¦ session_id æˆ–ç”¨æˆ·ç”»åƒæè¿°ï¼‰
3. **è§£é‡Šï¼ˆGraph/Globalï¼‰**ï¼šä¸ºä»€ä¹ˆæ¨èã€æ¨èä¾æ®æ˜¯ä»€ä¹ˆã€è¯æ®é“¾æ¥è‡ªå“ªäº›å®ä½“/å…³ç³»

### ç¦»çº¿æ¨èè¯„ä¼°ï¼ˆå¯é€‰ï¼Œé˜¶æ®µ 2/3 å»ºè®®åšï¼‰

> é€‚ç”¨äºâ€œæœ‰æ˜ç¡®ç”¨æˆ·-ç”µå½±äº¤äº’æ—¥å¿—â€çš„æ¨èè¯„ä¼°ï¼›GraphRAG ä¹Ÿå¯ä»¥åšâ€œå¯è§£é‡Šæ¨èâ€çš„ç¦»çº¿éªŒè¯ã€‚

- **æ•°æ®åˆ‡åˆ†**ï¼šæŒ‰æ—¶é—´æˆ³å¯¹æ¯ä¸ªç”¨æˆ·åš hold-outï¼ˆä¾‹å¦‚ä¿ç•™æœ€å 1ï½3 æ¡è¯„åˆ†ä½œä¸ºæµ‹è¯•ï¼‰
- **Top-K æŒ‡æ ‡**ï¼š`Precision@K`ã€`Recall@K`ã€`NDCG@K`ã€`Coverage@K`ï¼ˆç±»å‹è¦†ç›–ï¼‰
- **åŸºçº¿å¯¹æ¯”**ï¼šçƒ­é—¨æ¦œï¼ˆMostPopularï¼‰ã€æŒ‰ç±»å‹åŒ¹é…ï¼ˆContent-onlyï¼‰ã€ååŒè¿‡æ»¤ï¼ˆè‹¥åç»­å¼•å…¥ï¼‰

### ç³»ç»Ÿå›å½’æµ‹è¯•ï¼ˆä»£ç çº§ï¼‰

```bash
bash scripts/test.sh
```

### API å†’çƒŸæµ‹è¯•ï¼ˆé˜¶æ®µ 1 èµ·ï¼‰

```bash
curl -s http://localhost:8000/api/v1/chat \
  -H "Content-Type: backend/application/json" \
  -d '{"message":"æœ‰å“ªäº›ç±»ä¼¼ã€Šç›—æ¢¦ç©ºé—´ã€‹çš„ç”µå½±ï¼Ÿ","session_id":"smoke","agent_type":"hybrid_agent"}' | head
```

---

## ğŸ“Š éªŒæ”¶æ ‡å‡†

### é˜¶æ®µ 1: POC éªŒæ”¶

| æŒ‡æ ‡ | ç›®æ ‡ | éªŒæ”¶æ–¹æ³• |
|------|------|---------|
| **æ•°æ®å¯¼å…¥** | 50éƒ¨ç”µå½± | Neo4j æŸ¥è¯¢ `MATCH (m:__Entity__:`ç”µå½±`) RETURN count(m);`ï¼ˆåº”â‰ˆ50ï¼‰ |
| **æŸ¥è¯¢å“åº”** | < 3ç§’ | æµ‹è¯• NaiveRAG |
| **æ¨èè´¨é‡** | ç›¸å…³æ€§ > 70% | äººå·¥è¯„ä¼° |
| **ç³»ç»Ÿç¨³å®šæ€§** | 24hæ— å´©æºƒ | ç›‘æ§æ—¥å¿— |

### é˜¶æ®µ 2: å¢å¼ºç‰ˆéªŒæ”¶

| æŒ‡æ ‡ | ç›®æ ‡ | éªŒæ”¶æ–¹æ³• |
|------|------|---------|
| **æ•°æ®è§„æ¨¡** | 200éƒ¨ç”µå½± | Neo4j æŸ¥è¯¢ |
| **å…ƒæ•°æ®å®Œæ•´æ€§** | å¯¼æ¼”ã€æ¼”å‘˜ > 80% | æŠ½æ ·æ£€æŸ¥ |
| **æ¨èå¤šæ ·æ€§** | ç±»å‹è¦†ç›– > 15 | æµ‹è¯•æ¨èåˆ—è¡¨ |
| **å¯è§£é‡Šæ€§** | æ¨èç†ç”±åˆç† | äººå·¥è¯„ä¼° |

### é˜¶æ®µ 3: ç”Ÿäº§çº§éªŒæ”¶

| æŒ‡æ ‡ | ç›®æ ‡ | éªŒæ”¶æ–¹æ³• |
|------|------|---------|
| **æ•°æ®è§„æ¨¡** | 982éƒ¨ç”µå½± | Neo4j æŸ¥è¯¢ |
| **æŸ¥è¯¢æ€§èƒ½** | P95 < 5ç§’ | å‹åŠ›æµ‹è¯• |
| **å¹¶å‘èƒ½åŠ›** | 100 QPS | JMeter æµ‹è¯• |
| **å¯ç”¨æ€§** | 99.9% | ç›‘æ§ç»Ÿè®¡ |

---

## ğŸ“ å®æ–½æ£€æŸ¥æ¸…å•

### é˜¶æ®µ 1 æ£€æŸ¥æ¸…å•

- [ ] å¤‡ä»½é…ç½®æ–‡ä»¶ï¼ˆ.env, settings.pyï¼‰
- [ ] åˆ›å»ºæ•°æ®è½¬æ¢è„šæœ¬ï¼ˆconvert_poc_data.pyï¼‰
- [ ] ä¿®æ”¹ settings.pyï¼ˆä¸»é¢˜ã€å®ä½“ã€å…³ç³»ï¼‰
- [ ] è¿è¡Œæ•°æ®è½¬æ¢ï¼Œç”Ÿæˆ Markdown æ–‡æ¡£
- [ ] éªŒè¯ files/ ç›®å½•å†…å®¹
- [ ] å¯åŠ¨ Neo4j
- [ ] è¿è¡ŒçŸ¥è¯†å›¾è°±æ„å»º
- [ ] éªŒè¯å›¾è°±æ•°æ®ï¼ˆNeo4j Browserï¼‰
- [ ] å¯åŠ¨åç«¯æœåŠ¡
- [ ] å¯åŠ¨å‰ç«¯æœåŠ¡
- [ ] æµ‹è¯•åŸºç¡€æŸ¥è¯¢ï¼ˆ5 ä¸ªæµ‹è¯•ç”¨ä¾‹ï¼‰
- [ ] æµ‹è¯•æ¨èåŠŸèƒ½
- [ ] è®°å½•æ€§èƒ½æŒ‡æ ‡
- [ ] ç¼–å†™ POC æŠ¥å‘Š

### é˜¶æ®µ 2 æ£€æŸ¥æ¸…å•

- [ ] æ‰©å±•æ•°æ®åˆ° 200 éƒ¨ç”µå½±
- [ ] å®‰è£… IMDbPy åº“
- [ ] è·å– IMDb å…ƒæ•°æ®
- [ ] åˆ›å»ºå¯¼æ¼”èµ„æ–™æ–‡æ¡£
- [ ] åˆ›å»ºæ¼”å‘˜èµ„æ–™æ–‡æ¡£
- [ ] æ›´æ–° settings.pyï¼ˆæ–°å¢å¯¼æ¼”ã€æ¼”å‘˜ï¼‰
- [ ] é‡å»ºçŸ¥è¯†å›¾è°±
- [ ] æµ‹è¯•å¯¼æ¼”ç›¸å…³æŸ¥è¯¢
- [ ] æµ‹è¯•æ¼”å‘˜ç›¸å…³æŸ¥è¯¢
- [ ] è¯„ä¼°æ¨èè´¨é‡æå‡
- [ ] æµ‹è¯•æ¨èè§£é‡Šæ€§
- [ ] æ€§èƒ½å¯¹æ¯”æµ‹è¯•ï¼ˆé˜¶æ®µ1 vs é˜¶æ®µ2ï¼‰
- [ ] ç¼–å†™é˜¶æ®µæŠ¥å‘Š

### é˜¶æ®µ 3 æ£€æŸ¥æ¸…å•

- [ ] å…¨é‡æ•°æ®å¯¼å…¥ï¼ˆ982 éƒ¨ç”µå½±ï¼‰
- [ ] æ€§èƒ½ä¼˜åŒ–é…ç½®ï¼ˆsettings.pyï¼‰
- [ ] éƒ¨ç½² Neo4j ç”Ÿäº§ç¯å¢ƒ
- [ ] éƒ¨ç½² Redis ç¼“å­˜
- [ ] é…ç½® Nginx åå‘ä»£ç†
- [ ] é…ç½® gunicorn å¤šè¿›ç¨‹
- [ ] é…ç½®æ—¥å¿—ç›‘æ§
- [ ] é…ç½® Prometheus + Grafana
- [ ] å‹åŠ›æµ‹è¯•ï¼ˆ100 QPSï¼‰
- [ ] ç¨³å®šæ€§æµ‹è¯•ï¼ˆ72hï¼‰
- [ ] ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
- [ ] ç¼–å†™è¿ç»´æ–‡æ¡£
- [ ] ç¼–å†™ç”¨æˆ·æ‰‹å†Œ

---

## ğŸ¯ æˆåŠŸæ ‡å‡†

### æŠ€æœ¯æŒ‡æ ‡

| æŒ‡æ ‡ | POC | å¢å¼ºç‰ˆ | ç”Ÿäº§çº§ |
|------|-----|--------|--------|
| **ç”µå½±æ•°é‡** | 50 | 200 | 982 |
| **æŸ¥è¯¢å»¶è¿Ÿ** | < 3s | < 3s | < 5s |
| **æ¨èå‡†ç¡®ç‡** | > 70% | > 80% | > 85% |
| **å¹¶å‘èƒ½åŠ›** | 10 QPS | 50 QPS | 100 QPS |
| **ç³»ç»Ÿå¯ç”¨æ€§** | 90% | 95% | 99.9% |

### ä¸šåŠ¡æŒ‡æ ‡

- **ç”¨æˆ·æ»¡æ„åº¦**: æ¨èç»“æœæ»¡æ„åº¦ > 80%
- **æ¨èå¤šæ ·æ€§**: ç±»å‹è¦†ç›– > 15
- **å¯è§£é‡Šæ€§**: æ¨èç†ç”±åˆç†ç‡ > 75%
- **çŸ¥è¯†è¦†ç›–**: æ”¯æŒæŸ¥è¯¢åœºæ™¯ > 20 ç§

---

## ğŸ“Œ æ³¨æ„äº‹é¡¹

### æŠ€æœ¯é£é™©

1. **IMDb API é™æµ**
   - è§£å†³æ–¹æ¡ˆ: æ·»åŠ è¯·æ±‚é—´éš”ï¼Œä½¿ç”¨ç¼“å­˜
   - å¤‡é€‰æ–¹æ¡ˆ: ä½¿ç”¨ TMDb APIï¼ˆæ›´å®½æ¾çš„é™æµï¼‰

2. **Neo4j æ€§èƒ½ç“¶é¢ˆ**
   - è§£å†³æ–¹æ¡ˆ: å¢åŠ å†…å­˜ï¼Œä¼˜åŒ–ç´¢å¼•
   - å¤‡é€‰æ–¹æ¡ˆ: ä½¿ç”¨ Neo4j å› æœé›†ç¾¤

3. **LLM æˆæœ¬è¿‡é«˜**
   - è§£å†³æ–¹æ¡ˆ: ä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼ˆDeepSeekï¼‰
   - å¤‡é€‰æ–¹æ¡ˆ: å¢åŠ ç¼“å­˜ï¼Œå‡å°‘è°ƒç”¨

### æ•°æ®é£é™©

1. **æ•°æ®å¹´ä»£ä¹…è¿œ**
   - å½±å“: ç”¨æˆ·å¯èƒ½ä¸ç†Ÿæ‚‰ 1990 å¹´ä»£çš„ç”µå½±
   - è§£å†³æ–¹æ¡ˆ: åœ¨æ–‡æ¡£ä¸­æ·»åŠ æ—¶ä»£èƒŒæ™¯è¯´æ˜

2. **å…ƒæ•°æ®ç¼ºå¤±**
   - å½±å“: éƒ¨åˆ†ç”µå½±æ— æ³•è·å–è¯¦ç»†ä¿¡æ¯
   - è§£å†³æ–¹æ¡ˆ: ä½¿ç”¨é»˜è®¤å€¼æˆ–æ‰‹åŠ¨è¡¥å……

---

## ğŸ“š é™„å½•

### A. å¸¸ç”¨å‘½ä»¤

```bash
# æ•°æ®è½¬æ¢
python scripts/convert_poc_data.py
python scripts/convert_enhanced_data.py
python scripts/convert_full_data.py

# å…ƒæ•°æ®è·å–
python -m pip install imdbpy
python scripts/fetch_imdb_metadata.py
python scripts/create_person_docs.py

# çŸ¥è¯†å›¾è°±æ„å»º
python -m backend.infrastructure.integrations.build.main

# å¢é‡æ›´æ–°
python -m backend.infrastructure.integrations.build.incremental_update --once

# æœåŠ¡å¯åŠ¨
bash scripts/dev.sh backend
streamlit run frontend/app.py

# Neo4j æŸ¥è¯¢
cypher-shell -u neo4j -p 12345678
MATCH (m:__Entity__:`ç”µå½±`) RETURN count(m);
```

### B. æ•…éšœæ’æŸ¥

| é—®é¢˜ | å¯èƒ½åŸå›  | è§£å†³æ–¹æ³• |
|------|---------|---------|
| Neo4j è¿æ¥å¤±è´¥ | Neo4j æœªå¯åŠ¨ | `docker compose up -d neo4j` |
| å®ä½“æŠ½å–å¤±è´¥ | LLM API é”™è¯¯ | æ£€æŸ¥ OPENAI_API_KEY |
| æŸ¥è¯¢è¶…æ—¶ | ç´¢å¼•æœªåˆ›å»º | è¿è¡Œå…¨æ–‡ç´¢å¼•æ„å»º |
| æ¨èç»“æœå·® | æ•°æ®ä¸è¶³ | å¢åŠ ç”µå½±æ•°é‡ |

### C. å‚è€ƒèµ„æ–™

- **GraphRAG æ–‡æ¡£**: `docs/é¢†åŸŸé€‚é…æŒ‡å—.md`
- **è®¾è®¡æ–‡æ¡£**: `docs/ç”µå½±æ¨èç³»ç»ŸGraphRAGé€‚é…è®¾è®¡æ–‡æ¡£.md`
- **æ•°æ®æŠ¥å‘Š**: `docs/SparrowRecSysæ•°æ®å®Œæ•´æ€§æŠ¥å‘Š.md`
- **SparrowRecSys**: `SparrowRecSys-master/README.md`
- **MovieLens**: https://grouplens.org/datasets/movielens/

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-12-26
**ç»´æŠ¤è€…**: GraphRAG Team
