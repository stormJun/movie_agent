# 电影推荐系统：全量迁移指南（从学生管理域 → 电影域）

> 目标：**完整替换原来的所有数据载体**，让整个应用（建图、检索、问答、评估、前端示例）都基于 **SparrowRecSys / MovieLens** 电影数据运行。

> 注意：本文件位于 `docs/99-参考资料/历史文档/`，属于历史迁移指南。当前仓库已完成“backend 目录收敛 + 语义配置迁移”，
> 部分路径/配置入口与旧版不同。若你按本文执行，优先以 `.env.example` 与 `backend/config/rag_semantics.py` 为准。

本指南以“可执行”为第一原则：按顺序完成每一步后，你将得到一个只摄入电影语料、只输出电影知识的 GraphRAG 应用。

---

## 0. 迁移原则（必须理解）

1. **GraphRAG 的“数据载体”是 `files/`**  
   core 默认值在 `backend/graphrag_agent/config/settings.py`（`FILES_DIR = Path("files")`），运行期以 `.env` 的 `FILES_DIR` 为准
   （由 `backend/infrastructure/config/graphrag_settings.py` 注入到 core settings）。建图入口会递归读取 `files/` 下的所有支持格式文件。  
   结论：要“完整替换数据”，核心动作就是 **把 `files/` 从学生文档替换为电影语料**。

2. **全量建图是破坏性的**  
   全量建图会清空 Neo4j 中的节点与关系（`GraphStructureBuilder.clear_database()`），并丢弃旧索引。  
   结论：迁移前要备份 Neo4j 数据（如果你还需要旧域）。

3. **领域适配不仅是数据，还包括配置与示例**  
   电影域迁移至少需要同步更新：
   - `.env` / `backend/config/rag_semantics.py`：主题、实体/关系类型、工具描述、示例问题、回答格式（RESPONSE_TYPE）
   - `test/evaluation/*.json`：评估问答（否则评估还在问“奖学金/处分”）
   - `frontend`：示例问题来自服务侧语义配置（见 `backend/config/rag.py`），不改就还是旧域

---

## 1. 迁移范围（你要“完整替换”的清单）

### 1.1 运行期数据（必须替换）

- `files/`：从“学生管理文档”替换为“电影语料（MovieLens/SparrowRecSys 转换后的文档）”
- Neo4j：清空并重建为电影图谱（节点/关系/索引/社区）

### 1.2 配置与体验（建议替换，否则会混用旧域信息）

- `.env` / `backend/config/rag_semantics.py`：全部改为电影域口径
- `test/evaluation/questions.json` 与 `test/evaluation/answer.json`：替换为电影问答
- `frontend/components/sidebar.py` 文案（可选）：标题/关于说明可改为“电影推荐系统”

---

## 2. 迁移前准备（一次性）

### 2.1 环境与依赖

```bash
cd "$(git rev-parse --show-toplevel)"
python3 -m venv .venv
source .venv/bin/activate
python -m pip install -r requirements.txt
cp -n .env.example .env
```

### 2.2 Neo4j 启动与验证

```bash
docker compose up -d neo4j
docker logs neo4j
```

---

## 3. Step A：备份与“清空旧域数据”

### 3.1 备份配置（可回滚）

```bash
cd "$(git rev-parse --show-toplevel)"
cp .env .env.backup 2>/dev/null || true
cp backend/graphrag_agent/config/settings.py backend/graphrag_agent/config/settings.py.backup
```

### 3.2 备份或移出旧域文档（关键）

当前仓库的 `files/` 内包含学生管理相关文档（pdf/doc/txt）。如果不处理，建图会混入旧域。

推荐做法（二选一）：

**方案 1（推荐）：把旧文档移出 `files/`，放入归档目录（不参与摄入）**

```bash
cd "$(git rev-parse --show-toplevel)"
mkdir -p documents/legacy_student_files
mv files/* documents/legacy_student_files/
mkdir -p files
```

**方案 2：直接清空 `files/`（不可恢复，谨慎）**

```bash
cd "$(git rev-parse --show-toplevel)"
rm -rf files/*
```

> 注意：如果你是 git 仓库且这些文件被跟踪，`mv/rm` 会改变工作区；如需保留仓库历史但不影响本次建图，请优先使用方案 1 并在本地执行即可。

---

## 4. Step B：生成“电影域语料”（写入 `files/`）

### 4.1 数据源位置

SparrowRecSys 的 MovieLens 子集位于：

`SparrowRecSys-master/src/main/resources/webroot/sampledata/`

关键文件：

- `movies.csv`：movieId、title、genres
- `ratings.csv`：userId、movieId、rating、timestamp
- `links.csv`：movieId → imdbId、tmdbId

### 4.2 语料生成策略（推荐）

为了让 LLM 抽取更稳定，建议将 CSV 转成结构化 Markdown（或文本）：

1. **电影条目文档**：每条包含 movieId、标题、年份、类型、评分统计（count/avg）、外部 ID
2. **用户画像文档**：每个用户的评分概况、Top 类型偏好（由 ratings 聚合）
3. **类型汇总文档**：类型英文/中文对照、类型热度与高分电影示例（可选）

输出建议放在：

`files/movielens/`

并确保 `files/` 下 **只存在电影语料**。

> 本仓库目前没有内置“CSV→Markdown”的脚本；你可以直接复用 `docs/电影推荐系统实施方案.md` 中的脚本模板，或我可以在下一步给你补齐可直接运行的 `scripts/` 工具（推荐）。

---

## 5. Step C：修改领域配置（`backend/graphrag_agent/config/settings.py`）

迁移最关键的配置项如下（示例，仅展示需要改的核心字段）：

```python
KB_NAME = "电影推荐系统"
theme = "电影知识图谱"

entity_types = [
    "电影",
    "用户",
    "类型",
    "评分",
    "导演",  # 可选（阶段 2）
    "演员",  # 可选（阶段 2）
]

relationship_types = [
    "评分",   # 用户 -> 电影
    "属于",   # 电影 -> 类型
    "偏爱",   # 用户 -> 类型（由评分聚合得到）
    "相似",   # 电影 -> 电影（可选）
    "同类型", # 电影 -> 电影（可选）
    "执导",   # 导演 -> 电影（阶段 2）
    "主演",   # 演员 -> 电影（阶段 2）
]

lc_description = "用于需要具体电影信息的查询..."
gl_description = "用于需要总结归纳的查询..."
naive_description = "基础检索工具..."

examples = [
    "推荐一些科幻电影",
    "《肖申克的救赎》的评分是多少？",
    "有哪些类似《盗梦空间》的电影？",
    "分析用户1的观影偏好",
]
```

### 5.1 “完整替换”的校验点

做完上述改动后，全仓库不应再出现“学生管理/奖学金/处分”等作为默认交互示例（除非在历史文档中保留）。

---

## 6. Step D：替换评估数据（可选但强烈建议）

评估集文件：

- `test/evaluation/questions.json`
- `test/evaluation/answer.json`

当前内容是学生管理域问答。迁移到电影域后建议替换为 20+ 条电影问答（阶段 1 最少 5 条）。

示例问题方向：

- “某电影的类型/年份/平均评分/评分人数”
- “给我推荐 5 部某类型电影，并说明理由”
- “用户 X 喜欢哪些类型？为什么？”

> 如果你希望“答案可校验”，建议先用脚本从 `ratings.csv` 计算出某些电影的平均分/评分数，再写入 `answer.json`。

---

## 7. Step E：重建图谱（全量）

### 7.1 确认 `files/` 只包含电影语料

```bash
cd "$(git rev-parse --show-toplevel)"
ls -la files
```

### 7.2 执行全量建图（会清空 Neo4j）

```bash
python -m backend.infrastructure.integrations.build.main
```

### 7.3 验收（Neo4j）

```bash
cypher-shell -u neo4j -p 12345678 "MATCH (d:`__Document__`) RETURN count(d) AS documents;"
cypher-shell -u neo4j -p 12345678 "MATCH (c:`__Chunk__`) RETURN count(c) AS chunks;"
cypher-shell -u neo4j -p 12345678 "MATCH (e:__Entity__) RETURN labels(e) AS labels, count(*) AS cnt ORDER BY cnt DESC;"
```

---

## 8. Step F：启动服务与端到端验证

### 8.1 启动后端

```bash
bash scripts/dev.sh backend
```

### 8.2 启动前端

```bash
streamlit run frontend/app.py
```

### 8.3 冒烟测试（API）

```bash
curl -s http://localhost:8000/api/v1/chat \
  -H "Content-Type: backend/application/json" \
  -d '{"message":"推荐一些科幻电影","session_id":"movie_migrate","agent_type":"hybrid_agent"}' | head
```

---

## 9. 常见问题（迁移失败时优先排查）

1. **回答还出现学生管理内容**  
   - 几乎总是因为 `files/` 里还混有旧文档，或 Neo4j 没清空（未走全量建图）。

2. **英文电影信息抽取效果差**  
   - 当前分块器是 HanLP 中文分词，英文可能走 fallback（按字符切分）。可先增大 `CHUNK_SIZE` 或把电影语料写成“中文描述 + 结构化字段”的形式提升抽取稳定性。

3. **LLM 成本/耗时过高**  
   - 减少 `files/` 文档数量（合并成批量文件）、降低全量数据规模（先跑 50/200），或开启缓存并调小抽取范围。

---

## 10. 下一步（我建议你确认 3 个问题）

1. 你希望电影语料的最终形态是什么：**每部电影一个文件**，还是**每 50 部合并一个文件**？
2. 需要摄入“评分明细”到什么粒度：**全量评分事件**，还是只做 **聚合画像（均分/偏好）**？
3. 是否需要把 `frontend` 的标题、关于说明、示例问题区全部改成“电影推荐系统”口径？

---

## 11. 前端重构（可选但推荐）

如果你计划将当前 Streamlit 前端替换为 React 后台管理控制台，请参考：`docs/前端重构技术文档.md`。
