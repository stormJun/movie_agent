# CacheManager è¿ç§»è®¾è®¡æ–‡æ¡£

## æ–‡æ¡£ä¿¡æ¯

- **é¡¹ç›®**: GraphRAG Agent
- **æ–‡æ¡£ç‰ˆæœ¬**: v2.0 (ä¸€æ¬¡æ€§è¿ç§»æ–¹æ¡ˆ)
- **åˆ›å»ºæ—¥æœŸ**: 2025-01-19
- **ä½œè€…**: System Architect
- **çŠ¶æ€**: è®¾è®¡è¯„å®¡ä¸­

---

## ç›®å½•

- [1. èƒŒæ™¯ä¸åŠ¨æœº](#1-èƒŒæ™¯ä¸åŠ¨æœº)
- [2. å½“å‰æ¶æ„åˆ†æ](#2-å½“å‰æ¶æ„åˆ†æ)
- [3. æ¶æ„é—®é¢˜](#3-æ¶æ„é—®é¢˜)
- [4. ç›®æ ‡æ¶æ„è®¾è®¡](#4-ç›®æ ‡æ¶æ„è®¾è®¡)
- [5. è¯¦ç»†è¿ç§»æ–¹æ¡ˆ](#5-è¯¦ç»†è¿ç§»æ–¹æ¡ˆ)
- [6. æ¥å£è®¾è®¡](#6-æ¥å£è®¾è®¡)
- [7. ä¸€æ¬¡æ€§è¿ç§»å®æ–½è®¡åˆ’](#7-ä¸€æ¬¡æ€§è¿ç§»å®æ–½è®¡åˆ’)
- [8. é£é™©è¯„ä¼°ä¸ç¼“è§£](#8-é£é™©è¯„ä¼°ä¸ç¼“è§£)
- [9. æµ‹è¯•ç­–ç•¥](#9-æµ‹è¯•ç­–ç•¥)
- [10. å›æ»šæ–¹æ¡ˆ](#10-å›æ»šæ–¹æ¡ˆ)

---

## 1. èƒŒæ™¯ä¸åŠ¨æœº

### 1.1 æ ¸å¿ƒé—®é¢˜

å½“å‰ `CacheManager` ä½äº `backend/infrastructure/cache_manager`ï¼Œè¢« RAG å±‚ï¼ˆBaseAgentï¼‰ç›´æ¥ä½¿ç”¨ã€‚è¿™å¯¼è‡´äº†**æ¶æ„èŒè´£æ··æ·†**ï¼š

- âŒ RAG æœåŠ¡è´Ÿè´£æ£€ç´¢å’Œç”Ÿæˆï¼Œä¸åº”è¯¥æ‰¿æ‹…ä¼šè¯ç¼“å­˜èŒè´£
- âŒ ä¼šè¯ç¼“å­˜æ˜¯ Chat å±‚çš„å…³æ³¨ç‚¹ï¼Œåº”è¯¥ç”±åº”ç”¨å±‚ç¼–æ’
- âŒ ç¼“å­˜ç­–ç•¥ä¸ RAG é€»è¾‘è€¦åˆï¼Œè¿åå•ä¸€èŒè´£åŸåˆ™

### 1.2 è¿ç§»ç›®æ ‡

âœ… **æ¶æ„æ¸…æ™°æ€§**: å°†ä¼šè¯ç¼“å­˜ä» RAG å±‚ä¸Šç§»åˆ° Chat å±‚
âœ… **èŒè´£åˆ†ç¦»**: RAG ä¸“æ³¨äºæ£€ç´¢å’Œç”Ÿæˆï¼ŒChat è´Ÿè´£ä¼šè¯ç®¡ç†
âœ… **çµæ´»æ€§æå‡**: æ”¯æŒå¤šç§ç¼“å­˜ç­–ç•¥ï¼ˆæŒ‰ä¼šè¯ã€æŒ‰ç”¨æˆ·ã€å…¨å±€ï¼‰
âœ… **å¯æµ‹è¯•æ€§**: ç¼“å­˜é€»è¾‘ç‹¬ç«‹ï¼Œä¾¿äºå•å…ƒæµ‹è¯•

### 1.3 è¿ç§»ç­–ç•¥

**ä¸€æ¬¡æ€§è¿ç§»**: ç›´æ¥å®Œæˆæ¶æ„é‡æ„ï¼Œä¸å†ä¿ç•™æ—§çš„ç¼“å­˜é€»è¾‘

**ä¼˜åŠ¿**:
- âœ… é¿å…åŒå†™æ¨¡å¼çš„å¤æ‚æ€§å’Œç»´æŠ¤æˆæœ¬
- âœ… ä»£ç æ›´ç®€æ´ï¼Œæ²¡æœ‰å†å²åŒ…è¢±
- âœ… ä¸€æ¬¡æ€§å®Œæˆï¼Œå‡å°‘è¿ç§»å‘¨æœŸ
- âœ… æµ‹è¯•å’ŒéªŒè¯æ›´ç›´æ¥

---

## 2. å½“å‰æ¶æ„åˆ†æ

### 2.1 ç°çŠ¶æ¶æ„å›¾

```mermaid
graph TB
    subgraph "Server Layer"
        API[REST API]
    end

    subgraph "Application Layer"
        Chat[ChatHandler]
    end

    subgraph "Infrastructure Layer"
        Executor[GraphragExecutor]
        RagManager[RagManager]
        Agent[BaseAgent]
        Cache[CacheManager]
    end

    API --> Chat
    Chat --> Executor
    Executor --> RagManager
    RagManager --> Agent
    Agent --> Cache

    style Cache fill:#ffcccc
    style Agent fill:#ffcccc
```

**é—®é¢˜**:
- `BaseAgent` ç›´æ¥ä¾èµ– `CacheManager`
- ç¼“å­˜é€»è¾‘åµŒå…¥åœ¨ Agent å®ç°ä¸­
- Chat å±‚æ— æ³•æ§åˆ¶ç¼“å­˜ç­–ç•¥

### 2.2 ä»£ç ä½ç½®

| ç»„ä»¶ | å½“å‰ä½ç½® | èŒè´£ |
|------|---------|------|
| CacheManager | `backend/infrastructure/cache_manager` | ç¼“å­˜ç®¡ç† |
| BaseAgent | `backend/infrastructure/agents/base.py` | RAG æ£€ç´¢+ç”Ÿæˆ |
| ChatHandler | `backend/application/chat/handlers/chat_handler.py` | ä¼šè¯ç¼–æ’ |
| GraphragExecutor | `backend/infrastructure/rag/adapters/graphrag_executor.py` | RAG æ‰§è¡Œé€‚é…å™¨ |

### 2.3 å½“å‰è°ƒç”¨é“¾

```
HTTP Request
  â†“
ChatHandler.handle()
  â†“
GraphragExecutor.run()
  â†“
RagManager.run_plan_blocking()
  â†“
BaseAgent.ask() / ask_stream()
  â†“
CacheManager.get() / set()  â† ç¼“å­˜é€»è¾‘åœ¨è¿™é‡Œ
```

### 2.4 éœ€è¦ä¿®æ”¹çš„æ–‡ä»¶æ¸…å•

```
éœ€è¦ä¿®æ”¹çš„æ–‡ä»¶:
â”œâ”€â”€ backend/infrastructure/agents/base.py
â”‚   â””â”€â”€ ç§»é™¤ cache_manager åˆå§‹åŒ–å’Œè°ƒç”¨
â”‚
â”œâ”€â”€ backend/infrastructure/rag/adapters/graphrag_executor.py
â”‚   â””â”€â”€ ç®€åŒ–æ‰§è¡Œé€»è¾‘ï¼Œä¸å†å¤„ç†ç¼“å­˜
â”‚
â”œâ”€â”€ backend/application/chat/handlers/chat_handler.py
â”‚   â””â”€â”€ é›†æˆ ConversationCacheService
â”‚
â”œâ”€â”€ backend/server/api/rest/dependencies.py
â”‚   â””â”€â”€ ä¿®æ”¹ä¾èµ–æ³¨å…¥ï¼Œæ·»åŠ  ConversationCacheService
â”‚
â””â”€â”€ backend/server/api/rest/v1/chat.py
    â””â”€â”€ å¯èƒ½éœ€è¦è°ƒæ•´ API å“åº”ç»“æ„

éœ€è¦æ–°å¢çš„æ–‡ä»¶:
â”œâ”€â”€ backend/domain/chat/ports/conversation_cache_port.py
â”œâ”€â”€ backend/application/chat/services/conversation_cache_service.py
â””â”€â”€ backend/infrastructure/providers/cache/cache_manager_provider.py
```

---

## 3. æ¶æ„é—®é¢˜

### 3.1 èŒè´£æ··æ·†

```python
# backend/infrastructure/agents/base.py (å½“å‰)
class BaseAgent:
    def __init__(self):
        # âŒ Agent ä¸åº”è¯¥ç®¡ç†ç¼“å­˜
        self.cache_manager = CacheManager(
            key_strategy=ContextAwareCacheKeyStrategy(),
            storage_backend=HybridCacheBackend(...)
        )

    def ask(self, query: str, thread_id: str):
        # âŒ ç¼“å­˜é€»è¾‘ä¸ä¸šåŠ¡é€»è¾‘æ··åˆ
        cached = self.cache_manager.get(query, thread_id=thread_id)
        if cached:
            return cached

        result = self._execute_search(query)
        self.cache_manager.set(query, result, thread_id=thread_id)
        return result
```

**é—®é¢˜**:
- Agent æ˜¯ RAG æ‰§è¡Œå•å…ƒï¼Œä¸åº”è¯¥æ‰¿æ‹…ä¼šè¯ç®¡ç†èŒè´£
- ç¼“å­˜ç­–ç•¥ï¼ˆä¸Šä¸‹æ–‡çª—å£ã€éš”ç¦»çº§åˆ«ï¼‰åº”è¯¥æ˜¯ Chat å±‚çš„å†³å®š

### 3.2 çµæ´»æ€§ä¸è¶³

```python
# å½“å‰æ— æ³•åœ¨ Chat å±‚æ§åˆ¶ç¼“å­˜ç­–ç•¥
class ChatHandler:
    async def handle(self, message: str, session_id: str):
        # âŒ æ— æ³•æŒ‡å®šç¼“å­˜ç­–ç•¥
        # âŒ æ— æ³•æ§åˆ¶ç¼“å­˜é”®ç”Ÿæˆ
        # âŒ æ— æ³•é€‰æ‹©ç¼“å­˜å­˜å‚¨åç«¯
        result = await self._executor.run(...)
```

### 3.3 å¯æµ‹è¯•æ€§å·®

- æµ‹è¯• Agent æ—¶å¿…é¡» Mock CacheManager
- æ— æ³•ç‹¬ç«‹æµ‹è¯•ç¼“å­˜é€»è¾‘
- é›†æˆæµ‹è¯•å¤æ‚åº¦é«˜

---

## 4. ç›®æ ‡æ¶æ„è®¾è®¡

### 4.1 æ–°æ¶æ„å›¾

```mermaid
graph TB
    subgraph "Server Layer"
        API[REST API]
    end

    subgraph "Application Layer"
        Chat[ChatHandler]
        CacheService[ConversationCacheService]
    end

    subgraph "Domain Layer"
        CachePort[ConversationCachePort]
    end

    subgraph "Infrastructure Layer"
        Executor[GraphragExecutor]
        RagManager[RagManager]
        Agent[BaseAgent]
        CacheImpl[CacheManager]
    end

    API --> Chat
    Chat --> CacheService
    Chat --> Executor
    CacheService --> CachePort
    Executor --> RagManager
    RagManager --> Agent

    CacheImpl -.implements.-> CachePort

    style CacheService fill:#90EE90
    style CachePort fill:#87CEEB
    style CacheImpl fill:#DDA0DD
    style Agent fill:#ffffff
```

### 4.2 æ¶æ„åˆ†å±‚

| å±‚çº§ | èŒè´£ | ç»„ä»¶ |
|------|------|------|
| **Application** | ä¼šè¯ç¼–æ’ã€ç¼“å­˜ç­–ç•¥å†³ç­– | `ConversationCacheService` |
| **Domain** | ç¼“å­˜æ¥å£å®šä¹‰ | `ConversationCachePort` |
| **Infrastructure** | ç¼“å­˜å®ç°ã€RAG æ‰§è¡Œ | `CacheManager`, `BaseAgent` |

### 4.3 æ–°çš„è°ƒç”¨é“¾

```
HTTP Request
  â†“
ChatHandler.handle()
  â†“
ConversationCacheService.execute_with_cache()  â† ç¼“å­˜é€»è¾‘ä¸Šç§»åˆ°è¿™é‡Œ
  â”œâ”€ CacheManager.get()  (å°è¯•å‘½ä¸­ç¼“å­˜)
  â””â”€ GraphragExecutor.run()  (ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œ RAG)
       â†“
  BaseAgent.ask()  (ä¸“æ³¨äº RAGï¼Œä¸å†ç®¡ç†ç¼“å­˜)
  â†“
è¿”å›ç»“æœ
```

---

## 5. è¯¦ç»†è¿ç§»æ–¹æ¡ˆ

### 5.1 è¿ç§»ç­–ç•¥ï¼šä¸€æ¬¡æ€§é‡æ„

**æ ¸å¿ƒåŸåˆ™**ï¼š
1. **ç›´æ¥æ›¿æ¢**ï¼šä¸ä¿ç•™æ—§çš„ç¼“å­˜é€»è¾‘ï¼Œç›´æ¥å®Œæˆæ¶æ„é‡æ„
2. **æµ‹è¯•å…ˆè¡Œ**ï¼šåœ¨è¿ç§»å‰å®Œæˆå……åˆ†çš„æµ‹è¯•
3. **å¿«é€Ÿå›æ»š**ï¼šå¦‚æœå‡ºç°é—®é¢˜ï¼Œå¯ä»¥å¿«é€Ÿå›æ»šåˆ°æ—§ç‰ˆæœ¬
4. **å……åˆ†éªŒè¯**ï¼šåœ¨æµ‹è¯•ç¯å¢ƒå®Œæ•´éªŒè¯åå†éƒ¨ç½²åˆ°ç”Ÿäº§

### 5.2 ç›®å½•ç»“æ„å˜åŒ–

```
backend/
â”œâ”€â”€ application/
â”‚   â””â”€â”€ chat/
â”‚       â”œâ”€â”€ services/
â”‚       â”‚   â””â”€â”€ conversation_cache_service.py  â† æ–°å¢
â”‚       â””â”€â”€ handlers/
â”‚           â””â”€â”€ chat_handler.py  â† ä¿®æ”¹
â”œâ”€â”€ domain/
â”‚   â””â”€â”€ chat/
â”‚       â”œâ”€â”€ ports/
â”‚       â”‚   â””â”€â”€ conversation_cache_port.py  â† æ–°å¢
â”‚       â””â”€â”€ services/
â”‚           â””â”€â”€ rag_aggregator.py  â† ä¿æŒä¸å˜
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ cache_manager/  â† ä¿ç•™ï¼ˆä½œä¸ºå®ç°ï¼‰
â”‚   â”‚   â”œâ”€â”€ manager.py
â”‚   â”‚   â”œâ”€â”€ strategies/
â”‚   â”‚   â”œâ”€â”€ backends/
â”‚   â”‚   â””â”€â”€ models/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â””â”€â”€ base.py  â† ç§»é™¤ç¼“å­˜é€»è¾‘
â”‚   â””â”€â”€ providers/
â”‚       â””â”€â”€ cache/
â”‚           â””â”€â”€ cache_manager_provider.py  â† æ–°å¢é€‚é…å™¨
```

### 5.3 ä»£ç å˜æ›´æ¦‚è§ˆ

#### 5.3.1 BaseAgent ç®€åŒ–

```python
# Before: backend/infrastructure/agents/base.py
class BaseAgent:
    def __init__(self):
        # âŒ ç§»é™¤è¿™äº›
        self.cache_manager = CacheManager(...)
        self.global_cache_manager = CacheManager(...)

    def ask(self, query: str, thread_id: str):
        # âŒ ç§»é™¤è¿™äº›
        cached = self.cache_manager.get(query, thread_id=thread_id)
        if cached:
            return cached

        result = self._execute_search(query)
        self.cache_manager.set(query, result, thread_id=thread_id)
        return result

# After: backend/infrastructure/agents/base.py
class BaseAgent:
    def __init__(self):
        # âœ… åªä¿ç•™ RAG ç›¸å…³çš„åˆå§‹åŒ–
        self.llm = get_llm_model()
        self.embeddings = get_embeddings_model()
        # ... å…¶ä»– RAG ç›¸å…³é…ç½®

    def ask(self, query: str, thread_id: str):
        # âœ… ä¸“æ³¨äº RAG æ‰§è¡Œ
        result = self._execute_search(query)
        return result
```

#### 5.3.2 ChatHandler é›†æˆç¼“å­˜æœåŠ¡

```python
# Before: backend/application/chat/handlers/chat_handler.py
class ChatHandler:
    def __init__(self, executor: RAGExecutorPort, ...):
        self._executor = executor

    async def handle(self, message: str, session_id: str, ...):
        # âŒ ç›´æ¥è°ƒç”¨ executorï¼Œæ²¡æœ‰ç¼“å­˜æ§åˆ¶
        result = await self._executor.run(...)
        return result

# After: backend/application/chat/handlers/chat_handler.py
class ChatHandler:
    def __init__(
        self,
        cache_service: ConversationCacheService,  # â† æ–°å¢
        executor: RAGExecutorPort,
        ...
    ):
        self._cache_service = cache_service
        self._executor = executor

    async def handle(self, message: str, session_id: str, ...):
        # âœ… é€šè¿‡ç¼“å­˜æœåŠ¡æ‰§è¡Œ
        result = await self._cache_service.execute_with_cache(
            message=message,
            session_id=session_id,
            kb_prefix=kb_prefix,
            agent_type=agent_type,
        )
        return result
```

---

## 6. æ¥å£è®¾è®¡

### 6.1 Domain Layer: Port å®šä¹‰

**æ–‡ä»¶**: `backend/domain/chat/ports/conversation_cache_port.py`

```python
"""
ä¼šè¯ç¼“å­˜æ¥å£å®šä¹‰

ä½ç½®ï¼šbackend/domain/chat/ports/conversation_cache_port.py

èŒè´£ï¼š
- å®šä¹‰ç¼“å­˜èƒ½åŠ›çš„æŠ½è±¡æ¥å£
- ç”± Domain å±‚å®šä¹‰ï¼ŒApplication å±‚ä½¿ç”¨
- Infrastructure å±‚æä¾›å…·ä½“å®ç°
"""
from __future__ import annotations
from typing import Protocol, Any, Optional
from dataclasses import dataclass


@dataclass(frozen=True)
class CacheEntry:
    """ç¼“å­˜æ¡ç›®"""
    content: Any
    metadata: dict[str, Any]
    created_at: float
    access_count: int
    quality_score: int


class ConversationCachePort(Protocol):
    """
    ä¼šè¯ç¼“å­˜æ¥å£

    è®¾è®¡åŸåˆ™ï¼š
    1. æ¥å£æœ€å°åŒ–ï¼šåªæä¾›å¿…è¦çš„æ–¹æ³•
    2. è¯­ä¹‰æ¸…æ™°ï¼šæ–¹æ³•ååæ˜ æ„å›¾
    3. æ‰©å±•å‹å¥½ï¼šæ”¯æŒæœªæ¥åŠŸèƒ½æ‰©å±•
    """

    async def get(
        self,
        *,
        session_id: str,
        query: str,
        agent_type: str = "default",
    ) -> Optional[CacheEntry]:
        """
        è·å–ç¼“å­˜å†…å®¹

        Args:
            session_id: ä¼šè¯ ID
            query: ç”¨æˆ·æŸ¥è¯¢
            agent_type: Agent ç±»å‹ï¼ˆç”¨äºåŒºåˆ†ä¸åŒçš„ç¼“å­˜ç­–ç•¥ï¼‰

        Returns:
            ç¼“å­˜æ¡ç›®ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å› None
        """
        ...

    async def set(
        self,
        *,
        session_id: str,
        query: str,
        content: Any,
        agent_type: str = "default",
        metadata: Optional[dict[str, Any]] = None,
    ) -> None:
        """
        è®¾ç½®ç¼“å­˜å†…å®¹

        Args:
            session_id: ä¼šè¯ ID
            query: ç”¨æˆ·æŸ¥è¯¢
            content: ç¼“å­˜å†…å®¹
            agent_type: Agent ç±»å‹
            metadata: é¢å¤–å…ƒæ•°æ®
        """
        ...

    async def invalidate(
        self,
        *,
        session_id: str,
        query: Optional[str] = None,
    ) -> None:
        """
        ä½¿ç¼“å­˜å¤±æ•ˆ

        Args:
            session_id: ä¼šè¯ ID
            query: ç‰¹å®šæŸ¥è¯¢ï¼ˆå¦‚æœä¸º Noneï¼Œåˆ™æ¸…é™¤æ•´ä¸ªä¼šè¯çš„ç¼“å­˜ï¼‰
        """
        ...

    async def mark_quality(
        self,
        *,
        session_id: str,
        query: str,
        is_positive: bool,
        agent_type: str = "default",
    ) -> None:
        """
        æ ‡è®°ç¼“å­˜è´¨é‡

        Args:
            session_id: ä¼šè¯ ID
            query: ç”¨æˆ·æŸ¥è¯¢
            is_positive: æ˜¯å¦æ­£å‘åé¦ˆ
            agent_type: Agent ç±»å‹
        """
        ...

    async def get_metrics(
        self,
        *,
        session_id: Optional[str] = None,
    ) -> dict[str, Any]:
        """
        è·å–ç¼“å­˜æ€§èƒ½æŒ‡æ ‡

        Args:
            session_id: ä¼šè¯ IDï¼ˆå¦‚æœä¸º Noneï¼Œè¿”å›å…¨å±€æŒ‡æ ‡ï¼‰

        Returns:
            æ€§èƒ½æŒ‡æ ‡å­—å…¸
        """
        ...
```

### 6.2 Application Layer: Service å®ç°

**æ–‡ä»¶**: `backend/application/chat/services/conversation_cache_service.py`

```python
"""
ä¼šè¯ç¼“å­˜æœåŠ¡

ä½ç½®ï¼šbackend/application/chat/services/conversation_cache_service.py

èŒè´£ï¼š
- å®ç°ä¼šè¯çº§åˆ«çš„ç¼“å­˜ç­–ç•¥
- åè°ƒ RAG æ‰§è¡Œå’Œç¼“å­˜å‘½ä¸­
- æä¾›ç¼“å­˜ç»Ÿè®¡å’Œç›‘æ§
"""
from __future__ import annotations
import logging
from typing import Any, Optional
from datetime import datetime

from domain.chat.ports.conversation_cache_port import (
    ConversationCachePort,
    CacheEntry,
)
from application.ports.rag_executor_port import RAGExecutorPort


logger = logging.getLogger(__name__)


class ConversationCacheService:
    """
    ä¼šè¯ç¼“å­˜æœåŠ¡

    è®¾è®¡åŸåˆ™ï¼š
    1. ç¼“å­˜ç­–ç•¥é›†ä¸­ç®¡ç†
    2. æ”¯æŒå¤šç§ç¼“å­˜æ¨¡å¼
    3. æä¾›å®Œæ•´çš„ç›‘æ§èƒ½åŠ›
    """

    def __init__(
        self,
        cache_port: ConversationCachePort,
        executor: RAGExecutorPort,
        *,
        enable_cache: bool = True,
    ):
        """
        åˆå§‹åŒ–ç¼“å­˜æœåŠ¡

        Args:
            cache_port: ç¼“å­˜ç«¯å£å®ç°
            executor: RAG æ‰§è¡Œå™¨
            enable_cache: æ˜¯å¦å¯ç”¨ç¼“å­˜
        """
        self._cache = cache_port
        self._executor = executor
        self._enable_cache = enable_cache

    async def execute_with_cache(
        self,
        *,
        message: str,
        session_id: str,
        kb_prefix: str,
        agent_type: str = "hybrid_agent",
        debug: bool = False,
    ) -> dict[str, Any]:
        """
        æ‰§è¡ŒæŸ¥è¯¢ï¼ˆå¸¦ç¼“å­˜ï¼‰

        è¿™æ˜¯ç¼“å­˜æœåŠ¡çš„æ ¸å¿ƒæ–¹æ³•ï¼Œå°è£…äº†"å…ˆæŸ¥ç¼“å­˜ï¼Œæœªå‘½ä¸­åˆ™æ‰§è¡Œ"çš„é€»è¾‘

        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            session_id: ä¼šè¯ ID
            kb_prefix: çŸ¥è¯†åº“å‰ç¼€
            agent_type: Agent ç±»å‹
            debug: è°ƒè¯•æ¨¡å¼

        Returns:
            æ‰§è¡Œç»“æœå­—å…¸
        """
        # å¦‚æœç¦ç”¨ç¼“å­˜ï¼Œç›´æ¥æ‰§è¡Œ
        if not self._enable_cache:
            return await self._execute_rag(
                message=message,
                session_id=session_id,
                kb_prefix=kb_prefix,
                agent_type=agent_type,
                debug=debug,
            )

        # å°è¯•ä»ç¼“å­˜è·å–
        cached_entry = await self._cache.get(
            session_id=session_id,
            query=message,
            agent_type=agent_type,
        )

        if cached_entry is not None:
            logger.info(
                f"Cache hit for session={session_id}, query={message[:50]}"
            )
            return cached_entry.content

        # ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œ RAG
        logger.info(
            f"Cache miss for session={session_id}, query={message[:50]}"
        )
        result = await self._execute_rag(
            message=message,
            session_id=session_id,
            kb_prefix=kb_prefix,
            agent_type=agent_type,
            debug=debug,
        )

        # å†™å…¥ç¼“å­˜
        await self._cache.set(
            session_id=session_id,
            query=message,
            content=result,
            agent_type=agent_type,
            metadata={
                "kb_prefix": kb_prefix,
                "cached_at": datetime.now().isoformat(),
            },
        )

        return result

    async def _execute_rag(
        self,
        *,
        message: str,
        session_id: str,
        kb_prefix: str,
        agent_type: str,
        debug: bool,
    ) -> dict[str, Any]:
        """
        æ‰§è¡Œ RAG æŸ¥è¯¢

        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            session_id: ä¼šè¯ ID
            kb_prefix: çŸ¥è¯†åº“å‰ç¼€
            agent_type: Agent ç±»å‹
            debug: è°ƒè¯•æ¨¡å¼

        Returns:
            RAG æ‰§è¡Œç»“æœ
        """
        from domain.chat.entities.rag_run import RagRunSpec

        plan = [
            RagRunSpec(
                agent_type=agent_type,
                worker_name=None,
            )
        ]

        aggregated, runs = await self._executor.run(
            plan=plan,
            message=message,
            session_id=session_id,
            kb_prefix=kb_prefix,
            debug=debug,
        )

        result: dict[str, Any] = {"answer": aggregated.answer}
        if aggregated.reference:
            result["reference"] = aggregated.reference
        if aggregated.retrieval_results is not None:
            result["retrieval_results"] = aggregated.retrieval_results

        return result

    async def mark_feedback(
        self,
        *,
        session_id: str,
        query: str,
        is_positive: bool,
        agent_type: str = "default",
    ) -> None:
        """
        æ ‡è®°ç”¨æˆ·åé¦ˆ

        Args:
            session_id: ä¼šè¯ ID
            query: ç”¨æˆ·æŸ¥è¯¢
            is_positive: æ˜¯å¦æ­£å‘åé¦ˆ
            agent_type: Agent ç±»å‹
        """
        await self._cache.mark_quality(
            session_id=session_id,
            query=query,
            is_positive=is_positive,
            agent_type=agent_type,
        )

    async def clear_cache(
        self,
        *,
        session_id: str,
        query: Optional[str] = None,
    ) -> None:
        """
        æ¸…é™¤ç¼“å­˜

        Args:
            session_id: ä¼šè¯ ID
            query: ç‰¹å®šæŸ¥è¯¢ï¼ˆå¦‚æœä¸º Noneï¼Œæ¸…é™¤æ•´ä¸ªä¼šè¯ï¼‰
        """
        await self._cache.invalidate(session_id=session_id, query=query)

    async def get_cache_metrics(
        self,
        *,
        session_id: Optional[str] = None,
    ) -> dict[str, Any]:
        """
        è·å–ç¼“å­˜æŒ‡æ ‡

        Args:
            session_id: ä¼šè¯ IDï¼ˆå¦‚æœä¸º Noneï¼Œè¿”å›å…¨å±€æŒ‡æ ‡ï¼‰

        Returns:
            ç¼“å­˜æ€§èƒ½æŒ‡æ ‡
        """
        return await self._cache.get_metrics(session_id=session_id)
```

### 6.3 Infrastructure Layer: é€‚é…å™¨å®ç°

**æ–‡ä»¶**: `backend/infrastructure/providers/cache/cache_manager_provider.py`

```python
"""
CacheManager é€‚é…å™¨

ä½ç½®ï¼šbackend/infrastructure/providers/cache/cache_manager_provider.py

èŒè´£ï¼š
- å°†ç°æœ‰çš„ CacheManager é€‚é…åˆ° ConversationCachePort æ¥å£
- å¤„ç†åŒæ­¥/å¼‚æ­¥è½¬æ¢
- ç»´æŠ¤å‘åå…¼å®¹æ€§
"""
from __future__ import annotations
import asyncio
from typing import Any, Optional
from datetime import datetime

from domain.chat.ports.conversation_cache_port import (
    ConversationCachePort,
    CacheEntry,
)
from infrastructure.cache_manager import CacheManager
from infrastructure.cache_manager.strategies import (
    ContextAwareCacheKeyStrategy,
    GlobalCacheKeyStrategy,
)
from infrastructure.cache_manager.backends import HybridCacheBackend


class CacheManagerProvider(ConversationCachePort):
    """
    CacheManager é€‚é…å™¨

    å°†ç°æœ‰çš„åŒæ­¥ CacheManager é€‚é…åˆ°å¼‚æ­¥ ConversationCachePort æ¥å£
    """

    def __init__(
        self,
        cache_dir: str = "./cache",
        memory_max_size: int = 200,
        disk_max_size: int = 2000,
    ):
        """
        åˆå§‹åŒ–é€‚é…å™¨

        Args:
            cache_dir: ç¼“å­˜ç›®å½•
            memory_max_size: å†…å­˜ç¼“å­˜æœ€å¤§æ•°é‡
            disk_max_size: ç£ç›˜ç¼“å­˜æœ€å¤§æ•°é‡
        """
        # ä¼šè¯ç¼“å­˜ï¼šä¸Šä¸‹æ–‡æ„ŸçŸ¥
        self._session_cache = CacheManager(
            key_strategy=ContextAwareCacheKeyStrategy(context_window=3),
            storage_backend=HybridCacheBackend(
                cache_dir=f"{cache_dir}/sessions",
                memory_max_size=memory_max_size,
                disk_max_size=disk_max_size,
            ),
        )

        # å…¨å±€ç¼“å­˜ï¼šè·¨ä¼šè¯å…±äº«
        self._global_cache = CacheManager(
            key_strategy=GlobalCacheKeyStrategy(),
            storage_backend=HybridCacheBackend(
                cache_dir=f"{cache_dir}/global",
                memory_max_size=memory_max_size * 2,
                disk_max_size=disk_max_size * 2,
            ),
        )

    async def get(
        self,
        *,
        session_id: str,
        query: str,
        agent_type: str = "default",
    ) -> Optional[CacheEntry]:
        """
        è·å–ç¼“å­˜ï¼ˆå¼‚æ­¥åŒ…è£…ï¼‰
        """
        # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒåŒæ­¥æ–¹æ³•
        loop = asyncio.get_event_loop()
        cached = await loop.run_in_executor(
            None,
            lambda: self._session_cache.get(
                query=query,
                thread_id=session_id,
            ),
        )

        if cached is None:
            return None

        # è½¬æ¢ä¸º CacheEntry
        return self._to_cache_entry(cached)

    async def set(
        self,
        *,
        session_id: str,
        query: str,
        content: Any,
        agent_type: str = "default",
        metadata: Optional[dict[str, Any]] = None,
    ) -> None:
        """
        è®¾ç½®ç¼“å­˜ï¼ˆå¼‚æ­¥åŒ…è£…ï¼‰
        """
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(
            None,
            lambda: self._session_cache.set(
                query=query,
                result=content,
                thread_id=session_id,
            ),
        )

    async def invalidate(
        self,
        *,
        session_id: str,
        query: Optional[str] = None,
    ) -> None:
        """
        ä½¿ç¼“å­˜å¤±æ•ˆ
        """
        loop = asyncio.get_event_loop()

        if query is None:
            # æ¸…é™¤æ•´ä¸ªä¼šè¯çš„ç¼“å­˜ï¼ˆéœ€è¦éå†ï¼‰
            # TODO: å®ç°æŒ‰ä¼šè¯æ¸…é™¤çš„é€»è¾‘
            pass
        else:
            await loop.run_in_executor(
                None,
                lambda: self._session_cache.delete(
                    query=query,
                    thread_id=session_id,
                ),
            )

    async def mark_quality(
        self,
        *,
        session_id: str,
        query: str,
        is_positive: bool,
        agent_type: str = "default",
    ) -> None:
        """
        æ ‡è®°ç¼“å­˜è´¨é‡
        """
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(
            None,
            lambda: self._session_cache.mark_quality(
                query=query,
                is_positive=is_positive,
                thread_id=session_id,
            ),
        )

    async def get_metrics(
        self,
        *,
        session_id: Optional[str] = None,
    ) -> dict[str, Any]:
        """
        è·å–ç¼“å­˜æŒ‡æ ‡
        """
        metrics = self._session_cache.get_metrics()
        return {
            "hit_rate": metrics.get("exact_hit_rate", 0.0),
            "total_queries": metrics.get("total_queries", 0),
            "exact_hits": metrics.get("exact_hits", 0),
            "misses": metrics.get("misses", 0),
        }

    def _to_cache_entry(self, cached: Any) -> CacheEntry:
        """
        å°†ç¼“å­˜å†…å®¹è½¬æ¢ä¸º CacheEntry
        """
        from infrastructure.cache_manager import CacheItem

        if isinstance(cached, CacheItem):
            return CacheEntry(
                content=cached.get_content(),
                metadata=cached.metadata,
                created_at=cached.metadata.get("created_at", 0),
                access_count=cached.metadata.get("access_count", 0),
                quality_score=cached.metadata.get("quality_score", 0),
            )

        # ç®€å•ç±»å‹
        return CacheEntry(
            content=cached,
            metadata={},
            created_at=0,
            access_count=0,
            quality_score=0,
        )
```

---

## 7. ä¸€æ¬¡æ€§è¿ç§»å®æ–½è®¡åˆ’

### 7.1 æ€»ä½“æ—¶é—´å®‰æ’

**é¢„è®¡æ€»æ—¶é—´**: 5 ä¸ªå·¥ä½œæ—¥

| é˜¶æ®µ | å·¥ä½œå†…å®¹ | é¢„è®¡æ—¶é—´ | è´£ä»»äºº |
|------|---------|---------|--------|
| **å‡†å¤‡é˜¶æ®µ** | ä»£ç å¤‡ä»½ã€ç¯å¢ƒå‡†å¤‡ | 0.5 å¤© | DevOps + å¼€å‘ |
| **å¼€å‘é˜¶æ®µ** | æ–°åŠŸèƒ½å¼€å‘ã€æ—§ä»£ç ç§»é™¤ | 2 å¤© | å¼€å‘ |
| **æµ‹è¯•é˜¶æ®µ** | å•å…ƒæµ‹è¯•ã€é›†æˆæµ‹è¯• | 1.5 å¤© | å¼€å‘ + QA |
| **éƒ¨ç½²é˜¶æ®µ** | éƒ¨ç½²åˆ°ç”Ÿäº§ã€ç›‘æ§éªŒè¯ | 1 å¤© | DevOps + å¼€å‘ |

### 7.2 è¯¦ç»†æ­¥éª¤

#### Day 1 ä¸Šåˆï¼šå‡†å¤‡é˜¶æ®µ

**ç›®æ ‡**: ç¡®ä¿å¯ä»¥å¿«é€Ÿå›æ»š

- [ ] **ä»£ç å¤‡ä»½**
  ```bash
  # åˆ›å»ºå¤‡ä»½åˆ†æ”¯
  git checkout -b backup/before-cache-migration
  git push origin backup/before-cache-migration

  # åˆ›å»ºè¿ç§»åˆ†æ”¯
  git checkout -b feature/cache-migration
  ```

- [ ] **æ•°æ®åº“å¤‡ä»½**ï¼ˆå¦‚æœç¼“å­˜ä½¿ç”¨æ•°æ®åº“ï¼‰
  ```bash
  # å¤‡ä»½ç¼“å­˜æ•°æ®
  cp -r ./cache ./cache.backup.$(date +%Y%m%d)
  ```

- [ ] **ç¯å¢ƒå‡†å¤‡**
  - ç¡®è®¤æµ‹è¯•ç¯å¢ƒå¯ç”¨
  - å‡†å¤‡ç›‘æ§å’Œæ—¥å¿—ç³»ç»Ÿ
  - å‡†å¤‡å›æ»šè„šæœ¬

#### Day 1 ä¸‹åˆ - Day 2ï¼šå¼€å‘é˜¶æ®µ

**ç›®æ ‡**: å®Œæˆæ‰€æœ‰ä»£ç å˜æ›´

**Day 1 ä¸‹åˆ**:

- [ ] **åˆ›å»ºæ–°æ–‡ä»¶** (2 å°æ—¶)
  - [ ] `domain/chat/ports/conversation_cache_port.py`
  - [ ] `application/chat/services/conversation_cache_service.py`
  - [ ] `infrastructure/providers/cache/cache_manager_provider.py`

- [ ] **ä¿®æ”¹ç°æœ‰æ–‡ä»¶** (2 å°æ—¶)
  - [ ] `infrastructure/agents/base.py` - ç§»é™¤ç¼“å­˜é€»è¾‘
  - [ ] `application/chat/handlers/chat_handler.py` - é›†æˆç¼“å­˜æœåŠ¡
  - [ ] `server/api/rest/dependencies.py` - ä¿®æ”¹ä¾èµ–æ³¨å…¥

**Day 2**:

- [ ] **å®Œæˆä¾èµ–æ³¨å…¥è°ƒæ•´** (1 å°æ—¶)
  - [ ] ä¿®æ”¹ `get_chat_handler()` ä¾èµ–æ³¨å…¥
  - [ ] æ·»åŠ  `get_cache_service()` å‡½æ•°

- [ ] **ä»£ç è‡ªæµ‹** (2 å°æ—¶)
  - [ ] æœ¬åœ°è¿è¡Œï¼Œç¡®ä¿æ²¡æœ‰è¯­æ³•é”™è¯¯
  - [ ] æ‰‹åŠ¨æµ‹è¯•åŸºæœ¬åŠŸèƒ½

- [ ] **ä»£ç è¯„å®¡** (3 å°æ—¶)
  - [ ] æäº¤ Pull Request
  - [ ] å›¢é˜Ÿè¯„å®¡
  - [ ] æ ¹æ®åé¦ˆä¿®æ”¹

#### Day 3ï¼šæµ‹è¯•é˜¶æ®µ

**ç›®æ ‡**: å®Œæˆå®Œæ•´çš„æµ‹è¯•éªŒè¯

**ä¸Šåˆ**: å•å…ƒæµ‹è¯•

- [ ] **Port æ¥å£æµ‹è¯•** (1 å°æ—¶)
  ```python
  # tests/domain/chat/ports/test_conversation_cache_port.py
  - test_cache_miss
  - test_cache_set_and_get
  - test_cache_invalidation
  ```

- [ ] **Service é€»è¾‘æµ‹è¯•** (2 å°æ—¶)
  ```python
  # tests/application/chat/services/test_conversation_cache_service.py
  - test_cache_hit
  - test_cache_miss
  - test_cache_disabled
  - test_mark_feedback
  ```

- [ ] **Provider é€‚é…å™¨æµ‹è¯•** (1 å°æ—¶)
  ```python
  # tests/infrastructure/providers/cache/test_cache_manager_provider.py
  - test_async_wrapper
  - test_cache_entry_conversion
  - test_metrics
  ```

**ä¸‹åˆ**: é›†æˆæµ‹è¯•å’Œæ€§èƒ½æµ‹è¯•

- [ ] **é›†æˆæµ‹è¯•** (2 å°æ—¶)
  ```python
  # tests/integration/test_cache_integration.py
  - test_end_to_end_cache_flow
  - test_multi_session_isolation
  - test_cache_persistence
  ```

- [ ] **æ€§èƒ½æµ‹è¯•** (1 å°æ—¶)
  ```python
  # tests/performance/test_cache_performance.py
  - test_cache_hit_latency
  - test_cache_miss_latency
  - test_concurrent_access
  ```

- [ ] **å›å½’æµ‹è¯•** (1 å°æ—¶)
  - è¿è¡Œç°æœ‰æµ‹è¯•å¥—ä»¶
  - ç¡®ä¿æ²¡æœ‰åŠŸèƒ½å›å½’

#### Day 4ï¼šæµ‹è¯•ç¯å¢ƒéªŒè¯

**ç›®æ ‡**: åœ¨æµ‹è¯•ç¯å¢ƒå®Œæ•´éªŒè¯

**ä¸Šåˆ**: éƒ¨ç½²åˆ°æµ‹è¯•ç¯å¢ƒ

- [ ] **éƒ¨ç½²** (1 å°æ—¶)
  ```bash
  # éƒ¨ç½²åˆ°æµ‹è¯•ç¯å¢ƒ
  kubectl apply -f k8s/test/
  # æˆ–
  docker-compose -f docker-compose.test.yml up -d
  ```

- [ ] **å†’çƒŸæµ‹è¯•** (1 å°æ—¶)
  - æµ‹è¯•åŸºæœ¬èŠå¤©åŠŸèƒ½
  - æµ‹è¯•ç¼“å­˜å‘½ä¸­åœºæ™¯
  - æµ‹è¯•ç¼“å­˜æœªå‘½ä¸­åœºæ™¯

**ä¸‹åˆ**: å®Œæ•´åŠŸèƒ½æµ‹è¯•

- [ ] **åŠŸèƒ½æµ‹è¯•** (3 å°æ—¶)
  - å¤šè½®å¯¹è¯æµ‹è¯•
  - ä¸åŒ agent_type æµ‹è¯•
  - ä¸åŒ kb_prefix æµ‹è¯•
  - ä¼šè¯éš”ç¦»éªŒè¯

- [ ] **æ€§èƒ½éªŒè¯** (2 å°æ—¶)
  - å‹åŠ›æµ‹è¯•ï¼ˆ100 å¹¶å‘ï¼‰
  - ç¼“å­˜å‘½ä¸­ç‡éªŒè¯
  - å“åº”æ—¶é—´å¯¹æ¯”

- [ ] **ç›‘æ§éªŒè¯** (1 å°æ—¶)
  - ç¡®è®¤ç›‘æ§æŒ‡æ ‡æ­£å¸¸ä¸ŠæŠ¥
  - ç¡®è®¤æ—¥å¿—æ­£å¸¸è¾“å‡º
  - ç¡®è®¤å‘Šè­¦è§„åˆ™ç”Ÿæ•ˆ

#### Day 5ï¼šç”Ÿäº§éƒ¨ç½²

**ç›®æ ‡**: éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒå¹¶ç›‘æ§

**ä¸Šåˆ**: éƒ¨ç½²

- [ ] **ç”Ÿäº§éƒ¨ç½²** (1 å°æ—¶)
  ```bash
  # è“ç»¿éƒ¨ç½²æˆ–æ»šåŠ¨æ›´æ–°
  kubectl apply -f k8s/production/
  ```

- [ ] **å¥åº·æ£€æŸ¥** (0.5 å°æ—¶)
  - æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€
  - æ£€æŸ¥åŸºç¡€æŒ‡æ ‡
  - æ£€æŸ¥é”™è¯¯æ—¥å¿—

**ä¸‹åˆ**: ç›‘æ§ä¸éªŒè¯

- [ ] **å®æ—¶ç›‘æ§** (2 å°æ—¶)
  - ç›‘æ§ç¼“å­˜å‘½ä¸­ç‡
  - ç›‘æ§å“åº”æ—¶é—´ï¼ˆP50, P95, P99ï¼‰
  - ç›‘æ§é”™è¯¯ç‡
  - ç›‘æ§ç³»ç»Ÿèµ„æºï¼ˆCPU, å†…å­˜ï¼‰

- [ ] **åŠŸèƒ½éªŒè¯** (2 å°æ—¶)
  - æ‰§è¡Œå…³é”®ç”¨æˆ·åœºæ™¯
  - éªŒè¯å¤šç”¨æˆ·å¹¶å‘
  - éªŒè¯ç¼“å­˜æŒä¹…åŒ–

- [ ] **é—®é¢˜å¤„ç†** (2 å°æ—¶)
  - å¤„ç†å¯èƒ½å‡ºç°çš„é—®é¢˜
  - å¿…è¦æ—¶æ‰§è¡Œå›æ»š

- [ ] **æ€»ç»“ä¸æ–‡æ¡£** (1 å°æ—¶)
  - è®°å½•éƒ¨ç½²è¿‡ç¨‹
  - æ›´æ–°è¿è¡Œæ–‡æ¡£
  - æ€»ç»“ç»éªŒæ•™è®­

### 7.3 æ¯æ—¥æ£€æŸ¥æ¸…å•

**æ¯æ—¥ç»“æŸæ—¶**:
- [ ] ä»£ç å·²æäº¤åˆ° Git
- [ ] æµ‹è¯•å·²é€šè¿‡
- [ ] æ–‡æ¡£å·²æ›´æ–°
- [ ] æ˜æ—¥è®¡åˆ’å·²ç¡®è®¤

**æ¯æ—¥å¼€å§‹æ—¶**:
- [ ] æŸ¥çœ‹æ˜¨æ™šæ„å»ºå’Œæµ‹è¯•ç»“æœ
- [ ] æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„é—®é¢˜
- [ ] ç¡®è®¤ä»Šæ—¥å·¥ä½œé‡ç‚¹

---

## 8. é£é™©è¯„ä¼°ä¸ç¼“è§£

### 8.1 é£é™©çŸ©é˜µ

| é£é™© | å½±å“ | æ¦‚ç‡ | ç­‰çº§ | ç¼“è§£æªæ–½ |
|------|------|------|------|---------|
| ç¼“å­˜å‘½ä¸­ç‡ä¸‹é™ | é«˜ | ä¸­ | ğŸ”´ é«˜ | å……åˆ†çš„æµ‹è¯•éªŒè¯ï¼Œç›‘æ§å‘Šè­¦ |
| æ€§èƒ½å›å½’ | é«˜ | ä½ | ğŸŸ¡ ä¸­ | æ€§èƒ½åŸºå‡†æµ‹è¯•ï¼Œå‹åŠ›æµ‹è¯• |
| æ¶æ„å¤æ‚åº¦å¢åŠ  | ä¸­ | ä½ | ğŸŸ¢ ä½ | ä»£ç è¯„å®¡ï¼Œå®Œå–„æ–‡æ¡£ |
| å‘åå…¼å®¹æ€§ç ´å | é«˜ | ä½ | ğŸŸ¡ ä¸­ | ä¿ç•™å…¼å®¹çš„ Port æ¥å£ |
| æµ‹è¯•è¦†ç›–ä¸è¶³ | ä¸­ | ä½ | ğŸŸ¢ ä½ | ä¸¥æ ¼çš„æµ‹è¯•è¦æ±‚ |

### 8.2 ç¼“è§£ç­–ç•¥

#### 8.2.1 ç¼“å­˜å‘½ä¸­ç‡ç›‘æ§

```python
# ç›‘æ§æŒ‡æ ‡
expected_hit_rate = 0.80  # æœŸæœ›å‘½ä¸­ç‡ 80%

# å®æ—¶ç›‘æ§
actual_hit_rate = get_cache_hit_rate()

# å‘Šè­¦è§„åˆ™
if actual_hit_rate < expected_hit_rate * 0.9:  # ä½äºæœŸæœ›å€¼çš„ 90%
    send_alert(
        severity="warning",
        message=f"ç¼“å­˜å‘½ä¸­ç‡ {actual_hit_rate:.2%} < {expected_hit_rate * 0.9:.2%}"
    )
```

#### 8.2.2 æ€§èƒ½å›å½’æ£€æµ‹

```python
# æ€§èƒ½åŸºå‡†ï¼ˆåŸºäºè¿ç§»å‰çš„æµ‹é‡ï¼‰
baseline = {
    "p50_latency_ms": 100,
    "p95_latency_ms": 500,
    "p99_latency_ms": 1000,
}

# å®æ—¶ç›‘æ§
actual = get_current_latency()

# å‘Šè­¦è§„åˆ™ï¼ˆå…è®¸ 20% çš„æ³¢åŠ¨ï¼‰
if actual["p95"] > baseline["p95_latency_ms"] * 1.2:
    send_alert(
        severity="warning",
        message=f"P95 å»¶è¿Ÿ {actual['p95']}ms > {baseline['p95_latency_ms'] * 1.2}ms"
    )

# ä¸¥é‡å‘Šè­¦ï¼ˆè¶…è¿‡ 50%ï¼‰
if actual["p95"] > baseline["p95_latency_ms"] * 1.5:
    send_alert(
        severity="critical",
        message=f"P95 å»¶è¿Ÿä¸¥é‡æ¶åŒ–: {actual['p95']}ms",
        action="è€ƒè™‘å›æ»š"
    )
```

#### 8.2.3 é”™è¯¯ç‡ç›‘æ§

```python
# é”™è¯¯ç‡ç›‘æ§
max_error_rate = 0.01  # æœ€å¤§å…è®¸é”™è¯¯ç‡ 1%

actual_error_rate = get_error_rate()

if actual_error_rate > max_error_rate:
    send_alert(
        severity="critical",
        message=f"é”™è¯¯ç‡ {actual_error_rate:.2%} > {max_error_rate:.2%}",
        action="ç«‹å³æ£€æŸ¥æˆ–å›æ»š"
    )
```

---

## 9. æµ‹è¯•ç­–ç•¥

### 9.1 å•å…ƒæµ‹è¯•

#### 9.1.1 Port æ¥å£æµ‹è¯•

```python
# tests/domain/chat/ports/test_conversation_cache_port.py
import pytest
from domain.chat.ports.conversation_cache_port import ConversationCachePort

class MockCachePort(ConversationCachePort):
    """Mock å®ç°"""
    def __init__(self):
        self._cache = {}

    async def get(self, *, session_id, query, agent_type="default"):
        return self._cache.get((session_id, query))

    async def set(self, *, session_id, query, content, agent_type="default", metadata=None):
        self._cache[(session_id, query)] = CacheEntry(
            content=content,
            metadata=metadata or {},
            created_at=0,
            access_count=0,
            quality_score=0,
        )

    async def invalidate(self, *, session_id, query=None):
        if query:
            self._cache.pop((session_id, query), None)
        else:
            # æ¸…é™¤æ•´ä¸ªä¼šè¯
            keys_to_remove = [k for k in self._cache if k[0] == session_id]
            for key in keys_to_remove:
                self._cache.pop(key)

    async def mark_quality(self, *, session_id, query, is_positive, agent_type="default"):
        pass

    async def get_metrics(self, *, session_id=None):
        return {"hit_rate": 0.5}


@pytest.mark.asyncio
async def test_cache_miss():
    """æµ‹è¯•ç¼“å­˜æœªå‘½ä¸­"""
    port = MockCachePort()
    result = await port.get(session_id="test", query="hello")
    assert result is None

@pytest.mark.asyncio
async def test_cache_set_and_get():
    """æµ‹è¯•ç¼“å­˜è®¾ç½®å’Œè·å–"""
    port = MockCachePort()

    await port.set(
        session_id="test",
        query="hello",
        content={"answer": "world"}
    )

    result = await port.get(session_id="test", query="hello")
    assert result is not None
    assert result.content["answer"] == "world"

@pytest.mark.asyncio
async def test_cache_invalidation():
    """æµ‹è¯•ç¼“å­˜å¤±æ•ˆ"""
    port = MockCachePort()

    await port.set(
        session_id="test",
        query="hello",
        content={"answer": "world"}
    )

    # éªŒè¯ç¼“å­˜å­˜åœ¨
    result = await port.get(session_id="test", query="hello")
    assert result is not None

    # ä½¿ç¼“å­˜å¤±æ•ˆ
    await port.invalidate(session_id="test", query="hello")

    # éªŒè¯ç¼“å­˜å·²æ¸…é™¤
    result = await port.get(session_id="test", query="hello")
    assert result is None

@pytest.mark.asyncio
async def test_session_invalidation():
    """æµ‹è¯•ä¼šè¯çº§åˆ«ç¼“å­˜æ¸…é™¤"""
    port = MockCachePort()

    # è®¾ç½®å¤šä¸ªç¼“å­˜
    await port.set(session_id="test", query="q1", content={"answer": "a1"})
    await port.set(session_id="test", query="q2", content={"answer": "a2"})

    # æ¸…é™¤æ•´ä¸ªä¼šè¯
    await port.invalidate(session_id="test")

    # éªŒè¯æ‰€æœ‰ç¼“å­˜å·²æ¸…é™¤
    assert await port.get(session_id="test", query="q1") is None
    assert await port.get(session_id="test", query="q2") is None
```

#### 9.1.2 Service é€»è¾‘æµ‹è¯•

```python
# tests/application/chat/services/test_conversation_cache_service.py
import pytest
from unittest.mock import Mock, AsyncMock
from application.chat.services.conversation_cache_service import ConversationCacheService
from domain.chat.entities.rag_run import RagRunResult

@pytest.mark.asyncio
async def test_cache_hit():
    """æµ‹è¯•ç¼“å­˜å‘½ä¸­åœºæ™¯"""
    # Arrange
    mock_cache = Mock()
    mock_executor = Mock()

    # Mock ç¼“å­˜å‘½ä¸­
    mock_cache.get = AsyncMock(return_value={
        "content": {"answer": "cached answer"},
        "metadata": {},
        "created_at": 0,
        "access_count": 1,
        "quality_score": 3,
    })

    service = ConversationCacheService(
        cache_port=mock_cache,
        executor=mock_executor,
        enable_cache=True,
    )

    # Act
    result = await service.execute_with_cache(
        message="test query",
        session_id="test_session",
        kb_prefix="test_kb",
    )

    # Assert
    assert result["answer"] == "cached answer"
    mock_executor.run.assert_not_called()  # ä¸åº”è¯¥æ‰§è¡Œ RAG

@pytest.mark.asyncio
async def test_cache_miss():
    """æµ‹è¯•ç¼“å­˜æœªå‘½ä¸­åœºæ™¯"""
    # Arrange
    mock_cache = Mock()
    mock_executor = Mock()

    # Mock ç¼“å­˜æœªå‘½ä¸­
    mock_cache.get = AsyncMock(return_value=None)

    # Mock RAG æ‰§è¡Œ
    mock_executor.run = AsyncMock(return_value=(
        RagRunResult(
            answer="rag answer",
            reference=None,
            retrieval_results=None
        ),
        [],
    ))

    # Mock ç¼“å­˜è®¾ç½®
    mock_cache.set = AsyncMock()

    service = ConversationCacheService(
        cache_port=mock_cache,
        executor=mock_executor,
        enable_cache=True,
    )

    # Act
    result = await service.execute_with_cache(
        message="test query",
        session_id="test_session",
        kb_prefix="test_kb",
    )

    # Assert
    assert result["answer"] == "rag answer"
    mock_executor.run.assert_called_once()  # åº”è¯¥æ‰§è¡Œ RAG
    mock_cache.set.assert_called_once()  # åº”è¯¥å†™å…¥ç¼“å­˜

@pytest.mark.asyncio
async def test_cache_disabled():
    """æµ‹è¯•ç¦ç”¨ç¼“å­˜åœºæ™¯"""
    # Arrange
    mock_cache = Mock()
    mock_executor = Mock()

    # Mock RAG æ‰§è¡Œ
    mock_executor.run = AsyncMock(return_value=(
        RagRunResult(
            answer="rag answer",
            reference=None,
            retrieval_results=None
        ),
        [],
    ))

    service = ConversationCacheService(
        cache_port=mock_cache,
        executor=mock_executor,
        enable_cache=False,  # ç¦ç”¨ç¼“å­˜
    )

    # Act
    result = await service.execute_with_cache(
        message="test query",
        session_id="test_session",
        kb_prefix="test_kb",
    )

    # Assert
    assert result["answer"] == "rag answer"
    mock_cache.get.assert_not_called()  # ä¸åº”è¯¥æŸ¥è¯¢ç¼“å­˜
    mock_cache.set.assert_not_called()  # ä¸åº”è¯¥å†™å…¥ç¼“å­˜
    mock_executor.run.assert_called_once()  # åº”è¯¥æ‰§è¡Œ RAG

@pytest.mark.asyncio
async def test_mark_feedback():
    """æµ‹è¯•æ ‡è®°åé¦ˆ"""
    # Arrange
    mock_cache = Mock()
    mock_executor = Mock()

    mock_cache.mark_quality = AsyncMock()

    service = ConversationCacheService(
        cache_port=mock_cache,
        executor=mock_executor,
        enable_cache=True,
    )

    # Act
    await service.mark_feedback(
        session_id="test_session",
        query="test query",
        is_positive=True,
    )

    # Assert
    mock_cache.mark_quality.assert_called_once_with(
        session_id="test_session",
        query="test query",
        is_positive=True,
        agent_type="default",
    )
```

### 9.2 é›†æˆæµ‹è¯•

```python
# tests/integration/test_cache_integration.py
import pytest
import asyncio
from application.chat.services.conversation_cache_service import ConversationCacheService
from infrastructure.providers.cache.cache_manager_provider import CacheManagerProvider
from application.ports.rag_executor_port import RAGExecutorPort

class MockRAGExecutorPort:
    """Mock RAG æ‰§è¡Œå™¨"""
    async def run(self, plan, message, session_id, kb_prefix, debug):
        from domain.chat.entities.rag_run import RagRunResult

        # æ¨¡æ‹Ÿ RAG æ‰§è¡Œå»¶è¿Ÿ
        await asyncio.sleep(0.1)

        return (
            RagRunResult(
                answer=f"Answer for: {message}",
                reference="Mock reference",
                retrieval_results=None,
            ),
            [],
        )

@pytest.mark.asyncio
async def test_end_to_end_cache_flow():
    """ç«¯åˆ°ç«¯ç¼“å­˜æµç¨‹æµ‹è¯•"""
    # Arrange
    cache_provider = CacheManagerProvider(
        cache_dir="/tmp/test_cache",
        memory_max_size=10,
        disk_max_size=100,
    )
    executor = MockRAGExecutorPort()
    service = ConversationCacheService(
        cache_port=cache_provider,
        executor=executor,
        enable_cache=True,
    )

    # Act: ç¬¬ä¸€æ¬¡æŸ¥è¯¢ï¼ˆç¼“å­˜æœªå‘½ä¸­ï¼‰
    import time
    start = time.time()
    result1 = await service.execute_with_cache(
        message="ä»€ä¹ˆæ˜¯å¥–å­¦é‡‘ï¼Ÿ",
        session_id="test_user",
        kb_prefix="ecust",
    )
    time1 = time.time() - start

    # Act: ç¬¬äºŒæ¬¡æŸ¥è¯¢ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰
    start = time.time()
    result2 = await service.execute_with_cache(
        message="ä»€ä¹ˆæ˜¯å¥–å­¦é‡‘ï¼Ÿ",
        session_id="test_user",
        kb_prefix="ecust",
    )
    time2 = time.time() - start

    # Assert
    assert result1["answer"] == result2["answer"]  # ç­”æ¡ˆåº”è¯¥ç›¸åŒ
    assert time2 < time1  # ç¼“å­˜å‘½ä¸­åº”è¯¥æ›´å¿«

    # Act: è·å–æŒ‡æ ‡
    metrics = await service.get_cache_metrics(session_id="test_user")

    # Assert
    assert metrics["total_queries"] >= 2  # è‡³å°‘ 2 æ¬¡æŸ¥è¯¢
    assert metrics["hit_rate"] > 0  # åº”è¯¥æœ‰ç¼“å­˜å‘½ä¸­

@pytest.mark.asyncio
async def test_multi_session_isolation():
    """æµ‹è¯•å¤šä¼šè¯éš”ç¦»"""
    # Arrange
    cache_provider = CacheManagerProvider(
        cache_dir="/tmp/test_cache_isolation",
        memory_max_size=10,
        disk_max_size=100,
    )
    executor = MockRAGExecutorPort()
    service = ConversationCacheService(
        cache_port=cache_provider,
        executor=executor,
        enable_cache=True,
    )

    # Act: ç”¨æˆ· A æŸ¥è¯¢
    result_a = await service.execute_with_cache(
        message="æˆ‘çš„ä½™é¢æ˜¯å¤šå°‘ï¼Ÿ",
        session_id="user_a",
        kb_prefix="bank",
    )

    # Act: ç”¨æˆ· B æŸ¥è¯¢ç›¸åŒé—®é¢˜
    result_b = await service.execute_with_cache(
        message="æˆ‘çš„ä½™é¢æ˜¯å¤šå°‘ï¼Ÿ",
        session_id="user_b",
        kb_prefix="bank",
    )

    # Assert: ç­”æ¡ˆåº”è¯¥ç›¸åŒï¼Œä½†ç¼“å­˜åº”è¯¥éš”ç¦»
    assert result_a["answer"] == result_b["answer"]

    # è·å–æŒ‡æ ‡ï¼ˆåº”è¯¥åˆ†åˆ«ç»Ÿè®¡ï¼‰
    metrics_a = await service.get_cache_metrics(session_id="user_a")
    metrics_b = await service.get_cache_metrics(session_id="user_b")

    # éªŒè¯éš”ç¦»æ€§ï¼ˆè¿™é‡Œç®€åŒ–éªŒè¯ï¼‰
    assert metrics_a is not None
    assert metrics_b is not None
```

### 9.3 æ€§èƒ½æµ‹è¯•

```python
# tests/performance/test_cache_performance.py
import pytest
import time
import asyncio

@pytest.mark.asyncio
async def test_cache_performance():
    """ç¼“å­˜æ€§èƒ½æµ‹è¯•"""
    from application.chat.services.conversation_cache_service import ConversationCacheService
    from infrastructure.providers.cache.cache_manager_provider import CacheManagerProvider

    # ä½¿ç”¨çœŸå®çš„ç¼“å­˜ provider
    cache_provider = CacheManagerProvider(
        cache_dir="/tmp/test_cache_perf",
        memory_max_size=100,
        disk_max_size=1000,
    )

    # ä½¿ç”¨ mock executor
    class MockExecutor:
        async def run(self, plan, message, session_id, kb_prefix, debug):
            await asyncio.sleep(0.05)  # æ¨¡æ‹Ÿ RAG å»¶è¿Ÿ
            from domain.chat.entities.rag_run import RagRunResult
            return (
                RagRunResult(answer=f"Answer: {message}", reference=None, retrieval_results=None),
                [],
            )

    executor = MockExecutor()
    service = ConversationCacheService(
        cache_port=cache_provider,
        executor=executor,
        enable_cache=True,
    )

    # é¢„çƒ­ç¼“å­˜
    await service.execute_with_cache(
        message="test query",
        session_id="perf_test",
        kb_prefix="test_kb",
    )

    # æµ‹è¯•ç¼“å­˜å‘½ä¸­æ€§èƒ½
    iterations = 1000
    start = time.time()

    for _ in range(iterations):
        await service.execute_with_cache(
            message="test query",
            session_id="perf_test",
            kb_prefix="test_kb",
        )

    elapsed = time.time() - start

    # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
    avg_latency_ms = (elapsed / iterations) * 1000
    qps = iterations / elapsed

    print(f"\nç¼“å­˜æ€§èƒ½æµ‹è¯•ç»“æœ:")
    print(f"  æ€»è¿­ä»£æ¬¡æ•°: {iterations}")
    print(f"  æ€»è€—æ—¶: {elapsed:.2f}s")
    print(f"  å¹³å‡å»¶è¿Ÿ: {avg_latency_ms:.2f}ms")
    print(f"  QPS: {qps:.2f}")

    # Assert: éªŒè¯æ€§èƒ½è¦æ±‚
    assert avg_latency_ms < 10, f"å¹³å‡å»¶è¿Ÿ {avg_latency_ms:.2f}ms è¶…è¿‡ 10ms é˜ˆå€¼"
    assert qps > 100, f"QPS {qps:.2f} ä½äº 100 é˜ˆå€¼"

@pytest.mark.asyncio
async def test_concurrent_access():
    """å¹¶å‘è®¿é—®æµ‹è¯•"""
    from application.chat.services.conversation_cache_service import ConversationCacheService
    from infrastructure.providers.cache.cache_manager_provider import CacheManagerProvider

    cache_provider = CacheManagerProvider(
        cache_dir="/tmp/test_cache_concurrent",
        memory_max_size=100,
        disk_max_size=1000,
    )

    class MockExecutor:
        async def run(self, plan, message, session_id, kb_prefix, debug):
            await asyncio.sleep(0.01)
            from domain.chat.entities.rag_run import RagRunResult
            return (
                RagRunResult(answer=f"Answer: {message}", reference=None, retrieval_results=None),
                [],
            )

    executor = MockExecutor()
    service = ConversationCacheService(
        cache_port=cache_provider,
        executor=executor,
        enable_cache=True,
    )

    # å¹¶å‘æµ‹è¯•
    concurrency = 100
    requests_per_session = 10

    async def worker(session_id: str):
        for i in range(requests_per_session):
            await service.execute_with_cache(
                message=f"query_{i}",
                session_id=session_id,
                kb_prefix="test_kb",
            )

    # å¯åŠ¨å¹¶å‘ä»»åŠ¡
    start = time.time()

    tasks = [
        worker(f"session_{i % 10}")  # 10 ä¸ªä¸åŒä¼šè¯
        for i in range(concurrency)
    ]

    await asyncio.gather(*tasks)

    elapsed = time.time() - start

    print(f"\nå¹¶å‘è®¿é—®æµ‹è¯•ç»“æœ:")
    print(f"  å¹¶å‘æ•°: {concurrency}")
    print(f"  æ¯ä¼šè¯è¯·æ±‚æ•°: {requests_per_session}")
    print(f"  æ€»è€—æ—¶: {elapsed:.2f}s")
    print(f"  å¹³å‡ QPS: {(concurrency * requests_per_session) / elapsed:.2f}")

    # éªŒè¯æ²¡æœ‰é”™è¯¯
    assert True  # å¦‚æœæ²¡æœ‰æŠ›å‡ºå¼‚å¸¸ï¼Œè¯´æ˜å¹¶å‘å¤„ç†æ­£å¸¸
```

### 9.4 æµ‹è¯•è¦†ç›–ç‡è¦æ±‚

| æ¨¡å— | æœ€ä½è¦†ç›–ç‡ | æ¨èè¦†ç›–ç‡ |
|------|-----------|-----------|
| Port æ¥å£ | 80% | 90% |
| Service é€»è¾‘ | 85% | 95% |
| Provider é€‚é…å™¨ | 80% | 90% |
| é›†æˆæµ‹è¯• | è¦†ç›–å…³é”®åœºæ™¯ | è¦†ç›–æ‰€æœ‰åœºæ™¯ |
| æ€§èƒ½æµ‹è¯• | è¾¾åˆ°æ€§èƒ½æŒ‡æ ‡ | ä¼˜äºæ€§èƒ½æŒ‡æ ‡ 20% |

---

## 10. å›æ»šæ–¹æ¡ˆ

### 10.1 å›æ»šè§¦å‘æ¡ä»¶

| æ¡ä»¶ | é˜ˆå€¼ | åŠ¨ä½œ |
|------|------|------|
| ç¼“å­˜å‘½ä¸­ç‡ä¸‹é™ | > 15% | ç«‹å³å›æ»š |
| P95 å»¶è¿Ÿå¢åŠ  | > 30% | ç«‹å³å›æ»š |
| é”™è¯¯ç‡ä¸Šå‡ | > 1% | ç«‹å³å›æ»š |
| ç”¨æˆ·æŠ•è¯‰å¢åŠ  | > 10 ä¸ª/å°æ—¶ | ç«‹å³å›æ»š |
| ç³»ç»Ÿå´©æºƒ | N/A | ç«‹å³å›æ»š |

### 10.2 å›æ»šæ­¥éª¤

#### 10.2.1 å¿«é€Ÿå›æ»šï¼ˆä»£ç çº§ï¼‰

**æ—¶é—´**: < 5 åˆ†é’Ÿ

```bash
# 1. åˆ‡æ¢åˆ°å¤‡ä»½åˆ†æ”¯
git checkout backup/before-cache-migration

# 2. é‡æ–°éƒ¨ç½²
docker-compose down
docker-compose up -d

# æˆ– Kubernetes
kubectl rollout undo deployment/graphrag-agent
```

#### 10.2.2 é…ç½®çº§å›æ»š

**æ—¶é—´**: < 1 åˆ†é’Ÿ

```python
# å¦‚æœä¿ç•™äº†é…ç½®å¼€å…³ï¼Œå¯ä»¥é€šè¿‡é…ç½®å¿«é€Ÿåˆ‡æ¢
# backend/config/cache_config.py
CACHE_MIGRATION_ENABLED = False  # æ”¹ä¸º False

# æˆ–ç¯å¢ƒå˜é‡
# export CACHE_MIGRATION_ENABLED=false
```

#### 10.2.3 éªŒè¯å›æ»šæˆåŠŸ

```bash
# 1. æ£€æŸ¥æœåŠ¡çŠ¶æ€
curl http://localhost:8000/health

# 2. æ£€æŸ¥ç¼“å­˜å‘½ä¸­ç‡
curl http://localhost:8000/api/v1/cache/metrics

# 3. æ‰§è¡Œæµ‹è¯•æŸ¥è¯¢
curl -X POST http://localhost:8000/api/v1/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "test", "session_id": "test"}'

# 4. ç›‘æ§å…³é”®æŒ‡æ ‡
# - ç¼“å­˜å‘½ä¸­ç‡åº”æ¢å¤åˆ°è¿ç§»å‰æ°´å¹³
# - P95 å»¶è¿Ÿåº”æ¢å¤æ­£å¸¸
# - é”™è¯¯ç‡åº”æ¢å¤æ­£å¸¸
```

### 10.3 å›æ»šåæ£€æŸ¥æ¸…å•

- [ ] æœåŠ¡çŠ¶æ€æ­£å¸¸
- [ ] ç¼“å­˜å‘½ä¸­ç‡æ¢å¤åˆ°åŸºçº¿ï¼ˆÂ±5%ï¼‰
- [ ] å“åº”å»¶è¿Ÿæ¢å¤æ­£å¸¸ï¼ˆÂ±10%ï¼‰
- [ ] é”™è¯¯ç‡æ¢å¤æ­£å¸¸ï¼ˆ< 0.1%ï¼‰
- [ ] æ— æ–°å¢é”™è¯¯æ—¥å¿—
- [ ] ç”¨æˆ·æŠ•è¯‰åœæ­¢
- [ ] ç›‘æ§æŒ‡æ ‡æ­£å¸¸

### 10.4 å›æ»šååˆ†æ

å›æ»šåéœ€è¦è¿›è¡Œæ ¹å› åˆ†æï¼š

1. **æ”¶é›†æ—¥å¿—**
   ```bash
   # æ”¶é›†è¿ç§»æœŸé—´çš„æ—¥å¿—
   kubectl logs -l app=graphrag-agent --since=1h > migration_logs.txt
   ```

2. **åˆ†ææŒ‡æ ‡**
   - å¯¹æ¯”è¿ç§»å‰åçš„å…³é”®æŒ‡æ ‡
   - å®šä½æ€§èƒ½ä¸‹é™çš„å…·ä½“åŸå› 
   - åˆ†ææ˜¯å¦æœ‰ç¼“å­˜é€»è¾‘é”™è¯¯

3. **åˆ¶å®šä¿®å¤è®¡åˆ’**
   - æ ¹æ®åˆ†æç»“æœè°ƒæ•´å®ç°
   - è¡¥å……æµ‹è¯•ç”¨ä¾‹
   - é‡æ–°éªŒè¯åå†è¿ç§»

---

## 11. é…ç½®ç®¡ç†

### 11.1 ç¯å¢ƒå˜é‡

```bash
# .env

# ç¼“å­˜å¼€å…³
ENABLE_CACHE=true

# ç¼“å­˜é…ç½®
CACHE_DIR=./cache
CACHE_MODE=session  # session | user | global

# ç¼“å­˜å¤§å°
SESSION_CACHE_MEMORY_SIZE=200
SESSION_CACHE_DISK_SIZE=2000
GLOBAL_CACHE_MEMORY_SIZE=500
GLOBAL_CACHE_DISK_SIZE=5000

# ç›‘æ§
CACHE_METRICS_ENABLED=true
CACHE_ALERT_THRESHOLD_HIT_RATE=0.70
CACHE_ALERT_THRESHOLD_P95_MS=600
```

### 11.2 é…ç½®ç±»

**æ–‡ä»¶**: `backend/infrastructure/config/cache_config.py`

```python
from dataclasses import dataclass
from typing import Literal
import os


@dataclass(frozen=True)
class CacheConfig:
    """ç¼“å­˜é…ç½®"""

    # å¼€å…³
    enable_cache: bool = True

    # ç¼“å­˜æ¨¡å¼
    cache_mode: Literal["session", "user", "global"] = "session"

    # ç¼“å­˜ç›®å½•
    cache_dir: str = "./cache"

    # ä¼šè¯ç¼“å­˜
    session_cache_memory_size: int = 200
    session_cache_disk_size: int = 2000

    # å…¨å±€ç¼“å­˜
    global_cache_memory_size: int = 500
    global_cache_disk_size: int = 5000

    # ç›‘æ§
    cache_metrics_enabled: bool = True
    cache_alert_threshold_hit_rate: float = 0.70
    cache_alert_threshold_p95_ms: int = 600

    @classmethod
    def from_env(cls) -> "CacheConfig":
        """ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®"""
        return cls(
            enable_cache=os.getenv("ENABLE_CACHE", "true").lower() == "true",
            cache_mode=os.getenv("CACHE_MODE", "session"),
            cache_dir=os.getenv("CACHE_DIR", "./cache"),
            session_cache_memory_size=int(os.getenv("SESSION_CACHE_MEMORY_SIZE", "200")),
            session_cache_disk_size=int(os.getenv("SESSION_CACHE_DISK_SIZE", "2000")),
            global_cache_memory_size=int(os.getenv("GLOBAL_CACHE_MEMORY_SIZE", "500")),
            global_cache_disk_size=int(os.getenv("GLOBAL_CACHE_DISK_SIZE", "5000")),
            cache_metrics_enabled=os.getenv("CACHE_METRICS_ENABLED", "true").lower() == "true",
            cache_alert_threshold_hit_rate=float(os.getenv("CACHE_ALERT_THRESHOLD_HIT_RATE", "0.70")),
            cache_alert_threshold_p95_ms=int(os.getenv("CACHE_ALERT_THRESHOLD_P95_MS", "600")),
        )
```

---

## 12. ç›‘æ§ä¸å‘Šè­¦

### 12.1 ç›‘æ§æŒ‡æ ‡

```python
# ç¼“å­˜æ€§èƒ½æŒ‡æ ‡
CACHE_METRICS = {
    # å‘½ä¸­ç‡
    "cache_hit_rate": {
        "type": "gauge",
        "description": "ç¼“å­˜å‘½ä¸­ç‡",
        "labels": ["cache_type", "agent_type"],
    },

    # å»¶è¿Ÿ
    "cache_get_latency_ms": {
        "type": "histogram",
        "description": "ç¼“å­˜è·å–å»¶è¿Ÿ",
        "buckets": [1, 5, 10, 50, 100, 500, 1000],
    },

    # å®¹é‡
    "cache_size": {
        "type": "gauge",
        "description": "ç¼“å­˜å¤§å°",
        "labels": ["storage_type"],  # memory | disk
    },

    # è´¨é‡
    "cache_quality_score": {
        "type": "gauge",
        "description": "ç¼“å­˜è´¨é‡åˆ†æ•°",
        "labels": ["agent_type"],
    },
}
```

### 12.2 å‘Šè­¦è§„åˆ™

```yaml
# prometheus_alerts.yml
groups:
  - name: cache_alerts
    rules:
      - alert: LowCacheHitRate
        expr: cache_hit_rate < 0.7
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "ç¼“å­˜å‘½ä¸­ç‡è¿‡ä½"
          description: "ç¼“å­˜å‘½ä¸­ç‡ {{ $value }} < 70%"

      - alert: HighCacheLatency
        expr: histogram_quantile(0.95, cache_get_latency_ms) > 500
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "ç¼“å­˜å»¶è¿Ÿè¿‡é«˜"
          description: "P95 ç¼“å­˜å»¶è¿Ÿ {{ $value }}ms > 500ms"

      - alert: CacheCapacityHigh
        expr: cache_size{storage_type="memory"} / cache_max_size > 0.9
        for: 5m
        labels:
          severity: info
        annotations:
          summary: "å†…å­˜ç¼“å­˜å®¹é‡å‘Šè­¦"
          description: "å†…å­˜ç¼“å­˜ä½¿ç”¨ç‡ {{ $value }} > 90%"
```

---

## 13. é™„å½•

### 13.1 æœ¯è¯­è¡¨

| æœ¯è¯­ | å®šä¹‰ |
|------|------|
| CacheManager | ç°æœ‰çš„ç¼“å­˜ç®¡ç†å™¨å®ç°ï¼ˆä½äº `infrastructure/cache_manager`ï¼‰ |
| ConversationCacheService | æ–°çš„ä¼šè¯ç¼“å­˜æœåŠ¡ï¼ˆä½äº `application/chat/services`ï¼‰ |
| ConversationCachePort | ç¼“å­˜æ¥å£å®šä¹‰ï¼ˆä½äº `domain/chat/ports`ï¼‰ |
| CacheManagerProvider | CacheManager çš„é€‚é…å™¨ï¼ˆä½äº `infrastructure/providers/cache`ï¼‰ |
| ä¼šè¯ç¼“å­˜ | æŒ‰ `session_id` éš”ç¦»çš„ç¼“å­˜ï¼Œä¸Šä¸‹æ–‡æ„ŸçŸ¥ |
| å…¨å±€ç¼“å­˜ | è·¨ä¼šè¯å…±äº«çš„ç¼“å­˜ï¼Œç²¾ç¡® key å‘½ä¸­ |
| ä¸Šä¸‹æ–‡çª—å£ | ç”Ÿæˆç¼“å­˜é”®æ—¶è€ƒè™‘çš„å†å²å¯¹è¯è½®æ•° |
| è´¨é‡åˆ†æ•° | ç¼“å­˜é¡¹çš„è´¨é‡è¯„åˆ†ï¼ˆ-5 åˆ° +âˆï¼‰ |
| å¿«é€Ÿè·¯å¾„ | ä¼˜å…ˆè¿”å›é«˜è´¨é‡ç¼“å­˜çš„ä¼˜åŒ–è·¯å¾„ |

### 13.2 å‚è€ƒæ–‡æ¡£

- [è®°å¿†ç³»ç»Ÿæ–‡æ¡£](../../02-æ ¸å¿ƒæœºåˆ¶/02-æ ¸å¿ƒå­ç³»ç»Ÿ/è®°å¿†ç³»ç»Ÿ/README.md)
- [Phase 2 æ¶æ„è®¾è®¡](../02-æ¶æ„è®¾è®¡/phase2-architecture.md)
- [Hexagonal Architecture](https://alistair.cockburn.us/hexagonal-architecture/)
- [Domain-Driven Design](https://martinfowler.com/bliki/DomainDrivenDesign.html)

### 13.3 å˜æ›´æ—¥å¿—

| ç‰ˆæœ¬ | æ—¥æœŸ | ä½œè€… | å˜æ›´å†…å®¹ |
|------|------|------|---------|
| v1.0 | 2025-01-19 | System Architect | åˆå§‹ç‰ˆæœ¬ï¼ˆæ¸è¿›å¼è¿ç§»ï¼‰ |
| v2.0 | 2025-01-19 | System Architect | ä¿®æ”¹ä¸ºä¸€æ¬¡æ€§è¿ç§»æ–¹æ¡ˆ |

---

## 14. å®¡æ‰¹ä¸ç­¾å­—

| è§’è‰² | å§“å | ç­¾å­— | æ—¥æœŸ |
|------|------|------|------|
| æ¶æ„å¸ˆ | - | - | - |
| æŠ€æœ¯è´Ÿè´£äºº | - | - | - |
| äº§å“è´Ÿè´£äºº | - | - | - |
| QA è´Ÿè´£äºº | - | - | - |

---

**æ–‡æ¡£ç»“æŸ**
# âš ï¸ å·²å½’æ¡£ï¼šç¼“å­˜ç³»ç»Ÿè¿ç§»ä¸å†è¿›è¡Œï¼ˆå·²ç‰©ç†ä¸‹çº¿ï¼‰

æœ¬è®¾è®¡æ–‡æ¡£æè¿°çš„ CacheManager/provider è¿ç§»æ–¹æ¡ˆå¯¹åº”æ—§é˜¶æ®µçš„ç¼“å­˜ç³»ç»Ÿã€‚å½“å‰ç‰ˆæœ¬å·²å°†ç¼“å­˜ç³»ç»Ÿæ•´ä½“**ç‰©ç†ä¸‹çº¿**ï¼Œå¹¶ä»¥ Postgres æŒä¹…åŒ– + mem0 è®°å¿†ä½œä¸ºé—­ç¯åŸºç¡€ã€‚

å¦‚éœ€å›æº¯å†å²å†³ç­–å¯ç»§ç»­é˜…è¯»ï¼›ä½†è¯·å‹¿ä»¥æœ¬æ–‡æ¡£ä½œä¸ºç°è¡Œå®ç°ä¾æ®ã€‚
